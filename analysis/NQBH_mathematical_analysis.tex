\documentclass{article}
\usepackage[backend=biber,natbib=true,style=alphabetic,maxbibnames=50]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[utf8]{vietnam}
\DeclareUnicodeCharacter{00A0}{~}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,enumitem,float,graphicx,mathtools,tikz}
\usetikzlibrary{angles,calc,intersections,matrix,patterns,quotes,shadings}
\allowdisplaybreaks
\newtheorem{assumption}{Assumption}
\newtheorem{baitoan}{}
\newtheorem{cauhoi}{Câu hỏi}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{dangtoan}{Dạng toán}
\newtheorem{definition}{Definition}
\newtheorem{dinhly}{Định lý}
\newtheorem{dinhnghia}{Định nghĩa}
\newtheorem{example}{Example}
\newtheorem{ghichu}{Ghi chú}
\newtheorem{goal}{Goal}
\newtheorem{hequa}{Hệ quả}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{lemma}{Lemma}
\newtheorem{luuy}{Lưu ý}
\newtheorem{nhanxet}{Nhận xét}
\newtheorem{notation}{Notation}
\newtheorem{note}{Note}
\newtheorem{principle}{Principle}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{question}{Question}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{vidu}{Ví dụ}
\usepackage[left=1cm,right=1cm,top=5mm,bottom=5mm,footskip=4mm]{geometry}
\def\labelitemii{$\circ$}
\DeclareRobustCommand{\divby}{%
	\mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\title{Mathematical Analysis \& Numerical Analysis\\Giải Tích Toán Học \& Giải Tích Số}
\author{Nguyễn Quản Bá Hồng\footnote{A Scientist {\it\&} Creative Artist Wannabe. E-mail: {\tt nguyenquanbahong@gmail.com}. Bến Tre City, Việt Nam.}}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
	This text is a part of the series {\it Some Topics in Advanced STEM \& Beyond}:
	
	{\sc url}: \url{https://nqbh.github.io/advanced_STEM/}.
	
	Latest version:
	\begin{enumerate}
		\item {\it Mathematical Analysis -- Giải Tích Toán Học}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/analysis/NQBH_mathematical_analysis.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/analysis/NQBH_mathematical_analysis.tex}.
	\end{enumerate}
\end{abstract}
\tableofcontents

%------------------------------------------------------------------------------%

Tôi được giải Nhì Giải tích Olympic Toán Sinh viên 2014 (VMC2014) khi còn học năm nhất Đại học \& được giải Nhất Giải tích Olympic Toán Sinh viên 2015 (VMC2015) khi học năm 2 Đại học. Nhưng điều đó không có nghĩa là tôi giỏi Giải tích. Bằng chứng là 10 năm sau khi nhận các giải đó, tôi đang tự học lại Giải tích Toán học với hy vọng có 1 hay nhiều cách nhìn mới mẻ hơn \& mang tính ứng dụng hơn cho các đề tài cá nhân của tôi.

%------------------------------------------------------------------------------%

\section{Basic Analysis -- Giải Tích Cơ Bản}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Rudin1976}. {\sc Walter Rudin}. {\it Principles of Mathematical Analysis}.
	
	\item \cite{Tao_analysis_1}. {\sc Terence Tao}. {\it Analysis I}.
	
	\item \cite{Tao_analysis_2}. {\sc Terence Tao}. {\it Analysis II}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Real Analysis -- Giải Tích Thực}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{itemize}
	\item \cite{Rudin1987}. {\sc Walter Rudin}. {\it Real \& Complex Analysis}.
	
	{\sf Preface.} This book contains a 1st-year graduate course in which basic techniques \& theorems of analysis are presented in such a way that intimate connections between its various branches are strongly emphasized. Traditionally separate subjects of ``real analysis'' \& ``complex analysis'' are thus united; some of basic ideas from functional analysis are also included.
	
	Some examples of way in which these connections are demonstrated \& exploited: Riesz representation theorem \& Hahn--Banach theorem allow one to ``guess'' Poisson integral formula. They team up in proof of Runge's theorem. They combine with Blaschke's theorem on zeros of bounded holomorphic functions to give a proof of M\"untz--Szasz theorem, which concerns approximation on an interval. Fact $L^2$ is a Hilbert space is used in proof of Radon--Nikodym theorem, which leads to theorem about differentiation of indefinite integrals, which in turn yields existence of radial limits of bounded harmonic functions. Theorems of Plancherel \& Cauchy combined give a theorem of Paley \& Wiener which, in turn, is used in Denjoy-Carleman theorem about infinitely differentiable functions on real line. Maximum modulus theorem gives information about linear transformations on $L^p$-spaces.
	
	Since most of results presented here are quite classical (novelty lies in arrangement, \& some of proofs are new), I have not attempted to document source of every item. Refs are gathered at end, in Notes \& Comments. They are not always to original sources, but more often to more recent works where further refs can be found. In no case does absence of a ref imply any claim to originality on my part.
	
	Prerequisite for this book: a good course in advanced calculus (settheoretic manipulation, metric spaces, uniform continuity, \& uniform convergence). 1st 7 chaps of \cite{Rudin1973,Rudin1976} furnish sufficient preparation.
	
	1st 15 chaps should be taken up in order in which they are presented, except for Chap. 9, which can be postponed.
	
	Most important difference between 3e \& previous ones: entirely new chap on differentiation. Basic facts about differentiation are now derived from existence of Lebesgue points, which in turn is an easy consequence of so-called ``weak type'' inequality that is satisfied by maximal functions of measures on euclidean spaces. This approach yields \fbox{strong theorems with minimal effort}. Even more important: familiarize students with maximal functions, since these have become increasingly useful in several areas of analysis.
	
	Study of boundary behavior of Poisson integrals. A related one concerns $H^p$-spaces. Accordingly, large parts of Chaps. 11 \& 17 were rewritten simplified in process.
	
	{\sc Rudin} has also made several smaller changes in order to improve certain details: e.g., parts of Chap. 4 have been simplified; notions of equi-continuity \& weak convergence are presented in more detail; boundary behavior of conformal maps is studied by means of Lindell\"of's theorem about asymptotic valued of bounded holomorphic functions in a disc.
	
	{\sf Prologue: Exponential Function.} Most important function in mathematics, defined $\forall z\in\mathbb{C}$, by formula $\exp(z) = \sum_{n=0}^\infty \frac{z^n}{n!}$. This series converges absolutely for every $z$ \& converges uniformly on every bounded subset of complex plane. Thus $\exp$ is a continuous function. Important addition formula $\exp(a)\exp(b) = \exp(a + b)$ valid $\forall a,b\in\mathbb{C}$. Define $e\coloneqq\exp(1)$, usually replace $\exp(z)$ by customary shorter expression $e^z$. $e^0 = \exp(0) = 1$.
	
	\begin{theorem}
		(a) $e^z\ne0,\forall z\in\mathbb{C}$. (b) $\exp$ is its own derivative: $\exp'(z) = \exp(z)$. (c) Restriction of $\exp$ to real axis is a monotonically increasing positive function \& $e^x\to\infty$ as $x\to\infty$, $e^x\to0$ as $x\to-\infty$. (d) There exists a positive number $\pi$ s.t. $e^{\pi i/2} = i$ \& s.t. $e^z = 1$ iff $\frac{z}{2\pi i}\in\mathbb{Z}$. (e) $\exp$ is a periodic function, with period $2\pi i$. (f) Mapping $t\to e^{it}$ maps real axis onto unit circle. (g) If $w$ is a complex number \& $w\ne0$, then $w = e^z$ for some $z$.
	\end{theorem}
	Encounter integral of $\frac{1}{1 + x^2}$ over $\mathbb{R}$. To evaluate it, put $\varphi(t) = \frac{\sin t}{\cos t}$ in $(-\frac{\pi}{2},\frac{\pi}{2})$, $\varphi' = 1 + \varphi^2$. Hence $\varphi$ is a monotonically increasing mapping of $(-\frac{\pi}{2},\frac{\pi}{2})$ onto $\mathbb{R}$, \& obtain $\int_\mathbb{R} \frac{dx}{1 + x^2} = \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \frac{\varphi'(t)\,{\rm d}t}{1 + \varphi^2(t)} = \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} {\rm d}t = \pi$.
	\begin{itemize}
		\item {\sf Chap. 1. Abstract Integration.}
		\begin{itemize}
			\item {\sf Set-theoretic notations \& terminology.}
			\item {\sf Concept of measurability.}
			\item {\sf Simple functions.}
			\item {\sf Elementary properties of measures.}
			\item {\sf Arithmetic in $[0,\infty]$.}
			\item {\sf Integration of positive functions.}
			\item {\sf Integration of complex functions.}
			\item {\sf Role played by sets of measure 0.}
		\end{itemize}
		\item {\sf Chap. 2. Positive Borel Measures.}
		\begin{itemize}
			\item {\sf Vector spaces.}
			\item {\sf Topological preliminaries.}
			\item {\sf Riesz representation theorem.}
			\item {\sf Regularity properties of Borel measures.}
			\item {\sf Lebesgue measure.}
			\item {\sf Continuity properties of measurable functions.}
		\end{itemize}
		\item {\sf Chap. 3. $L^p$-Spaces.}
		\begin{itemize}
			\item {\sf Convex functions \& inequalities.}
			\item {\sf$L^p$-spaces.}
			\item {\sf Approximation by continuous functions.}
		\end{itemize}
		\item {\sf Chap. 4. Elementary Hilbert Space Theory.}
		\begin{itemize}
			\item {\sf Inner products \& linear functionals.}
			\item {\sf Orthonormal sets.}
			\item {\sf Trigonometric series.}
		\end{itemize}
		\item {\sf Chap. 5. Examples of Banach Space Techniques.}
		\begin{itemize}
			\item {\sf Banach spaces.}
			\item {\sf Consequences of Baire's theorem.}
			\item {\sf Fourier coefficients of $L^1$-functions.}
			\item {\sf Hahn--Banach theorem.}
			\item {\sf An abstract approach to Poisson integral.}
		\end{itemize}
		\item {\sf Chap. 6. Complex Measures.}
		\begin{itemize}
			\item {\sf Total variation.}
			\item {\sf Absolute continuity.}
			\item {\sf Consequences of Radon--Nikodym theorem.}
			\item {\sf Bounded linear functionals on $L^p$.}
			\item {\sf Riesz representation theorem.}
		\end{itemize}
		\item {\sf Chap. 7. Differentiation.}
		\begin{itemize}
			\item {\sf Derivatives of measures.}
			\item {\sf Fundamental theorem of Calculus.}
			\item {\sf Differentiable transformations.}
		\end{itemize}
		\item {\sf Chap. 8. Integration on Product Spaces.}
		\begin{itemize}
			\item {\sf Measurability on cartesian products.}
			\item {\sf Product measures.}
			\item {\sf Fubini theorem.}
			\item {\sf Completion of product measures.}
			\item {\sf Convolutions.}
			\item {\sf Distribution functions.}
		\end{itemize}
		\item {\sf Chap. 9. Fourier Transforms.}
		\begin{itemize}
			\item {\sf Formal properties.}
			\item {\sf Inversion theorem.}
			\item {\sf Plancherel theorem.}
			\item {\sf Banach algebra $L^1$.}
		\end{itemize}
		\item {\sf Chap. 10. Elementary Properties of Holomorphic Functions.}
		\begin{itemize}
			\item {\sf Complex differentiation.}
			\item {\sf Integration over paths.}
			\item {\sf Local Cauchy theorem.}
			\item {\sf Power series representation.}
			\item {\sf Open mapping theorem.}
			\item {\sf Global Cauchy theorem.}
			\item {\sf Calculus of residues.}
		\end{itemize}
		\item {\sf Chap. 11. Harmonic Functions.}
		\begin{itemize}
			\item {\sf Cauchy--Riemann equations.}
			\item {\sf Poisson integral.}
			\item {\sf Mean value property.}
			\item {\sf Boundary behavior of Poisson integrals.}
			\item {\sf Representation theorems.}
		\end{itemize}
		\item {\sf Chap. 12. Maximum Modulus Principle.}
		\begin{itemize}
			\item {\sf Introduction.}
			\item {\sf Schwarz lemma.}
			\item {\sf Phragmen--Lindel\"of method.}
			\item {\sf An interpolation theorem.}
			\item {\sf A converse of maximum modulus theorem.}
		\end{itemize}
		\item {\sf Chap. 13. Approximation by Rational Functions.}
		\begin{itemize}
			\item {\sf Preparation.}
			\item {\sf Runge's theorem.}
			\item {\sf Mittag--Leffler theorem.}
			\item {\sf Simply connected regions.}
		\end{itemize}
		\item {\sf Chap. 14. Conformal Mapping.}
		\begin{itemize}
			\item {\sf Preservation of angles.}
			\item {\sf Linear fractional transformations.}
			\item {\sf Normal families.}
			\item {\sf Riemann mapping theorem.}
			\item {\sf Class ${\cal S}$.}
			\item {\sf Continuity at boundary.}
			\item {\sf Conformal mapping of an annulus.}
		\end{itemize}
		\item {\sf Chap. 15. Zeros of Holomorphic Functions.}
		\begin{itemize}
			\item {\sf Infinite products.}
			\item {\sf Weierstrass factorization theorem.}
			\item {\sf An interpolation problem.}
			\item {\sf Jensen's formula.}
			\item {\sf Blaschke products.}
			\item {\sf M\"untz--Szasz theorem.}
		\end{itemize}
		\item {\sf Chap. 16. Analytic Continuation.}
		\begin{itemize}
			\item {\sf Regular points \& singular points.}
			\item {\sf Continuation along curves.}
			\item {\sf Monodromy theorem.}
			\item {\sf Construction of a modular function.}
			\item {\sf Picard theorem.}
		\end{itemize}
		\item {\sf Chap. 17. $H^p$-Spaces.}
		\begin{itemize}
			\item {\sf Subharmonic functions.}
			\item {\sf Spaces $H^p$ \& $N$.}
			\item {\sf Theorem of F. \& M. Riesz.}
			\item {\sf Factorization theorems.}
			\item {\sf Shift operator.}
			\item {\sf Conjugate functions.}
		\end{itemize}
		\item {\sf Chap. 18. Elementary Theory of Banach Algebras.}
		\begin{itemize}
			\item {\sf Introduction.}
			\item {\sf Invertible elements.}
			\item {\sf Ideals \& homomorphisms.}
			\item {\sf Applications.}
		\end{itemize}
		\item {\sf Chap. 19. Holomorphic Fourier Transforms.}
		\begin{itemize}
			\item {\sf Introduction.}
			\item {\sf2 theorems of Paley \& Wiener.}
			\item {\sf Quasi-analytic classes.}
			\item {\sf Denjoy--Carleman theorem.}
		\end{itemize}
		\item {\sf Chap. 20. Uniform Approximation by Polynomials.}
		\begin{itemize}
			\item {\sf Introduction.}
			\item {\sf Some lemmas.}
			\item {\sf Mergelyan's theorem.}
		\end{itemize}
		\item {\sf Appendix: Hausdorff's Maximality Theorem.}
		\item {\sf Notes \& Comments.}
	\end{itemize}
\end{itemize}

%------------------------------------------------------------------------------%

\section{Complex Analysis -- Giải Tích Phức}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{itemize}
	\item \cite{Gamelin2001}. {\sc Theodore W. Gamelin}. {\it Complex Analysis}.
	
	\item \cite{Rudin1987}. {\sc Walter Rudin}. {\it Real \& Complex Analysis}.
\end{itemize}

%------------------------------------------------------------------------------%

\section{Numerical Analysis}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Atkinson_Han2009}. {\sc Kendall Atkinson, Weimin Han}. {\it Theoretical Numerical Analysis: A Functional Analysis Framework}.
	
	{\sf Series Preface.} Mathematics is playing an ever more important role in physical \& biological sciences, provoking a blurring of boundaries between scientific disciplines \& a resurgence of interest in modern as well as classical techniques of applied mathematics. This renewal of interest, both in research \& teaching, has led to establishment of series: {\it Texts in Applied Mathematics (TAM)}.
	
	Development of new courses is a natural consequence of a high level of excitement on research frontier as newer techniques, e.g. numerical \& symbolic computer systems, dynamical systems, \& chaos, mix with \& reinforce traditional methods of applied mathematics. thus, purpose of this textbook series is to meet current \& future needs of these advances \& to encourage teaching of new courses.
	
	TAM will publish textbooks suitable for use in advanced undergraduate \& beginning graduate courses, \& will complement {\it Applied Mathematical Sciences (AMS)} series, which will focus on advanced textbooks \& research-level monographs.
	
	{\sf Preface.} This textbook has grown out of course which we teach periodically at University of Iowa. Have beginning graduate students in mathematics who wish to work in numerical analysis from a theoretical perspective, \& they need a background in those ``tools of the trade''. In the past, such students would ordinarily begin with a 1-year course in {\it real \& complex analysis}, followed by a 1 or 2 semester course in {\it functional analysis} \& possibly a graduate  level course in {\it ODEs, PDEs}, or {\it integral equations}. Still expect students to take most of these standard courses. The course based on this book allows these students to move more rapidly into a research program.
	
	Textbook covers basic results of functional analysis, approximation theory, Fourier analysis \& wavelets, calculus \& iteration methods for nonlinear equations, FDMs, Sobolev spaces \& weak formulations of BVPs, FEMs, elliptic variational inequalities \& their numerical solution, numerical methods for solving integral equations of 2nd kind, boundary integral equations for planar regions with a smooth boundary curve, \& multivariable polynomial approximations. Presentation of each topic is meant to be an introduction with a certain degree of depth. Comprehensive references on a particular topic are listed at end of each chapter for further reading \& study. For 3e, add a chapter on multivariable polynomial approximation \& revise numerous sections from 2e to varying degrees. Include a good number of new exercises.
	
	Material in text is presented in a mixed manner. Some topics are treated with complete rigor, whereas others are simply presented without proof \& perhaps illustrated (e.g. principle of uniform boundedness). Have chosen to avoid introducing a formalized framework for {\it Lebesgue measure \& integration} \& also for {\it distribution theory}. Instead use standard results on completion of normed spaces \& unique extension of densely defined bounded linear operators. This permits us to introduce Lebesgue spaces formally \& without their concrete realization using measure theory. Describe some of standard material on measure theory \& distribution theory in an intuitive manner, believing this is sufficient for much of subsequent mathematical development. In addition, give a number of deeper results without proof, citing the existing literature. Examples of this are the {\it open mapping theorem, Hahn--Banach theorem, principle of uniform boundedness}, \& a number of results on {\it Sobolev spaces}.	
	\begin{itemize}
		\item {\sf1. Linear Spaces.}
		\begin{itemize}
			\item {\sf Linear spaces.}
			\item {\sf Normed spaces.}
			\item {\sf Inner product spaces.}
			\item {\sf Spaces of continuously differentiable functions.}
			\item {\sf$L^p$ spaces.}
			\item {\sf Compact sets.}
		\end{itemize}
		\item {\sf2. Linear Operators on Normed Spaces.}
		\begin{itemize}
			\item {\sf Operators.}
			\item {\sf Continuous linear operators.}
			\item {\sf Geometric series theorem \& its variants.}
			\item {\sf Some more results on linear operators.}
			\item {\sf Linear functionals.}
			\item {\sf Adjoint operators.}
			\item {\sf Weak convergence \& weak compactness.}
			\item {\sf Compact linear operators.}
			\item {\sf Resolvent operator.}
		\end{itemize}
		\item {\sf3. Approximation Theory.}
		\begin{itemize}
			\item {\sf Approximation of continuous functions by polynomials.}
			\item {\sf Interpolation theory.}
			\item {\sf Best approximation.}
			\item {\sf Best approximations in inner product spaces, projection on closed convex sets.}
			\item {\sf Orthogonal polynomials.}
			\item {\sf Projection operators.}
			\item {\sf Uniform error bounds.}
		\end{itemize}
		\item {\sf4. Fourier Analysis \& Wavelets.}
		\begin{itemize}
			\item {\sf Fourier series.}
			\item {\sf Fourier transform.}
			\item {\sf Discrete Fourier transform.}
			\item {\sf Haar wavelets.}
			\item {\sf Multiresolution analysis.}
		\end{itemize}
		\item {\sf5. Nonlinear Equations \& Their Solution by Iteration.}
		\begin{itemize}
			\item {\sf Banach fixed-point theorem.}
			\item {\sf Applications to iterative methods.}
			\item {\sf Differential calculus for nonlinear operators.}
			\item {\sf Newton's method.}
			\item {\sf Completely continuous vector fields.}
			\item {\sf Conjugate gradient method for operator equations.}
		\end{itemize}
		\item {\sf6. FDM.}
		\begin{itemize}
			\item {\sf Finite difference approximations.}
			\item {\sf Lax equivalence theorem.}
			\item {\sf More on convergence.}
		\end{itemize}
		\item {\sf7. Sobolev Spaces.}
		\begin{itemize}
			\item {\sf Weak derivatives.}
			\item {\sf Sobolev spaces.}
			\item {\sf Properties.}
			\item {\sf Characterization of Sobolev spaces via Fourier transform.}
			\item {\sf Periodic Sobolev spaces.}
			\item {\sf Integration by parts formulas.}
		\end{itemize}
		\item {\sf8. Weak Formulations of Elliptic BVPs.}
		\begin{itemize}
			\item {\sf A model BVP.}
			\item {\sf Some general results on existence \& uniqueness.}
			\item {\sf Lax--Milgram lemma.}
			\item {\sf Weak formulations of linear elliptic BVPs.}
			\item {\sf A BVP of linearized elasticity.}
			\item {\sf Mixed \& dual formulations.}
			\item {\sf Generalized Lax--Milgram lemma.}
			\item {\sf A nonlinear problem.}
		\end{itemize}
		\item {\sf9. Galerkin Method \& Its Variants.}
		\begin{itemize}
			\item {\sf Galerkin method.}
			\item {\sf Petrov--Galerkin method.}
			\item {\sf Generalized Galerkin method.}
			\item {\sf Conjugate gradient method: variational formulation.}
		\end{itemize}
		\item {\sf10. Finite Element Analysis.}
		\begin{itemize}
			\item {\sf1D examples.}
			\item {\sf Basics of FEM.}
			\item {\sf Error estimates of finite element interpolations.}
			\item {\sf Convergence \& error estimates.}
		\end{itemize}
		\item {\sf11. Elliptic Variational Inequalities \& Their Numerical Approximations.}
		\begin{itemize}
			\item {\sf From variational equations to variational inequalities.}
			\item {\sf Existence \& uniqueness based on convex minimization.}
			\item {\sf Existence \& uniqueness results for a family of EVIs.}
			\item {\sf Numerical approximations.}
			\item {\sf Some contact problems in elasticity.}
		\end{itemize}
		\item {\sf12. Numerical Solution of Fredholm Integral Equations of 2nd Kind.}
		\begin{itemize}
			\item {\sf Projection methods: General theory}
			\item {\sf Examples.}
			\item {\sf Iterated projection methods.}
			\item {\sf Nystr\"om method.}
			\item {\sf Product integration.}
			\item {\sf Iteration methods.}
			\item {\sf Projection methods for nonlinear equations.}
		\end{itemize}
		\item {\sf13. Boundary Integral Equations.} In Chap. 10, examined FEMs for numerical solution of Laplace's equation. Propose an alternative approach. Introduce idea of reformulating Laplace's equation as a {\it boundary integral equation} (BIE), \& then consider numerical solution of Laplace's equation by numerically solving its reformulation as a BIE. Some of most important BVPs for elliptic PDEs have been studied \& solved numerically by this means; \& depending on requirements of problem, use of BIE reformulations may be the most efficient means of solving these problems. Examples of other equations solved by use of BIE reformulations are Helmholtz equation $\Delta u + \lambda u = 0$ \& biharmonic equation $\Delta^2u = 0$. Consider use of boundary integral equations in solving only planar problems for Laplace's equation. For domain $D$ for equation, restrict it or its complement to be a simply-connected set with a smooth boundary $S$. Most of results \& methods given here will generalize to other equations, e.g., Helmholtz's equation. Use notation popular in literature on boundary integral equations.
		\begin{itemize}
			\item {\sf Boundary integral equations.} contain a theoretical framework for BIE reformulations of Laplace's equation in $\mathbb{R}^2$, giving most popular of such boundary integral equations. For much of history of BIE, those of 2nd kind have been most popular; this includes work of {\sc Ivar Fredholm, Carl Neumann, David Hilbert}, \& others in late 1800s \& early 1900s. Let $D$ be a bounded open simply-connected region in plane, \& denote its boundary by $S$. At a point $P\in S$, let ${\bf n}_P$ denote inner unit normal to $S$. Restate principal BVPs of interest when solving Laplace's equation on $D$.
			
			\begin{problem}[Interior Dirichlet problem]
				Find $u\in C(\overline{D})\cap C^2(D)$ that satisfies
				\begin{equation}
					\label{interior Dirichlet prob}
					\left\{\begin{split}
						\Delta u(P) &= 0&&P\in D,\\
						u(P) &= f(P)&&P\in S,
					\end{split}\right.
				\end{equation}
				with $f\in C(S)$ a given boundary function.
			\end{problem}
			
			\begin{problem}[Interior Neumann problem]
				Find $u\in C^1(\overline{D})\cap C^2(D)$ that satisfies
				\begin{equation}
					\label{interior Neumann prob}
					\left\{\begin{split}
						\Delta u(P) &= 0&&P\in D,\\
						u(P) &= f(P)&&P\in S,
					\end{split}\right.
				\end{equation}
				with $f\in C(S)$ a given boundary function.
			\end{problem}
			Another important BVP is that with a mixture of Neumann \& Dirichlet boundary conditions on different sections of boundary, or perhaps some combination of them. Techniques introduced here can also be used to study \& solve such mixed BVPs, but omit any such discussion here. Corresponding to interior Dirichlet \& Neumann problems given, there are corresponding exterior problems. Functions satisfying Laplace's equation are often called {\it harmonic functions}. Study of Laplace's equation is often referred to as {\it potential theory}, since many applications involve finding a potential function $u$ in order to construct a conservative vector field $\nabla u$. A theorem summarizing main results on solvability of above BVPs:
			
			\begin{theorem}
				Let the function $f\in C(S)$; \& assume $S$ can be parameterized by a twice continuously differentiable function. Then:
				\item[(i)] The Dirichlet problem \eqref{interior Dirichlet prob} has a unique solution.
				\item[(ii)] The Neumann problem \eqref{interior Neumann prob} has a unique solution, up to the addition of an arbitrary constant, provided $\int_S f(Q)\,{\rm d}S = 0$.
			\end{theorem}
			
			\begin{itemize}
				\item {\sf Green's identities \& representation formula.} A very important tool for studying elliptic PDEs: {\it divergence theorem} or {\it Gauss's theorem} (Prop. 7.6.1) but restate it in the form needed for planar Laplace equation, a form usually called {\it Green's theorem}. State result for regions $\Omega$ that are not simply-connected \& whose boundaries need not be smooth. Need this form when proving Green's representation formula.
			\end{itemize}
			
			\item {\sf Boundary integral equations of 2nd kind.} Discuss numerical solution of such BIE of 2nd kind.
			\item {\sf A boundary integral equation of 1st kind.} Introduce briefly study of BIE of 1st kind, \& discuss use of Fourier series as a means of studying these equations \& numerical methods for their solution.
		\end{itemize}
		\item {\sf14. Multivariable Polynomial Approximations.}
		\begin{itemize}
			\item {\sf Notation \& best approximation results.}
			\item {\sf Orthogonal polynomials.}
			\item {\sf Hyperinterpolation.}
			\item {\sf A Galerkin method for elliptic equations.}
		\end{itemize}
	\end{itemize}
	
	\item \cite{Burden_Faires_Burden2015}. {\sc Richard L. Burden, J. Douglas Faires, Annette M. Burden}. {\it Numerical Analysis}.
	
	\item \cite{Isaacson_Keller1994}. {\sc Eugene Isaacson, Herbert Bishop Keller}. {\it Analysis of Numerical Methods}.
	
	{\sf Preface.} There have been great changes in computing equipment \& in development of numerical methods, however, the analysis required to understand \& to devise new methods has not changed. To the list of important topics omitted in original edition (namely, linear programming, rational approximation, \& Monte Carlo) must now add fast transforms, FEs, wavelets, complexity theory, multigrid methods, adaptive gridding, path following, \& parallel algorithms. Hopefully, some energetic young numerical analyst will incorporate all these missing topics into an updated version to aid the burgeoning field of scientific computing.
	
	Digital computers, though mass produced for $\le15$ years, have become indispensable for much current scientific research. 1 basic reason: by implementing numerical methods, computers form a universal tool for ``solving'' broad classes of problems. While numerical methods have always been useful, clear: their role in scientific research is now of fundamental importance. No modern applied mathematician, physical scientist, or engineer can be properly trained without some understanding of numerical methods.
	
	Authors attempt, in this book, to supply some of required knowledge. In presenting material, stress techniques for development of new methods. This requires knowing why a particular method is effective on some problems but not on others. Hence led to analysis of numerical methods rather than merely their description \& listing.
	
	Certainly solving of scientific problems should not be \& is not sole motivation for studying numerical methods. Analysis of numerical methods is a broad \& challenging mathematical activity whose central theme is \fbox{effective constructibility} of various kinds of approximations.
	
	Many numerical methods have been neglected in this book since do not attempt to be exhaustive. Procedures treated are either quite good \& efficient by present standards or else their study is considered instructive (while their use may not be advocated). Unfortunately limitations of space \& our own experience have resulted in omission of many important topics that we would have liked to include, e.g., linear programming, rational approximation, Monte Carlo methods.
	
	The present work, it turns out, could be considered a mathematics text in selected areas of analysis \& matrix theory. Essentially no mathematical preparation beyond advanced calculus \& elementary linear algebra (or matrix theory) is assumed. Relatively important material on norms in finite-dimensional spaces, not taught in most elementary courses, is included in Chap. 1. Some familiarity with existence theory for differential equations would be useful, but is not necessary. A cursory knowledge of the classical PDEs of mathematical physics would help in Chap. 9. No significant use is made of theory of functions of a complex variable \& our book is elementary in that sense. Deeper results of numerical methods would also rely heavily on functional analysis, avoided here.
	
	The listing of algorithms to concretely describe a method is avoided. Hence some practical experience in using numerical methods is assumed or should be obtained. Examples \& problems are given which extend or amplify the analysis in many cases (starred problems are more difficult). Assumed: instructor will supplement these with computational problems, according to availability of computing facilities.	
	\begin{itemize}
		\item {\sf Chap. 1: Norms, Arithmetic, \& Well-Posed Computations.}
		\begin{itemize}
			\item {\sf Introduction.} Treat 3 topics generally useful for analysis of various numerical methods studied throughout the book. Sect. 1: give elements of theory of {\it norms} of finite dimensional vectors \& matrices. This subject properly belongs to field of {\it linear algebra}. In later chaps, may occasionally employ notion of norm of a function: a straightforward extension of notion of a vector norm to infinite-dimensional case. Won't introduce corresponding natural generalization, i.e., notion of norm of a linear transformation acting on a space of functions. Such ideas are dealt with in {\it functional analysis}, \& might profitably be used in a more sophisticated study of numerical methods. Sect. 2: study briefly practical problem of effect of rounding errors on basic operations of arithmetic. Except for calculations involving only exact-integer arithmetic, rounding errors are invariably present in any computation. A most important feature of later analysis of numerical methods: incorporation of a treatment of effects of such rounding errors. Sect. 3: describe computational problems ``reasonable'' in some general sense. In effect, a numerical method which produces a solution insensitive to small changes in data or to rounding errors is said to yield a {\it well-posed computation}. How to determine the sensitivity of a numerical procedure is dealt with in special cases throughout the book. Indicate heuristically that: \fbox{any {\it convergent} algorithm is a well-posed computation}.
			\item {\sf Norms of vectors \& matrices.} Assume: reader familiar with basic theory of linear algebra, not necessarily in its abstract setting, but at least with specific reference to finite-dimensional linear vector spaces over the field of complex scalars. By ``basic theory'' we of course include: theory of linear systems of equations, some elementary theory of determinants, \& theory of matrices or linear transformations to about Jordan normal form. Hardly employ Jordan form in present study. In fact a much weaker result can frequently be used in its place (when the divisor theory or invariant subspaces are not actually involved). 
			
			\begin{theorem}
				For any square matrix $A$ of order $n$ there exists a nonsingular matrix $P$, of order $n$, s.t. $B = P^{-1}AP$ is upper triangular \& has the eigenvalues of $A$, say $\lambda_i\coloneqq\lambda_i(A)$, $i = 1,\ldots,n$, on the principal diagonal (i.e., any square matrix is equivalent to a triangular matrix).
			\end{theorem}
			\item {\sf Floating-point arithmetic \& rounding errors.} Will have to refer, on occasion, to the errors due to ``rounding'' in basic arithmetic operations. Such errors are inherent in all computations in which only a fixed number of digits are retained. This is, of course, the case with all modern digital computers \& consider here an example of 1 way in which many of them do or can do arithmetic: {\it floating-point arithmetic}. Although most electronic computers operate with numbers in some kind of binary representation, most humans still think in terms of a decimal representation \& so will employ the later here.
			\item {\sf Well-posed computations.} {\sc Hadamard} introduced notion of well-posed or properly posed problems in theory of PDEs. However, it seems that a related concept is quite useful in discussing computational problems of almost all kinds. Refer to this as notion of a well-posed computing problem. 1st, must clarify what is meant by a ``computing problem'' in general. Here will take it to mean an {\it algorithm} or equivalently: {\it a set of rules specifying the order \& kind of arithmetic operations (i.e., rounding rules) to be used on specified data}. Such a computing problem may have as its object, e.g., determination of roots of a quadratic equation or of an approximation to solution of a nonlinear PDE. How any such rules are determined for a particular purpose need not concern us at present (this is, in fact, what much of the rest of this book is about). Suppose specified data for some particular computing problem are quantities $a_1,\ldots,a_m$, which denote as the $m$-dimensional vector ${\bf a}$. Then if quantities to be computed are $x_1,\ldots,x_n$, can write \fbox{${\bf x} = {\bf f}({\bf a})$}, where of course the $n$-dimensional function ${\bf f}(\cdot)$ is determined by the rules.
			
			Define a computing problem to be {\it well-posed} iff the algorithm meets 3 requirements:
			\begin{enumerate}
				\item 1st requirement: a ``solution'' $\bf x$ should {\it exist} for the given data $\bf a$, implied by ${\bf x} = {\bf f}({\bf a})$.
			\end{enumerate}
		\end{itemize}
		\item {\sf Chap. 2: Numerical Solution of Linear Systems \& Matrix Inversion.}
		\item {\sf Chap. 3: Iterative Solutions of Nonlinear Equations.}
		\item {\sf Chap. 4: Computation of Eigenvalues \& Eigenvectors.}
		\item {\sf Chap. 5: Basic Theory of Polynomial Approximation.}
		\item {\sf Chap. 6: Differences, Interpolation Polynomials, \& Approximate Differentiation.}
		\item {\sf Chap. 7: Numerical Integration.}
		\item {\sf Chap. 8: Numerical Solution of ODEs.}
		\begin{itemize}
			\item {\sf Introduction.} To study effectiveness of various methods for numerical solution of differential equation problems, illustrate theory for case of general 1st order ODE:
			\begin{equation}
				\label{general 1st order ODE}
				\tag{g1ODE}
				\left\{\begin{split}
					\frac{dy}{dx} &= f(x,y),\\
					y(a) &= y_0\mbox{ in }(a,b).
				\end{split}\right.
			\end{equation}
			Require to find a solution $y = y(x)$ of \eqref{general 1st order ODE} in some interval $[a,b]$. Under suitable restrictions on function $f(x,y)$, well known that a unique solution exists, e.g., existence \& uniqueness of solution are assured if $f(x,y)$ is bounded, continuous in $x$, \& Lipschitz continuous w.r.t. $y$ in some sufficiently large rectangle $R_C$: $[a\le x\le b,\ |y - y_0|\le C]$. The class of methods to be discussed uses a subdivision of interval $I\coloneqq[a,b]$ by a finite set of distinct points $I_\Delta$: $x_0 = a$, $x_{i+1} = x_i + \Delta x_i$, $i = 0,1,\ldots,N$. Finer subdivisions also play a role \& are denoted by same generic symbol $I_\Delta$. Set of points defining a subdivision is frequently called a {\it net, grid, lattice}, or {\it mesh}. The quantities $\Delta x_i$ are called the {\it net spacings} or {\it mesh widths}. Corresponding to each point of the net, seek a quantity, say $u_i$, which is to approximate $y_i\coloneqq y(x_i)$, the exact solution at the corresponding net point. The set of values $\{u_i\}$ is called a {\it net function}. Clearly, the values $\{y_i\}$ also form a net function on $I_\Delta$. Use generic symbol $\{u_i\}$ to denote a net function on any subdivision.
			
			For most of methods treated in this chapter, quantities $\{u_i\}$ are to be determined from a set of (usually non-algebraic) equations which in {\it some sense} approximate system \eqref{general 1st order ODE}; these approximating equations are called {\it difference equations}. Natural requirements for approximating difference equations are that for any function $f(x,y)$ (in some class of sufficiently often differentiable functions):
			\begin{enumerate}
				\item They have a unique solution.
				\item Their solution, at least for ``sufficiently small'' net spacings, should be ``close'' to the exact  solution of \eqref{general 1st order ODE}.
				\item Their solution should be ``effectively computable''.
			\end{enumerate}
			Property (a) is trivially satisfied by many of difference equations to be studied, so-called {\it explicit schemes}. Whether or not the {\it implicit schemes} satisfy condition (a) is determined by a study of roots of a sequence of equations (or systems), of form $z = g(z)$. In general, if $\Delta x_i$ is small enough, the implicit equations have a unique solution. Property (b) is related to question of convergence, as $\max_i \Delta x_i\to0$, of $\{u_i\}$ to $\{y_i\}$. The study of such {\it convergence properties} of difference solution will occupy a considerable part of this chapter. Sects. 1--3 examine separately convergence of each of several special methods. Sects. 5--6: a general treatment of convergence which includes previous cases. Vaguely formulated property (c) involves 2 important considerations: (i) number of single precision computations required; (ii) growth of roundoff errors in computed difference ``solution''. Of course, these 2 points are related since having to compensate for rounding errors by using more significant figures usually entails additional computations. A trivial 1st approximation of (i) is based on operational count for infinite precision arithmetic. Growth of roundoff error is related to notion of {\it stability} of difference equations. Stability theory of difference equations treated in Sect. 5 is based on study of difference equations with constant coefficients developed in Sect. 4. Sect. 5: Establish main general theorem of this chapter, i.e., stability is equivalent to convergence for consistent methods.
			
			There are a number of systematic ways in which one can ``derive'' or rather generate difference equations that approximate or are consistent with \eqref{general 1st order ODE}. I.e., these difference equations seem to be discrete models for continuous problem \eqref{general 1st order ODE}. But, no matter how reasonable the derivation, the efficacy of such difference equations can only be determined by checking conditions (a)--(c). Subsect. 1.4: derive a discrete model which seems quite reasonable, but is absolutely useless since growth of roundoff error cannot be controlled (i.e., unstable). Sect. 5: develop a simple criterion for recognizing when a finite difference scheme is stable \& convergent.
			
			It should be recalled that some of numerical methods for approximating solutions of ODEs, \& systems of them, also have important theoretical applications. In fact, 1 of basic existence \& uniqueness proofs uses {\it Euler--Cauchy difference method} (resist temptation to present such a proof here). Rather, assume: Problem \eqref{general 1st order ODE} is ``well-posed'', i.e., it has a unique solution with a certain number of continuous derivatives \& furthermore, the solution depends differentiably on initial data. Can guarantee well-posedness of Problem \eqref{general 1st order ODE} for a wide class of functions $f(x,y)$. Will be interested in showing that certain difference methods have properties (a)--(c) for such a class of functions $f(x,y)$.
			
			At the present time there seems to be no general way of formulating an ``ideal method'' for solving \eqref{general 1st order ODE}. An ``ideal method'' is one which requires least amount of work (number of single precision computations) to produce an approximation solution of \eqref{general 1st order ODE} accurate to within a given $\epsilon > 0$.
			
			Derive a number of inequalities with use of 2 simple lemmas:
			\begin{lemma}
				$1 + x\le e^x$, $\forall x\in\mathbb{R}$. $1 + x = e^x\Leftrightarrow x = 0$. Consequently, $0\le(1 + x)^n\le e^{nx}$, $\forall z\ge-1,n\ge0$.
			\end{lemma}
			
			\begin{question}
				Can list all elementary inequalities derived from Taylor's theorem or Maclaurin's series?
			\end{question}
			
			\item {\sf Methods based on approximating derivative: Euler--Cauchy method.} To illustrate basic concepts, consider simple difference approximation to \eqref{general 1st order ODE} which results from approximation derivative by a forward difference quotient,
			\begin{equation}
				\label{general 1st order ODE: forward difference}
				\frac{u_{i+1} - u_i}{h} = f(x_i,u_i),\ i = 0,1,\ldots,N - 1.
			\end{equation}
			For simplicity only, chose a {\it uniform net}
			\begin{equation}
				\label{uniform net}
				I_h:x_0 = a,\ x_i = x_0 + ih,\ i = 0,\ldots,N,\ h = \frac{b - a}{N}.
			\end{equation}
			Initial condition is replaced by $u_0 = y_0 + e_0$ where have intentionally permitted introduction of an initial error $e_0$. Equations \eqref{general 1st order ODE} are difference equations of Euler--Cauchy method, also called {\it polygon method}, where the polygon is constructed by joining successive points $(x_i,u_i)$ with straight line segments. Each segment has slop given by value of $f$ at left endpoint.
			
			Existence of a unique solution $u_i$ of difference equations follows from writing \eqref{general 1st order ODE: forward difference} as
			\begin{equation}
				\label{general 1st order ODE: forward difference 1}
				u_{i+1} = u_i + hf(x_i,u_i),\ i = 0,1,\ldots,N - 1.
			\end{equation}
			Then with $u_0$ given by $u_0 = y_0 + e_0$, yield recursively $u_1,u_2,\ldots,u_N$ provided only that $f(x_i,u_i)$ is defined. Present analysis of \eqref{general 1st order ODE: forward difference 1} is based on using infinite precision arithmetic. I.e., numbers that would be calculated in finite precision arithmetic satisfy $U_{i+1} = [U_i + hf(x_i,U_i)] + \rho_{i+1}$ where $\rho_{i+1}$ is rounding error made in evaluating term in brackets. Study error $U_i - y_i$ as $h\to0$. A consideration of error $\{e_i\}$ defined by
			\begin{equation}
				\label{error}
				\tag{err}
				e_i\coloneqq u_i - y_i,\ j = 0,1,\ldots,N.
			\end{equation}
			For this study, require that, in some region $S$ to be specified later, $f(x,y)$ be continuous in $x$ \& satisfy a uniform Lipschitz condition in variable $y$:
			\begin{equation}
				\label{Lipschitz condition}
				|f(x,y) - f(x,y')|\le K|y - y'|\mbox{ for some constant } K > 0,\ \forall(x,y),(x,y')\in S.
			\end{equation}
			If $K = 0$, then $f(x,y)$ is independent of $y$ \& \eqref{general 1st order ODE} is a simple problem of quadrature treated in Chap. 7. Will need a measure of error by which exact solution of \eqref{general 1st order ODE} fails to satisfy difference relation \eqref{general 1st order ODE: forward difference}. This error is called {\it local truncation error} or discretization error \& is defined by
			\begin{equation}
				\label{local truncation error}
				\tau_{i+1}\coloneqq\frac{y_{i+1} - y_i}{h} - f(x_i,y_i),\ i = 0,1,\ldots,N - 1.
			\end{equation}
			This relation is frequently written as
			\begin{equation}
				\label{local truncation error 1}
				y_{i+1} = y_i + hf(x_i,y_i) + h\tau_{i+1},\ i = 0,1,\ldots,N - 1.
			\end{equation}
			An explicit representation of $\tau_i$ will be derived shortly [under additional conditions on $f(x,y)$]. If $\tau_i$ vanish as $h\to0$, say: difference equations are {\it consistent} with differential equation. Subsect. 2: for another consistent scheme, corresponding difference solution $\{u_i\}$ can diverge as $h\to0$, from exact solution $\{y_i\}$ even though $e_0$ is small.
			
			\begin{theorem}
				Let $\{u_i\}$ be the solution \eqref{general 1st order ODE: forward difference} \& $y(x)$ the solution of \eqref{general 1st order ODE} where $f(x,y)$ satisfies \eqref{Lipschitz condition} in the strip $S:[a\le x\le b,\ |y| < \infty]$. then, with the definitions of \eqref{local truncation error 1} of $\{\tau_i\}$:
				\begin{equation}
					|u_i - y(x_i)|\le e^{K(x_i - a)}\left(|e_0| + \frac{\tau}{K}\right),\ i = 0,1,\ldots,N,\mbox{ where } \tau\coloneqq\max_i |\tau_i|.
				\end{equation}
			\end{theorem}
			
		\end{itemize}
		\item {\sf Chap. 9: Difference Methods for PDEs.}
	\end{itemize}
	
	\item \cite{Quarteroni_Valli1994}. {\sc Alfio Quarteroni, Alberto Valli}. {\it Numerical Approximation of PDEs}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{$C_0$ Semigroup -- Nửa Nhóm $C_0$}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Anh_Ke_semigroup}. {\sc Cung Thế Anh, Trần Đình Kế}. {\it Nửa Nhóm Các Toán Tử Tuyến Tính \& Ứng Dụng}.
	
	\begin{itemize}
		\item {\sf Chap. 1: Nửa Nhóm Tuyến Tính.} Nội dung: các khái niệm cơ bản của $C_0$-nửa nhóm các toán tử tuyến tính bị chặn \& các khái niệm, kết quả liên quan đến toán tử sinh, cho phép nghiên cứu các phương trình vi phân tuyến tính dạng $x'(t) = Ax(t)$ trong không gian vô hạn chiều. Trong không gian hữu hạn chiều, $C_0$-nửa nhóm tương ứng với toán tử nghiệm (hay ma trận nghiệm cơ bản) \& toán tử sinh tương ứng với ma trận hệ số $A$.		
		
		\item {\sf Chap. 2: Lý Thuyết Phương Trình Tiến Hóa.}
		\item {\sf Chap. 3: Ứng Dụng Trong Lý Thuyết Phương Trình Đạo Hàm Riêng.}
		\item {\sf Chap. 4: Ứng Dụng Trong Lý Thuyết Điều Khiển.}
		\item {\sf Chap. 5: Nửa Nhóm Suy Rộng.}
	\end{itemize}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Differential Geometry -- Hình Học Vi Phân}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Carmo2016}. {\sc Manfredo P. do Carmo}. {\it Differential Geometry of Curves \& Surfaces}.
	\item \cite{Delfour_Zolesio2001,Delfour_Zolesio2011}. {\sc Michael C. Delfour, Jean-Paul Zol\'{e}sio}. {\it Shapes \& Geometries}.
	\item \cite{Kuhnel2015}. {\sc Wolfgang K\"uhnel}. {\it Differential Geometry}.
	\item \cite{Walker2015}. {\sc Shawn W. Walker}. {\it The Shapes of Things}.
	
	``Differential geometry is the detailed study of the {\it shape} of a surface (manifold), including {\it local} \& {\it global} properties. A plane in $\mathbb{R}^3$ is a very simple surface \& does not require many tools to characterize. An ``arbitrarily'' shaped surface, e.g., hood of a car, has many distinguished geometric features (e.g., highly curved regions, regions of near flatness, etc.). Characterizing these features quantitatively \& qualitatively requires the tools of differential geometry. Geometric details are important in many physical \& biological processes, e.g., surface tension, biomembranes.
	
	The framework of differential geometry is built by 1st defining a local map (i.e., surface parameterization) which defines the surface. Then, a calculus framework is built up on the surface analogous to the standard ``Euclidean calculus''. Other approaches are also possible, e.g., those with implicit surfaces defined by level sets \& distance functions. But parameterizations, though arbitrary, are quite useful in a variety of settings $\Rightarrow$ stick mostly with those. Emphasize: The geometry of a surface does not depend on a particular parameterization. Otherwise, we will emphasize the distinction between {\tt object 1} \& {\tt object 2}.
	
	We will use this ``abuse'' of notation when there is no possibility of ambiguity.
	
	{\bf Open set.} The concept of open set is critical in multivariate calculus to properly define differentiability. The notation for referencing boundaries of sets, as well as the closure of sets, is practical for referencing geometric details of solid objects \& their surfaces.
	
	{\bf Compactness.} Compact support is useful for ignoring boundary effects. This concept is needed to keep the ``action of a function'' away from the boundary of a set, or to localize the function in a region of interest. 1 reason is to avoid potential difficulties with differentiating a function at its boundary of definition. Or, more commonly, we wish to ignore a quantity depending on the value of a function at a boundary point, e.g., $\int_{\partial S} f = 0$ if $f$ has compact support in $S$.
	
	{\bf Topological mapping{\tt/}homeomorphism.} A bijective, continuous mapping $\boldsymbol{\Phi}$ whose inverse $\boldsymbol{\Phi}^{-1}$ is also continuous is called a {\it topological mapping} or {\it homeomorphism}. Point sets that can be topologically mapped onto each other are said to be {\it homeomorphic}. Sets that are homeomorphic have the ``same topology'', i.e., their connectedness is the same; they have the same kinds of ``holes''. See \cite[Sect. 2.3.1]{Walker2015} for what can happen when a mapping is not a homeomorphism.
	
	{\bf Rigid motion mapping.} A mapping $\boldsymbol{\Phi}$ is called a {\it rigid motion} if any pair of points ${\bf a},{\bf b}$ are the same distance apart as the corresponding pair $\boldsymbol{\Phi}({\bf a}),\boldsymbol{\Phi}({\bf b})$.
	
	{\bf Orthogonal Transformations.} Define the (affine) linear map $\boldsymbol{\Phi}$ (transformation)
	\begin{equation}
		\label{transformation}
		\widetilde{\bf x} = \boldsymbol{\Phi}({\bf x}) = A{\bf x} + {\bf b}.
	\end{equation}
	If $A$ satisfies the properties $A^{-1} = A^\top$, $\det A = 1$ then $\boldsymbol{\Phi}$ represents a rigid motion. Basically, $\boldsymbol{\Phi}$ consists of a rotation represented by $A$ followed by a translation represented by ${\bf b}$. A rigid motion can be used to transition from 1 Cartesian coordinate system to another. If ${\bf b} = {\bf 0}$ \& $A^{-1} = A^\top$, $\det A = 1$, then $\boldsymbol{\Phi}({\bf x}) = A{\bf x}$ is a linear map known as a {\it direct orthogonal transformation}, which is nothing more than a rotation of the coordinate system with the origin as the center. If $A^{-1} = A^\top$, $\det A = 1$ is replaced by $A^{-1} = A^\top$, $\det A = -1$, then $\boldsymbol{\Phi}({\bf x}) = A{\bf x}$ is called an {\it opposite orthogonal transformation}, which consists of a rotation about the origin \& a reflection in a plane. Both $A^{-1} = A^\top$, $\det A = \pm1$ are examples of {\it orthogonal matrices}.
	
	{\bf Interpretation of transformations.} Can interpret $\widetilde{\bf x} = \boldsymbol{\Phi}({\bf x}) = A{\bf x} + {\bf b}$ in 2 different ways. Consider a point $P\in\mathbb{R}^3$ with coordinates ${\bf x}$:
	\begin{itemize}
		\item {\it Alias} (Euler perspective). Viewing \eqref{transformation} as a transformation of coordinates, it appears that ${\bf x},\widetilde{\bf x}$ are the coordinates of the same point w.r.t. 2 different coordinate systems, equivalently, the point is referenced by 2 different ``names'' (sets of coordinates).
		\item {\it Alibi} (Lagrange perspective). Viewing \eqref{transformation} as a mapping of sets, it appears that ${\bf x},\widetilde{\bf x}$ are the coordinates of 2 different points w.r.t. the same coordinate system, equivalently, the point at $\widetilde{\bf x}$ ``was previously'' at ${\bf x}$ before applying the map.
	\end{itemize}
	The concept of material point is directly related to the alibi viewpoint. One can think of a ``particle'' of material, i.e., {\it material point}, initially located at ${\bf x}$, that then moves to $\widetilde{\bf x}$ because of some physical process. The transformation \eqref{transformation} simply represents the kinematic outcome of that physical process, which is a standard concept in deformable continuum mechanics, especially nonlinear elasticity.
	
	{\bf General transformations.} In general, transformation may not be linear. The alias viewpoint yields a {\it curvilinear} coordinate system. The alibi viewpoint implies that the set $S$ is {\it deformed} into the set $S' = \boldsymbol{\Phi}(S)$. 
	
	{\bf Parametric approach -- what is a surface?} A {\it surface} is a set of points in space that is ``regular enough''. A random scattering of points in space does not match our intuitive notion of what a surface is, i.e., it is not regular enough. The boundary of a sphere does match our notion of a surface, i.e., regular enough to be a surface because a sphere is ``smooth''. {\it Intuition}: Can think of creating a surface as deforming a flat rubber sheet into a curved sheet. Let $U\subset\mathbb{R}^2$ be a ``flat'' domain \& let ${\bf X}:U\to\mathbb{R}^3$ be this deforming transformation, i.e., for each point $(s_1,s_2)^\top\in U$ there is a corresponding point ${\bf x} = (x_1,x_2,x_3)^\top\in\mathbb{R}^3$ s.t. ${\bf x} = {\bf X}(s_1,s_2)$. Let $\Gamma = {\bf X}(U)$ denote the surface obtained from ``deforming'' $U$. Call ${\bf x} = {\bf X}(s_1,s_2)$ a {\it parametric representation} of the surface $\Gamma$, where $s_1,s_2$ are called the {\it parameters} of the representation. Refer to $U$ as a {\it reference} domain.
	
	{\bf Allowable parameterization{\tt/}immersion.} If use ${\bf x} = {\bf X}(s_1,s_2)$ to define surfaces, then we must place assumptions on ${\bf X}$ to guarantee that $\Gamma = {\bf X}(U)$ is a valid surface. At the bare minimum, ${\bf X}$ must be continuous to avoid ``tearing'' the rubber sheet. But if want to perform calculus on $\Gamma$, need more:
	\begin{assumption}[Regularity assumptions on ${\bf X}$]
		An allowable parameterization{\tt/}immersion is a parameterization of the form ${\bf x} = {\bf X}(s_1,s_2)$ satisfying:
		\item[(A1)] The function ${\bf X}(s_1,s_2)\in C^\infty(U)$ \& each point ${\bf x} = {\bf X}(s_1,s_2)\in\Gamma$ corresponds to just 1 point $(s_1,s_2)\in U$, i.e., ${\bf X}$ is injective.
		\item[(A2)] The Jacobian matrix $J = [\partial_{s_1}{\bf X},\partial_{s_2}{\bf X}]$ is of rank $2$ on $U$, i.e., the columns of $J$ are linearly independent.
	\end{assumption}
	{\bf Regular surface.} The fundamental property that makes a set of points in $\mathbb{R}^3$ a surface is that it {\it locally looks like a plane} at every point. If you ``zoom into'' a surface, it should look flat. Definition defining a surface in terms of a parameterization is inadequate. Want to define a set in $\mathbb{R}^3$ that is ``intrinsically'' 2D \& is smooth enough so we can perform calculus on it, without regard to a specific parameterization.
	
	\begin{definition}[Regular surface]
		
	\end{definition}
	
	\begin{remark}[Local chart]
		
	\end{remark}
\end{enumerate}
1 trong những ứng dụng của Hình Học Vi Phân là {\it Shape Calculus \& Tangential Calculus -- Phép Tính Vi Tích Phân cho Tối Ưu Hình Dáng \& Phép Tính Vi Tích Phân Trên Mặt Phẳng Tiếp Tuyến}.

\subsection{Calculus on Surfaces}
{\bf Goal.} Define \& develop the fundamental tools of calculus on a regular surface. Start with the notion of differentiability of functions defined only on a surface. Define the concept of vector fields in a surface. Then proceed to develop the gradient \& Laplacian operators w.r.t. a surface. These operators allow for alternative expressions of the summed \& Gaussian curvatures. Derive integration by parts on surfaces, i.e., the domain of integration is a surface. Conclude with some useful identities \& inequalities. Always take $\Gamma$: a regular surface, either with or without a boundary.

%------------------------------------------------------------------------------%

\section{Distribution Theory -- Lý Thuyết Phân Phối}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Simon2022}. {\sc Jacques Simon}. {\it Distributions}. Analysis for PDEs Set: Vol. 3.
	
	To {\sc Laurent Schwartz}, For his {\it Theory of Distributions}, obviously, without which this book could not have existed, but also, \& above, for his kindness \& courage. The clarity of {\sc Schwartz}'s analysis classes at the \'Ecole Polytechnique in 1968 made the dunce that I was there happy. Even if I arrived late, even if I had skipped a few sessions, everything was clear, lively \& easy to understand. His soft voice, benevolent smile, mischievous eye -- especially when, with an air of nothing, he was watching for reactions to 1 of his veiled jokes, ``a tore, from the Greek toro, the tyre'' -- he made people love analysis. When master's students at the university demanded ``a grade average for all'' in 1969, most professors either complied or slunk away. Not {\sc Schwartz}. When the results were posted -- I was there, to make up easily for the calamitous grades I had earned at Polytechnique -- he came along, frail, in front of a fairly excited horde. He explained, in substance: ``An examination given to all, without any value, would no longer allow one to rise in society through knowledge. Removing selection on the basis of merit would leave the field open to selection by money or social origin.'' Preminitory, alas.
	
	-- Gửi {\sc Laurent Schwartz}, vì {\it Theory of Distributions} của ông, rõ ràng là, nếu không có nó thì cuốn sách này không thể tồn tại, nhưng cũng hơn thế nữa, vì lòng tốt \& lòng dũng cảm của ông. Sự rõ ràng của các lớp giải tích của {\sc Schwartz} tại \'Ecole Polytechnique năm 1968 đã khiến kẻ ngốc như tôi ở đó vui mừng. Ngay cả khi tôi đến muộn, ngay cả khi tôi đã bỏ lỡ 1 vài buổi học, mọi thứ đều rõ ràng, sống động \& dễ hiểu. Giọng nói nhẹ nhàng, nụ cười nhân hậu, đôi mắt tinh nghịch của ông -- đặc biệt là khi, với vẻ mặt vô hồn, ông đang theo dõi phản ứng với 1 trong những trò đùa che đậy của mình, ``1 vết rách, từ tiếng Hy Lạp toro, lốp xe'' -- ông đã khiến mọi người yêu thích giải tích. Khi sinh viên thạc sĩ tại trường đại học yêu cầu ``điểm trung bình cho tất cả'' vào năm 1969, hầu hết các giáo sư đều tuân thủ hoặc lẩn tránh. Nhưng không phải {\sc Schwartz}. Khi kết quả được công bố -- tôi đã ở đó, để dễ dàng bù đắp cho điểm số thảm hại mà tôi đã đạt được tại Polytechnique -- ông ấy đã đi đến, yếu ớt, trước 1 đám đông khá phấn khích. Ông giải thích, về cơ bản: ``1 kỳ thi dành cho tất cả mọi người, không có giá trị nào, sẽ không còn cho phép 1 người thăng tiến trong xã hội thông qua kiến thức. Loại bỏ việc lựa chọn dựa trên thành tích sẽ để lại lĩnh vực này cho việc lựa chọn theo tiền bạc hoặc nguồn gốc xã hội.'' Thật đáng tiếc, đó là lời mở đầu.
	\begin{itemize}
		\item {\sf Introduction.} {\bf Objective.} This book is 3rd of 7 volumes dedicated to solving PDEs in physics:
		\begin{itemize}
			\item Vol. 1: Banach, Frechet, Hilbert, \& Neumann Spaces
			\item Vol. 2: Continuous Functions
			\item Vol. 3: Distributions
			\item Vol. 4: Integration
			\item Vol. 5: Sobolev Spaces
			\item Vol. 6: Traces
			\item Vol. 7: PDEs
		\end{itemize}
		This 3rd volume aims to construct space of distributions with real or vectorial values \& to provide main properties useful in studying PDEs.
		
		{\bf Intended audience.} Have looked for simple methods that require a minimal level of knowledge to make this tool accessible to as wide an audience as possible -- doctoral students, university students, engineers -- without loosing generality \& even generalizing certain results, which may be of interest to some researchers. Led us to choose an unconventional approach that prioritizes semi-norms \& sequential properties, whether related to completeness, compactness or continuity.
		
		{\bf Utility of distributions.} Main advantage of distribution: distributions provide derivatives of all continuous or integrable functions, even those which are not differentiable, \& thus broaden scope of application of differential calculus. Especially useful for solving PDEs.
		
		To this end, a family of objects, the distributions, is defined, with following properties:
		\begin{itemize}
			\item Any continuous function is a distribution.
			\item Any distribution has partial derivatives, which are distributions.
			\item For a differentiable function, find conventional derivatives.
			\item Any limit of distributions is a distribution.
			\item Any Cauchy sequence of distributions has a limit.
		\end{itemize}
		These properties may be roughly summarized by saying: space $\mathcal{D}'$ of distributions is the {\it completion w.r.t. derivation} of space $C$ of continuous functions. This construction, due to {\sc Laurent Schwartz}, is completed here for distributions on an open subset $\Omega$ of $\mathbb{R}^d$ with values in a Neumann space $E$, i.e., a sequentially complete separable semi-normed space. This includes values in a Banach or Fr\'echet space.
		\item {\sf Notations.}
		\item {\sf Chap. 1: Semi-Normed Spaces \& Function Spaces.}
		\begin{itemize}
			\item {\sf Semi-normed spaces.}
			\item {\sf Comparison of semi-normed spaces.}
			\item {\sf Continuous mappings.}
			\item {\sf Differentiable functions.}
			\item {\sf Spaces $C^m(\Omega;E),C_{\rm b}^m(\Omega;E),{\bf C}_{\rm b}^m(\Omega;E)$.}
			\item {\sf Integral of a uniformly continuous function.}
		\end{itemize}
		\item {\sf Chap. 2: Space of Test Functions.}
		\begin{itemize}
			\item {\sf Functions with compact support.}
			\item {\sf Compactness in their whole of support of functions.}
			\item {\sf Space $\mathcal{D}(\Omega)$.}
			\item {\sf Sequential completeness of $\mathcal{D}(\Omega)$.}
			\item {\sf Comparison of $\mathcal{D}(\Omega)$ to various spaces.}
			\item {\sf Convergent sequences in $\mathcal{D}(\Omega)$.}
			\item {\sf Covering by crown-shaped sets \& partitions of unity.}
			\item {\sf Control of $C_K^m(\Omega)$-norms by semi-norms of $\mathcal{D}(\Omega)$.}
			\item {\sf Semi-norms that are continuous on all $C_K^\infty(\Omega)$.}
		\end{itemize}
		\item {\sf Chap. 3: Space of Distributions.}
		\begin{itemize}
			\item {\sf Space $\mathcal{D}'(\Omega'E)$.}
			\item {\sf Characterization of distributions.}
			\item {\sf Inclusion of $C(\Omega;E)$ into $\mathcal{D}'(\Omega;E)$.}
			\item {\sf Case where $E$ is not a Neumann space.}
			\item {\sf Measures.}
			\item {\sf Continuous functions \& measures.}
		\end{itemize}
		\item {\sf Chap. 4: Extraction of Convergent Subsequences.}
		\begin{itemize}
			\item {\sf Bounded subsets of $\mathcal{D}'(\Omega;E)$.}
			\item {\sf Convergence in $\mathcal{D}'(\Omega;E)$.}
			\item {\sf Sequential completeness of $\mathcal{D}'(\Omega;E)$.}
			\item {\sf Sequential compactness in $\mathcal{D}'(\Omega;E)$.}
			\item {\sf Change of space $E$ of values.}
			\item {\sf Space $E$-weak.}
			\item {\sf Space $\mathcal{D}'(\Omega;E\mbox{-weak})$ \& extractability.}
		\end{itemize}
		\item {\sf Chap. 5: Operations on Distributions.}
		\begin{itemize}
			\item {\sf Distributions fields.}
			\item {\sf Derivatives of a distribution.}
			\item {\sf Image under a linear mapping.}
			\item {\sf Product with a regular function.}
			\item {\sf Change of variables.}
			\item {\sf Some particular changes of variables.}
			\item {\sf Positive distributions.}
			\item {\sf Distributions with values in a product space.}
		\end{itemize}
		\item {\sf Chap. 6: Restriction, Gluing \& Support.}
		\begin{itemize}
			\item {\sf Restriction.}
			\item {\sf Additivity w.r.t. domain.}
			\item {\sf Local character.}
			\item {\sf Localization-extension.}
			\item {\sf Gluing.}
			\item {\sf Annihilation domain \& support.}
			\item {\sf Properties of annihilation domain \& support.}
			\item {\sf Space $\mathcal{D}_K'(\Omega;E)$.}
		\end{itemize}
		\item {\sf Chap. 7: Weighting.}
		\begin{itemize}
			\item {\sf Weighting by a regular function.}
			\item {\sf Regularizing character of weighting by a regular function.}
			\item {\sf Derivatives \& support of distributions weighted by a regular weight.}
			\item {\sf Continuity of weighting by a regular function.}
			\item {\sf Weighting by a distribution.}
			\item {\sf Comparison of definitions of weighting.}
			\item {\sf Continuity of weighting by a distribution.}
			\item {\sf Derivatives \& support of a weighted distribution.}
			\item {\sf Miscellaneous properties of weighting.}
		\end{itemize}
		\item {\sf Chap. 8: Regularization \& Applications.}
		\begin{itemize}
			\item {\sf Local regularization.}
			\item {\sf Properties of local approximations.}
			\item {\sf Global regularization.}
			\item {\sf Convergence of global approximations.}
			\item {\sf Properties of global approximations.}
			\item {\sf Commutativity \& associativity of weighting.}
			\item {\sf Uniform convergence of sequences of distributions.}
		\end{itemize}
		\item {\sf Chap. 9: Potentials \& Singular Functions.}
		\begin{itemize}
			\item {\sf Surface integral over a sphere.}
			\item {\sf Distribution associated with a singular function.}
			\item {\sf Derivatives of a distribution associated with a singular function.}
			\item {\sf Elementary Newtonian potential.}
			\item {\sf Newtonian potential of order $n$.}
			\item {\sf Localized potential.}
			\item {\sf Dirac mass as derivatives of continuous functions.}
			\item {\sf Heaviside potential.}
			\item {\sf Weighting by a singular weight.}
		\end{itemize}
		\item {\sf Chap. 10: Line Integral of a Continuous Field.}
		\begin{itemize}
			\item {\sf Line integral along a $C^1$ path.}
			\item {\sf Change of variable in a path.}
			\item {\sf Line integral along a piecewise $C^1$ path.}
			\item {\sf Homotopy invariance theorem.}
			\item {\sf Connectedness \& simply connectedness.}
		\end{itemize}
		\item {\sf Chap. 11: Primitives of Functions.}
		\begin{itemize}
			\item {\sf Primitive of a function field with a zero line integral.}
			\item {\sf Tubular flows \& concentration theorem.}
			\item {\sf Orthogonality theorem for functions.}
			\item {\sf Poincar\'e's theorem.}
		\end{itemize}
		\item {\sf Chap. 12: Properties of Primitives of Distributions.}
		\begin{itemize}
			\item {\sf Representation by derivatives.}
			\item {\sf Distribution whose derivatives are zero or continuous.}
			\item {\sf Uniqueness of a primitive.}
			\item {\sf Locally explicit primitive.}
			\item {\sf Continuous primitive mapping.}
			\item {\sf Harmonic distributions, distributions with a continuous Laplacian.}
		\end{itemize}
		\item {\sf Chap. 13: Existence of Primitives.}
		\begin{itemize}
			\item {\sf Peripheral gluing.}
			\item {\sf Reduction to function case.}
			\item {\sf Orthogonality theorem.}
			\item {\sf Poincar\'e's generalized theorem.}
			\item {\sf Current of an incompressible 2D field.}
			\item {\sf Global vs. local primitives.}
			\item {\sf Comparison of existence conditions of a primitive.}
			\item {\sf Limits of gradients.}
		\end{itemize}
		\item {\sf Chap. 14: Distributions of Distributions.}
		\begin{itemize}
			\item {\sf Characterization.}
			\item {\sf Bounded sets.}
			\item {\sf Convergent sequences.}
			\item {\sf Extraction of convergent subsequences.}
			\item {\sf Change of space of values.}
			\item {\sf Distributions of distributions with values in $E$-weak.}
		\end{itemize}
		\item {\sf Chap. 15: Separation of Variables.}
		\begin{itemize}
			\item {\sf Tensor products of test functions.}
			\item {\sf Decomposition of test functions on a product of sets.}
			\item {\sf Tensorial control theorem.}
			\item {\sf Separation of variables.}
			\item {\sf Kernel theorem.}
			\item {\sf Regrouping of variables.}
			\item {\sf Permutation of variables.}
		\end{itemize}
		\item {\sf Chap. 16: Banach Space Valued Distributions.}
		\begin{itemize}
			\item {\sf Finite order distributions.}
			\item {\sf Weighting of a finite order distribution.}
			\item {\sf Finite order distribution as derivatives of continuous functions.}
			\item {\sf Finite order distribution as derivative of a single function.}
			\item {\sf Distributions in a Banach space as derivatives of functions.}
			\item {\sf Non-representability of distributions with values in a Fr\'echet space.}
			\item {\sf Extendability of distributions with values in a Banach space.}
			\item {\sf Cancellation of distributions with values in a Banach space.}
		\end{itemize}
	\end{itemize}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Functional Analysis -- Giải Tích Hàm}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Alt2016}. {\sc Hans Wilhelm Alt}. {\it Linear Functional Analysis}.
	\item \cite{Brezis2011}. {\sc Ha\"\i m Brezis}. {\it Functional Analysis, Sobolev Spaces \& PDEs}.
	\item \cite{Evans2010}. {\sc Lawrence C. Evans}. {\it PDEs}.
	\item \cite{Rudin1991}. {\sc Walter Rudin}. {\it Functional Analysis}.
	
	``Functional analysis is the study of certain topological-algebraic structures \& of the methods by which knowledge of these structures can be applied to analytic problems.''
	
	The material of a theory should be fully adequate for almost all applications to concrete problems. \& this is what ought to be stressed in such a course: The close interplay between the abstract \& the concrete is not only the most useful aspect of the whole subject but also the most fascinating one.
	
	Many problems that analysts study are not primarily concerned with a single object such as a function, a measure, or an operator, but they deal instead with large classes of such objects. Most of the interesting classes that occur in this way turn out to be vector spaces, either with real scalars or with complex ones. Since limit processes play a role in every analytic problem (explicitly or implicitly), it should be no surprise that these vector spaces are supplied with metrics, or at least with topologies, that bear some natural relation to the objects of which the spaces are made up. The simplest \& most important way of doing this is to introduce a {\it norm}. The resulting structure is called a {\it normed vector space}, or a normed linear space, or simply a {\it normed space}.
	
	``The theory of distributions frees differential calculus from certain difficulties that arise because nondifferentiable functions exist. This is done by extending it to a class of objects (called {\it distributions} or {\it generalized functions}) which is much larger than the class of differential functions to which calculus applies in its original form. Here are some features that any such extension ought to have in order to be useful; our setting is some open subset of $\mathbb{R}^d$:
	\begin{enumerate}
		\item Every continuous function should be a distribution.
		\item Every distribution should have partial derivatives which are again distributions. For differentiable functions, the new motion of derivative should coincide with the old one. (Every distribution should therefore be infinitely differentiable $C^\infty$.)
		\item The usual formal rules of calculus should hold.
		\item There should be a supply of convergence theorems that is adequate for handling the usual limit processes.'' -- \cite[Chap. 6, pp. 149--150]{Rudin1991}
	\end{enumerate}
	\item \cite{Simon1987}. {\sc Jacques Simon}. {\it Compact sets in the space $L^p(0,T;B)$}.
	\item \cite{Simon2022}. {\sc Jacques Simon}. {\it Distributions}.
	\item \cite{Thanh_Thanh_Vu_gth}. {\sc Đinh Ngọc Thanh, Bùi Lê Trọng Thanh, Huỳnh Quang Vũ}. {\it Bài Giảng Giải Tích Hàm}.
	\item {\sc Yosida}.
\end{enumerate}

\subsection{Discrete Functional Analysis -- Giải Tích Hàm Rời Rạc}
Giải Tích Hàm Rời Rạc cung cấp các tools \& theorems để chứng minh các kết quả bên Numerical Analysis.

\noindent\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite[Sect. 5: Appendix: Discrete Functional Analysis]{Gallouet_Herbin_Latche_Mallem2018}. {\sc Gallou\"{e}t, Herbin, Latch\'{e}, J.-C., Mallem, K.} {\it Convergence of the marker-and-cell scheme for the incompressible NSEs on non-uniform grids}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Inverse Problems -- Bài Toán Ngược}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Aster_Borchers_Thurber2018}. {\sc Richard Aster, Brian Borchers, Clifford H. Thurber}. {\it Parameter Estimation \& Inverse Problems}.
	\item \cite{Kirsch2021}. {\sc Andreas Kirsch}. {\it An Introduction to The Mathematical Theory of Inverse Problems}.
	\item \cite{Ito_Jin2015}. {\sc Kazufumi Ito, Bangti Jin}. {\it Inverse Problems}.
	
	
	Due to the pioneering works of many prominent mathematicians, including {\sc A. N. Tikhonov \& M. A. Lavrentiev}, the concept of inverse{\tt/}ill-posed problems has been widely accepted \& received much attention in mathematical sciences as well as applied disciplines, e.g., heat transfer, medical imaging \& geophysics. Inverse theory has played an extremely important role in many scientific developments \& technological innovations.
	
	Amongst numerous existing approaches to numerically treat ill-posed inverse problems, Tikhonov regularization is the most powerful \& versatile general-purposed method. Recently, Tikhonov regularization with nonsmooth penalties has demonstrated great potentials in many practical applications. The use of nonsmooth regularization can improve significantly the reconstruction quality. Their Bayesian counterparts also start to attract considerable attention. However, it also brings great challenges to its mathematical analysis \& efficient numerical implementation.
	
	The primary goal of this monograph is to blend up-to-date mathematical theory with state-of-art numerical algorithms for Tikhonov regularization. The main focus lies in nonsmooth regularization \& their convergence analysis, parameter choice rules, nonlinear problems, efficient algorithms, direct inversion methods \& Bayesian inversion. A clear understanding of these different facets of Tikhonov regularization, or more generally nonsmooth models for inverse problems, is expected to greatly broaden the scope of the approach \& to promote further developments, in particular in the search of better model{\tt/}methods. However, a seamless integration of these facets is still rare due to its relatively recent origin.
	
	The presentation focuses on 2 components of applied inverse theory: mathematical theory (linear \& nonlinear Tikhonov theory) \& numerical algorithms (including nonsmooth optimization algorithms, direct inversion methods \& Bayesian inversion). Discuss nonsmooth regularization in the context of classical regularization theory, especially consistency, convergence rates, \& parameter choice rules. These theoretical developments cover both linear \& nonlinear inverse problems. The nonsmoothness of the emerging models poses significant challenges to their efficient \& accurate numerical solution. Describe a number of efficient algorithms for relevant nonsmooth optimization problems, e.g., augmented Lagrangian method \& semismooth Newton method. The sparsity regularization is treated in great detail. In the application of these algorithms, often a good initial guess is very beneficial, which for a class of inverse problems can be obtained by direct inversion methods. Further, describe Bayesian framework, which quantifies the uncertainties associated with 1 particular solution, Tikhonov solution, \& provide the mechanism for choosing regularization parameters \& selecting the proper regularization model. Shall describe the implementation details of relevant computational techniques.
	
	The topic of Tikhonov regularization is very broad, \& surely we are not able to cover it in 1 single volume. The choice of materials is strongly biased by our limited knowledge. In particular, we do not intend to present the theoretical results in their most general form, but to illustrate the main ideas. However, pointers to relevant references are provided throughout.
	
	The book is intended for senior undergraduate students \& beginning graduate students. The prerequisite includes basic PDEs \& functional analysis. However, experienced researchers \& practitioners in inverse problems may also find it useful.
	\begin{itemize}
		\item {\sf1. Introduction.}
		\item {\sf2. Models in Inverse Problems.}
		\item {\sf3. Tikhonov Theory for Linear Problems.} Inverse problems suffer from instability, which poses significant challenges to their stable \& accurate numerical solution. Therefore, specialized techniques are required. Since the ground-breaking work of the Russian mathematician {\sc A. N. Tikhonov}, regularization, especially Tikhonov regularization, has been established as 1 of the most powerful \& popular techniques for solving inverse problems. Discuss Tikhonov regularization for linear inverse problems $Ku = g^\dagger$ where $K:X\to Y$: a bounded linear operator, $X,Y$: Banach spaces. In practice, have at hand only noisy data $g^\delta$, whose accuracy w.r.t. exact data $g^\dagger = Ku^\dagger$ ($u^\dagger$ is the true solution) is quantified in some error metric $\phi$, which measures the model output $g^\dagger$ relative to the measurement data $g^\delta$. Denote the accuracy by $\phi(u,g^\delta)$ to indicate its dependence on the data $g^\delta$, \& mostly concerned with the choice $\phi(u,g^\delta) = \|Ku - g^\delta\|^p$.
		
		In Tikhonov regularization, solve a nearby {\it well-posed} optimization problem of the form
		\begin{equation}
			\min_{u\in\mathcal{C}} J_\alpha(u)\coloneqq\phi(u,g^\delta) + \alpha\psi(u),
		\end{equation}
		\& take its minimizer, denoted by $u_\alpha^\delta$, as a solution. Functional $J_\alpha$: Tikhonov functional, consisting of 2 terms, the fidelity term $\phi(u,g^\delta)$ \& regularization term $\psi(u)$. Roughly, the former measures the proximity of the model output $Ku$ to the observational data $g^\delta$ \& hence incorporates the information in the data $g^\delta$, whereas the latter encodes a priori information, e.g., smoothness, sparsity, monotonicity, \& other structural properties of the unknown. The nonnegative scalar $\alpha$ is known as the regularization parameter, \& it controls the relative weight given to the 2 terms. The choice of the parameter $\alpha$ is essential for successfully applying Tikhonov regularization to practical problems. The set $\mathcal{C}\subset X$ is convex \& closed, \& it reflects constraint on the sought-for solution, e.g., positivity \& other physical constraints.
		
		An appropriate choice of the functionals $\phi,\psi$ depends very much on specific applications, or more precisely, on the noise model \& prior information, respectively. A list of some common choices for the fidelity $\phi$ \& regularization $\psi$: {\sf Common data fidelity functionals $\phi(u,g^\delta)$. $\Omega$: bounded domain. For Poisson \& speckle noises, the fidelity functionals are not nonnegative, since a constant depending on data $g^\delta$ is omitted.} noise model $\phi(u,g^\delta)$
		\begin{itemize}
			\item additive Gaussian $\|Ku - g^\delta\|_{L^2(\Omega)}^2$
			\item additive impulsive $\|Ku - g^\delta\|_{L^1(\Omega)}$
			\item Poisson $\int_\Omega Ku - g^\delta\log Ku\,{\rm d}x$
			\item speckle noise $\int_\Omega \log Ku + \frac{g^\delta}{Ku}\,{\rm d}x$
			\item Huber $\|L_\delta(Ku - g^\delta)\|_{L^1(\Omega)}$,
			\begin{equation*}
				L_\delta(t) = \left\{\begin{split}
					&\frac{1}{2}t^2&&|t|\le\delta,\\
					&\delta\left(t - \frac{\delta}{2}\right)&&|t| > \delta.
				\end{split}\right.
			\end{equation*}
		\end{itemize}
		{\sf Several common regularization functionals $\psi(u)$. $\Omega$: an open bounded domain.} prior model $\psi(u)$
		\begin{itemize}
			\item generalized Gaussian $\|u\|_{L^p(\Omega)}^p$, $1\le\nu\le2$
			\item BV or TV: $\|u\|_{{\rm BV}(\Omega)}$ or $|u|_{{\rm TV}(\Omega)}$
			\item Sobolev $\|u\|_{W^{1,p}(\Omega)}^p$
			\item elastic-net $\|u\|_{l^1} + \frac{\gamma}{2}\|u\|_{l^2}^2$
			\item sparsity $\|u\|_{l^p}^p$, $0\le p < 2$
		\end{itemize}
		The fidelity $\phi$ \& penalty $\psi$ are often derived in a Bayesian setting, since Tikhonov minimizer is identical with the maximum a posteriori estimate of the posterior distribution. Outline:
		\begin{itemize}
			\item 1st discuss fundamental question of existence \& stability of a Tikhonov minimizer $u_\alpha^\delta$, \& consistency, i.e., convergence of minimizer $u_\alpha^\delta$ as the noise level $\delta\to0$ (with parameter $\alpha$ suitably chosen). These are necessary for the well-posedness of Tikhonov formulation. Discuss value function calculus due to {\sc A. N. Tikhonov}, which are important for designing \& analyzing Tikhonov models.
			\item Discuss convergence rates, which is concerned with quality of approximation $u_\alpha^\delta$ relative to a true solution $u^\dagger$, under different conditions on the ``true'' solution $u^\dagger$. Regularization parameter $\alpha$ is essential for performance of Tikhonov method, discuss several choice rules.
			\item Discuss an extension of the formulation $J_\alpha$ to the case of multiple penalties, to accommodate multiple distinct features, as are often observed in many practical problems.
		\end{itemize}		
		
		\item {\sf4. Tikhonov Theory for Nonlinear Problems.}
		\item {\sf5. Nonsmooth Optimization.}
		\item {\sf6. Direct Inversion Methods.}
		\item {\sf7. Bayesian Inference.}
		\item {\sf Appendix A: Singular Value Decomposition.}
		\item {\sf Appendix B: Noise Models.}
		\item {\sf Appendix C: Exponential Families.}
	\end{itemize}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Measure \& Integration -- Độ Đo \& Tích Phân}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Evans_Gariepy2015}. {\sc Lawrence C. Evans, Ronald F. Gariepy}. {\it Measure Theory \& Fine Properties of Functions}.
	\item \cite{Tao_measure_theory}. {\sc Terence Tao}. {\it An Introduction To Measure Theory}. {\sf[45 Amazon ratings][31 Goodreads ratings]}
	
	{\sf Amazon review.} This is a graduate text introducing the fundamentals of measure theory \& integration theory, which is the foundation of modern real analysis. The text focuses 1st on the concrete setting of Lebesgue measure \& the Lebesgue integral (which in turn is motivated by the more classical concepts of Jordan measure \& the Riemann integral), before moving on to abstract measure \& integration theory, including the standard convergence theorems, Fubini's theorem, \& the Carath\'eodory extension theorem. Classical differentiation theorems, e.g., Lebesgue \& Rademacher differentiation theorems, are also covered, as connections with probability theory. The material is intended to cover a quarter or semester's worth of material for a 1st graduate course in real analysis. There is an emphasis in the text on typing together the abstract \& the concrete sides of the subject, using the latter to illustrate \& motivate the former. The central role of key principles (e.g. Littlewood's 3 principles) as providing guiding intuition to the subject is also emphasized. There are a large number of exercises throughout that develop key aspects of the theory, \& are thus an integral component of the text. As a supplementary section, a discussion of general problem-solving strategies in analysis is also given. The last 3 sections discuss optional topics related to the main matter of the book.
	
	{\bf Preface.} ``In the fall of 2010, taught an introductory 1-quarter course on graduate real analysis, focusing in particular on the basics of measure \& integration theory, both in Euclidean spaces \& in abstract measure spaces. This text is based on my lecture notes of that course, which are also available online
	on my blog \url{terrytao.wordpress.com}, together with some supplementary
	material, e.g., a section on problem solving strategies in real analysis which evolved from discussions with my students.
	
	This text is intended to form a prequel to my graduate text \cite{Tao_epsilon_I} (henceforth referred to as An epsilon of room, Vol. I ), which is an introduction to analysis of Hilbert \& Banach spaces (e.g. $L^p$ \& Sobolev spaces), point-set topology, \& related topics e.g. Fourier analysis \& theory of distributions; together, they serve as a text for a complete 1st-year graduate course in real analysis.
	
	The approach to measure theory here is inspired by the text [StSk2005], which was used as a secondary text in my course. 1st half of course is devoted almost exclusively to measure theory on Euclidean spaces $\mathbb{R}^d$ (starting with the more elementary Jordan-Riemann-Darboux theory, \& only then moving on to the more sophisticated Lebesgue theory), deferring abstract aspects of measure theory to 2nd half of course. I found that this approach strengthened the student's intuition in the early stages of course, \& helped provide motivation for more abstract constructions, e.g. Carath\'eodory's general construction of a measure from an outer measure.
	
	Most of the material here is self-contained, assuming only an undergraduate knowledge in real analysis (\& in particular, on Heine-Borel theorem, which will be used as the foundation for our construction of Lebesgue measure); a secondary real analysis text can be used in conjunction with this one, but it is not strictly necessary. A small number of exercises, however, will require some knowledge of point-set topology or of set-theoretic concepts e.g. cardinals \& ordinals.
	
	A large number of exercises are interspersed throughout the text, \& it is intended that the reader perform a significant fraction of these exercises while going through the text. Indeed, many of the key results \& examples in the subject will in fact be presented through the exercises. In my own course, I used the exercises as the basis for the examination questions, \& indicated this well in advance, to encourage the students to attempt as many of the exercises as they could as preparation for the exams.
	
	The core material is contained in Chap. 1, \& already comprises a full quarter's worth of material. Sect. 2.1 is a much more informal section than the rest of the book, focusing on describing problem solving strategies, either specific to real analysis exercises, or more generally, applicable to a wider set of mathematical problems; this section evolved from various discussions with students throughout the course. The remaining 3 sections in Chap. 2 are optional topics, which require understanding most of the material in Chap. 1 as a prerequisite (although Sect. 2.3 can be read after completing Sect. 1.4).
	\begin{itemize}
		\item {\sf Chap. 1: Measure Theory.}
		\item {\sf2.1. Problem solving strategies.} Purpose: list (in no particular order) a number of common problem solving strategies for attacking real analysis exercises e.g. that presented in this text. Some of these strategies are specific to real analysis type problems, but others are quite general \& would be applicable to other mathematical exercises.
		\begin{itemize}
			\item {\bf Split up equalities into inequalities.} If one has to show that 2 numerical quantities $X,Y$ are equal, try proving that $X\le Y$ \& $Y\le X$ separately. Often 1 of these will be very easy, \& the other one harder; but the easy direction may still provide some clue as to what needs to be done to establish the other direction. In a similar spirit, to show that 2 sets $E,F$ are equal, try proving that $E\subset F$ \& $F\subset E$.
			\item {\bf Give yourself an epsilon of room.} If one has to show that $X\le Y$, try proving that $X\le Y + \varepsilon$ for any $\varepsilon > 0$. (This trick combines well
			with {\it Split up equalities into inequalities}. In a similar spirit:
			\begin{itemize}
				\item If one needs to show that a quantity $X$ vanishes, try showing that $|X|\le\varepsilon$, $\forall\varepsilon > 0$.
				\item If one wishes to show that 2 functions $f,g$ agree a.e., try showing 1st that $|f(x) - g(x)|\le\varepsilon$ holds for almost every $x$, or even just outside of a set of measure at most $\varepsilon$, for any given $\varepsilon > 0$.
				\item If one wants to show that a sequence $x_n$ of real numbers converges to 0, try showing that $\limsup_{n\to\infty} |x_n|\le\varepsilon$, $\forall\varepsilon > 0$. (The proof of the Lebesgue differentiation theorem is in this spirit.)
			\end{itemize}
			Don't be too focused on getting all of your error terms adding up to exactly $\varepsilon$; usually, as long as the final error bound consists of terms that can all be made as small as one wishes by choosing parameters in a suitable way, that is enough. E.g., an error term e.g. $10\varepsilon$ is certainly OK, or even more complicated expressions e.g. $\frac{10\varepsilon}{\delta} + 4\delta$ if one has the ability to choose $\delta$ as small as one wishes, \& then after $\delta$ is chosen, one can then also set $\varepsilon$ as small as one wishes (in a manner that can depend on $\delta$).
			
			1 caveat: For finite $x$, \& any $\varepsilon > 0$, it is true that $x + \varepsilon > 0$ \& $x - \varepsilon < x$, but this statement is not true when $x = \pm\infty$. So remember to exercise some care with the epsilon of room trick when some quantities are infinite.
		\end{itemize}
		\item {\bf Decompose (or approximate) a rough or general object into (or by) a smoother or simpler one.} If one has to prove something about an unbounded (or infinite measure) set, consider proving it for bounded (or finite measure) sets 1st if this looks easier. In a similar spirit:
		\begin{itemize}
			\item If one has to prove something about a measurable set, try proving it for open, closed, compact, bounded, or elementary sets 1st.
			\item If one has to prove something about a measurable function, try proving it for functions that are continuous, bounded, compactly supported, simple, absolutely integrable, etc.
			\item If one has to prove something about an infinite sum or sequence, try proving it 1st for finite truncations of that sum or sequence (but try to get all the bounds independent of the number of terms in that truncation, so that you can still pass to the limit!).
			\item If one has to prove something about a complex-valued function, try it for real-valued functions 1st.
			\item If one has to prove something about a real-valued function, try it for unsigned functions 1st.
			\item If one has to prove something about a simple function, try it for indicator functions 1st.
		\end{itemize}
		In order to pass back to the general case from these special cases, one will have to somehow decompose the general object into a combination of special ones, or approximate general objects by special ones (or as a limit of a sequence of special objects). In the latter case, one may need an epsilon of room, \& some sort of limiting analysis may be needed to deal with the errors in the approximation (it is not always enough to just ``pass to the limit'', as one has to justify that the desirable properties of the approximating object are preserved in the limit). {\sc Littlewood}'s principles \& their variants are often useful for thus purpose.
		\begin{note}
			One should not do this blindly, as one might then be loading on a bunch of distracting but ultimately useless hypotheses that end up being a lot less help than one might hope. But they should be kept in mind as something to try if one starts having thoughts e.g. ``Gee, it would be nice at this point if I could assume that $f$ is continuous{\tt/}real-valued{\tt/}simple{\tt/}unsigned{\tt/}etc.''.
			
			In the more quantitative areas of analysis \& PDE, one sees a common variant of the above technique, namely the method of {\it a priori estimates}. Here, one needs to prove an estimate or inequality for all functions in a large, rough class (e.g. all rough solutions to a PDE). One can often then 1st prove this inequality in a much smaller (but still ``dense'') class of ``nice'' functions, so that there is little difficulty justifying the various manipulations (e.g., exchanging integrals, sums, or limits, or integrating by parts) that one wishes to perform. Once one obtains these a priori estimates, one can then often take some sort of limiting argument to recover the general case.
		\end{note}
		\item {\bf If one needs to flip an upper bound to a lower bound or vice versa, look for a way to take reflections or complements.} Sometimes one needs a lower bound for some quantity, but only has techniques that give upper bounds. In some cases, though, one can ``reflect'' an upper bound into a lower bound (or vice versa) by replacing a set $E$ contained in some space $X$ with its complement $X\backslash E$, or a function $f$ with its negation $-f$ (or perhaps subtracting $f$ from some dominating function $F$ to obtain $F - f$). This trick works best when the objects being reflected are contained in some sort of ``bounded'', ``finite measure'', or ``absolutely integrable'' container, so that one avoids having the dangerous situation of having to subtract infinite quantities from each other.
		
		A typical example of this is when one deduces downward monotone convergence for sets from upward monotone convergence for sets.
		\item {\bf Uncountable unions can sometimes be replaced by countable or finite unions.}
		\item {\bf If it is difficult to work globally, work locally instead.}
		\item {\bf Be willing to throw away an exceptional set.}
		\item {\bf Draw pictures \& try to build counterexamples.}
		\item {\bf Try simpler cases 1st.}
		\item {\bf Abstract away any information that you believe or suspect to be irrelevant.}
		\item {\bf Exploit Zeno's paradox: a single epsilon can be cut up into countably many sub-epsilons.}
		\item {\bf If you expand your way to a double sum, a double integral, a sum of an integral, or an integral of a sum, try interchanging the 2 operations.}
		\item {\bf Pointwise control, uniform control, \& integrated (average) control are all partially convertible to each other.}
		\item {\bf If the conclusion \& hypotheses look particularly close to each other, just expand out all the definitions \& follow your nose.}
		\item {\bf Don't worry too much about exactly what $\varepsilon$ (or $\delta$, or $N$, etc.) needs to be. It can usually be chosen or tweaked later if necessary.}
		\item {\bf Once one has started to lose some constants, don't be hesitant to lose some more.}
		\item {\bf One can often pass to a subsequence to improve the convergence properties.} In real analysis, one often ends up possessing a sequence of objects, e.g. a sequence of functions $f_n$, which may converge in some rather slow or weak fashion to a limit $f$. Often, one can improve the convergence of this sequence by passing to a subsequence. E.g.:
		\begin{itemize}
			\item In a metric space, if a sequence $x_n$ converges to a limit $x$, then one can find a subsequence $x_{n_j}$ which converges quickly to the same limit $x$; e.g., one can ensure that $d(x_{n_j},x) < 2^{-j}$ (or one can replace $2^{-j}$ with any other positive expression depending on $j$). In particular, one can make $\sum_{j=1}^\infty d(x_{n_j},x)$ \& $\sum_{j=1}^\infty d(x_{n_j},x_{n_{j+1}})$ absolutely convergent, which is sometimes useful.
			\item A sequence of functions that converges in $L^1$ norm or in measure can be refined to a subsequence that converges pointwise a.e. as well.
			\item A sequence in a (sequentially) compact space may not converge at all, but some subsequence of it will always converge.
			\item The {\it pigeonhole principle}: A sequence which takes only finitely many values has a subsequence that is constant. More generally, a sequence which lives in the union of finitely many sets has a subsequence that lives in just 1 of these sets.
		\end{itemize}
		Often, the subsequence is good enough for one's applications, \& there are also a number of ways to get back from a subsequence to the original sequence, e.g.:
		\begin{itemize}
			\item In a metric space, if you know that $x_n$ is a Cauchy sequence, \& some subsequence of $x_n$ already converges to $x$, then this drags the entire sequence with it, i.e., $x_n\to x$ also.
			\item The {\it Urysohn subsequence principle}: In a topological space, if every subsequence of a sequence $x_n$ itself has a subsequence that converges to a limit $x$, then the entire sequence converges to $x$.
		\end{itemize}
		\item {\bf A real limit can be viewed as a meeting of the limit superior \& limit inferior.}		
	\end{itemize}
\end{enumerate}
The point of view of integration defined as a Riemann integral may be historically grounded \& useful in many areas of mathematics but is far from being adequate for the requirements of modern analysis since Riemann integral can be defined only for a special class of functions \& this class is not closed under the process of taking pointwise limits of sequence (not even monotonic sequences) of functions in this class.

``The useful \& far-reaching idea of Lebesgue \& others was to compute the $(n + 1)$-dimensional volume `in the other direction' by 1st computing the $n$-dimensional volume of the set where the function $> y$. This volume is a well-behaved, monotone nonincreasing function of $y$, which then can be integrated in the manner of Riemann. This method of integration not only works for a large class of functions (which is closed under taking pointwise limits), but it also greatly simplifies a problem that used to plague analysts: {\it Is it permissible to exchange limits \& integration?}'' -- \cite[Chap. 1, pp. 1--2]{Lieb_Loss2001}

Lebesgue integration theory is 1 of the great triumphs of 20th century mathematics \& is the culmination of a long struggle to find the right perspective from which to view integration theory.

%------------------------------------------------------------------------------%

\section{Mean-Field Game Theory -- Lý Thuyết Trò Chơi Trường Trung Bình}
\textbf{\textsf{Community -- Cộng đồng.}} {\sc Nicholetta Tchou (French), Đào Mạnh Khang (Vietnamese), Michael Hinterm\"uller (Austrian), Steven-Marian Stengl (German)}.

\subsection{Wikipedia{\tt/}mean-field game theory}
``{\it Mean-field game theory} is the study of strategic decision making by small interacting \href{https://en.wikipedia.org/wiki/Agent_(economics)}{agents} in very large populations. It lies at the intersection of \href{https://en.wikipedia.org/wiki/Game_theory}{game theory} with stochastic analysis \& \href{https://en.wikipedia.org/wiki/Control_theory}{control theory}. The use of the term ``mean field'' is inspired by \href{https://en.wikipedia.org/wiki/Mean-field_theory}{mean-field theory} in physics, which considers the behavior of systems of large numbers of particles where individual particles have negligible impacts upon the system. In other words, each agent acts according to his minimization or maximization problem taking into account other agents' decisions \& because their population is large we can assume the number of agents goes to infinity \& a representative agent exists.

In traditional \href{https://en.wikipedia.org/wiki/Game_theory}{game theory}, the subject of study is usually a game with 2 players \& discrete time space, \& extends the results to more complex situations by induction. However, for games in continuous time with continuous states (differential games or stochastic differential games) this strategy cannot be used because of the complexity that the dynamic interactions generate. On the other hand with MFGs we can handle large numbers of players through the mean representative agent \& at the same time describe complex state dynamics.

This class of problems was considered in the economics literature by \href{https://en.wikipedia.org/wiki/Boyan_Jovanovic}{Boyan Jovanovic} \& \href{https://en.wikipedia.org/wiki/Robert_W._Rosenthal}{Robert W. Rosenthal}, in the engineering literature by Minyi Huang, Roland Malhame, \& \href{https://en.wikipedia.org/wiki/Peter_E._Caines}{Peter E. Caines} \& independently \& around the same time by mathematicians Jean-Michel Lasry \& \href{https://en.wikipedia.org/wiki/Pierre-Louis_Lions}{Pierre-Louis Lions}.

In continuous time a mean-field game is typically composed of a \href{https://en.wikipedia.org/wiki/Hamilton%E2%80%93Jacobi%E2%80%93Bellman_equation}{Hamilton-Jacobi-Bellman equation} that describes the \href{https://en.wikipedia.org/wiki/Optimal_control}{optimal control} problem of an individual \& a \href{https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation}{Fokker--Planck equation} that describes the dynamics of the aggregate distribution of agents. Under fairly general assumptions it can be proved that a class of mean-field games is the limit as $N\to\infty$ of an $N$-player \href{https://en.wikipedia.org/wiki/Nash_equilibrium}{Nash equilibrium}.

A related concept to that of mean-field games is ``mean-field-type control''. In this case, a \href{https://en.wikipedia.org/wiki/Social_planner}{social planner} controls the distribution of states \& chooses a control strategy. The solution to a mean-field-type control problem can typically be expressed as a dual adjoint Hamilton-Jacobi-Bellman equation coupled with \href{https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation}{Kolmogorov equation}. Mean-field-type game theory is the multi-agent generalization of the single-agent mean-field-type control.

\subsubsection{General Form of a Mean-field Game}
The system of equations
\begin{equation*}
	\left\{\begin{split}
		-\partial_tu - \nu\Delta u + H(x,m,Du) &= 0,\\
		\partial_tm - \nu\Delta m - \nabla\cdot(D_pH(x,m,Du)m) &= 0,\\
		m(0) &= m_0,\\
		u(T,x) &= G(x,m(T)),
	\end{split}\right.
\end{equation*}
can be used to model a typical Mean-field game. The basic dynamics of this set of equations can be explained by an average agent's optimal control problem. In a mean-field game, an average agent can control their movement $\alpha$ to influence the population's overall location by
\begin{equation*}
	dX_t = \alpha_tdt + \sqrt{2\nu}dB_t,
\end{equation*}
where $\nu$: a parameter, $B_t$: a standard Brownian motion. By controlling their movement, the agent aims to minimize their overall expected cost $C$ throughout the time period $[0,T]$:
\begin{equation*}
	C = \mathbb{E}\left[\int_0^T L(X_s,\alpha_s,m(s))\,{\rm d}s + G(X_T,m(T))\right],
\end{equation*}
where $L(X_s,\alpha_s,m(s))$ is the running cost at time $s$ \& $G(X_T,m(T))$ is the terminal cost at time $T$. By this definition, at time $t$ \& position $x$, the value function $u(t,x)$ can be determined as
\begin{equation*}
	u(t,x) = \inf_\alpha \mathbb{E}\left[\int_t^T L(X_s,\alpha_s,m(s))\,{\rm d}s + G(X_T,m(T))\right].
\end{equation*}
Given the definition of the value function $u(t,x)$, it can be tracked by the Hamilton-Jacobi equation. The optimal action of the average players $\alpha^*(t,x)$ can be determined as $\alpha^*(t,x) = D_pH(x,m,Du)$. As all agents are relatively small \& cannot single-handedly change the dynamics of the population, they will individually adapt the optimal control \& the population would move in that way. This is similar to a Nash Equilibrium, in which all agents act in response to a specific set of others' strategies. The optimal control solution then leads to the Kolmogorov-Fokker-Planck equation $\partial_tm - \nu\Delta m - \nabla\cdot(D_pH(x,m,Du)m) = 0$.

\subsubsection{Finite State Games}
A prominent category of mean field is games with a finite number of states \& a finite number of actions per player. For those games, the analog of the Hamilton-Jacobi-Bellman equation is the Bellman equation, \& the discrete version of the Fokker-Planck equation is the Kolmogorov equation. Specifically, for discrete-time models, the players' strategy is the Kolmogorv equation's probability matrix. In continuous time models, players have the ability to control the transition rate matrix.

A discrete mean field game can be defined by a tuple $\mathcal{G} = (\mathcal{E},\mathcal{A},\{Q_a\},{\bf m}_0,\{c_a\},\beta)$ where $\mathcal{E}$ is the state space, $\mathcal{A}$ the action set, $Q_a$ the transition rate matrices, ${\bf m}_0$ the initial state, $\{c_a\}$ the cost functions \& $\beta\in\mathbb{R}$ a discount factor. Furthermore, a mixed strategy is a measurable function $\pi:\mathbb{R}^+\times\mathbb{E}\to\mathcal{P}(\mathcal{A})$, that associates to each state $i\in\mathcal{E}$ \& each time $t\ge0$ a probability measure $\pi_i(t)\in\mathcal{P}(\mathcal{A})$ on the set of possible actions. Thus $\pi_{i,a}(t)$ is the probability that, at time $t$ a player in state $i$ takes action $a$, under strategy $\pi$. Additionally, rate matrices $\{Q_a({\bf m}^\pi(t))\}_{a\in\mathcal{A}}$ define the evolution over the time of population distribution, where ${\bf m}^\pi(t)\in\mathcal{P}(\mathcal{E})$ is the population distribution at time $t$.

\subsubsection{Linear-quadratic Gaussian game problem}
From Caines (2009), a relatively simple model of large-scale games is the \href{https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic%E2%80%93Gaussian_control}{linear-quadratic Gaussian} model. The individual agent's dynamics are modeled as a \href{https://en.wikipedia.org/wiki/Stochastic_differential_equation}{stochastic differential equation}
\begin{equation*}
	dX_i = (a_iX_i + b_iu_i)dt + \sigma_idW_i,\ i = 1,\ldots,N,
\end{equation*}
where $X_i$: the state of the $i$th agent, $u_i$: control of the $i$th agent, $W_i$: independent \href{https://en.wikipedia.org/wiki/Wiener_process}{Wiener processes} $\forall i = 1,\ldots,N$. The individual agent's cost is
\begin{equation*}
	J_i(u_i,\nu) = \mathbb{E}\left[\int_0^\infty e^{-\rho t}[(X_i - \nu)^2 + ru_i^2]\,{\rm d}t\right],\ \nu = \Phi\left(\frac{1}{N}\sum_{k\ne i}^N X_k + \eta\right).
\end{equation*}
The coupling between agents occurs in the cost function.

\subsubsection{General \& Applied Use}
The paradigm of Mean Field Games has become a major connection between distributed decision-making \& stochastic modeling. Starting out tin the stochastic control literature, it is gaining rapid adoption across a range of applications, including:
\begin{enumerate}
	\item {\bf Financial market.} Carmona reviews applications in financial engineering \& economics that can be cast \& tackled within the framework of the MFG paradigm. Carmona argues that models in macroeconomics, contract theory, finance, $\ldots$, greatly benefit from the switch to continuous time from the more traditional discrete-time models. He considers only continuous time models in his review chapter, including systemic risk, price impact, optimal execution, models for bank runs, high-frequency trading, \& cryptocurrencies.
	\item {\bf Crowd motions.} MFG assumes that individuals are smart players which try to optimize their strategy \& path w.r.t. certain costs (equilibrium with rational expectations approach). MFG models are useful to describe the anticipation phenomenon: the forward part describes the crowd evolution while the backward gives the process of how the anticipations are built. Additionally, compared to multi-agent microscopic model computations, MFG only requires lower computational costs for the macroscopic simulations. Some researchers have turned to MFG in order to model the interaction between populations \& study the decision-making process of intelligent agents, including aversion \& congestion behavior between 2 groups of pedestrians, departure time choice of morning commuters, \& decision-making processes for autonomous vehicle.
	\item {\bf Control \& mitigation of Epidemics.} Since the epidemic has affected society \& individuals significantly, MFG \& mean-field controls (MFCs) provide a perspective to study \& understand the underlying population dynamics, especially in the context of the Covid-19 pandemic response. MFG has been used to extend the SIR-type dynamics with spatial effects or allowing for individuals to choose their behaviors \& control their contributions to the spread of the disease. MFC is applied to design the optimal strategy to control the virus spreading within a spatial domain, control individuals' decisions to limit their social interactions, \& support the government's nonpharmaceutical interventions.'' -- \href{https://en.wikipedia.org/wiki/Mean-field_game_theory}{Wikipedia{\tt/}mean-field game theory}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Ordinary Differential Equations (ODEs) -- Phương Trình Vi Phân Đạo Hàm Thường}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Teschl2012}. {\sc Gerald Teschl}. {\it ODEs \& Dynamical Systems}.
	
	{\bf Preface.} When publish a textbook on such a classical subject 1st equation you will be faced with is: {\it Why another book on this subject?} While there were many good books on the subject available, none of them quite fit my needs. Wanted a concise but rigorous introduction with full proofs that also covered classical topics e.g. Sturm--Liouville BVPs, differential equations in complex domain $+$ modern aspects of qualitative theory of differential equations.
	
	{\it Content.} Main aim: give a self-contained introduction to the field of ODEs with emphasis on dynamical systems point of view while still keeping an eye on classical tools. 1st part: introductory course for bachelor's level students, typically not possible to cover everything \& one has to skip some of the more advanced sects. 2nd part: a natural continuation beginning with planar examples (culminating in generalized Poincar\'e--Bendixson theorem), continuing with the fact that things get much more complicated in 3 \& more dimensions, \& ending with stable manifold \& Hartman--Grobmann theorem. 3rd \& last part gives a brief introduction to chaos, focusing on 2 selected topics: Interval maps with logistic map as prime example $+$ identification of homoclinic orbits as a source for chaos \& Melnikov method for perturbations of periodic orbits \& for finding homoclinic orbits. Show how a computer system {\it Mathematica} can help with investigation of differential equations.
	
	\begin{itemize}
		\item {\sf Chap. 1: Introduction.}
		\begin{itemize}
			\item {\sf{\sc Newton}'s equations.} In classical mechanics a particle is described by a point in space whose location is given by a function ${\bf x}:\mathbb{R}\to\mathbb{R}^3$.
			\item {\sf Classification of differential equations.}
			\item {\sf 1st-order autonomous equations.}
			\item {\sf Finding explicit solutions.}
			\item {\sf Qualitative analysis of 1st-order equations.}
			\item {\sf Qualitative analysis of 1st-order parabolic equations.}
		\end{itemize}
		\item {\sf Chap. 2: IVPs.}
		\begin{itemize}
			\item {\sf Fixed point theorems.}
			\item {\sf Basic existence \& uniqueness result.}
			\item {\sf Some extensions.}
			\item {\sf Dependence on initial condition.}
			\item {\sf Regular perturbation theory.}
			\item {\sf Extensibility of solutions.}
			\item {\sf{\sc Euler}'s method \& Peano theorem.}
		\end{itemize}
		\item {\sf Chap. 3: Linear equations.}
		\begin{itemize}
			\item {\sf Matrix exponential.}
			\item {\sf Linear autonomous 1st-order systems.}
			\item {\sf Linear autonomous equations of order $n$.}
			\item {\sf General linear 1st-order systems.}
			\item {\sf Linear equations of order $n$.}
			\item {\sf Periodic linear systems.}
			\item {\sf Perturbed linear 1st-order systems.}
			\item {\sf Appendix: Jordan canonical form.}
		\end{itemize}
		\item {\sf Chap. 4: Differential equations in complex domain.}
		\begin{itemize}
			\item {\sf Basic existence \& uniqueness result.}
			\item {\sf Frobenius method for 2nd-order equations.}
			\item {\sf Linear systems with singularities.}
			\item {\sf Frobenius method.}
		\end{itemize}
		\item {\sf Chap. 5: BVPs.}
		\begin{itemize}
			\item {\sf Introduction.}
			\item {\sf Compact symmetric operators.}
			\item {\sf Sturm--Liouville equations.}
			\item {\sf Regular Sturm--Liouville problems.}
			\item {\sf Oscillation theory.}
			\item {\sf Periodic Sturm--Liouville equations.}
		\end{itemize}
		\item {\sf Chap. 6: Dynamical systems.}
		\begin{itemize}
			\item {\sf Dynamical systems.}
			\item {\sf Flow of an autonomous equation.}
			\item {\sf Orbits \& invariant sets.}
			\item {\sf Poincar\'e map.}
			\item {\sf Stability of fixed points.}
			\item {\sf Stability via {\sc Lyapunov}'s method.}
			\item {\sf{\sc Newton}'s equation in 1D.}
		\end{itemize}
		\item {\sf Chap. 7: Planar dynamical systems.}
		\begin{itemize}
			\item {\sf Examples from ecology.}
			\item {\sf Examples from electrical engineering.}
			\item {\sf Poincar\'e--Bendixson theorem.}
		\end{itemize}
		\item {\sf Chap. 8: Higher dimensional dynamical systems.}
		\begin{itemize}
			\item {\sf Attracting sets.}
			\item {\sf Lorenz equation.}
			\item {\sf Hamiltonian mechanics.}
			\item {\sf Completely integrable Hamiltonian systems.}
			\item {\sf Kepler problem.}
			\item {\sf KAM theorem.}
		\end{itemize}
		\item {\sf Chap. 9: Local behavior near fixed points.}
		\begin{itemize}
			\item {\sf Stability of linear systems.}
			\item {\sf Stable \& unstable manifolds.}
			\item {\sf Hartman--Grobman theorem.}
			\item {\sf Appendix: Integral equations.}
		\end{itemize}
		\item {\sf Chap. 10: Discrete dynamical systems.}
		\begin{itemize}
			\item {\sf Logistic equation.}
			\item {\sf Fixed \& periodic points.}
			\item {\sf Linear difference equations.}
			\item {\sf Local behavior near fixed points}.
		\end{itemize}
		\item {\sf Chap. 11: 1D Discrete dynamical systems.}
		\begin{itemize}
			\item {\sf Period doubling.}
			\item {\sf{\sc Sarkovskii}'s theorem.}
			\item {\sf On def of chaos.}
			\item {\sf Cantor sets \& tent map.}
			\item {\sf Symbolic dynamics.}
			\item {\sf Strange attractors{\tt/}repellers \& fractal sets.}
			\item {\sf Homoclinic orbits as source for chaos.}
		\end{itemize}
		\item {\sf Chap. 12: Periodic solutions.}
		\begin{itemize}
			\item {\sf Smale horseshoe.}
			\item {\sf Smale--Birkhoff homoclinic theorem.}
			\item {\sf{\sc Melnikov}'s method for homoclinic orbits.}
		\end{itemize}
		\item {\sf Chap. 13: Chaos in higher dimensional systems.}
	\end{itemize}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Partial Differential Equations (PDEs) -- Phương Trình Vi Phân Đạo Hàm Riêng}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Brezis2011}. {\sc Ha\"im Brezis}. {\it Functional Analysis, Sobolev Spaces, \& Partial Differential Equations}.
	\item \cite{Evans2010}. {\sc Lawrence C. Evans}. {\it Partial Differential Equations}.
	
	{\sf Preface to 2e.} ``Although have not always followed these many pieces of advice \& criticism, have thought carefully about them all. When you write a big book on a big subject, the temptation is to include everything. A critic famously once imagine Tolstoy during the writing of {\it War \& Peace}: ``The book is long, but even if it were twice as long, if it were 3 times as long, there would always be scenes that have been omitted, \& these Tolstoy, waking up in the middle of the night, must have regretted. There must have been a night when it occurred to him that he had not included a yacht race $\ldots$'' ({\sc G. Moore}, {\it Avowals}).
	
	This image notwithstanding, I have tried to pack into this 2e as many fascinating new topics in PDE as I could manage, most notably in the new Chap. 12 on nonlinear wave equations. There are new sections on Noether's Theorem \& on local minimizers in calculus of variations, on Radon transform, on Turing instabilities for reaction-diffusion systems, etc. I have rewritten \& expanded the previous discussions on blow-up of solutions, on group \& phrase velocities, \& on several further subjects. Have also updated \& greatly increased citations to books in the bibliograpy \& have moved references to research articles to within the text. There are countless further minor modifications in notation \& wording. Most importantly, have added $\approx80$ new exercises, most quite interesting \& som rather elaborate. There are now $> 200$ in total. \& there is a yacht race among the problems for Chap. 10.'' -- LCE, Jan 2010, Berkely
		
	{\sf Preface to 1e.} ``Present in this book a wide-ranging survey of many important topics in theory of PDEs, with particular emphasis on various modern approaches. Have made a huge number of editorial decisions about what to keep \& what to toss out, \& can only claim that this selection seems to me about right. Of course include usual formulas for solutions of usual linear PDE, but also devote large amounts of exposition to energy methods within Sobolev spaces, to calculus of variations, to conservation laws, etc. Ggeneral working principles in the writing have been these:
	\begin{enumerate}
		\item {\bf PDE theory is (mostly) not restricted to 2 independent variables.} Many texts describe PDE as if functions of 2 variables $(x,y)$ or $(t,x)$ were all that matter. This emphasis seems to me misleading, as modern discoveries concerning many types of equations, both linear \& nonlinear, have allowed for rigorous treatment of these in any number of dimensions. Also find it unsatisfactory to ``classify'' PDEs: this is possible in 2 variables, but creates false impression that there is some kind of general \& useful classification scheme available in general.
		\item {\bf Many interesting equations are nonlinear.} Overall we know too much about linear PDE \& too little about nonlinear PDE. Have accordingly introduced nonlinear concepts early in the text \& have tried hard to emphasize everywhere nonlinear analogues of linear theory.
		\item {\bf Understanding generalized solutions is fundamental.} Many of PDEs we study, especially nonlinear 1st-order equations, do not in general possess smooth solutions $\Rightarrow$ essential to devise some kind of proper notion of generalized or weak solution. An important but subtle undertaking, \& much of the hardest material in this book concerns uniqueness of appropriately defined weak solutions.
		\item {\bf PDE theory is not a branch of functional analysis.} Whereas certain classes of equations can profitably be viewed as generating abstract operators between Banach spaces, insistence on an overly abstract viewpoint, \& consequent ignoring of deep calculus \& measure theoretic estimates, is ultimately limiting.
		\item {\bf Notation is a nightmare.} Have really tried to introduce consistent notation, which works for all the important classes of equations studied. This attempt is sometimes at variance with notational conventions within a given subarea.
		\item {\bf Good theory is (almost) as useful as exact formulas.} Incorporate this principle into the overall organization of the text, which is subdivided into 3 parts, roughly mimicking historical development of PDE theory itself. Part I concerns the search the explicit formulas for solutions, \& Part II abandoning of this quests in favor of general theory asserting the existence \& other properties of solutions for linear equations. Part III is mostly modern endeavor of fashioning general theory for important classes of nonlinear PDE.
	\end{enumerate}
	Also explicitly comment: intend the development within each section to be rigorous \& complete (exceptions being the frankly heuristic treatment of asymptotics in \S4.5 \& an occasional reference to a research paper). I.e., even locally within each chapter the topics do not necessarily progress logically from ``easy'' to ``hard'' concepts. There are many difficult proofs \& computations early on, but as compensation many easier ideas later. The student should certainly omit on 1st reading some of the more arcane proofs.
	
	Emphasize that this is a {\it textbook}, \& not a reference book. Have tried everywhere to present essential ideas in the clearest possible settings, \& therefore have almost never established sharp versions of any of theorems. Research articles \& advanced monographs, many of them listed in Bibliography, provide such precision \& generality. Goal has rather been to explain, as best I can, many fundamental ideas of the subject within fairly simple contexts.
	
	Have come to realize that I must be more than slightly mad to try to write a book of this length \& complexity, but I am not yet crazy enough to think that I have made no mistakes $\Rightarrow$ maintain a listing of errors which come to light, \& will make this accessible through \url{math.berkeley.edu} homepage.	
	\begin{itemize}
		\item {\sf1. Introduction.}
		\item {\sf2. 4 Important Linear PDE.}
		\item {\sf3. Nonlinear 1st-Order PDE.}
		\item {\sf4. Other Ways to Represent Solutions.}
		\item {\sf5. Sobolev Spaces.}
		\item {\sf6. 2nd-Order Elliptic Equations.}
		\item {\sf7. Linear Evolution Equations.}
		\begin{itemize}
			\item {\sf2nd-order parabolic equations.}
			\item {\sf2nd-order hyperbolic equations.}
			\item {\sf Hyperbolic systems of 1st-order equations.}
			\item {\sf Semigroup theory.}
		\end{itemize}
		\item {\sf8. Calculus of Variations.}
		\item {\sf9. Nonvariational Techniques.}
		\item {\sf10. Hamilton--Jacobi Equations.}
		\item {\sf11. Systems of Conservation Laws.}
		\item {\sf12. Nonlinear Wave Equations.}
		\item {\sf Appendix A: Notation.}
		\item {\sf Appendix B: Inequalities.}
		\item {\sf Appendix C: Calculus.}
		\item {\sf Appendix D: Functional Analysis.}
		\item {\sf Appendix E: Measure Theory.}
	\end{itemize}
	
	\item \cite{Gilbarg_Trudinger2001}. {\sc David Gilbarg, Neil S. Trudinger}. {\it Elliptic Partial Differential Equations of 2nd Order}.
	
	\item {\sc John C. Hunter}. {\it Notes on PDEs}.
	
	\begin{itemize}
		\item {\sf Chap. 1: Preliminaries.}
		\item {\sf Chap. 2: Laplace's Equation.}
		\item {\sf Chap. 3: Sobolev Spaces.}
		\item {\sf Chap. 4: Elliptic PDEs.}
		\item {\sf Chap. 5: Heat \& Schr\"odinger Equations.}
		\item {\sf Chap. 6: Parabolic Equations.}
		\item {\sf Chap. 7: Hyperbolic Equations.} Hyperbolic PDEs arise in physical applications as models of waves, e.g., acoustic, elastic, electromagnetic, or gravitational waves. Qualitative properties of hyperbolic PDEs differ sharply from those of parabolic PDEs. E.g., they have finite domains of influence \& dependence, \& singularities in solutions propagate without being smoothed.
		\begin{itemize}
			\item {\sf Wave equation.} Wave equation: a prototypical example of a hyperbolic PDE:
			\begin{equation}
				\label{wave}
				u_{tt} = \Delta u.
			\end{equation}
			Consider 1D wave equation on $\mathbb{R}$: $u_{tt} = u_{xx}$. General solution is d'Alembert solution $u(t,x) = f(x - t) + g(x + t)$ where $f,g$ are arbitrary functions (may verify directly). This solution describes a superposition of 2 traveling waves with arbitrary profiles, one propagating with speed 1 to the right, the other with speed 1 to the left. Cf. this solution with general solution of 1D heat equation $u_t = u_{xx}$ which is given for $t > 0$ by $u(t,x) = \frac{1}{\sqrt{4\pi t}}\int_\mathbb{R} e^{-\frac{(x - y)^2}{4t}}f(y)\,{\rm d}y$. Some of qualitative properties of wave equation that differ from those of heat equation, which are evident from these solutions, are:
			\begin{itemize}
				\item wave equation has finite propagation speed \& domains of influence
				\item wave equation is reversible in time
				\item solutions of wave equation do not become smoother in time
				\item wave equation does not satisfy a maximum principle.
			\end{itemize}
			A suitable IBVP for wave equation with Dirichlet BCs on a bounded open set $\Omega\subset\mathbb{R}^d$ for $u:\mathbb{R}\times\Omega\to\mathbb{R}$ is given by
			\begin{equation}
				\label{wave BVP}
				\left\{\begin{split}
					u_{tt} &= \Delta u&&\mbox{in }\mathbb{R}\times\Omega,\\
					u &= 0&&\mbox{on }\mathbb{R}\times\Gamma,\\
					u(0) = g,\ u_t(0) &= h&&\mbox{in }\Omega.
				\end{split}\right.
			\end{equation}
			Require 2 initial conditions since wave equation is 2nd-order in time. E.g., in 2D space, this IBVP would describe the small vibrations of an elastic membrane, with displacement $z = u(t,x,y)$, e.g., a drum. The membrane is fixed at its edge $\Gamma$, \& has initial displacement $g$ \& initial velocity $h$. Could also add a nonhomogeneous term to PDE, which would describe an external force, but omit it for simplicity.
			
			{\bf Energy estimates.}
			
			\item {\sf Defs. of weak solutions.}
			\item {\sf Existence of weak solutions.}
			\item {\sf Continuity of weak solutions.}
			\item {\sf Uniqueness of weak solutions.}
		\end{itemize}
		\item {\sf Chap. 8: Friedrich Symmetric Systems.}
	\end{itemize}
	
	\item {\sc Trần Vĩnh Hưng}. {\it An Undergraduate Course in Partial Differential Equations}.
	
	{\sf Preface.} PDEs are often used to describe various phenomena across natural sciences (physics, chemistry), social sciences (economics), engineering (electrical \& mechanical engineering), \& other scientific domains. From a mathematical viewpoint, many important PDEs are grounded in rich physical, geometric, \& probabilistic contexts.
	\begin{goal}
		Provide an overview of core concepts related to some fundamental PDEs, tailored for an upper-level undergraduate PDE class. Prerequisites in: multivariable calculus, ODEs, linear algebra, real analysis (e.g., at level of baby Rudin). Not required students have taken measure theory or functional analysis prior to this class. Distinctive feature of this text: avoid requiring prior knowledge of measure theory, function spaces, \& functional analysis.
	\end{goal}	
	Since PDEs form a large subject with many important \& influential topics, impossible to study all fascinating equations in a single undergraduate course. Instead, focus on selected foundational equations. The book should be thought of as a bridge to prepare students for graduate-level PDE courses. In particular, it will not contain contents related to measure theory \& functional analysis. Use ChatGPT to convert handwritten lecture notes to \LaTeX\ files -- a game-changing tip. Deeply appreciative of ChatGPT for its role in this translation process. aim at an upper-level undergraduate course without requirements on measure theory \& functional analysis, \& such a course seems suitable at a US institution.
	
	\begin{itemize}
		\item {\sf Chap. 1: Introduction to PDEs.}
		\begin{itemize}
			\item {\sf Introduction.} Distinguish between ODEs \& PDEs. ODEs are equations involving derivatives of exactly 1 variable of some unknown functions. PDEs are equations involving partial derivatives of some unknown functions. Basically, if $u$ is the unknown, then a PDE for $u$ is an equation that has partial derivatives of $u$ in it. Can view ODEs as a subset of PDEs, but surely not vice versa. PDEs are often used to describe various phenomena coming from: Natural Sciences: physics, chemistry, $\ldots$ Social Sciences: economics, $\ldots$ Engineering: electrical engineering, mechanical engineering, $\ldots$. E.g., denote by $u(t,x) =$ temperature at location $x$ \& time $t\ge0$ then under some appropriate conditions, $u$ solves a {\it heat equation}. There are many important PDEs with rich backgrounds from physical, geometric, \& probabilistic phenomena, \& impossible to study them all in an undergraduate PDE course. Can only select some basic \& important ones to focus on. Give motivations to each PDE.
			\item {\sf Notations.}
			\item {\sf An example of a PDE.}
			\item {\sf Linear PDEs \& 4 Important Equations.} In general, a PDE can be written as $L[u] = 0$ where $u$: unknown, $L[\cdot]$: a certain differential operator. Another form: $L[u] = f(x)$ where RHS $f = f(x)$: a given function, typically representing a source term. Def: $L[\cdot]$ is a \emph{linear differential operator} if $L[su + rv] = sL[u] + rL[v]$, $\forall r,s\in\mathbb{R}$, $u,v$: smooth functions. If $L[\cdot]$ is a linear differential operator, $L[u] = 0,L[u] = f(x)$ are linear PDEs, then for $u_1,u_2$: 2 solutions, then so is its linear combination $ru_1 + su_2$ for $r,s\in\mathbb{R}$: {\it Superposition principle}: simple but very important point, will use this superposition principle a lot when study linear PDEs. There are many important linear PDEs, focus on 4 most basic \& important PDEs.
			\item {\sf Some Nonlinear Equations.}
			\begin{itemize}
				\item {\sf Linear transport equation} of the form $L[u] = u_t + cu_x = 0$ in $(0,\infty)\times\mathbb{R}$.
				\item {\sf Laplace's equation} of the form $L[u] = -\Delta u(x) = 0$ in $\mathbb{R}^d$.
				\item {\sf Heat equation} of the form $L[u] = u_t - \Delta u = 0$ in $(0,\infty)\times\mathbb{R}^d$.
				\item {\sf Wave equation} of the form $L[u] = u_{tt} - \Delta u = 0$ in $(0,\infty)\times\mathbb{R}^d$.
			\end{itemize}
			Laplace's equation represents an elliptic PDE. Heat equation represents a parabolic PDE. Wave equation represents a hyperbolic PDE.
			\item {\sf Some More Characterizations of PDEs.} Most of important PDEs in practice are nonlinear, i.e., $L[u]$ is not a linear operator. Will not be able to study all such important nonlinear PDEs, only focus on some cases.
			\begin{itemize}
				\item {\sf Burgers' equation} of the form $u_t + uu_x = 0$ in $(0,\infty)\times\mathbb{R}$, typically, come with an initial condition $u(0,x) = g(x)$. Burgers' equation is a very important equation in the literature, use {\it method of characteristics} to study it. Although Burgers' equation is nonlinear, if still naively assume that $u = a$, $u(t,x) = g(x - tu(t,x))$: an implicit relation as $u$ occurs on both sides. If this holds, then does $u$ solve Burgers' equation?
				\item {\sf Hamilton--Jacobi equation} of the form \fbox{$u_t + H(Du) = 0$} in $(0,\infty)\times\mathbb{R}^d$, $u(0,x) = g(x)$ where $H:\mathbb{R}^d\to\mathbb{R}$: a given function, called {\it Hamiltonian} in the literature. If $H$ is not a linear function, then Hamilton--Jacobi equation is nonlinear. Ex: Hamiltonians $H({\bf x}) = |{\bf x}|,H({\bf x}) = |{\bf x}|^2$ for ${\bf x}\in\mathbb{R}^d$.
			\end{itemize}
			Superposition principle is not true for nonlinear PDEs: 1 of reasons why rather hard to study nonlinear PDEs in general.
			\item {\sf Goals in Studying PDEs.} 1st, for each meaningful PDE, will give motivation of why study it. Then aim:
			\begin{enumerate}
				\item {\it Solve PDE explicitly if possible.} Doable for some equations, but not so in general.
				\item When PDEs are {\it not explicitly solvable}, then what do we do? Want to develop some theories to study PDE \& their solutions.
			\end{enumerate}
			Typically, in 2nd scenario, 1st main goal: {\it wellposedness theory}, which consists of 3 main questions:
			\begin{itemize}
				\item {\it Existence}: Does PDE have a solution?
				\item {\it Uniqueness}: Is there only 1 solution to PDE?
				\item {\it Stability}: Do small changes in initial or boundary conditions create only small changes in solutions?
			\end{itemize}
			Say a PDE is {\it wellposed} if all 3 points hold. For problems arising from physical applications, rather important to have 1 \& only 1 solution, which is consistent with phenomena. Further, would prefer that our problem is stable, i.e., unique solution would change just a little if conditions specifying problem change a little. This stability is also extremely important when need to approximate problem either theoretically or numerically.
			
			After wellposedness theory is established, study properties of solutions e.g.:
			\begin{itemize}
				\item {\it Regularity theory}: How regular{\tt/}smooth is our solution?
				\item {\it Asymptotic behavior}: What is behavior of $u(t,x)$ w.r.t. parameters (typically small ones) in problem?
				\item {\it Large time behavior}: What is the behavior of $\lim_{t\to\infty} u(t,x)$?
			\end{itemize}
			These are very important questions in applications.
		\end{itemize}
		\item {\sf Chap. 2: Transport Equation.}
		\begin{itemize}
			\item {\sf Transport Equation with Constant Coefficients.}
			\item {\sf Nonhomogeneous Transport Equation.}
			\item {\sf General Transport Equations.}
			\item {\sf Transport Equation in Multidimensions.}
		\end{itemize}
		\item {\sf Chap. 3: Laplace \& Heat Equations.}
		\begin{itemize}
			\item {\sf Derivations of Laplace \& Heat Equations.}
			\item {\sf Laplace's Equation \& Poisson's Equation.}
			\item {\sf Mean Value Property of Harmonic Functions.}
			\item {\sf Strong Maximum Principle \& A Uniqueness Result for Harmonic Functions.}
			\item {\sf{\sc Liouville}'s Theorem.}
			\item {\sf Energy Method for Laplace Equation.}
			\item {\sf Heat Equation.}
			\item {\sf Heat Equation on 1st Quadrant.}
			\item {\sf Maximum Principle for Heat Equation.}
			\item {\sf Maximum Principle for Laplace Equation -- Revisited.}
			\item {\sf Energy Method for Heat Equation.}
			\item {\sf Nonhomogeneous Heat Equation.}
		\end{itemize}
		\item {\sf Chap. 4: Wave Equations.}
		\begin{itemize}
			\item {\sf Derivation of 1D Wave Equation.}
			\item {\sf1D Wave Equation.}
			\item {\sf Wave Equation in 1st Quadrant.}
			\item {\sf Geometric Interpretation of Solutions in 1D.}
			\item {\sf Energy Method \& Uniqueness of Solutions.}
			\item {\sf{\sc Duhamel}'s Principle for Nonhomogeneous Wave Equation.}
			\item {\sf2D \& 3D Wave Equations.}
		\end{itemize}
		\item {\sf Chap. 5: Separation of Variables \& Fourier Series.}
		\begin{itemize}
			\item {\sf Quick Overview of Fourier Series.}
			\item {\sf Homogeneous Heat Equations.}
			\item {\sf Nonhomogeneous Heat Equations.}
			\item {\sf Homogeneous Wave Equations.}
			\item {\sf Separation of Variables for a Porous Medium Equation.}
			\item {\sf Separation of Variables for Laplace Equation.}
			\item {\sf{\sc Tychonov}'s Solution to 1D Heat Equation.}
		\end{itemize}
		\item {\sf Chap. 6: 1st-order Equations.} 1st study general 1st-order equations using method of characteristics. Then study Burgers' equation \& Hamilton--Jacobi equations in further details. Def: A \emph{1st-order PDE} is a PDE that involves the unknown \& its 1st-order partial derivatives only. In particular, it does not involve 2nd-order or higher-order partial derivatives.
		\begin{itemize}
			\item {\sf Cauchy Problems for 1st-order PDE.} Most general form of Cauchy problems for 1st-order PDEs:
			\begin{equation*}
				\left\{\begin{split}
					u_t(t,x) + F(t,x,u,Du) &= 0&&\mbox{in }(0,\infty)\times\mathbb{R}^d,\\
					u(0,x) &= g(x)&&\mbox{on }\mathbb{R}^d.
				\end{split}\right.
			\end{equation*}
			\item {\sf{\sc Burger}'s Equation.}
			\item {\sf Rankine--Hugoniot Condition for {\sc Burgers}' Equation.}
			\item {\sf Shock Waves \& Rarefaction Waves for {\sc Burgers}' Equation.}
			\item {\sf Hamilton--Jacobi Equations.}
			\item {\sf Hamiltonian ODE.}
			\item {\sf Spatially Homogeneous Hamiltonians.}
			\item {\sf Hopf--Lax Formula for a Quadratic Hamilton--Jacobi Equation.}
			\item {\sf Connections Between a Quadratic Hamilton--Jacobi Equation \& {\sc Burgers}' Equation in 1D.}
		\end{itemize}
	\end{itemize}
	\item John 91
	
	\item \cite{Lions_Magenes1972}. {\sc J. L. Lions, E. Magenes}. {\it Problemes aux limites non homogenes et applications (tome I) -- Non-Homogeneous BVPs \& Applications Vol. I}.
	
	\begin{itemize}
		\item {\sf Chap. 1: Hilbert Theory of Trace \& Interpolation Spaces.} Aim: give fundamental results of theory of trace \& interpolation spaces in the {\it Hilbert case}. Some indications about possible generalizations to non-Hilbert case are given in Comments \& in Sect. 14 along with basic literature.
		\begin{itemize}
			\item {\sf1. Some Function Spaces.}
			\item {\sf2. Intermediate Derivatives Theorem.}
			\item {\sf3. Trace Theorem.}
			\item {\sf4. Trace Spaces \& Non-Integer Order Derivatives.}
			\item {\sf5. Interpolation Theorem.}
			\item {\sf6. Reiteration Properties \& Duality of Spaces $[X,Y]_0$.}
			\item {\sf7. Spaces $H^s(\mathbb{R}^d),H^s(\Gamma)$.}
			\item {\sf8. Trace Theorem in $H^m(\Omega)$.}
			\item {\sf9. Spaces $H^s(\Omega),s\ge0$.}
			\item {\sf10. Some Further Properties of Spaces $[X,Y]_0$.}
			\item {\sf11. Subspaces of $H^s(\Omega)$. Spaces $H_0^s(\Omega)$.}
			\item {\sf12. Spaces $H^{-s}(\Omega),s > 0$.}
			\item {\sf13. Intersection Interpolation.}
			\item {\sf14. Holomorphic Interpolation.}
			\item {\sf15. Another Intrinsic Definition of Spaces $[X,Y]_0$.}
			\item {\sf16. Compactness Properties.}
			\item {\sf17. Comments.}
		\end{itemize}
		
		\item {\sf Chap. 2: Elliptic Operators. Hilbert Theory.}
		\begin{itemize}
			\item {\sf1. Elliptic Operators \& Regular BVPs.}
			\item {\sf2. Green's Formula \& Adjoint BVPs.}
			\item {\sf3. Regularity of Solutions of Elliptic Equations in Interior of $\Omega$.}
			\item {\sf4. A priori Estimates in Half-Space.}
			\item {\sf5. A priori Estimates in Open Set $\Omega$ \& Existence of Solutions in $H^s(\Omega)$-Spaces, with Real $s\ge2m$.}
			\item {\sf6. Application of Transposition: Existence of Solutions in $H^s(\Omega)$-Spaces, with Real $s\le0$.}
			\item {\sf7. Application of Interpolation: Existence of Solutions in $H^s(\Omega)$-Spaces, with Real $0 < s < 2m$.}
			\item {\sf8. Complements \& Generalizations.}
			\item {\sf9. Variational Theory of BVPs.}
			\item {\sf10. Comments.}
			\item {\sf11. Problems.}
		\end{itemize}
		\item {\sf Chap. 3: Variational Evolution Equations.}
		\begin{itemize}
			\item {\sf1. An Isomorphism Theorem.}
			\item {\sf2. Transposition.}
			\item {\sf3. Interpolation.}
			\item {\sf4. Example: Abstract Parabolic Equations, Initial Condition Problem (I).}
			\item {\sf5. Example: Abstract Parabolic Equations, Initial Condition Problem (II).}
			\item {\sf6. Example: Abstract Parabolic Equations, Periodic Solutions.}
			\item {\sf7. Elliptic Regularization.}
			\item {\sf8. Equations of 2nd Order in $t$.}
			\item {\sf9. Equations of 2nd Order in $t$; Transposition.}
			\item {\sf10. Schroedinger Type Equations.}
			\item {\sf11. Schroedinger Type Equations; Transposition.}
			\item {\sf12. Comments.}
			\item {\sf13. Problems.}
		\end{itemize}
	\end{itemize}
	
	\item {\sc J. L. Lions, E. Magenes}. {\it Problemes aux limites non homogenes et applications (tome II) -- Non-Homogeneous BVPs \& Applications Vol. II}.
	\begin{itemize}
		\item {\sf Chap. 4: Parabolic Evolution Operators. Hilbert Theory.}
		\item {\sf Chap. 5: Hyperbolic Evolution Operators, of Petrowski \& of Schroedinger. Hilbert Theory.}
		\item {\sf Chap. 6: Applications to Optimal Control Problems.}
		\item {\sf Appendix: BVPs \& Operator Extensions.}
	\end{itemize}
	
	\item {\sc J. L. Lions, E. Magenes}. {\it Problemes aux limites non homogenes et applications (tome III) -- Non-Homogeneous BVPs \& Applications Vol. III}.
	\begin{itemize}
		\item {\sf Chap. 7: Scalar \& Vector Ultra-Distributions.}
		\item {\sf Chap. 8: Elliptic BVPs in Spaces of Distributions \& Ultra-Distributions.}
		\item {\sf Chap. 9: Evolution Equations in Spaces of Distributions \& Ultra-Distributions.}
		\item {\sf Chap. 10: Parabolic BVPs in Spaces of Ultra-Distributions.}
		\item {\sf Chap. 11: Evolution Equations of 2nd Order in $t$ \& Schroedinger Type Equations.}
		\item {\sf Appendix: Calculus of Variations in Gevrey Type Spaces.}
	\end{itemize}
	
	\item Strauss 07
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Weak solution -- Nghiệm yếu}

\begin{definition}[Weak solution -- Nghiệm yếu]
	``In mathematics, a \emph{weak solution} (also called a \emph{generalized solution}) to an ODE or PDE is a function for which the derivatives may not all exist but which is nonetheless deemed to satisfy the equation in some precisely defined sense. There are many different definitions of weak solution, appropriate for different classes of equations. 1 of the most important is based on the notion of \href{https://en.wikipedia.org/wiki/Distribution_(mathematics)}{distributions}.'' -- \href{https://en.wikipedia.org/wiki/Weak_solution}{Wikipedia{\tt/}weak solution}
\end{definition}
``Avoiding the language of distributions, one starts with a differential equation \& rewrites it in such a way that no derivatives of the solution of the equation show up (the new form is called the \href{https://en.wikipedia.org/wiki/Weak_formulation}{weak formulation}, \& the solutions to it are called {\it weak solutions}). Somewhat surprisingly, a differential equation may have solutions which are not differentiable; \& the weak formulation allows one to find such solutions.

Weak solutions are important because many differential equations encountered in modeling real-world phenomena do not admit of sufficiently smooth solutions, \& the only way of solving such equations is using the weak formulation. Even in situations where an equation does have differentiable solutions, it is often convenient to 1st prove the existence of weak solutions \& only alter show that those solutions are in fact smooth enough.'' -- \href{https://en.wikipedia.org/wiki/Weak_solution}{Wikipedia{\tt/}weak solution}

\begin{example}[1st-order wave equation]
	The 1st-order \href{https://en.wikipedia.org/wiki/Wave_equation}{wave equation} $\partial_tu + \partial_xu = 0$ in $\mathbb{R}^2$ with $u = u(t,x)$ has the weak form $\int_{\mathbb{R}^2} u\partial_t\varphi + u\partial_x\varphi\,{\rm d}t\,{\rm d}x = 0$ has a solution $u(t,x) = |t - x|$ which may be checked by splitting the integrals over region $\{x\ge t\}$ \& $\{x\le t\}$ where $u$ is smooth.
\end{example}
``The notion of weak solution based on distribution is sometimes inadequate. In the case of \href{https://en.wikipedia.org/wiki/Hyperbolic_system}{hyperbolic systems}, the notion of weak solution based on distributions does not guarantee uniqueness, \& it is necessary to supplement it with {\it entropy conditions} or some other selection criterion. In fully nonlinear PDE e.g. \href{https://en.wikipedia.org/wiki/Hamilton%E2%80%93Jacobi_equation}{Hamilton-Jacobi equation}, there is a very different definition of weak solution called \href{https://en.wikipedia.org/wiki/Viscosity_solution}{\it viscosity solution}.'' -- \href{https://en.wikipedia.org/wiki/Weak_solution}{Wikipedia{\tt/}weak solution}

\subsubsection{General idea}
When solving a differential equation in $u$, one can rewrite it using a \href{https://en.wikipedia.org/wiki/Test_function}{test function} $\varphi$ s.t. whatever derivatives in $u$ show up in the equation, they are ``transferred'' via integration by parts to $\varphi$, resulting in an equation without derivatives of $u$. This new equation generalizes the original equation to include solutions which are not necessarily differentiable. The approach illustrated above works in great generality. Consider a linear differential operator in an open set $W\subset\mathbb{R}^d$:
\begin{equation*}
	P({\bf x},\partial)u({\bf x}) = \sum a_\alpha({\bf x})\partial^\alpha u({\bf x}),
\end{equation*}
where the multi-index $\alpha = (\alpha_1,\ldots,\alpha_d)$ varies over some finite set in $\mathbb{N}^d$ \& the coefficients $a_\alpha$ are smooth enough functions of ${\bf x}\in\mathbb{R}^d$. The differential equation $P({\bf x},\partial)u({\bf x} = 0$ can, after being multiplied by a smooth test function $\varphi\in C_c^\infty(W)$ \& integrated by parts, be written as
\begin{equation*}
	\int_W u({\bf x})Q({\bf x},\partial)\varphi({\bf x})\,{\rm d}{\bf x} = 0,
\end{equation*}
where the differential operator $Q({\bf x},\partial)$ is given by the formula
\begin{equation*}
	Q({\bf x},\partial)\varphi({\bf x}) = \sum (-1)^{|\alpha|}\partial^\alpha[a_\alpha({\bf x})\varphi({\bf x})],
\end{equation*}
which is the \href{https://en.wikipedia.org/wiki/Formal_adjoint}{formal adjoint} of $P({\bf x},\partial)$.

In summary, if the original (strong) problem was to find a $|\alpha|$-times differentiable function $u$ defined on the open set $W$ s.t. $P({\bf x},\partial)u({\bf x}) = 0$, $\forall{\bf x}\in W$ (a so-called {\it strong solution}), then an integrable function $u$ would be said to be a {\it weak solution} if $\int_W u({\bf x})Q({\bf x},\partial)\varphi({\bf x})\,{\rm d}{\bf x} = 0$, $\forall\varphi\in C_c^\infty(W)$.

%------------------------------------------------------------------------------%

\subsection{Viscosity solution -- Nghiệm trơn{\tt/}nhớt}

\begin{example}[Viscosity solution for Hamilton--Jacobi equation]
	Hamilton--Jacobi equation.
\end{example}

%------------------------------------------------------------------------------%

\subsection{Very weak solution -- Nghiệm rất yếu}

\begin{example}[Very weak solution of porous medium equation (PME) \cite{Vazquez2007}]
	.
\end{example}

\begin{example}[Very weak solution of multi-dimensional slow diffusion equations with a singular quenching term \cite{Dao_Diaz_Nguyen2020}]
	Given $f\in L_\delta^1(\Omega),\lambda\ge0$, a function $u\in L_\delta^1(\Omega)$ is called a \emph{very weak solution} of
	\begin{equation*}
		\left\{\begin{split}
			-\Delta(|u|^{m-1}u) + \lambda u &= f&&\mbox{in }\Omega,\\
			|u|^{m-1}u &= 1&&\mbox{on }\Gamma,
		\end{split}\right.
	\end{equation*}
	if $|u|^{m-1}u\in L^1(\Omega)$ and
	\begin{equation*}
		\int_\Omega u^m\Delta\varphi + \lambda u\varphi\,{\rm d}{\bf x} = \int_\Omega f\varphi\,{\rm d}{\bf x} - \int_\Gamma \partial_{\bf n}\varphi\,{\rm d}{\bf x}.
	\end{equation*}
\end{example}

\begin{example}[Very weak solution of NSEs \cite{Tsai2018}]
	.
\end{example}

\subsection{Navier--Stokes Equations [NSEs]}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Amirat_Bresch_Lemoine_Simon2001}. {\sc Youcef Amirat, Didier Bresch, J\'{e}r\^{o}me Lemoine, Jacques Simon}. {\it Effect of rugosity\footnote{sự gồ ghề.} on a flow governed by stationary NSEs}. {\sf[92 citations]}
	
	{\bf Keywords.} NSEs, asymptotic behavior, rugosity.
	
	{\bf Abstract.} Study stationary flow of a fluid occupying a 3D infinite horizontal domain bounded by a rough wall being at rest \& by a plane moving with a constant velocity. The rough wall is a plane covered with periodically distributed asperities of size $\varepsilon$. Prove: outside a neighborhood of rough region, the flow behaves asymptotically as a Couette flow, as $\varepsilon\to0$, up to an exponentially small error.
	\begin{itemize}
		\item {\sf 1. Introduction.} Numerical simulation of flows on rough walls, riblets or waves, e.g., requires \fbox{wall laws}. These wall laws are boundary conditions imposed on a fictive flat wall inside the domain in order to get rid of the region with strong gradient containing rugosity by taking into account their effect on the flow. Actually, these wall laws come from empirical logarithmic calculations $\to$ motivate mathematical study of effect of rugosity of some simplified situations in order to see how such laws could be rigorously derived. Consider a viscous incompressible fluid occupying a 3D infinite horizontal domain bounded by 2 walls, a plane one \& a rough one, which is a plane covered with periodically distributed rugosities. The rough wall is assumed to be at rest \& the plane one moves with a constant horizontal velocity. Prove: existence of a Couette flow, depending on the size $\varepsilon$ of the asperities, approximating the stationary Navier--Stokes flow outside the rough region, up to an error decreasing exponentially fast w.r.t. $\varepsilon$. A similar result established for a Stokes flow, with an explicitly calculated Couette approximaton. Extra difficulty: because of nonlinearity, no longer able to perform such an explicit calculation. Prove: velocity is the sum of 3 terms: a Couette flow $\frac{x_3}{l_3}$ where $x_3$ is the vertical coordinate \& $l_3$: thickness of the flow; another Couette flow $\varepsilon\left(\frac{x_3}{l_3} - 1\right)f_\varepsilon$ where $f_\varepsilon$ is a constant vector; a remainder $w_\varepsilon$ being bounded outside a neighborhood of the rough wall by $|w_\varepsilon(x)|\le c\exp\left(-\frac{c'x_3}{\varepsilon}\right)$. Exponential control of convergence relies on a Saint-Venant type estimate.
	\end{itemize}	
	
	\item \cite{Amrouche_Penel_Seloula2013}. {\sc Ch\'{e}rif Amrouche, Patrick Penel, Nour Seloula}. {\it Some remarks on the boundary conditions in the theory of NSEs}. {\sf[19 citations]}
	
	{\bf Keywords.} NSEs, boundary conditions, weak solutions.
	
	{\bf Abstract.} Address some theoretical questions related to the choice of boundary conditions, essential for modeling \& numerical computing in mathematical fluid mechanics. Unlike the standard choice of well known nonslip boundary conditions, emphasize 3 selected of slip conditions, \& particularly stress on the interaction between the appropriate functional setting \& status of these conditions.
	\begin{itemize}
		\item {\sf 1. Intro -- Motivation.} Consider in a bounded cylindrical domain $Q_T\coloneqq(0,T)\times\Omega$ NSE as fundamental model of classical fluid mechanics
		\begin{equation}
			\label{iNSEs}
			\partial_t{\bf u} + ({\bf u}\cdot\nabla){\bf u} = \nabla\cdot(2\nu\mathbb{D}{\bf u}) - \nabla p + {\bf f},\ \nabla\cdot{\bf u} = 0\mbox{ in } Q_T,\ {\bf u}|_{t=0} = {\bf u}_0\mbox{ in }\Omega,
		\end{equation}
		to describe viscous incompressible Newtonian fluids. Due to a constant density, conservation of mass is expressed by incompressibility condition. 1st eqn: conservation of momentum. Kinematic pressure $p$ so-called {\it associated pressure, de facto determined up to an additive constant in terms of velocity ${\bf u}(t,{\bf x})$}. Given data are ${\bf f}$: external force density, ${\bf u}_0$: initial velocity also prescribing initial pressure, $\Omega\subset\mathbb{R}^3$: geometrical bounded set filled by fluid, a connected domain with an impermeable smooth boundary $\Gamma$, $\nu > 0$: kinematic or eddy viscosity. Tensor $\mathbb{D}{\bf u}$ denotes {\it deformation tensor}, defined by symmetrized gradient of velocities $\frac{1}{2}(\nabla{\bf u} + \nabla^\top)$. Appropriate boundary conditions must be introduced to supplement \eqref{iNSEs} in a ``good agreement'' with the particular physical information. They lead to various IBVPs. Essential is the well-posedness of these problems which are of great importance for applications (meteorology, oceanography, environment, \& engineering) \& for numerical computation of corresponding flows. Operator $P_\sigma$: Helmholtz-Leray projector, abstract model for \eqref{iNSEs} reads
		\begin{equation}
			\label{iNSEs abstract}
			\partial_t{\bf u} + P_\varepsilon[({\bf u}\cdot\nabla){\bf u}] = \nu P_\sigma\Delta{\bf u} + P_\sigma{\bf f}.
		\end{equation}
		In general (in the case of domains with boundary) the Stokes operator $-P_\sigma\Delta$ is not the Laplacian operator, a known difficulty \& a crucial question, especially for numerical simulations \& for engineering applications: {\it How to dispose appropriate algorithms with the ``good'' Stokes operator taking into account the boundary conditions?}
		
		Many known results concern the case of non-slip boundary conditions, \cite{Serrin1959}: the choice of a non-slip boundary condition is not always suitable since it does not reflect behavior of fluid on or near the boundary in the general case, it does not contain the description of physical boundary layers near the walls.
		
		In order to solve various models for velocities, consider vector fields whose some components on the boundary vanish, the tangential ones or only the normal component. Geometry \& regularity of $\Omega$ play an important role. In Hilbertian theory the space ${\bf V}\coloneqq\{{\bf v}\in{\bf H}^1(\Omega);\nabla\cdot{\bf v} = 0\mbox{ in }\Omega,\ {\bf v}\cdot{\bf n} = 0\mbox{ on }\Gamma\}$ is the functional space of reference. Useful Helmholtz-type decompositions are required to characterize the considered vector fields, to distinguish \& to precise behavior on boundary.
		
		The basic spatial boundary condition for velocity ${\bf u}$, expresses the impermeability of $\Gamma$, \& says that normal component of ${\bf u}$ is zero: $u_n\coloneqq{\bf u}\cdot{\bf n} = 0$ on $\Gamma_T$, where $\Gamma_T\coloneqq(0,T)\times\Gamma$, ${\bf n}$: outward unit vector normal on $\Gamma_T$. One can preserve this impermeability condition as a constraint for ${\bf u}$, then need 2 more boundary conditions: different tangential behaviors can be observed along boundary, related to velocity or to vorticity. Tangential components of any vector field ${\bf v}$ are defined on $\Gamma_T$ \& computed by ${\bf v}_{\boldsymbol{\tau}}\coloneqq{\bf v}\times{\bf n}\times{\bf n} = {\bf v} - v_n{\bf n}$. Most of studied NS models follow Stokes proposal for velocity ${\bf u}_{\boldsymbol{\tau}} = {\bf 0}$ on $\Gamma_T$, precisely conditions expressing nonslip boundary conditions. A microscopic rugosity of boundary or viscosity of fluid can justify use of such conditions. Together obviously lead to ${\bf u}|_{\Gamma_T} = {\bf 0}$, standard homogeneous Dirichlet--Stokes boundary conditions.
		
		H. Navier \cite{Navier1827} have suggested in 1824 another type of complementary boundary conditions, based on a proportionality between tangential components of normal dynamic tensor \& velocity
		\begin{equation}
			\label{Navier slip b.c.}
			2\nu[\mathbb{D}{\bf u}\cdot{\bf n}]_{\boldsymbol{\tau}} + \alpha{\bf u}_{\boldsymbol{\tau}} = {\bf 0}\mbox{ on }\Gamma_T,
		\end{equation}
		where $\alpha\ge0$: coefficient of friction, can depend on rugosity of $\Gamma$, also can depend on velocity field itself \& on viscosity parameter. Corresponding NS model \eqref{iNSEs} with Navier's slip b.c. \eqref{Navier slip b.c.} is well-posed \& theory is in recent progress. Navier boundary conditions are often used to simulate flows near rough walls (Amirat-Bresch-Lemoine-Simon [2], Bucur-Feireisl-Necasova [17], Bucur-Feireisl-Necasova-Wolf [18], Jager-Michelic [27] \& [28], Bulicek-Malek-Rajagopal [19] (such as in aerodynamics, in weather forecasts \& in hemodynamics) as well as perforated walls ([7]). Such slip boundary conditions are used in LES of turbulent flows.
		
		Taking use of vorticity vector field $\boldsymbol{\omega}\coloneqq\nabla\times{\bf u}$, in the case of a flat boundary \& when $\alpha = 0$, $u_n = 0$ \& Navier's slip bc may be replaced by {\it Navier-type boundary conditions}:
		\begin{equation}
			u_n = 0,\ \operatorname{curl}{\bf u}\times{\bf n} = {\bf 0}\mbox{ on }\Gamma_T.
		\end{equation}
		Among other choices of slip boundary conditions, related to vorticity, consider generalized impermeability conditions (see Bellout-Neustupa-Penel [10])
		\begin{equation}
			\nabla\times{\bf u}\cdot{\bf n} = \boldsymbol{\omega}\cdot{\bf n} = 0,\ \nabla\times\boldsymbol{\omega}\cdot{\bf n} = 0\mbox{ on }\Gamma_T.
		\end{equation}
		With these 2 complementary boundary conditions, NS model looks promising, it presents not less than the same qualitative properties as standard model with Dirichlet--Stokes boundary conditions.
		
		\item {\sf2. Notations \& preliminary results.}
		\item {\sf3. $L^p$-theory for Stokes problem.}
		\item {\sf4. Variant of Stokes problem $(\mathcal{S}_n)$.}
		\item {\sf5. $L^P$-theory for Stokes problem with pressure boundary condition.}
		\item {\sf6. Time-dependent Stokes problem.}
		\item {\sf7. Navier--Stokes model with generalized impermeability b.c.}
	\end{itemize}
		
	\item \cite{Amrouche_Rodriguez-Bellido2011}. {\sc Ch\'{e}rif Amrouche, M. \'{A}ngeles Rodr\'{\i}guez-Bellido}. {\it Stationary Stokes, Oseen, \& NSEs with singular data}.
	\item \cite{An_Li2009}. {\sc Rong An, Kai Tai Li}. {\it Existence of weak solution to nonhomogeneous steady NSEs with mixed boundary conditions}.
	\item \cite{An_Li_Li2009}. {\sc Rong An, Yuan Li, Kai Tai Li}. {\it Regularity of solutions to stationary NSEs with mixed boundary conditions}.
	\item \cite{Bansch2001}. {\sc Eberhard B\"{a}nsch}. {\it Finite element discretization of the NSEs with a free capillary surface}.
	\item \cite{Bellout_Neustupa_Penel2004}. {\sc Hamid Bellout, Ji\v{r}\'i Neustupa, Patrick Penel}. {\it On the NSE with boundary conditions based on vorticity}.
	\item \cite{Benes2011}. {\sc Michal Bene\v{s}}. {\it Mixed IBVP for 3D NSEs in polyhedral domains}.
	\item \cite{Benes_Kucera2007}. {\sc Michal Bene\v{s}, Petr Ku\v{c}era}. {\it Non-steady NSEs with homogeneous mixed boundary conditions \& arbitrarily large initial condition}.
	\item \cite{Benes_Kucera2012}. {\sc Michal Bene\v{s}, Petr Ku\v{c}era}. {\it On the Navier--Stokes flows for heat-conducting fluids with mixed boundary conditions}.
	\item \cite{Benes_Kucera2016}. {\sc Michal Bene\v{s}, Petr Ku\v{c}era}. {\it Solutions to the NSEs with mixed boundary conditions in 2D bounded domains}.	
	\item \cite{Bernardi_Hecht_Verfurth2009}. {\sc Christine Bernardi, Fr\'{e}d\'{e}ric Hecht, R\"{u}diger Verf\"{u}rth}. {\it A finite element discretization of 3D NSEs with mixed boundary conditions}.
	\item \cite{Bernardi_Rebollo_Yakoubi2015}. {\sc Christine Bernardi, Tom\'{a}s Chac\'{o}n Rebollo, Driss Yakoubi}. {\it Finite element discretization of the Stokes \& NSEs with boundary conditions on the pressure}.
	\item \cite{Bernardi_Rebollo_Yakoubi2015}. {\sc Christine Bernardi, Toni Sayah}. {\it A posteriori error analysis of the time dependent NSEs with mixed boundary conditions}.
	\item \cite{Berselli2009}. {\sc Luigi C. Berselli}. {\it Some criteria concerning the vorticity \& the problem of global regularity for the 3D NSEs}.
	\item \cite{Boukrouche_Boussetouan_Paoli2014}. {\sc Mahdi Boukrouche, Imane Boussetouan, Laetitia Paoli}. {\it Non-isothermal Navier-Stokes system with mixed boundary conditions \& friction law: uniqueness \& regularity properties}.
	\item \cite{Braack_Mucha2014}. {\sc Malte Braack, Piotr Boguslaw Mucha}. {\it Directional do-nothing condition for the NSEs}.
	\item \cite{Brizitskii2009}. {\sc R. V. Brizitski\u{\i}}. {\it Investigation of a class of control problems for stationary NSEs with mixed boundary conditions}.
	\item \cite{Brown_Mitrea_Mitrea_Wright2010}. {\sc R. Brown, I. Mitrea, M. Mitrea, M. Wright}. {\it Mixed BVPs for the Stokes system}.
	\item \cite{Bucur_Feireisl_Necasova_Wolf2008}. {\sc Dorin Bucur, Eduard Feireisl, \v{S}\'{a}rka Ne\v{c}asov\'{a}, Joerg Wolf}. {\it On the asymptotic limit of the Navier-Stokes system on domains with rough boundaries}.
	\item \cite{Bulicek_Malek_Rajagopal2007}. {\sc M. Bul\'{i}\v{c}ek, J. M\'{a}lek, K. R. Rajagopal}. {\it Navier's slip \& evolutionary {N}avier-{S}tokes-like systems with pressure \& shear-rate dependent viscosity}.
	\item \cite{Cahouet_Chabard1988}. {\sc J. Cahouet, J.-P. Chabard}. {\it Some fast 3D finite element solvers for the generalized Stokes problem}.
	\item \cite{Camano_Oyarzua_Ruiz-Baier_Tierra2018}. {\sc Jessika Cama\~{n}o, Ricardo Oyarz\'{u}a,  Ricardo Ruiz-Baier, Giordano Tierra}. {\it Error analysis of an augmented mixed method for the Navier-Stokes problem with mixed boundary conditions}.
	\item \cite{Cattabriga1961}. {\sc Lamberto Cattabriga}. {\it Su un problema al contorno relativo al sistema di equazioni di Stokes}.
	\item \cite{Chen_Osborne_Qian2009}. {\sc Gui-Qiang Chen, Dan Osborne, Zhongmin Qian}. {\it The NSEs with the kinematic \& vorticity boundary conditions on non-flat boundaries}.
	\item \cite{Daikh_Yakoubi2017}. {\sc Yasmina Daikh, Driss Yakoubi}. {\it Spectral discretization of the Navier-Stokes problem with mixed boundary conditions}.
	\item \cite{Deuring_von-Walh1995}. {\sc Paul Deuring, Wolf von Wahl}. {\it Strong solutions of the Navier-Stokes system in Lipschitz bounded domains}.
	\item \cite{Ebmeyer_Frehse2001}. {\sc Carsten Ebmeyer, Jens Frehse}. {\it Steady NSEs with mixed boundary value conditions in 3D Lipschitzian domains}.
	\item \cite{Elghaoui_Pasquetti1999}. {\sc M.  Elghaoui, R. Pasquetti}. {\it Mixed spectral-boundary element embedding algorithms for the NSEs in the vorticity-stream function formulation}.
	\item \cite{Farhloul_Nicaise_Paquet2008}. {\sc Mohamed Farhloul, Serge Nicaise, Luc Paquet}. {\it A refined mixed FEM for the stationary NSEs with mixed boundary conditions}.
	\item \cite{Fefferman2006}. {\sc Charles L. Fefferman}. {\it Existence \& smoothness of the NSE}: {\bf The millennium prize problems}.
	\item \cite{Foias_Manley_Rosa_Temam2001}. {\sc C. Foias, O. Manley, R. Rosa, R. Temam}. {\it NSEs \& Turbulence}.
	\item \cite{Foias_Manley_Temam1987}. {\sc C. Foias, O. Manley,  R. Temam}. {\it Attractors for the B\'{e}nard problem: existence \& physical bounds on their fractal dimension}.
	\item \cite{Fujita_Kato1964}. {\sc Hiroshi Fujita, Tosio Kato}. {\it On the Navier-Stokes IVP. I}.
	\item \cite{Fursikov1980}. {\sc A. V. Fursikov}. {\it Some control problems \& results related to the unique solvability of the mixed BVP for the NSEs \& Euler 3D systems}.
	\item \cite{Fursikov1981}. {\sc A. V. Fursikov}. {\it Control problems \& theorems concerning unique solvability of a mixed BVP for 3D NSEs \& Euler equations}.
	\item \cite{Fursikov1982}. {\sc A. V. Fursikov}. {\it Properties of solutions of control problems that are connected with the Navier-Stokes system}.
	\item \cite{Galdi2000}. {\sc Giovanni P. Galdi}. {\it An introduction to the Navier-Stokes IBVP}.
	\item \cite{Galdi2011}. {\sc Giovanni P. Galdi}. {\it An introduction to the mathematical theory of NSEs}.
	\item \cite{Gie_Kelliher2012}. {\sc Gung-Min Gie, James P. Kelliher}. {\it Boundary layer analysis of the NSEs with generalized Navier boundary conditions}.
	\item \cite{Guerra_Sequeira2015}. {\sc Telma Guerra,  Ad\'{e}lia Sequeira, Jorge Tiago}. {\it Existence of optimal boundary control for NSEs with mixed boundary conditions}.
	\item \cite{Heywood_Rannacher_Turek1996}. {\sc John G. Heywood, Rolf Rannacher, Stefan Turek}. {\it Artificial boundaries \& flux \& pressure conditions for the incompressible NSEs}.
	\item \cite{Hoang2010}. {\sc Luan Thach Hoang}. {\it Incompressible fluids in thin domains with Navier friction boundary conditions (I)}.
	\item \cite{Hoang2013}. {\sc Luan Thach Hoang}. {\it Incompressible fluids in thin domains with Navier friction boundary conditions (II)}.
	\item \cite{Hoang_Sell2010}. {\sc Luan Thach Hoang, George R. Sell}. {\it NSEs with Navier boundary conditions for an oceanic model}.
	\item \cite{Hou_Pei2019}. {\sc Yanren Hou, Shuaichao Pei}. {\it On the weak solutions to steady NSEs with mixed boundary conditions}.
	\item \cite{Iftimie_Raugel2001}. {\sc Drago\c{s} Iftimie, Genevi\`eve Raugel}. {\it Some results on NSEs in thin 3D domains}.
	\item \cite{Iftimie_Raugel_Sell2007}. {\sc Drago\c{s} Iftimie, Genevi\`eve Raugel, George R. Sell}. {\it NSEs in thin 3D domains with Navier boundary conditions}.
	\item \cite{Iftimie_Sueur2011}. {\sc Drago\c{s} Iftimie, Franck Sueur}. {\it Viscous boundary layers for the NSEs with the Navier slip conditions}.
	\item \cite{Iliescu_John_Layton2002}. {\sc Traian Iliescu, Volker John, William J. Layton}. {\it Convergence of finite element approximations of large eddy motion}.
	\item \cite{Illarionov_Chebotarev2001}. {\sc A. A. Illarionov, A. Yu. Chebotarev}. {\it On the solvability of a mixed BVP for stationary NSEs}.
	\item \cite{Jager_Mikelic2000}. {\sc Willi J\"{a}ger, Andro Mikeli\'{c}}. {\it On the interface boundary condition of Beavers, Joseph, \& Saffman}.
	\item \cite{Jager_Mikelic2001}. {\sc Willi J\"{a}ger, Andro Mikeli\'{c}}. {\it On the roughness-induced effective boundary conditions for an incompressible viscous flow}.
	\item \cite{John2002}. {\sc Volker John}. {\it Slip with friction \& penetration with resistance boundary conditions for the NSEs---numerical tests \& aspects of the implementation}.
	\item \cite{John_Layton_Sahin2004}. {\sc Volker John, W. Layton, N. Sahin}. {\it Derivation \& analysis of near wall models for channel \& recirculating flows}.
	\item \cite{Kaladhar_Komuraiah_Madhusudhan-Reddy2019}. {\sc K. Kaladhar, E. Komuraiah, K. Madhusudhan Reddy}. {\it Soret \& Dufour effects on chemically reacting mixed convection flow in an annulus with {N}avier slip \& convective boundary conditions}.
	\item \cite{Kelliher2006}. {\sc James P. Kelliher}. {\it NSEs with Navier boundary conditions for a bounded domain in the plane}.
	\item \cite{Kim_Cao2015}. {\sc Tujin Kim, Daomin Cao}. {\it Some properties on the surfaces of vector fields \& its application to the Stokes \& Navier-Stokes problems with mixed boundary conditions}.
	\item \cite{Kim2016}. {\sc Tujin Kim}. {\it Erratum to ``Some properties on the surfaces of vector fields \& its application to the Stokes \& Navier-Stokes problems with mixed boundary conditions'' [{N}onlinear {A}nal. 113 (2015) 94--114] [ {MR}3281848]}
	\item \cite{Kim_Cao2016}. {\sc Tujin Kim, Daomin Cao}. {\it The steady {N}avier-{S}tokes \& Stokes systems with mixed boundary conditions including one-sided leaks \& pressure}.
	\item \cite{Kim_Cao2017}. {\sc Tujin Kim, Daomin Cao}. {\it Non-stationary NSEs with mixed boundary conditions}.
	\item \cite{Kim_Huang2018}. {\sc Tujin Kim, Feimin Huang}. {\it The non-steady Navier-Stokes systems with mixed boundary conditions including friction conditions}.
	\item \cite{Korobkov_Pileckas_Russo2015}. {\sc Mikhail V. Korobkov, Konstantin Pileckas, Remigio Russo}. {\it Solution of Leray's problem for stationary NSEs in plane \& axially symmetric spatial domains}.
	\item \cite{Kracmar_Neustupa2001}. {\sc S. Kra\v{c}mar, J. Neustupa}. {\it A weak solvability of a steady variational inequality of the Navier-Stokes type with mixed boundary conditions}.
	\item \cite{Kucera1998a}. {\sc Petr Ku\v{c}era}. {\it A structure of the set of critical points to the NSEs with mixed boundary conditions}.
	\item \cite{Kucera1998b}. {\sc Petr Ku\v{c}era}. {\it Solutions of the stationary Navier-Stokes equations with mixed boundary conditions in bounded domain}.
	\item \cite{Kucera2009}. {\sc Petr Ku\v{c}era}. {\it Basic properties of solution of the non-steady NSEs with mixed boundary conditions in a bounded domain}.
	\item \cite{Kucera2010}. {\sc Petr Ku\v{c}era}. {\it The time-periodic solutions of the NSEs with mixed boundary conditions}.
	\item \cite{Kucera_Skalak1998}. {\sc Petr Ku\v{c}era, Zden\v{e}k Skal\'{a}k}. {\it Local solutions to the NSEs with mixed boundary conditions}.
	\item \cite{Ladyzhenskaya1969}. {\sc O. A. Ladyzhenskaya}. {\it The Mathematical Theory of Viscous Incompressible Flow}.
	\item \cite{Lasiecka_Szulc_Zochowski2018}. {\sc Irena Lasiecka, Katarzyna Szulc, Antoni \.{Z}ochowski}. {\it Boundary control of small solutions to fluid-structure interactions arising in coupling of elasticity with NSE under mixed boundary conditions}.
	\item \cite{Lemarie-Rieusset2002}. {\sc Pierre Gilles Lemari\'{e}-Rieusset}. {\it Recent developments in the Navier-Stokes problem}.
	\item \cite{le-Roux_Reddy1993}. {\sc C. le Roux, B. D. Reddy}. {\it The steady NSEs with mixed boundary conditions: application to free boundary flows}.
	\item \cite{Lemarie-Rieusset2016}. {\sc Pierre Gilles Lemari\'{e}-Rieusset}. {\it The Navier-Stokes problem in the 21st century}.
	\item \cite{Leray1933}. {\sc Jean Lerray}. {\it \'{E}tude de diverses \'{e}quations int\'{e}grales non lin\'{e}aires et de quelques probl\`emes que pose l'hydrodynamique}.
	\item \cite{Leray1934a}. {\sc Jean Lerray}. {\it Essai sur les mouvements plans d'un liquide visqueaux que limitent des parois}.
	\item \cite{Leray1934b}. {\sc Jean Lerray}. {\it Sur le mouvement d'un liquide visqueux emplissant l'espace}.
	\item \cite{Li_An2008}. {\sc Kai Tai Li, Rong An}. {\it On the rotating NSEs with mixed boundary conditions}.
	\item \cite{Liakos2001}. {\sc Anastasios Liakos}. {\it Discretization of the NSEs with slip boundary condition}.
	\item \cite{Liakos2004}. {\sc Anastasios Liakos}. {\it Discretization of the Navier-Stokes equations with slip boundary condition. II}.
	\item \cite{Liu_Yu2008}. {\sc Dongjie Liu, Dehao Yu}. {\it The coupling method of natural boundary element \& mixed finite element for stationary NSE in unbounded domains}.
	\item \cite{Lyashko_Prokhur1985}. {\sc I. I. Lyashko, N. Z. Prokhur}. {\it Construction of stable schemes for solving a mixed BVP for evolution generalization of 3D NSEs}.
	\item \cite{Mazya_Rossmann2007}. {\sc Vladimir Maz'ya, J. Rossmann}. {\it$L_p$ estimates of solutions to mixed BVPs for the Stokes system in polyhedral domains}.
	\item \cite{Mazya_Rossmann2009}. {\sc Vladimir Maz'ya, J. Rossmann}. {\it Mixed boundary value problems for the stationary Navier-Stokes system in polyhedral domains}.
	\item \cite{Mihailov1968}. {\sc V. P. Miha\u{\i}lov}. {\it The mixed boundary value problem for the Navier-Stokes system of equations}.
	\item \cite{Mitrea_Monniaux2008}. {\sc Marius Mitrea, Sylvie Monniaux}. {\it On the analyticity of the semigroup generated by the Stokes operator with Neumann-type boundary conditions on Lipschitz subdomains of Riemannian manifolds}.
	\item \cite{Mitrea_Monniaux2009}. {\sc Marius Mitrea, Sylvie Monniaux}. {\it The nonlinear Hodge-Navier-Stokes equations in Lipschitz domains}.
	\item \cite{Monniaux2006}. {\sc Sylvie Monniaux}. {\it NSEs in arbitrary domains: the Fujita-Kato scheme}.
	\item \cite{Mukminov1992a}. {\sc F. Kh. Mukminov}. {\it On the decay of the solution of the first mixed problem for a linearized system of NSEs in a domain with a noncompact boundary}.
	\item \cite{Mukminov1992b}. {\sc F. Kh. Mukminov}. {\it On the rate of decay of the solution of a mixed problem for a system of NSEs in a domain with a noncompact boundary}.
	\item \cite{Nguyen_Raymond2015}. {\sc Nguyen Phuong Anh, Jean-Pierre Raymond}. {\it Boundary stabilization of the NSEs in the case of mixed boundary conditions}.
	\item \cite{Nicaise_Paquet_Rafilipojaona2007}. {\sc S. Nicaise, L. Paquet, Rafilipojaona}. {\it A refined mixed finite element method for stationary NSEs with mixed boundary conditions using Lagrange multipliers}.
	\item \cite{Ovsienko1978}. {\sc V. G. Ovsienko}. {\it A mixed boundary value problem for nonstationary NSEs on the exterior of a circular cylinder}.
	\item \cite{Papoutsis-Kiachagias_Magoulas_Mueller_Othmer_Giannakoglou2015}. {\sc E. M. Papoutsis-Kiachagias, N. Magoulas, J. Mueller, C. Othmer, K. C. Giannakoglou}. {\it Noise reduction in car aerodynamics using a surrogate objective function \& the continuous adjoint method with wall functions}
	\item \cite{Phan_Sergio2017}. {\sc Phan Đức Duy, S\'{e}rgio S. Rodrigues}. {\it Gevrey regularity for NSEs under Lions boundary conditions}.
	\item \cite{Plotnikov_Sokolowski2008}. {\sc P. I. Plotnikov, J. Sokolowski}. {\it Stationary BVPs for compressible NSEs}.
	\item \cite{Plotnikov_Sokolowski2012}. {\sc Pavel Plotnikov, Jan Soko\l owski}. {\it Compressible NSEs: Theory \& Shape Optimization}.
	\item \cite{Rossmann2009}. {\sc J\"{u}rgen Rossmann}. {\it Mixed BVPs for Stokes \& Navier-Stokes systems in polyhedral domains}.
	\item \cite{Sene_Ngom_Ngom2019}. {\sc Abdou S\`ene, Timack Ngom, Evrad M. D. Ngom}. {\it Global stabilization of the NSEs around an unstable steady state with mixed boundary kinetic energy controller}.
	\item \cite{Seregin2015}. {\sc Gregory Seregin}. {\it Lecture notes on regularity theory for NSEs}.	 
	\item \cite{Sohr2001,Sohr2013}. {\sc Hermann Sohr}. {\it The NSEs: An Elementary Functional Analytic Approach}.
	
	{\sf Primary objective.} To develop an elementary \& self-contained approach to the mathematical theory of a viscous incompressible fluid in a domain $\Omega\subset\mathbb{R}^d$, described by NSEs. Formulate the theory for a completely general domain $\Omega$.
	\item \cite{Su_Li2008}. {\sc Jian Su, Kai Tai Li}. {\it A FEM for 3D stationary rotating NSEs in primitive variables with mixed boundary conditions}.
	\item \cite{Tao2013}. {\sc Terence Tao}. {\it Localisation \& compactness properties of the Navier-Stokes global regularity problem}.
	\item \cite{Tartar2006}. {\sc Luc Tartar}. {\it An introduction to Navier--Stokes equation \& oceanography}.
	
	In memory of {\sc Jean Lerray \& Olga Ladyzhenskaya}, pioneering mathematical study of NSE -- an important of these lecture notes. {\sc Georges Tartar} dedicated his life to what he believed God expected from him. As for me, once the doubt had entered my mind, what other choice did it leave me but to search for the truth, in all fields?
	
	{\bf Preface.} To an uninformed observer, it may seem that there is more interest in NSE nowadays, but many who claim to be interested show such a lack of knowledge about continuum mechanics that one may wonder about such a superficial attraction. Could 1 of the Clay Millennium Prizes be the reason behind this renewed interest? Reading text of conjectures to be solved for winning that particular prize leaves the impression that the subject was not chosen by people interested in continuum mechanics, as selected questions have almost no physical content. Invariance by translation or scaling is mentioned, but why is invariance by rotations not pointed out \& why is Galilean invariance\footnote{Velocities involved for ordinary fluids being much smaller than the velocity of light $c$, no relativistic corrections are necessary \& Galilean invariance should then be used, but one should be aware that once the mathematical equation has been written it is not automatic that its solutions will only use velocities bounded by $c$. One should learn to distinguish between a mathematical property of an equation \& a conjecture that some property holds which one guesses from the belief that the equation corresponds to a physical problem. One should learn about which defects are already known concerning how a mathematical model describes physical reality, but one should not forget that a mathematical model which is considered obsolete from the physical point of view may still be useful for mathematical reasons. I often wonder why so many forget to mention the defects of the models that they study.
	
	-- Vận tốc liên quan đến chất lỏng thông thường nhỏ hơn nhiều so với vận tốc ánh sáng $c$, không cần hiệu chỉnh tương đối tính \& nên sử dụng bất biến Galilei, nhưng người ta nên lưu ý rằng 1 khi phương trình toán học đã được viết thì nó không tự động cho rằng nó lời giải sẽ chỉ sử dụng vận tốc giới hạn bởi $c$. Người ta nên học cách phân biệt giữa 1 thuộc tính toán học của 1 phương trình \& 1 phỏng đoán mà 1 số thuộc tính nắm giữ mà người ta đoán từ niềm tin rằng phương trình tương ứng với 1 bài toán vật lý. Người ta nên tìm hiểu về những khiếm khuyết đã được biết đến liên quan đến cách mô hình toán học mô tả thực tế vật lý, nhưng người ta không nên quên rằng 1 mô hình toán học được coi là lỗi thời xét theo quan điểm vật lý vẫn có thể hữu ích vì lý do toán học. Tôi thường tự hỏi tại sao nhiều người lại quên đề cập đến những khiếm khuyết của các mô hình mà họ nghiên cứu.} omitted, as it is the essential fact which makes equation introduced by {\sc Navier}\footnote{The equation which one calls now after both {\sc Navier \& Stokes} was introduced by {\sc Navier}, while {\sc Stokes} only later introduced the equation without inertial effects, which is linear \& does not present so much mathematical difficulty nowadays, but there are cases where the nonlinear term in Navier equation disappears \& the equation reduces to the Stokes equation, an example being irrotational flows. If one believes that the Stokes equation is a good model for small velocities (\& bounded derivatives of the velocity) then using Stokes equation in a frame moving at a local velocity \& invoking Galilean invariance makes one discover Navier equation; shall point out other defects of the model along the way.} much better than that introduced later by {\sc Stokes}? If one had used the word ``turbulence'' to make the donator believe that he would be giving 1 million dollars away for an important realistic problem in continuum mechanics, why has attention been restricted to unrealistic domains without boundary (the whole space $\mathbb{R}^3$, or a torus for periodic solutions), as if one did not know that vorticity is created at the boundary of the domain? The problems seem to have been chosen in the hope that they will be solved by specialists of harmonic analysis, \& it has given the occasion to some of these specialists to help others in showing the techniques that they use, as in a recent book  \cite{Lemarie-Rieusset2002}; some of the techniques are actually very similar to those that I have learnt in the theory of interpolation spaces, on which I have already written some lecture notes which I plan to revise, \& I hope that this particular set of lecture notes on NSE \& another one not yet finished on kinetic theory may help the readers understand a little more about the physical content of the equation, \& also its limitations, which many do not seem to be aware of.
	
	Being a mathematician interested in science, \& having learnt more than most mathematicians about various aspects of mechanics \& physics,\footnote{Classical mechanics is an 18th century point of view of mechanics, which requires ODEs as mathematical tools. Continuum mechanics is an 18th--19th century point of view of mechanics, which requires PDEs as mathematical tools; the same is true for many aspects of physics. However, 20th century aspects of mechanics (plasticity, turbulence) or physics (quantum effects) require mathematical tools which are beyond PDEs, similar to those that {\sc Tartar} has tried to develop in research work, improving concepts e.g. {\it homogenization, compensated compactness \& $H$-measures}.} 1 reason for teaching various courses \& writing lecture notes is to help isolated researchers to learn about some aspects unknown to most mathematicians whom they could meet, or read. A consequence of this choice is then to make researchers aware that some who claim to work on problems of continuum mechanics or physics have forgotten to point out known defects of the models that they use.\footnote{Of course, I also suffer from the same disease of not having learnt enough, but my hope is that by explaining what I have already understood \& by showing how to analyze \& criticize classical models, many will acquire my understanding \& a few will go much further than I have on the path of discovery.}
	
	I once heard my advisor, {\sc Jacques-Louis Lions}, mention that once the detailed plan of a book is made, the book is almost written, \& he was certainly speaking of experience as he had already written a few books at the time. He gave me the impression that he could write directly a very reasonable text, which he gave to a secretary for typing; maybe he then gave chapters to 1 of his students, as he did with me for 1 of his books \cite{Lions1969}, \& very few technical details had to be fixed. His philosophy seemed to be that there is no need to spend too much time polishing the text or finding the best possible statement, as the goal is to take many readers to the front of research, or to be more precise to 1 front of research, because in the beginning he changed topics every 2 or 3 years. As for myself, I have not yet written a book, \& the main reason is that I am quite unable to write in advance a precise plan of what I am going to talk about, \& I have never been very good at writing even in my mother tongue (French). When I write, I need to read again \& again what I have already written until I find the text acceptable (\& that notion of acceptability evolves with time \& I am horrified by my style of 20 years ago), so this way of writing is quite inefficient, \& makes writing a book prohibitively long. 1 solution would be not to write books, \& when I go to a library I am amazed by the number of books which have been written on so many subjects, \& which I have not read, because I never read much. Why then should I add a new book? However, I am even more amazed by the number of books which are not in the library, \& although I have access to a good inter-library loan service myself, I became concerned with how difficult it is for isolated students to have access to scientific knowledge (\& I do consider mathematics as part of science, of course).
	
	I also thought of a different question. It is clear that fewer \& fewer students in industrialized countries are interested in studying mathematics, for various reasons, \& as a consequence more \& more mathematicians are likely to come from developing countries. It will therefore be of utmost importance that developing countries should not simply become a reservoir of good students that industrialized countries would draw upon, but that these countries develop a sufficiently strong scientific environment for the benefit of their own economy \& people, so that only a small proportion of the new trained generations of scientists would become interested in going to work abroad. I have seen the process of decolonization at work in the early 1960s, \& I have witnessed the consequences of too hasty a transition, which was not to the benefit of the former colonies, \& certainly the creation of a scientific tradition is not something that can be done very fast. I see the development of mathematics as a good way to start building a scientific infrastructure, \& inside mathematics the fields that I have studied should play an important role, where mathematics interacts with continuum mechanics \& physics.
	
	In the spring of 1999, I found the right solution for me, which is to give a course \& to prepare lecture notes for students, trying to write down after each lecture the 2 or 3 pages describing what I have just taught; for such short texts my problems about writing are not too acute. I could hardly have guessed at the beginning of the course how much an introduction to oceanography my course would become, \& when after a short introduction \& the description of some classical methods for solving NSE (in the over-simplified version which mathematicians usually consider), it was time to describe some of the models considered in oceanography, I realized that I did not believe too much in the derivation of these models, \& I preferred to finish the course by describing some of the general mathematical tools for studying the nonlinear PDEs of continuum mechanics, some of which I have developed myself. The resulting set of lecture notes is not as good as I would have liked, but an important point was to make this introductory course available on the Internet. In the spring of 2000, I wrote similar lecture notes for a course divided into 2 parts, the 1st part on Sobolev spaces, \& the 2nd part on theory of interpolation spaces, \& in the fall of 2001, I wrote lecture notes for an introduction to kinetic theory; of course, it is my plan to finish \& review these lecture notes to make them more widely available by publishing them.
	
	I decided at that time to add some information that one rarely finds in courses of mathematics, something about the people who have participated in the creation of the knowledge related to the subject of the course. I had the privilege to study in Paris in the late 1960s, to have great teachers like {\sc Laurent Schwartz \& Jacques-Louis Lions}, \& to have met many famous mathematicians. This has given me a different view of mathematics than the one that comes from reading books \& articles, which I find too dry, \& I have tried to give a little more life to my story by telling something about the actors; for those mathematicians whom I have met, I have used their 1st name in the text, \& I have tried to give some simple biographical data for all people quoted in the text, in order to situate them, both in time \& in space. For mathematicians of the past, a large part of this information comes from using {\it The MacTutor History of Mathematics archive} (\url{http://www-history.mcs.stand.ac.uk/history}). My interest in history is not recent, but my interest in the history of mathematics has increased recently, in part from finding the above-mentioned archive, but also as a result of seeing so many ideas badly attributed, \& I have tried to learn more about the mathematicians who have introduced some of the ideas which I was taught when I was a student in Paris in the late 1960s, \& be as accurate as possible concerning the work of all. I hope that I shall be given the correct information by anyone who finds 1 of my inaccuracies, \& that I shall be forgiven for these unintentional errors.
	
	I was born in France in Dec 1946 from a Syrian father \& a French mother \& I left France for political reasons, \& since 1987 I have enjoyed the hospitality of an American university, {\sc Carnegie Mellon} University, in Pittsburgh PA, but I am still a French citizen, \& I only have resident status in United States. This may explain my interest in mentioning that others have worked in a different country than the one where they were born, \& I want to convey the idea that the development of mathematics is an international endeavor, but I am not interested in the precise citizenship of the people mentioned, or if they feel more attached to the country were they were born or the one where they work; e.g., I quote {\sc Olga Oleinik} as being born in Ukraine \& having worked in Moscow, Russia, \& obviously Ukraine was not an independent country when she was born, but was when she died; a French friend, {\sc G\'erard Tronel}, has told me that she did feel more Russian than Ukrainian, but if I have been told that information about her I completely lack information about others. Because some countries have not always existed or have seen their boundaries change by their own expansion or that of other countries, some of my statements are anachronistic, like when I say that {\sc Leonardo Da Vinci} was Italian, but I do not say that for {\sc Archimedes}, who is known to have died at the hand of a Roman soldier, or decide about {\sc Euclid}, or {\sc al Khwarizmi}, as it is not known where they were born.
	
	I observe that there have been efficient schools in some areas of mathematics at some places \& at some moments in time, \& when I was a student in Paris in the late 1960s, {\sc Jacques-Louis Lions} had mentioned that Moscow was the only other place comparable to Paris for its concentration of mathematicians. Although the conditions might be less favorable outside important centers, I want to think that a lot of good work could be done elsewhere, \& my desire is that my lecture notes may help isolated researchers participate more in the advance of scientific knowledge. A few years ago, an Italian friend, {\sc GianPietro Del Piero}, told me that he had taught for a few months in Somalia, \& he mentioned that 1 student had explained to him that he should not be upset if some of the students fell asleep during his lectures, because the reason was not their lack of interest in the course, but the fact that sometimes they had eaten nothing for a few days. It was by thinking about these courageous students who, despite the enormous difficulties that they encounter in their everyday life, are trying to acquire some precious knowledge about mathematics, that I devised my plan to write lecture notes \& make them available to all, wishing that they could arrive freely to isolated students \& researchers, working in much more difficult conditions than those having access to a good library, or in contact with good teachers. I hope that publishing this revised version will have the effect that it will reach many libraries scattered around the world, where isolated researchers have access.
	
	I hope that my lack of organizational skills will not bother the readers too much. I consider teaching courses like leading groups of newcomers into countries which are often unknown to them, but not unknown to me, as I have often wandered around; some members of a group who have already read about the region or have been in other expeditions with guides more organized than me might feel disoriented by my choice of places to visit, \& indeed I may have forgotten to show a few interesting places, but my goal is:
	\begin{goal}
		Familiarize readers with the subject \& encourage them to acquire an open \& scientific point of view, \& not to write a definitive account of the subject.
		
		-- Giúp người đọc làm quen với chủ đề \& khuyến khích họ có được quan điểm \& khoa học cởi mở, \& không viết 1 bài tường thuật dứt khoát về chủ đề này.
	\end{goal}
	There are results which are repeated, but it is inevitable in a real course that one should often recall results which have already been mentioned. There are also results which are mentioned without proof, \& sometimes they are proven later but sometimes they are not, \& if no references are given, one should remember that I have been trained as a mathematician, \& that my statements without proofs have indeed been proven in a mathematical sense, because if they had not I would have called them conjectures instead;\footnote{Some people like to talk of pure mathematics vs. applied mathematics, but I do not think that such a distinction is accurate, as I mentioned in the introduction of an article for a conference at \'Ecole Polytechnique (Palaiseau, France) in the fall of 1983, but because that introduction was cut by political censors, it is worth repeating that for what concerns different parts of mathematics there are those which I know, those which I do not know well but think that they could be useful to me, \& those which I do not know well but do not see how they could be useful to me, \& all this evolves with time, so I finally wonder if it is reasonable to classify mathematics as being pure or applied. I consider myself as an ``applied'' mathematician, although I give it a French meaning (a mathematician interested in other fields of science), opposed to a British meaning (a specialists of continuum mechanics, allowed to use an incomplete mathematical proof without having to call the result a conjecture), \& in French universities, applied mathematicians in the British style are found in departments of m\'ecanique. Probably for the reason of funding, which strangely enough is given more easily to people who pretend to do applied research, some who have studied to become mathematicians practice the art of using words which make naive people wrongly believe that they know continuum mechanics or physics, \& I find this attitude potentially dangerous for the university system.} however, I am also human \& my memory is not perfect \& I may have made mistakes. I think that the right attitude in mathematics is to be able to explain all the statements that one makes, but in a course one has to assume that the reader already has some basic knowledge of mathematics, \& some proofs of a more elementary nature are omitted. Here \& there I mention a result that I have heard of, but for which I never read a proof or did not make up my own proof, \& I usually say so. If many proofs are mine it does not necessarily mean that I was the 1st to prove the corresponding result, but that I am not aware of a prior proof, maybe because I never read much. Actually, my advisor mentioned to me that it is useful to read only the statement of a theorem \& one should read the proof only if one cannot supply one.\footnote{The MacTutor archive mentions an interesting anecdote in this respect concerning a visit of {\sc Antoni Zygmund} to the University of Buenos Aires, Argentina, in 1948; {\sc Alberto Calder\'on} was a student there \& he was puzzled by a question that {\sc Zygmund} had asked, \& he said that the answer was in {\sc Zygmund}'s own book {\it Trigonometric Series}, but there was disagreement on this point; what had happened was that {\sc Calder\'on} had read a statement in the book \& supplied his own proof, which was more general than the one written, so it also answered the question that {\sc Zygmund} had just asked, but {\sc Calder\'on} had wrongly assumed that {\sc Zygmund}'s proof in his book, which he had never checked, was similar to his. {\sc Franco Brezzi} mentioned to me that {\sc Ennio De Giorgi} had once told {\sc Claudio Baiocchi} something similar, that he almost never read a proof, \& that he did his own proofs for the interesting theorems but that he did not bother to think about the uninteresting ones.}
	
	My personal mathematical training has been in functional analysis \& PDEs, starting at \'Ecole Polytechnique, Paris, France, where I had 2 great teachers, {\sc Laurent Schwartz \& Jacques-Louis Lions}. Having studied there in order to become an engineer, but having had to change my orientation once I had been told that such a career required administrative skills (which I lack completely), I opted for doing research in mathematics with an interest in other sciences \& I asked {\sc Jacques-Louis Lions} to be my advisor, \& it was normal that once I had been taught enough on the mathematical side, I would apply my improved understanding to investigating questions of continuum mechanics \& physics which I had heard about as a student, \& to developing the new mathematical tools which are necessary for that.
	
	In my lectures I also try to teach mathematicians about the defects of the models used, but I want to apologize for some of the words which I use, which may have offended some. I have a great admiration for the achievements of physicists \& engineers\footnote{I am not mentioning biologists \& chemists because biology was not part of my studies, \& although I have learnt some chemistry, I only hope to understand it in a better way once my program for understanding continuum mechanics \& physics has progressed enough.} during the last century, \& a lot of the improvements in our lives result from their understanding, which is so different than the type of understanding that mathematicians are trained to achieve. If I write that something that they say does not make any sense, it is not a criticism towards physicists or engineers, who are following the rules of their profession, but it is a challenge to my fellow mathematicians that there is something there that mathematicians ought to clarify. I am grateful to {\sc Robert Dautray}\footnote{A good reference for learning classical mathematical tools \& their use in problems of engineering or physics is the collection of books that {\sc Robert Dautray} had persuaded {\sc Jacques-Louis Lions} to edit with him.} for offering me a position at Commissariat à l'\'Energie Atomique from 1982--1987, \& for helping me understand more about physics through his advice during these years; he helped me understand what the challenges are, \& I hope that through my lecture notes more will understand about the challenges, \& that should make Science progress.
	
	The support of a few friends gave me the strength to decide to complete the writing of some unfinished lecture notes \& to revise those which I had already written, with a view to publishing them to attain a wide audience. I want to express my gratitude to {\sc Th\'er\`ese Briffod}, for her hospitality when I carried out the 1st revision of this course in August 2002, but also for her help in making me understand better an important question in life, having compassion for those who are in difficulty.
	\begin{itemize}
		\item {\sf Introduction.} In teaching a mathematical course where NSE plays a role, one must mention the pioneering work of {\sc Jean Lerray} in the 1930s. Some of the problems that {\sc Jean Lerray} left unanswered are still open today,\footnote{Most problems are much too academic from the point of view of continuum mechanics, because the model used by {\sc Jean Lerray} is too crude to be meaningful, \& the difficulties of the open questions are merely of a technical mathematical nature. Also, {\sc Jean Leray} unfortunately called turbulent the weak solutions that he was seeking, \& it must be stressed that turbulence is certainly not about regularity or lack of regularity of solutions, nor about letting time go to $\infty$ either.} but some improvements were started by {\sc Olga Ladyzhenskaya}, followed by a few others, like James SERRIN, \& my advisor, {\sc Jacques-Louis Lions}, from whom I learnt the basic principles for the mathematical analysis of these equations in the late 1960s.
	\end{itemize}

	\item \cite{Temam1977,Temam2000}. {\sc Roger Temam}. {\it NSES: Theory \& Numerical Analysis}.
	\item \cite{Temam1983,Temam1995}. {\sc Roger Temam}. {\it NSEs \& nonlinear functional analysis}.
	\item \cite{Tsai2018}. {\sc Tai-Peng Tsai}. {\it Lectures on NSEs}.
	\item \cite{Verfurth1987}. {\sc R\"{u}diger Verf\"{u}rth}. {\it Finite element approximation of incompressible NSEs with slip boundary condition}.
	\item \cite{Verfurth1991}. {\sc R\"{u}diger Verf\"{u}rth}. {\it Finite element approximation of incompressible NSEs with slip boundary condition. II}.
	\item \cite{Yudovich1963}. {\sc V. I. Yudovich}. {\it Non-stationary flow of an ideal incompressible liquid}.
	\item \cite{Yudovich1967}. {\sc V. I. Yudovich}. {\it An example of the loss of stability \& the generation of a secondary flow of a fluid in a closed container}.
\end{enumerate}

\subsection{Schr\"odinger equations}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Weinstein1983}. {\sc Michael I. Weinstein}. {\it Nonlinear {S}chr\"{o}dinger equations \& sharp interpolation estimates}.
	\begin{itemize}
		\item NQBH. Master 2 Seminar: {\it On the smallest constant for a Gagliardo--Nirenberg functional inequality}. [\href{https://github.com/NQBH/advanced_STEM_beyond/blob/main/Master_of_Science/Master_Seminar/NQBH_Master_seminar.pdf}{report}][\href{https://github.com/NQBH/advanced_STEM_beyond/blob/main/Master_of_Science/Master_Seminar/NQBH_Master_seminar_summary.pdf}{summary}][\href{https://github.com/NQBH/advanced_STEM_beyond/blob/main/Master_of_Science/Master_Seminar/NQBH_Master_seminar_slide.pdf}{slide}]
	\end{itemize}
	{\bf Abstract.} Obtain a sharp sufficient condition for global existence for nonlinear Schr\"odinger equation $2i\phi_t + \Delta\phi + |\phi|^{2\sigma}\phi = 0$, in $\mathbb{R}^+\times\mathbb{R}^N$ in case $\sigma = \frac{2}{N}$, in terms of an exact stationary solution (nonlinear ground state) of NLS, derived by solving a variational problem to obtain the ``best constant'' for classical interpolation estimates of Nirenberg \& Gagliardo.
	\begin{itemize}
		\item {\sf Sect. 1: Introduction.} The ``best constant'' of an interpolation estimate among various norms often has an analytical or geometrical significance.
		\begin{goal}
			Present a relationship between the best constant for a classical interpolation inequality due to Nirenberg \& Gagliardo, \& a sharp criterion for existence of global solutions to nonlinear Schr\"odinger equation:
			\begin{equation}
				\label{nonlinear Schrodinger}
				\tag{nSch}
				2i\partial_t\phi + \Delta\phi + |\phi|^{2\sigma}\phi = 0\mbox{ in }\mathbb{R}^+\times\mathbb{R}^N,\ \phi(0,{\bf x}) = \phi_0({\bf x})
			\end{equation}
			in critical case $\sigma = \frac{2}{N}$.
		\end{goal}
		\item {\sf Sect. 2: Solution of a Variational Problem.}
		\item {\sf Sect. 3: Global Existence for IVP in Critical Case $\sigma = \frac{2}{N}$.}
		\item {\sf Sect. 4: Blowing Up Solutions.}
		\item {\sf Sect. 5: Numerical Observations \& Open Questions.}
	\end{itemize}
\end{enumerate}

\subsection{Water Waves Systems}
\textbf{\textsf{Community -- Cộng đồng.}} {\sc Vincent Duchene, David Lannes, Michael I. Weinstein}.

\noindent\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item {\sc Vincent Duch\^ene}. {\it Many Models for Water Waves}.
	\item \cite{Lannes2013}. {\sc David Lannes}. {\it The Water Waves Problem}.
\end{enumerate}

\subsection{Elliptic PDEs}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Agmon1965,Agmon2010}. {\sc Shmuel Agmon}. {\it Lectures on Elliptic BVPs}.
	\item \cite{Gilbarg_Trudinger2001}. {\sc David Gilbarg, Neil S. Trudinger}. {\it Elliptic PDEs of 2nd Order}.
	\item \cite{Grisvard1980}. {\sc Pierre Grisvard}. {\it BVPs in Nonsmooth Domains}.
	\item \cite{Grisvard1985,Grisvard2011}. {\sc Pierre Grisvard}. {\it Elliptic Problems in Nonsmooth Domains}.
	\item \cite{Han_Lin2011}. {\sc Qing Han, Fanghua Lin}. {\sc Elliptic PDEs}.
	\item \cite{Hung_Phuc2020}. {\sc Nguyễn Quốc Hưng, Nguyễn Công Phúc}. {\it Pointwise gradient estimates for a class of singular quasilinear equations with measure data}.
	
	{\bf Keywords.} Riesz's potential, Wolff's potential, pointwise gradient estimate, Reifenberg flat domain.
	
	{\bf Abstract.} Local \& global pointwise gradient estimates are obtained for solutions to quasilinear elliptic equation with measure data $-\nabla\cdot(A({\bf x},\nabla u)) = \mu$ in a bounded \& possibly nonsmooth domain $\Omega\subset\mathbb{R}^n$ where $\nabla\cdot(A({\bf x},\nabla u))$ is modeled after the $p$-Laplacian. Extend earlier known results to the singular case in which $\frac{3n - 2}{2n - 1} < p\le2 - \frac{1}{n}$.
	
	\begin{itemize}
		\item {\sf Sect. 1: Introduction \& main results.} Consider quasilinear elliptic equation with measure data $-\nabla\cdot(A({\bf x},\nabla u)) = \mu$ in a bounded open subset $\Omega$ of $\mathbb{R}^n$, $n\ge2$, $\mu$: a finite signed measure in $\Omega$, nonlinearity $A = (A_1,\ldots,A_n):\mathbb{R}^n\times\mathbb{R}^n\to\mathbb{R}^n$ is vector-valued function.
		
		\begin{goal}
			Obtain pointwise estimates for gradients of solutions to $-\nabla\cdot(A({\bf x},\nabla u)) = \mu$ by means of nonlinear potentials of Wolff type.
		\end{goal}
		Assume $A = A({\bf x},\xi)$ satisfies growth, ellipticity, \& continuity assumptions. Dini's condition $\int_0^1 \omega(r)^{\gamma_0}\frac{dr}{r} < \infty$.
		
		A typical model for main PDE is given by $p$-Laplace equation with measure data $-\Delta_p u\coloneqq-\nabla\cdot(|\nabla u|^{p - 2}\nabla u) = \mu$ in $\Omega$, or its nondegenerate version ($s > 0$): $-\nabla\cdot((|\nabla u| + s^2)^{\frac{p - 2}{2}}\nabla u) = \mu$ in $\Omega$.
		\item {\sf Sect. 2: Sharp quantitative $C^{1,\sigma}$ regularity estimates.}
		\item {\sf Sect. 3: Interior pointwise gradient estimates.}
		\item {\sf Sect. 4: Global pointwise gradient estimates.}
	\end{itemize}
	\item \cite{Ladyzhenskaya_Uraltseva1968}. {\sc Olga A. Ladyzhenskaya, Nina N. Ural'tseva}. {\it Linear \& Quasilinear Elliptic Equations}.
	\item \cite{Mazya_Rossmann2010}. {\sc Vladimir Maz'ya, J\"{u}rgen Rossmann}. {\it Elliptic Equations in Polyhedral Domains}.
	\item \cite{Necas1967,Necas2012}. {\sc Jind\v{r}ich Ne\v{c}as}. {\it Les m\'{e}thodes directes en th\'{e}orie des \'{e}quations elliptiques -- Direct Methods in The Theory of Elliptic Equations}.
\end{enumerate}

\subsection{Parabolic PDEs}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Friedman1964}. {\sc Avner Friedman}. {\it PDEs of Parabolic Type}.
	\item \cite{Holcman_Schuss2018}. {\sc David Holcman, Zeev Schuss}. {\it Asymptotics of Elliptic \& Parabolic PDEs -- \& Their Applications in Statistical Physics, Computational Neuroscience, \& Biophysics}.
	\item \cite{Knabner_Angermann2003}. {\sc Peter Knabner, Lutz Angermann}. {\it Numerical Methods for Elliptic \& Parabolic PDEs}.
	\item \cite{Krylov2008}. {\sc N. V. Krylov}. {\it Lectures on Elliptic \& Parabolic Equations in Sobolev Spaces}.
	\item \cite{Ladyzhenskaja_Solonnikov_Uralceva1968}. {\sc O. A. Lady\v{z}enskaja, V. A. Solonnikov, N. N. Ural'ceva}. {\it Linear \& Quasi-linear Equations of Parabolic Type}.
	\item \cite{Lunardi1995}. {\sc Alessandra Lunardi}. {\it Analytic Semigroup \& Optimal Regularity in Parabolic Problems}.
\end{enumerate}

\subsection{Hyperbolic PDEs}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Alinhac2009}. {\sc Serge Alinhac}. {\it Hyperbolic PDEs}.
	\item \cite{Benzoni-Gavage_Serre2007}. {\sc Sylvie Benzoni-Gavage, Denis Serre}. {\it Multidimensional Hyperbolic PDEs}.
	\item \cite{Ikawa2000}. {\sc Mitsuru Ikawa}. {\it Hyperbolic PDEs \& Wave Phenomena}.
	\item \cite{Lasiecka_Triggiani2000}. {\sc Irena Lasiecka, Roberto Triggiani}. {\it Control Theory for PDEs: Continuous \& Approximation Theories. II: Abstract Hyperbolic-Like Systems Over a Finite Time Horizon}.
	\item \cite{Lax1987}. {\sc Peter D. Lax}. {\it Hyperbolic Systems of Conversation Laws \& The Mathematical Theory of Shock Waves}.
	\item \cite{Lax2006} . {\sc Peter D. Lax}. {\it Hyperbolic PDEs}.
	\item \cite{Rauch2012}. {\sc Jeffrey Rauch}. {\it Hyperbolic PDEs \& Geometric Optics}.
	
	\item \cite{Tartar2008}. {\sc Luc Tartar}. {\it From Hyperbolic Systems to Kinetic Theory: A Personalized Quest}.
	
	{\sf Amazon review.} Equations of state are not always effective in continuum mechanics. {\sc Maxwell \& Boltzmann} created a kinetic theory of gases, using classical mechanics. How could they derive the irreversible Boltzmann equation from a reversible Hamiltonian framework? By using probabilities, which destroy physical reality! Forces at distance are non-physical as we know from {\sc Poincar\'e}'s theory of relativity. Yet {\sc Maxwell \& Boltzmann} only used trajectories like hyperbolas, reasonable for rarefied gases, but wrong without bound trajectories if the ``mean free path between collisions'' tends to 0. {\sc Tartar} relies on his H-measures, a tool created for homogenization, to explain some of the weaknesses, e.g., from quantum mechanics: there are no ``particles'', so the Boltzmann equation \& the 2nd principle, cannot apply. He examines modes used by energy, proves which equation governs each mode, \& conjectures that the result will not look like the Boltzmann equation, \& there will be more modes than those indexed by velocity!
	
	{\sf Editorial reviews.}
	\begin{itemize}
		\item ``The book is well organized $\ldots$ {\sc Tartar} is excellent in bringing out the essence of ideas \& methods $\ldots$ The monograph is an interesting read from $> 1$ point of view. 1st, the mathematically literate reader finds an extensive $\ldots$ review of the relevant subjects; reading the sketches of proofs offers a bird's eye view of the underlying concepts as well as the exceptional mind of the author $\ldots$ All in all, a remarkable book.'' -- {\sc Reinhard Illner}, SIAM Reviews, Vol. 51 (2), June, 2009
		\item ``This is a very nice book devoted to hyperbolic systems of conservation laws $\ldots$ This book can be recommended to all researchers in respective areas, especially to graduate students.'' -- {\sc Mitsuru Yamazaki}, athematical Reviews, Issue 2010 j
	\end{itemize}
	``Dedicated to {\sc Robert Dautray}, helped me at a critical time, when I could no longer bear the rejection in the academic world (partly for having refused the current methods of falsifications, \& partly because I was too interested in science for a mathematician), \& he also guided me in my readings while I worked at Commissariat à l'\'Energie Atomique, so that I did not get lost like many other mathematicians in the jungle of models which physicists have generated, \& I could understand what mathematical tools should be developed for helping understand in a better way how nature works.'' to {\sc Peter Lax} gave an example of how a good mathematician can work, by putting some order in a corner of the physical world where the preceding knowledge was made up of a few examples \& too many guesses. Why have there been so few mathematicians who wanted to follow his example?
	
	{\bf Preface.} After publishing \cite{Tartar2006,Tartar2007},\footnote{{\sc Claude Louis Marie Henri Navier}, French mathematician, 1785--1836. He had worked in Paris, France. He introduced the equation now known as NSEs in 1821, although he did not understand about shear stress.}\footnote{{\sc Sergei L'vovich Sobolev}, Russian mathematician, 1908--1989. He had worked in Leningrad, in Moscow, \& in Novosibirsk, Russia. There is now a Sobolev Institute of Mathematics of the Siberian branch of the Russian Academy of Sciences, Novosibirsk, Russia. I 1st met {\sc Sergei Sobolev} when I was a student, in Paris in 1969, \& conversed with him in French, which he spoke perfectly (all educated Europeans at the beginning of 20th century learned French).} revised versions of lecture notes for graduate courses taught in the spring of 1999 \& in the spring of 2000, another set of lecture notes for a graduate course taught in the fall of 2001, entitled ``Introduction to kinetic theory''. For this one, there had been no version available on Internet, \& I had not even written the notes for the last 4 lectures, \& after a few years, I find it useful to make the text available to a larger audience by publishing a revised \& completed version, but I had to change the title in a significant way.
	
	In \cite{Tartar2007}, I had written that my reasons for publishing lecture notes is to tell the readers some of what I have understood, the technical mathematical aspects of the course, the scientific questions behind the theories, \& more, \& I shall have succeeded if many become aware, \& go forward on the path of discovery, not mistaking research \& development, knowing when \& why they do 1 or the other, \& keeping a higher goal in mind when for practical reasons they decide to obey the motto of the age for a while, {\it publish or perish}.
	
	In the fall of 2001, I had done precisely that, \& I had taught the mathematical results that I had proven during my quest for understanding about kinetic theory, which I had started in the early 1970s, but I had also taught about what is wrong with kinetic theory, which I had started to understand in the early 1980s, \& I had tried to teach a little about continuum mechanics \& physics with the critical mind of a mathematician, so that the students could understand what were the results of my detective work on this particular question of kinetic theory, \& understand how to attack other questions of continuum mechanics or physics by themselves later (having in mind the defects that have already been found on each question, by me or by others).
	
	In \cite{Tartar2007}, I had suggested to the readers who already know something about continuum mechanics or physics to look at my lecture notes, to read about the defects which I know about in classical models, because other authors rarely mention these defects even though they have heard about them. This set of lecture notes, written with a concern towards kinetic theory, is of this type. I had suggested to the readers who do not yet know much about continuum mechanics or physics, to start with more classical descriptions about the problems, e.g., by consulting the books which have been prepared under the direction of {\sc Robert Dautray}, \& of {\sc Jacques-Louis Lions},\footnote{{\sc Jacques-Louis Lions}, French mathematician, 1928--2001. He received the Japan Prize in 1991. He had worked in Nancy \& in Paris, France; he held a chair (analyse mathématique des systèmes et de leur contrôle, 1973--1998) at Coll\`ege de France, Paris. The laboratory dedicated to functional analysis \& numerical analysis which he initiated, funded by CNRS (Centre National de la Recherche Scientifique) \& Université Paris VI (Pierre et Marie Curie), is now named after him, the Laboratoire Jacques-Louis Lions. I 1st had {\sc Jacques-Louis Lions} as a teacher at \'Ecole Polytechnique in Paris in 1966--1967, \& I did research under his direction, until my thesis in 1971.} whom he had convinced to help him.
	
	I have mentioned that my personal point of view, which is that one should not follow the path of the majority when reason clearly points to a different direction, probably owes a lot to having been raised as the son a (Calvinist) Protestant minister, but I had lost the faith when I was 12 or 13 years old, \& I may not have explained well why I later found myself forced to practice the art o the detective in deciding what had to be discarded from what I could reasonably trust until some new information became available. Becoming a mathematician had been 1 of the reasons, because mathematicians must know what is proven \& what is only conjectured, \& when later I became interested in understanding continuum mechanics \& physics from a mathematical point of view, I found that the analysis that must be done in organizing the information, as well as the misinformation that ``scientists'' transmit about the real world, is quite similar to the analysis that must be done in organizing the information \& misinformation that various religious traditions transmit, \& in both these approaches, one can observe the perverse influence of political factors.
	
	The particular difficulty that I had encountered myself around 1980 was related to the political perversion of the French academic system itself, because I found myself facing an unimaginable situation of forgeries, organized by a ``mathematician'' \& continued by a ``physicist'', which turned into a nightmare when I was repeatedly confronted with the racist behavior of those who insisted that it was normal that I should not have the same rights as others.\footnote{This happened in one of the campuses of University Paris XI (Paris Sud), Orsay, France, from 1979--1982.}
	
	Fortunately, {\sc Robert Dautray} provided me with a new job outside this strange ``academic'' world,\footnote{I worked at CEA (Commissariat à l'\'Energie Atomique) in Limeil, France, from 1982--1987.} \& I was extremely grateful to him for that, as it contrasted a lot with the rejection that I was feeling in the mathematical world, including the strange opposition of my mentors, {\sc Laurent Schwartz \& Jacques-Louis Lions}\footnote{{\sc Laurent Schwartz}, French mathematician, 1915--2002. He received the Fields Medal in 1950. He had worked in Nancy, in Paris, France, at \'Ecole Polytechnique, which was 1st in Paris (when I had him as a teacher in 1965--1966), \& then in Palaiseau, \& at Université Paris 7 (Denis Diderot), Paris.} who had chosen the side of the forgers against me, probably because they had some different, wrong information. However, I am even more grateful to {\sc Robert Dautray} for something that very few people could have provided me, as my understanding of physics could not have improved in the way it did without his help, which was mostly through telling me what to read, \& it is natural that I should dedicate this set of lecture notes to him, although he may not agree entirely with my personal analysis on the subject of kinetic theory.
	
	My new job, or more precisely what I had understood about what I had to do, had been both simple \& impossible, to understand physics in a better way, through a mathematical approach, of course. I felt that {\sc Robert Dautray} understood that physics had reached a few dead ends, where physicists were hitting some walls which had been created before them, by other physicists who had invented the wrong games for understanding how nature works. It should not have been too critical, as it is natural that guessing produces a few answers that are not completely right, although they may not be completely wrong, \& using the art of the engineer one can make things work even though one does not have the correct equations for describing the processes that one wants to tame, but this approach in science has its limitations. In order to go forward, one needs to apply a scientific approach, \& practice the art of the detective to discover what has been done wrong, \& then one needs to do it in a better way, ideally in the right way, if that is possible. I thought that {\sc Robert Dautray} was not only aware of that, but that he saw that some of this work of providing more order must be done by mathematicians, at least well-trained mathematicians.
	
	The job of a detective is certainly made quite difficult if he{\tt/}she is forbidden to ask questions to important witnesses, or if he{\tt/}she realizes that there is a wall of silence \& that there is information that could be useful for his{\tt/}her search which some powerful group does not want him{\tt/}her to discover. That type of difficulty exists in physics, as well as in other sciences, including mathematics. At the beginning, some guessed rule had been successful in 1 situation, \& although it was dangerous to apply a similar guess indiscriminately for all kinds of problems, it had been done, but what made this practice quite unfortunate was then to create a dogma, \& to teach it to new generations of students. Because no hints were given that some of these rules could be slightly wrong, or even completely misleading, these physicists were not really trained as scientists, \& it is not surprising that many of them ended up working like engineers, mistaking physics \& technology, \& not caring much for the fact that some of the currently taught ``laws of physics'' are obviously wrong: they are simply the laws that physicists have guessed in their quest about the laws that nature follows, \& it would have been surprising that their 1st guess had been right.
	
	Before 1982, I had mostly thought about questions concerning continuum mechanics, developing homogenization \& the compensated compactness method, partly with {\sc Francois Murat}, but I had also understood a question of the appearance nonlocal effects by homogenization of some hyperbolic equations, \& I thought that this was a more rational explanation than the strange games of spontaneous absorption \& emission that physicists had invented, so that their probabilistic games were just 1 possible approach to describing the correct effective equations, confirming what I had already discovered before, that probabilities are introduced by physicists when they face a situation that they do not understand, so that it should be pointed out how crucial it is to introduce probabilities as late as possible in the analysis of a problem, ideally not at all if possible, but certainly further \& further away from 1 generation to the next. However, up to 1982, I did not see how to include quantum mechanics \& statistical mechanics in my approach to the PDEs of continuum mechanics \& physics.
	
	After 1982, the 1st step was relatively easy, \& in reading what {\sc Robert Dautray} had told me I identified a few points which are certainly wrong in the laws that physicists use; however, making them right seemed to require the development of new mathematical tools. The tool of H-measures, which I started describing at the end of 1986, was something that I had already guessed 2 years before, but its extension to semilinear hyperbolic systems has eluded me since, \& I see that extension as necessary to explain some of the strange rules about quantum mechanics, \& then derive better rules than those of statistical mechanics.
	
	At the end of 1983, a year before the 1st hint about new mathematical tools, I already ``knew'' what is wrong with kinetic theory, which is the subject of this set of lecture notes, as a consequence of having ``understood'' what is wrong with quantum mechanics. As I am a mathematician, I use quotes because I want to emphasize that it was not yet mathematical knowledge, \& it was not about a precise conjecture either because I could not formulate one at the time, but I had acquired the certitude that some aspects of what the physicists say will not appear in the new mathematical framework that I was searching for.
	
	The main mistake of physicists had been to stick to 18th century ideas of classical mechanics, instead of observing that if the 19th century ideas about continuum mechanics are inadequate for explaining what is observed at a microscopic level, it is because one needs new mathematical tools for 20th century mechanics{\tt/}physics (turbulence, plasticity, atomic physics), which have no probability in them, of course, as the use of probabilities is the sign that one does not understand what is going on. It had been a mistake to concentrate too much effort on problems of PDEs which show finite-dimensional effects, for which 18th century mechanics is adapted, instead of observing that the more interesting problems of PDEs all show infinite-dimensional effects, which cannot be grasped with 18th{\tt/}19th century ideas; actually, my subject of research since the early 1970s had been precisely focused on studying the effect of microstructuers in PDEs, a subject which I have decided to describe as {\it beyond PDEs}. The certitude that mathematics brings is that there are absolutely no particles at atomic level, there are only waves, so that there cannot be any particles interacting in the way that had been assumed by {\sc Maxwell} \& by {\sc Boltzmann}.
	
	Nevertheless, one should be careful not to disparage {\sc Maxwell \& Boltzmann} for the fact that their pioneering work in kinetic theory has some defects, because they had shown a good physical intuition for the way to correct an important defect of continuum mechanics, which is that the constitutive relations used are wrong, because they result from the inexact postulate that the relations valid at equilibrium are true at all times.
	
	That there are no particles \& that they are waves could have been understood earlier, as a consequence of an observation of {\sc Poincar\'e} in his study of relativity, that instantaneous forces at a distance do not make any sense, which {\sc Einstein} after him had probably not understood so well,\footnote{{\sc Albert Einstein}, German-born physicists, 1879--1955. He received the Nobel Prize in Physics in 1921, for his services to theoretical physics, \& especially for his discovery of the law of the photoelectric effect. He had worked in Bern, in Z\"urich, Switzerland, in Prague, now capital of Czech Republic, at ETH (Eidgenössische Technische Hochschule), Zürich, Switzerland, in Berlin, Germany, \& at IAS (Institute for Advanced Study), Princeton, NJ. The Max Planck Institute for Gravitational Physics in Potsdam, Germany, is named after him, the Albert Einstein Institute.} \& that ``particles'' feel a field that transmits the interactions as waves, but {\sc Poincar\'e} had died many years before the wave nature of ``particles'' was confirmed by an observation of {\sc L. de Broglie} in his study of ``electrons'',\footnote{Prince {\sc Louis Victor Pierre Raymond de Broglie}, 7th Duc de Broglie, French physicist, 1892--1987. He received the Nobel Prize in Physics in 1929, for his discovery of the wave nature of electrons. He had worked in Paris, France.} that they are waves. Unfortunately, the idea that there are only waves \& no particles was then completely messed up in the following development of quantum mechanics, which led to that strange dogmatic discipline where ``nonexistence particles'' are assumed to play ``esoteric probabilistic games''.
	
	At the end of 1983, I had then ``understood'' that there are absolutely no particle at a microscopic level, so that {\it real gases are not made of particles}, \& I understood it in a mathematical way in the late 1980s, by introducing H-measures, which are related to oscillations \& concentration effects in weakly converging sequences, \& then by proving transport equations for them when one considers sequences of solutions of particular linear hyperbolic systems. Better mathematical results are still needed in order to understand the case of semilinear hyperbolic systems, which I believe is the mathematical problem to study to explain all the strange effects which are observed at a microscopic level.
	
	Although {\sc Maxwell \& Boltzmann} had done quite a good job in postulating their equations for kinetic theory, because it is not yet clear a century \& a half after them how to write the equations correctly, it is useful to describe some defects in their work to show some limitations of kinetic theory, in the same way that one shows the limitations of classical mechanics by pointing out that {\sc Newton}'s work was unchallenged for 2 centuries, until relativity was introduced by {\sc Poincar\'e}, \& then {\sc Einstein}, so that one knows now that one needs relativistic corrections when the velocities involved can be compared with the speed of light $c$.
	
	Some have thought that what I had understood with H-measures was well known, but it is exactly as if one says that {\sc Laurent Schwartz}'s theory of distributions had been introduced by {\sc Dirac},\footnote{{\sc Paul Adrien Maurice Dirac}, English physicist, 1902--1984. He received Nobel Prize in Physics in 1933, jointly with {\sc Erwin Schr\"odinger}, for the discovery of new productive forms of atomic theory. He had worked in Cambridge, England, holding the Lucasian chair (1932--1969).} \& the authors of such remarks only show that they cannot recognize mathematics when they see it. However, such deceptive statements were also made by good mathematicians, \& in that case it shows something else: in each religion, there is a fundamentalist party who is interested in enforcing dogmas, not always because all these people believe in them, but often because some prefer to slow down the advance of knowledge (usually for keeping the power they have over the naive who believe in these dogmas), \& in the case that I consider it means slowing down the evolution of science in general, \& physics in particular, \& it is not too difficult to understand the political motivation of those who behave in this way, \& they often associate with people who do not hide that their work is political, but insist in brainwashing the naive that it is correct.
	
	Although I advocate using reason for criticizing without concessions the points of view that are taught in order to find better ``truths'', one should observe that this approach is more suited to mathematicians than to physicists or engineers, but not all mathematicians have been trained well enough for following that path, \& that might explain why some people initially trained as mathematicians write inexact statements, which they often do not change after being told about their mistakes, which others repeat then without knowing that they propagate errors; if their goal had not been to mislead others, a better strategy would have been to point out that some statements were only conjectures.
	
	Of course, although a few problems of continuum mechanics or physics have led to some of the mathematical questions described in this course, I have added some results for the usual reason that mathematicians are supposed to discover general structures hidden behind particular results, \& describe something more general after having done a systematic study, akin to a cleaning process.
	
	I had not consciously been following the path that {\sc Peter Lax} had opened,\footnote{{\sc Peter David Lax}, Hungarian-born mathematician, born in 1926. He received the Wolf Prize in 1987, for his outstanding contributions to many areas of analysis \& applied mathematics, jointly with {\sc Kiyoshi Ito}. He received the Abel Prize in 2005. He works at NYU (New York University), New York, NY.} of developing mathematics for a better understanding of continuum mechanics \& physics. I 1st heard him talk at the Lions--Schwartz seminar at IHP (Institut Henri Poincaré) in Paris, in the late 1960s, about $N$-waves for the Burgers equation, to show that there are 2 invariants for integrable data (whose sum is the classical invariant $\in_\mathbb{R} u(t,\cdot)\,{\rm d}x$), \& about the Korteweg--de Vries equation (not yet popularized as the KdV equation), to discuss its infinite list of invariants. Then, I heard him talk in 1971 in Madison, WI, during my 1st visit to United States, at a meeting of MRC (Mathematics Research Center) in Madison, WI, organized by {\sc Eduardo Zarantonello}, \& {\sc Peter Lax} talked about ``entropies'' for systems, but I did not know enough about hyperbolic systems of conservation laws at the time to appreciate the importance of the results that he was presenting. Actually, I knew almost nothing of that subject, which was not really known among mathematicians in France in the early 1970s, \& I may have helped to make it better known by teaching a few courses on the subject in the late 1970s, but I had 1st heard about the details in a course by {\sc Joel Smoller} in Orsay in 1973, then in discussions with {\sc Ron DiPerna}, \& with {\sc Constantine Dafermos}, \& then in a course by {\sc Takaaki Nishida} in Orsay in the late 1970s, before I started teaching it myself.
	
	Although I had understood early that {\sc Laurent Schwartz} was not interested in continuum mechanics or physics, I had taken some time to make the same observation concerning {\sc Jacques-Louis Lions}, but in the late 1970s, once that I was explaining the point of view that one should try to understand more about the physical meaning of the equations that one is studying, I had been surprised to hear {\sc Jacques-Louis Lions} defend the opposite position, that in his opinion this was not strictly necessary, so after that I had no more doubts about his interests, \& our paths separated. A few years ago, {\sc Peter Lax} recalled a discussion from the 1950s where {\sc Jacques-Louis Lions} had been criticized by British applied mathematicians for focusing too much on functional analysis \& for caring very little about continuum mechanics, \& that {\sc Jacques-Louis Lions} found nothing better than replying with a joke,\footnote{{\sc Jacques-Louis Lions}'s answer was that the British could not be trusted, since the time they had burnt {\sc Jeanne d'Arc} (Joan of {\sc Arc}).} which showed that he was already against understanding more about continuum mechanics.
	
	In the early 1970s, after working with {\sc Francois Murat} on an extension of the work of {\sc Sergio Spagnolo} on G-convergence, before I borrowed the term homogenization from {\sc Ivo Babu\v{s}ka} for designing it \& {\sc Francois Murat} chose to call our approach H-convergence, it had been the work of {\sc\'Evariste Sanchez-Palencia} that helped me understand the connection of our work with continuum mechanics, \& after that I insisted more \& more about the usefulness of understanding about the possible physical meanings of the equations that one studies. The main features which I tried then to develop in my research work now look to me very similar to those which {\sc Peter Lax} had chosen for himself, to learn about results in continuum mechanics \& physics \&, after developing an intuition for a particular field, to select a good subject \& to put some order in it by creating an adapted mathematical framework, \& eventually introduce new mathematical tools for studying it.
	
	In some way, the qualities that {\sc Peter Lax} has shown are not so common among mathematicians, even those who have been in contact with him. When I 1st met {\sc Ralph Phillips} in the spring of 1983, in Stanford, CA, I asked him a question about a remark of {\sc Leonardo Da Vinci}, which I thought must be classical for specialists of scattering,\footnote{In the beginning of 1982, while I was visiting the Scuola Normale Superiore in Pisa, Italy, I was told to take the train to Firenze (Florence) to see an exhibition of a manuscript of {\sc Leonardo Da Vinci}. To explain the fact that the surface of the moon reflects the light from the sun in every direction, {\sc Leonardo} had assume that there were oceans on the moon \& that because of waves the light could be reflected in various directions. We know now that there are no oceans on the moon, so that he was wrong, but I had admired {\sc Leonardo}'s inventiveness, \& I had thought that he had not been too far from guessing why a rough surface can reflect light in every direction.} but I was surprised to discover that {\sc Ralph Phillips} had no physical intuition at all, \& that for him scattering theory was just a chapter of functional analysis, so that he had not thought of using his collaboration with {\sc Peter Lax} on the subject for learning about the physical phenomena which could be covered by their mathematical theory. Some have worked on a subject that {\sc Peter Lax} had initialized, like that of hyperbolic systems of conservation laws, \& many have pushed their work in directions totally disconnected from reality, despite a warning from {\sc Constantin Dafermos} that {\it the umbilical cord that joins the theory of systems of conservation laws with continuum physics is still vital for the proper development of the subject \& it should not be severed}\footnote{dây rốn nối lý thuyết hệ thống các định luật bảo toàn với vật lý liên tục vẫn rất quan trọng cho sự phát triển đúng đắn của môn học \& nó không nên bị cắt đứt.}.
	
	E.g., why are there people who play with models where there are shocks which do not satisfy some of the conditions that {\sc Peter Lax} had introduced, \& who forget to point out that the models that they use have been postulated by engineers, \& why is it that they do not see that they are obviously incompatible with classical ideas in thermodynamics? Of course, I have been teaching for many years that thermodynamics is flawed \& should be improved, but that does not mean that any model which is incompatible with classical thermodynamics can be considered a good model of physical reality!
	
	When {\sc Peter Lax} introduced ``entropy conditions'' for systems,\footnote{{\sc Constantine Dafermos} prefers to call them E-conditions, as these notions are not always linked to thermodynamic entropy, \& I had chosen myself to write ``mathematical entropies'' in making the distinction.} he was generalizing the work for the scalar case of {\sc Eberhard Hopf}, \& of {\sc Kruzhkov}, who had found an intrinsic way for expressing a condition introduced by {\sc Olga Oleinik}, \& he had observed that if a sequence of approximations like that created by the method of artificial viscosity converges almost everywhere, then an ``entropy condition'' holds, but he knew how difficult it was to obtain enough estimates for proving that desired strong convergence.\footnote{In the mid 1960s, {\sc James Glimm} had found a way to estimate the total variation of the solution of some systems, for initial data having a small variation. It was only a few years after that approach of {\sc Peter Lax} that I introduced a different method, based on the results of compensated compactness that I had introduced with {\sc Francois Murat}, but it appeared difficult to apply for systems, \& the 1st to succeed was {\sc Ron DiPerna}.} Some authors do not seem to have understood that they just repeat {\sc Peter Lax}'s argument when they write articles with statements that if something converges strongly, then the Hilbert expansion is true, without pointing out the known defects of that conjecture of {\sc Hilbert} that letting the ``mean free path between collisions'' tend to 0 in the Boltzmann equation gives the Euler equation for an ideal gas, that the Boltzmann equation has been derived by assuming that a gas is rarefied \& that, apart from having also postulated irreversibility by introducing probabilities, it does not make any sense to apply it to a dense gas by making a ``mean free path between collisions'' tend to 0, \& that as real gases are not ideal, i.e., either the Boltzmann equation does not apply to real gases or that the Hilbert expansion is false.
	
	As in preceding lecture notes \cite{Tartar2006,Tartar2007}, I have given information in footnotes about the people who have participated in the creation of the knowledge related to the subject of the course, \& I refer to the prefaces of those lecture notes in explaining my motivation, \& I just want to repeat the motto of {\sc Hugo} of Saint {\sc Victor}, {\it Learn everything, \& you will see afterward that nothing is useless}, as it corresponds to what I have understood in my quest about how creation of knowledge occurs.
	
	I have often heard people say about famous scientists from the past, that luck played an important role in their discoveries, but the truth must be that they would have missed the importance of the new hints that had occurred if they had not known beforehand all the aspects of their problems. Those who present chance as an important factor in discovery probably wish that every esoteric subject that they like be considered important \& funded, but that is not at all what the quoted motto is about.
	
	I hope that the many pieces of the puzzle that I describe in this course will help a few mathematicians to understand a way to follow the path of {\sc Peter Lax}, by doing mathematics on problems which have been selected with care, so that in the end they help clarify a piece of that important puzzle, understanding physics in a better way.
	
	I would not have been able to complete the publication of my 1st 2 lecture notes \& to think about revising \& completing this 3rd set of lecture notes without the support of {\sc Lucia Ostoni}, \& I want to thank her for that \& for much more, having given me the stability that I had lacked so much in the last 25 years, so that I could feel safer in resuming my research of giving a sounder mathematical foundation to 20th century continuum mechanics \& physics.'' -- Milano, Jul 2007, {\sc Luc Tartar}
	\begin{itemize}
		\item {\sc Pierre Curie}, French physicist, 1859--1906. He \& his wife, {\sc Marie Sklodowska-Curie}, Polish-born physicist, 1867--1934, received Nobel Prize in Physics in 1903, in recognition of the extraordinary services they have rendered by their joint research on the radiation phenomena discovered by Prof. {\sc Henri Becquerel}, jointly with {\sc Antoine Henri Becquerel}. {\sc Marie Sklodowska-Curie} also received the Nobel Prize in Chemistry in 1911, in recognition of her services to the advancement of chemistry by the discovery of the elements radium \& polonium, by the isolation of radium \& the study of the nature of compounds of this remarkable element. They had worked in Paris, France. University Paris VI in Paris, France, is named after them, Université Pierre et Marie Curie.
		\item {\sc Max Karl Ernst Ludwig Planck}, German physicist, 1858--1947. He received the Nobel Prize in Physics in 1918, in recognition of the services he rendered to the advancement of physics by his discovery of energy quanta. He had worked in Kiel \& in Berlin, Germany. There is a Max Planck Society for the Advancement of the Sciences, which promotes research in many institutes, mostly in Germany (I spent my sabbatical year 1997--1998 at the Max Planck Institute for Mathematics in the Sciences in Leipzig, Germany).
		\item {\sc Erwin Rudolf Josef Alexander Schr\"odinger}, Austrian-born physicists, 1887--1961. He received the Nobel Prize in Physics in 1933, jointly with {\sc Paul Adrien Maurice Dirac}, for the discovery of new productive forms of atomic theory. He had worked in Vienna, Austria, in Jena \& in Stuttgart, Germany, in Breslau (then in Germany, now Wroc\l aw, Poland), in Zürich, Switzerland, in Berlin, Germany, in Oxford, England, in Graz, Austria, \& in Dublin, Ireland.
		\item {\sc Ricardo Wolf}, German-born inventor, diplomat \& philanthropist, 1887--1981. He emigrated to Cuba before World War I; from 1961 to 1973 he was Cuban Ambassador to Israel, where he stayed afterwards. The Wolf Foundation was established in 1976 with his wife,  {\sc Francisca Subirana-Wolf}, 1900--1981, to promote science \& art for the benefit of mankind.
		\item {\sc Kiyosi Ito}, Japanese mathematician, born in 1915. He received the Wolf Prize in 1987, for his fundamental contributions to pure \& applied probability theory, especially the creation of the stochastic differential \& integral calculus, jointly with {\sc Peter Lax}. He worked in Kyoto, Japan, although he worked at some time at Aarhus University, Aarhus, Denmark (1966--1969) and at Cornell University, Ithaca, NY (1969--1975).
		\item {\sc Alfred Nobel}, Swedish industrialist \& philanthropist,  1833--1896. He created a fund to be used as awards for people whose work most benefited humanity.
		\item {\sc Antoine Henri Becquerel}, French physicist, 1852--1908. He received the Nobel Prize in Physics in 1903, in recognition of the extraordinary services he has rendered by his discovery of spontaneous radioactivity, jointly with {\sc Pierre Curie \& Marie Sk\l odowska-Curie}. He had worked in Paris, France.
	\end{itemize}
	{\bf Detailed Description of Lectures.}
	\begin{itemize}
		\item {\sf Lecture 1: Historical Perspective.} {\it Conservation laws, linearized wave equation, quasi-linear wave equation, gas dynamics, Burgers equation}.
		
		``The goal of these lectures is to study PDEs related to questions of kinetic theory, \& to elucidate some of the questions of {\it continuum mechanics} or {\it physics} which lie behind these problems.
		
		One may arrive at these questions from different ways \& many interesting mathematical questions arise in the various approaches.
		
		From a {\it classical mechanics} point of view, one imagines a collection of rigid bodies moving under some set of forces, e.g., gravitational attraction between them, \& one wants to study the evolution of such a system. Of course, one should also consider electromagnetic effects, \& {\sc Alfv\'en} has explained by electromagnetic effects some of the features observed in galaxies,
		
		\item {\sf Lecture 2: Hyperbolic Systems: Riemann Invariants, Rarefaction Waves.} {\it Linear system, linear hyperbolic or strictly hyperbolic system, eigenvalues \& eigenvectors, solution of linear hyperbolic system, quasi-linear hyperbolic or strictly hyperbolic system, gas dynamics, Riemann problem, solution of linear case, Riemann invariants, integral curves, Riemann invariants for gas dynamics, simple waves, equations for Riemann problem, linearly degenerate of genuinely nonlinear fields, case of gas dynamics}.
		
		\item {\sf Lecture 3: Hyperbolic Systems: Contact Discontinuities, Shocks.} {\it Contact discontinuities, conservation forms, weak solution, Rankine--Hugoniot conditions, case of gas dynamics, shocks, entropy \& entropy flux}.
		
		\item {\sf Lecture 4: Burgers Equation \& 1D Scalar Case.} {\it Burgers equation, Burgers--Hopf equation \& Hopf--Cole transform, 1-sided inequality for $u_x$ implying uniqueness, Lax--Friedrichs scheme, CFL condition, order-preserving property, Crandall--Tartar lemma, application to Lax--Friedrichs scheme}.
		
		\item {\sf Lecture 5: 1D Scalar Case: E-Conditions of {\sc Lax} \& of {\sc Oleinik}.} {\it Galilean transformation, nonuniqueness, {\sc Oleinik} E-condition, Lax E-condition, rarefaction wave, shock}.
		
		\item {\sf Lecture 6: {\sc Hopf}'s Formulation of E-Condition of {\sc Oleinik}.} {\it{\sc Hopf}'s entropy condition, a family of entropy giving {\sc Oleinik} E-condition, Lax generalization to systems, Lax--Friedrichs scheme, viscous shock profile}.
		
		\item {\sf Lecture 7: Burgers Equation: Special Solutions.} {\it1-sided inequality for $u_x$ implying uniqueness, perturbation of a constant, perturbation of Riemann data, various scalings, perturbation of a rarefaction wave}.
		
		\item {\sf Lecture 8: Burgers Equation: Small Perturbations; Heat Equation.} {\it danger of linearization, heat equation, Fokker--Planck equation, elementary solution of heat equation, difference scheme for 1D heat equation}.
		
		\item {\sf Lecture 9: Fourier Transform; Asymptotic Behavior for Heat Equation.} {\it Fourier transform of integrable functions, derivation \& multiplication, Fourier transform on $\mathcal{S}(\mathbb{R}^d),\mathcal{S}'(\mathbb{R}^d)$, Plancherel formula, inverse Fourier transform, affine change of variable, Fourier transform of a convolution product, Fourier transform for heat equation, semigroup, scaling \& decay, relation with moments \& decay, matrix of inertia \& anisotropic Gaussians, solving a diffusion equation with anisotropic Gaussians}.
		
		\item {\sf Lecture 10: Radon Measure; Law of Large Numbers.} {\it Radon measures, Fourier transform of a Radon measure, center of mass \& convolution, law of large numbers, matrix of inertia \& convolution, strong law of large numbers}.
		
		\item {\sf Lecture 11: A 1D Model with Characteristic Speed $\frac{1}{\varepsilon}$.} {\it Explicit difference schemes, 1D model with velocities $\pm\frac{1}{\varepsilon}$, limit as $\varepsilon\to0$}.
		
		\item {\sf Lecture 12: A 2D Generalization; Perron--Frobenius Theory.} {\it2D model with velocities $\pm\frac{1}{\varepsilon}$ along axes, reducible matrices, a condition for irreducibility, $\rho(A)$ is a simple eigenvalue with positive eigenvector, case of other eigenvalues of modulus $\rho(A)$, primitive or imprimitive irreducible matrices, a criterion using length of loops, asymptotic behavior of $A^n\omega$ as $n\to\infty$.}
		
		\item {\sf Lecture 13: A General Finite-Dimensional Model with Characteristic Speed $\frac{1}{\varepsilon}$.} {\it $Me = 0$, $e$ positive, $L^\infty$ estimate, coerciveness on $e^\bot$, estimates, convergence}.
		
		\item {\sf Lecture 14: Discrete Velocity Models.} {\it Conservations in a collision, probabilities, general model, properties of coefficients, entropy, conservations \& decay of entropy, 4 velocities Maxwell model, general semi-linear case, local existence, 1D 4 velocities model \& Broadwell model, finite propagation speed, condition for positivity, forward invariant sets for ODEs, characterization of forward invariant sets, forward invariant sets for a semi-linear system, characterization, a model with a bounded forward invariant set, Carleman model, formal (Hilbert) expansion for Broadwell model, restriction of convolution product on circle}.
		
		\item {\sf Lecture 15: Mimura--Nishida \& Crandall-Tartar Existence Theorems.} {\it Mimura--Nishida existence theorem, Crandall--Tartar existence theorem, use of bounds on entropy}.
		
		\item {\sf Lecture 16: Systems Satisfying My Condition (S).} {\it Condition (S), spaces $V_c,W_c$, product on $W_{c_1}\times W_{c_2}$ with $c_1\ne c_2$, global existence $t\in\mathbb{R}$ for small data in $L^1$, a case of necessity for small data, local existence for data in $L^1$, asymptotic behavior, a Mimura--Nishida type estimate}.
		
		\item {\sf Lecture 17: Asymptotic Estimates for Broadwell \& Carleman Models.} Asymptotic behavior for Broadwell model, 2d 4 velocities model, Illner--Reed estimate for Carleman model, self-similar solutions of Carleman model.
		
		\item {\sf Lecture 18: Oscillating Solutions; 2D Broadwell Model.} {\it Oscillating solutions of Carleman model, div-curl lemma, application, systems stable by weak convergence, Gagliardo--Nirenberg estimate, application to 2D 4 velocities model}.
		
		\item {\sf Lecture 19: Oscillating Solutions: Carleman Model.} {\it Rescaling of a solution, bounded sequences of solutions, general system of 2 equations, extracting converging subsequences, an infinite system, uniqueness, strength of oscillations \& differential inequalities}.
		
		\item {\sf Lecture 20: Carleman Model: Asymptotic Behavior.} {\it Integrable nonnegative data \& rescaling, strong convergence in $|x| > t + \varepsilon$, a subsequence converges to a solution of Carleman with support in $|x|\le t$, formal (Hilbert) limit of the Broadwell model, case of Carleman model, Kurtz scaling, oscillating solutions for Broadwell model}.
		
		\item {\sf Lecture 21: Oscillating Solutions: Broadwell Model.} {\it Properties of weak limits \& the weak limit $X_{111}$ of $u_nv_nw_n$, estimat for $X_{111}$, inequality for $\sigma_w$, periodically modulated case, Carleman model, Broadwell model, a system for Fourier coefficients}.
		
		\item {\sf Lecture 22: Generalized Invariant Regions; Varadhan Estimate.} {\it Broadwell model, Varadhan potential of interaction $I(t)$, decrease of $I(t)$, Carleman model}.
		
		\item {\sf Lecture 23: Questioning Physics; from Classical Particles to Balance Laws.} {\it Potential in $\frac{1}{r}$, Maxwell--Heaviside equation \& Lorentz force, conservation of mass \& balance of momentum, Cauchy stress}.
		
		\item {\sf Lecture 24: Balance Laws; What Are Forces?} {\it Conservation of mass in the sense of distributions, balance of momentum in the sense of distributions, fluid quantities in kinetic theory}.
		
		\item {\sf Lecture 25: D. Bernoulli: from Masslets \& Springs to 1D Wave Equation.} {\it Evolution equation, equilibria, time-dependent case, vibration frequencies, deriving equations for $f(t,{\bf x},{\bf v})$}.
		
		\item {\sf Lecture 26: Cauchy: from Masslets \& Springs to 2D Linearized Elasticity.} {\it1D case, a 1D dissipative model, linearized elasticity}.
		
		\item {\sf Lecture 27: 2-Body Problem.} {\it Conservation of linear \& angular momentum, parametrization of collisions}.
		
		\item {\sf Lecture 28: Boltzmann Equation.} {\it General form, forces in {\it distance} ${\rm dist}^{-s}$, a critical question, Fokker--Planck equation, conservation, fluid quantities, conservation laws, collision invariants, characterization of collision invariants, variation of entropy \& importance of Maxwellian distributions, relation with thermodynamics}.
		
		\item {\sf Lecture 29: Illner--Shinbrot \& Hamdache Existence.} {\it Iterative method, estimates to be proven, a choice of function \& verification}.
		
		\item {\sf Lecture 30: Hilbert Expansion.} {\it Expansion, coefficient of $\varepsilon^{-1}$, coefficient of $\varepsilon^0$, viscous stress tensor, rectangular ``Gaussians''}.
		
		\item {\sf Lecture 31: Compactness by Integration.} {\it$f,f_t + {\bf v}f_{\bf x},f_{\bf v}\in L^2\Rightarrow f\in H_{\rm loc}^{\frac{1}{2}}$, commutator of $\partial_t + {\bf v}\partial_{\bf x}$ \& $\partial_{v_k}$, discrete analogue of commutation, discrete analogue of half derivatives, compactness by integration}.
		
		\item {\sf Lecture 32: Wave Front Sets; H-Measures.} {\it1st-order equations \& bicharacteristic rays, Wigner transform, H-measures, localization principle}.
		
		\item {\sf Lecture 33: H-Measures \& ``Idealized Particles''.} {\it H-measures for wave equations, internal energy \& equipartition of energy}.
		
		\item {\sf Lecture 34: Variants of H-Measures.} {\it Geometrical optics, my proposal for introducing a characteristic length, {\sc G\'erard}'s proposal of semi-classical measures, {\sc P.-L. Lions \& Paul}'s proposal to define them with Wigner transform, an observation of {\sc Wigner}, $k$-point correlation measures, properties of correlation measures, conclusion}.
		
		\item {\sf Lecture 35: Biographical Information.} Basic biographical information for people whose name is associated with something mentioned in the lecture notes.
		\item {\sf Lecture 36: Abbreviations \& Mathematical Notation.}
	\end{itemize}
\end{enumerate}

\subsection{Porous Medium Equations [PMEs]}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Acker_Kawohl1989}. {\sc Andrew F. Acker, Bernhard Kawohl}. {\it Remarks on quenching}.\hfill{\sf[95 citations]}
	\item \cite{Bonforte_Figalli_Vazquez2018}. {\sc Matteo Bonforte, Alessio Figalli, Juan Luis V\'{a}zquez}. {\it Sharp global estimates for local \& nonlocal porous medium-type equations in bounded domains}.\hfill{\sf[55 citations]}
	
	{\bf Keywords.} nonlocal diffusion, nonlinear equations, bounded domains, a priori estimates, positivity, boundary behavior, regularity, Harnack inequalities.
	
	{\bf Abstract.} Provide a quantitative study of nonnegative solutions to nonlinear diffusion equations of porous medium-type of the form $\partial_tu + \mathcal{L}u^m = 0$, $m > 1$, where the operator $\mathcal{L}$ belongs to a general class of linear operators, \& eqn is posed in a bounded domain $\Omega\subset\mathbb{R}^N$. As possible operators: include 3 most common definitions of the fractional Laplacian in a bounded domain with zero Dirichlet conditions, \& also a number of other nonlocal versions. In particular, $\mathcal{L}$ can be a fractional power of a uniformly elliptic operator with $C^1$ coefficients. Since nonlinearity is given by $u^m$ with $m > 1$, eqn is degenerate parabolic.
	
	Basic well-posed theory for this class of equations was recently developed by Bonforte \& V\'azquez. Address regularity theory: decay \& positivity, boundary behavior, Harnack inequalities, interior \& boundary regularity, \& asymptotic behavior. All this is done in a quantitative way, based on sharp a priori estimates. Although focusing on fractional models, results cover also local case when $\mathcal{L}$ is a uniformly elliptic operator, \& provide new estimates even in this setting.
	
	A surprising aspect discovered: possible presence of nonmatching powers for long-time boundary behavior, i.e., when $\mathcal{L} = (-\Delta)^s$ is a spectral power of Dirichlet Laplacian inside a smooth domain, can prove that: (i) when $s > 2\left(1 - \frac{1}{m}\right)$, for large times all solutions behave as ${\rm dist}^{\frac{1}{m}}$ near the boundary; (ii) when $s\le2\left(1 - \frac{1}{m}\right)$, different solutions may exhibit different boundary behavior. This unexpected phenomenon is a completely new feature of nonlocal nonlinear structure of this model, \& not present in semilinear elliptic equation $\mathcal{L}u^m = u$.
	\begin{itemize}
		\item {\sf Sect. 1: Introduction.}
		\begin{goal}
			Address question of obtaining a priori estimates, positivity, boundary behavior, Harnack inequalities, \& regularity for a suitable class of weak solutions of nonlinear nonlocal diffusion equations of form $\partial_tu + \mathcal{L}F(u) = 0$ in $Q_\infty = (0,\infty)\times\Omega$, where $\Omega\subset\mathbb{R}^N$ is a bounded domain with $C^{1,1}$ boundary, $N\ge2$ (results work also in 1D if fractional exponent $0 < s <\frac{1}{2}$. The interval $\frac{1}{2}\le s < 1$ requires some minor modifications preferred to avoid.), $\mathcal{L}$: a linear operator representing diffusion of local or nonlocal type, the prototype example being fractional Laplacian (class of admissible operators).
		\end{goal}
		Although arguments hold for a rather general class of nonlinearities $F:\mathbb{R}\to\mathbb{R}$, for simplicity, focus on model case $F(u)\coloneqq u^m$ with $m > 1$.
		
		Use of nonlocal operators in diffusion equations reflects the need to model presence of long-distance effects not included in evolution driven by Laplace operator: well documented in literature. Physical motivation \& relevance of nonlinear diffusion models with nonlocal operators. Because $u$ usually represents a density, all data \& solutions are supposed to be nonnegative. Since the problem is posed on a bounded domain, need boundary or external conditions assumed to be of Dirichlet type.
		
		Extensively studied when $\mathcal{L} = -\Delta,F(u) = u^m$, $m > 1$, eqn becomes classical PME. Here interested in treating nonlocal diffusion operators, in particular fractional Laplacian operators. Since working on a bounded domain, the concept of fractional Laplacian operator admits several nonequivalent versions, the best known being the restricted fractional Laplacian (RFL), the spectral fractional Laplacian (SFL), \& the censored fractional Laplacian (CFL). RFL is usually known as the {\it standard fractional Laplacian}, or plainly fractional Laplacian, \& the CFL is often called the {\it regional fractional Laplacian}.
		
		The case of SFL operator with $F(u) = u^m$, $m > 1$, was already studied in [Bonforte \& Vázquez 2015; 2016]. In [Bonforte \& Vázquez 2016] presented a rather abstract setting where they were able to treat not only usual fractional Laplacians but also a large number of variants listed. Rather general increasing nonlinearities $F$ were allowed. Basic questions of existence \& uniqueness of suitable solutions for this problem were solved in [Bonforte \& Vázquez 2016] in the class of ``weak dual solutions'', an extension of the concept of solution introduced in [Bonforte \& Vázquez 2015] having proved to be quite flexible \& efficient. Derived a number of a priori estimates (absolute bounds \& smoothing effects) in that generality.
		
		Since these basic facts are settled, here focus on finer aspects of theory, mainly sharp boundary estimates \& decay estimates. Such upper \& lower bounds will be formulated in terms of 1st eigenfunction $\Phi_1$ of $\mathcal{L}$, which under our assumptions will satisfy $\Phi_1\asymp{\rm dist}(\cdot,\Gamma)^\gamma$ for a certain characteristics power $\gamma\in(0,1]$ depending on particular operator being considered. Typical values: $\gamma = s$ (SFL), $\gamma = 1$ (RFL), $\gamma = s - \frac{1}{2}$ for $s > \frac{1}{2}$ (CFL) $\Rightarrow$ get various kinds of local \& global Harnack-type inequalities.
		
		Some of the boundary estimates obtained for parabolic case are essentially elliptic in nature. Study of this issue for stationary problems is done in a companion paper [Bonforte et al. 2017b]. Advantage: many arguments are clearer, since parabolic problem is more complicated than elliptic one. Clarifying such differences is 1 of main contributions. Prove both interior \& boundary regularity, \& to find large-time asymptotic behavior of solutions.
		
		{\sf Notation.} Some notation of general use. Notation $a\asymp b$ whenever there exist universal constants $c_0,c_1 > 0$ s.t. $c_0b\le a\le c_1b$. $a\lor b = \max\{a,b\},a\land b = \min\{a,b\}$. Always consider bounded domains $\Omega$ with boundary of class $C^2$. Use short form ``solution'' to mean ``weak dual solution'', unless differently stated.
		
		{\bf Presentation of results on sharp boundary behavior.} A basic principle: sharp boundary estimates depend not only on $\mathcal{L}$ but also on behavior of nonlinearity $F(u)$ near $u = 0$, i.e., on exponent $m > 1$. [$\ldots$]
		
		{\bf Asymptotic behavior \& regularity.}
		\item {\sf Sect. 2: General class of operators \& their kernels.} The interest of theory developed here lies both in the sharpness of results \& in wide range of applicability. Mentioned most relevant examples appearing in literature. Theory applies to a general class of operators with definite assumptions. Properties having to be assumed on class of admissible operators, which some of them already appeared in [Bonforte \& Vázquez 2016]. To further develop theory, need to introduce more hypotheses. [Bonforte \& Vázquez 2016] only uses properties of Green function, here make some assumptions also on kernel of $\mathcal{L}$ whenever it exists. Assumptions on the kernel $K$ of $\mathcal{L}$ are needed for positivity results, because need to distinguish between local \& nonlocal cases. Perform study of kernel $K$.
		\item {\sf Sect. 3: Reminders about weak dual solutions.}
		\item {\sf Sect. 4: Upper boundary estimates.}
		\item {\sf Sect. 5: Lower bounds.}
		\item {\sf Sect. 6: Summary of general decay \& boundary results.}
		\item {\sf Sect. 7: Asymptotic behavior.}
		\item {\sf Sect. 8: Regularity results.}
		\item {\sf Sect. 9: Numerical evidence.}
		\item {\sf Sect. 10: Complements, extensions, \& further examples.}
	\end{itemize}
	\item {\sc Matteo Bonforte, Maria Pia Gualdani, Peio Ibarrondo}. {\it Time-Fractional Porous Medium Type Equations: Sharp Time Decay \& Regularization.}.
	
	{\bf Keywords.} PME, fast diffusion equation, nonlocal operators, Caputo fractional time derivative, subdiffusion comparison principle, regularity estimates, long time behavior.
	\begin{itemize}
		\item {\sf Sect 1. Intro.} Several phenomena, from physics to biology to finance, exhibit events during which fractional behavior \& memory effects become predominant; e.g., viscoelastic materials (whose response depends on their current \& past states), certain geographical processes including movement of groundwater or transportation through porous media, neuronal \& gene regulation networks, but also control theory \& more recent modeling of financial market. Fractional calculus provides a reliable tools to describe memory effects. In 1967 M. Caputo, in the context of modeling heterogeneous elastic fields, introduced the {\it Caputo time derivative} of order $\alpha$:
		\begin{equation}
			\label{Caputo time fractional derivative}
			D_t^\alpha f(t)\coloneqq\frac{1}{\Gamma(1 - \alpha)}\frac{\rm d}{{\rm d}t}\int_0^t \frac{f(\tau) - f(0)}{(t - \tau)^\alpha}\,{\rm d}\tau,\ \alpha\in(0,1).
		\end{equation}
		Caputo modeled certain type of fluid diffusing in porous media using this novel nonlocal operator. In these geothermal studies, Darcy's Law is adapted to describe fluids that may carry solid particles obstructing the pores, thus diminishing their size \& creating a pattern of mineralization. This phenomenon has recently been observed in various other types of porous materials, including building materials, \& zeolite.
		
		Systems where particles exhibit anomalous diffusion (sub- or super-diffusion behavior) often involve memory effects, e.g., diffusion in porous media, turbulent flows, \& biological transport processes. These applications require mathematical models allowing particles to do macroscopical long jumps (L\'evy flights), leading to the use of nonlocal operators in the spatial \& time variables. Many different mathematical models describing anomalous diffusion in a porous medium in literature. Main PDE:
		\begin{equation}
			\label{CPME}
			\tag{CPME}
			D_t^\alpha = -\mathcal{L}u^m,\ m > 0,
		\end{equation}
		\& includes a general class of densely defined operators $\mathcal{L}$ both of local \& nonlocal type. Eqn \eqref{CPME} is a {\it density dependent diffusion} resulting in a characteristic scaling $\frac{x}{t^{\frac{\alpha}{2 + d(m - 1)}}}$, whenever diffusion operator is $\mathcal{L} = -\Delta$.
		
		From a mathematical point of view, characteristic scaling of the wetting front variable in anomalous diffusion differs from 1 of classical Heat Eqn $\frac{x}{\sqrt{t}}$. Originally, Caputo derivative arose in linear setting to achieve a subdiffusive characteristic scaling of form $\frac{x}{t^{\frac{\alpha}{2}}}$ with $\alpha\in(0,1)$. Non-locality in time, or memory effect, represents a ``waiting time'' phenomenon typically derived within stochastic framework of Continuous Time Random Walk. \eqref{CPME} encompasses a wide variety of anomalous diffusion models combining local \& nonlocal spatial operators, Caputo fractional time derivative, \& $m$-power like nonlinearities for any $m > 0$. Provide a comprehensive qualitative \& quantitative study of \eqref{CPME}. Beside global well-posedness, main contributions are 3fold: (i) study of comparison principle \& time monotonicity formula, (ii) $L^p$-$L^\infty$ smoothing effects, (iii) optimal long time behavior. {\sf Surprising facts}: {\it regularity effects} \& {\it non-extinction in finite time} for all solutions of \eqref{CPME} when $m\in(0,1)$. Notably: memory effect slows down diffusion, minimizing relevance of nonlinearity parameter $m$ in ranges $m\in(0,1)$ \& $m > 1$. Diffusive nature of eqn still provides a regularization of solution, a feature previously unknown for nonlinear equations involving Caputo derivatives. All these results are new even for classical Laplacian $\mathcal{L} = -\Delta$ \& $\alpha\in(0,1)$.
		
		Within mathematical framework, prototype subdiffusive PDE is ``Heat Eqn with memory'':
		\begin{equation}
			\label{heat with memory}
			D_t^\alpha u = \Delta u.
		\end{equation}
		{\sf Vast literature.} well-posedness \& regularity in $\mathbb{R}^d$, optimal asymptotic decay for solutions of \eqref{heat with memory} for Cauchy problem in $\mathbb{R}^d$. For Dirichlet problem on bounded domains, long time decay estimates, also allowing for general operators with variable coefficients in space \& time. Global well-posedness of \eqref{CPME} with $m = 1$ for singular solutions on bounded domains. From a nonlinear perspective, consider several fractional nonlinear models \& obtain sharp decay estimates of $L^q$ norms using fractional ODEs techniques. Porous Medium with fractional pressure, associated to Caﬀarelli--Vázquez model studied in its Caputo derivative version. Develop a theory of fractional gradient flows in Hilbert spaces, analogous of Brezis-Komura theory with fractional time derivative. This theory provides well-posedness for both linear \& for nonlinear problems.
		
		Memory effects complicate analysis quite a lot. Memory effects somehow destroy semigroup structure, essential in the De Giorgi-Nash-Moser theory. A nontrivial adaptation of Green function method, achieved by employing novel time monotonicity estimates, a feature coming as a surprise in context of Caputo setting.
		
		To provide further insights about results, some numerology\footnote{the use of numbers to try to tell somebody what will happen in the future. số học.} is in order: asymptotic estimates correspond to known estimates in formal limit $m\to1$, which does not happen in the --formal-- limit $\alpha\to1^-$. Neither exponents of smoothing effects nor the ones in long time behavior estimates, correspond to known ones when $\alpha = 1$.
		
		Principal findings:
		\begin{itemize}
			\item {\bf Comparison principle \& time monotonicity.}
			\item {\bf Smoothing effects \& boundary estimates.}
			\item {\bf Case of unbounded domains.}
			\item {\bf Optimal long time behavior.}
		\end{itemize}		
		\item {\sf Discretized problem.}
		\item {\sf Continuous problem.}
		\item {\sf Smoothing effects.}
		\item {\sf Sharp time decay of $L^p$-norms.}
		\item {\sf Open questions.}
		\item {\sf Appendix A: Fractional ODEs.}
	\end{itemize}
	
	{\bf Abstract.} Consider a class of porous medium type of equations with Caputo time derivative. Prototype problem: $D_t^\alpha u = -\mathcal{L}u^m$ posed on a bounded Euclidean domain $\Omega\subset\mathbb{R}N$ with zero Dirichlet boundary conditions. The operator $\mathcal{L}$ falls within a wide class of either local or nonlocal operators, \& nonlinearity is allowed to be of degenerate or singular type, namely, $0 < m < 1$ \& $m > 1$. Most general form of a variety of models used to describe anomalous\footnote{different from what is normal or expected. dị thường.} diffusion processes with memory effects, \& finds application in various fields, e.g., visco-elastic materials, signal processing, biological systems, \& geophysical science. Prove existence of unique solution \& new $L^p$-$L^\infty$ smoothing effects. The comparison principle, provided in the most general setting, serves as a crucial tool in the proof \& provides a novel monotonicity formula. Consequently, establish: regularizing effects from diffusion are stronger than memory effects introduced by fractional time derivative. Solution attains boundary conditions pointwise. Prove: solution does not vanish in finite time if $0 < m < 1$, unlike case with classical time derivative. Provide a sharp rate of decay for any $L^p$-norm of solution for any $m > 0$. Memory effects weaken the spatial diffusion \& mitigate the difference between slow \& fast diffusion.
	
	
	\item \cite{Dao_Diaz_Nguyen2020}. {\sc Đào Nguyên Anh, Jesus Ildefonso D\'{i}az, Nguyễn Quản Bá Hồng}. {\it Pointwise gradient estimates in multi-dimensional slow diffusion equations with a singular quenching term}. {\sf[4 citations]}
	
	{\bf Keywords.} singular absorption, nonlinear diffusion equations, pointwise gradient estimates, quenching phenomenon, free boundary.
	
	{\bf Abstract.} Consider high-dimensional equation $\partial_tu - \Delta u^m + u^{-\beta}\chi_{\{u > 0\}}$, extend \cite{Kawohl_Kersner1992} 1D case. Prove existence of a very weak solution (VWS) $u\in C([0,T];L_\delta^1(\Omega))$ with $u^{-\beta}\chi_{\{u > 0\}}\in L^1((0,T)\times\Omega)$, $\delta({\bf x})\coloneqq d({\bf x},\partial\Omega)$. Prove some pointwise gradient estimates for a certain range of the dimension $N$, $m\ge1$, $\beta\in(0,m)$, mainly when the absorption dominates over diffusion $1\le m < 2 + \beta$. Prove a new kind of universal gradient estimate when $m + \beta\le2$. Consider several qualitative properties (e.g. finite time quenching phenomena \& finite speed of propagation) \& study of Cauchy problem.
	
	\begin{goal}
		Extend to high-dimensional case \cite{Kawohl_Kersner1992} for a 1D degenerate diffusion equation with a singular absorption term. Study nonnegative solutions of possibly degenerate reaction-diffusion multi-dimensional problem $\partial_tu - \Delta u^m + u^{-\beta}\chi_{\{u > 0\}}$ in $(0,\infty)\times\Omega$, $u^m = 0$ on $(0,\infty)\times\Gamma$, $u(0,{\bf x}) = u_0({\bf x})$ in $\Omega$.
	\end{goal}
	$\Omega$: an open regular bounded domain of $\mathbb{R}^N$, e.g., with $\Gamma$ of calss $C^{1,\alpha}$ for some $\alpha\in(0,1]$, $N\ge1$, $m\ge 1$ ($m > 1$ corresponds to a typical slow diffusion) \& mainly $\beta\in(0,m)$ with some remarks for case $\beta\ge m$. Treat separately the case of whole space $\Omega = \mathbb{R}^N$. The absorption term $u^{-\beta}\chi_{\{u > 0\}}$ becomes singular (\& the diffusion becomes degenerate if $m > 1$) when $u = 0$, \& by this normalization, have $u(t,{\bf x}) = 0\Rightarrow u^{-\beta}\chi_{\{u > 0\}}(t,{\bf x}) = 0$. Boundary condition implies an automatic permanent singularity on $\Gamma$, in contrast to other related problems in which the singularity is permanently excluded of the boundary $u^m = 1$ on $(0,\infty)\times\Gamma$.  Change of unknown $v\coloneqq1 - u^m$ in semilinear case $m = 1$ leads to the formulation $\partial_tv - \Delta v = \frac{\chi_{\{v < 1\}}}{(1 - v)^\beta}$ on $(0,\infty)\times\Omega$. Study the associated Cauchy problem in $(0,\infty)\times\mathbb{R}^N$ can be regarded from 2 different points of view according to the assumptions made on the asymptotic behavior of the initial datum when $|{\bf x}|\to\infty$.	
	\begin{goal}
		Analyze problem of type (P) \& (CP) when $u_0({\bf x})\searrow0$ as $|{\bf x}|\to\infty$.
	\end{goal}
	{\sf Motivation.} Problem (P) was regarded as the limit case of regularized Langmuir--Hinshelwood model in chemical catalyst kinetics for elliptic- \& parabolic equations.
	
	{\sf Interesting point.} Solutions may raise to a free boundary defined as $\partial\{(t,{\bf x});u(t,{\bf x}) > 0\}$. (P1) denoted as a {\it quenching problem}. Appearance of a blow-up time for $\partial_tu$ at the 1st time $T_{\rm c} > 0$ in which $u(T_{\rm c},{\bf x}) = 0$ at some point ${\bf x}\in\Omega$.
	
	Case $\beta\ge m$ presents special difficulties when the free boundary $\partial\{(t,{\bf x});u(t,{\bf x}) > 0\}$ is a nonempty hypersurface, this set corresponds to the set of {\it rupture points} in study of thin films. This case $\beta\ge m$ also arises in the modeling of micro-electromechanical systems (MEMS), in which mainly $m = 1,\beta = 2$.
	
	\item \cite{Kawohl1992}. {\sc Bernhard Kawohl}. {\it Remarks on quenching, blow up, \& dead cores}.
	\item \cite{Kawohl1996}. {\sc Bernhard Kawohl}. {\it Remarks on quenching}.
	\item \cite{Kawohl_Kersner1992}. {\sc Bernhard Kawohl, Robert Kersner}. {\it On degenerate diffusion with very strong absorption}.
	\item \cite{Phillips1987}. {\sc Daniel Phillips}. {\it Existence of solutions of quenching problems}.\hfill{\sf[100 citations]}
	
	Prove existence of weak solutions to PME when $N\ge1$, $m = 1$, $\beta\in(0,1)$.
	\item \cite{Vazquez2007}. {\sc Juan Luis V\'{a}zquez}. {\it The Porous Medium Equation}.
	
	{\sf Note.} Có nhiều bộ ký hiệu xung đột nhau do tác giả chắp vá quyển sách từ nhiều bài báo, công trình khác nhau. Nên cẩn thận khi thống nhất bộ ký hiệu.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Scientific Computing -- Tính Toán Khoa Học}

\begin{enumerate}
	\item \cite{Press_Teukolsky_Vetterling_Flannery_recipe_C++}. {\sc William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery}. {\it Numerical Recipes: The Art of Scientific Computing}. {\sf[158 Amazon ratings][155 Goodreads ratings]}
	
	{\sf Amazon review.} Co-authored by 4 leading scientists from academia \& industry, Numerical Recipes 3e starts with basic mathematics \& computer science \& proceeds to complete, working routines. Widely recognized as the most comprehensive, accessible \& practical basis for scientific computing, this new edition incorporates $> 400$ Numerical Recipes routines, many of them new or upgraded. The executable C++ code, now printed in color for easy reading, adopts an object-oriented style particularly suited to scientific applications. The whole book is presented in the informal, easy-to-read style that made earlier editions so popular. New key features:
	\begin{itemize}
		\item 2 new chapters, 25 new sections, 25\% longer than 2e.
		\item Thorough upgrades throughout the text
		\item $> 100$ completely new routines \& upgrades of many more.
		\item New Classification \& Inference chapter, including Gaussian mixture models, HMMs, hierarchical clustering, Support Vector Machines
		\item New Computational Geometry chapter covers KD trees, quad- \& octrees, Delaunay triangulation, \& algorithms for lines, polygons, triangles, \& spheres
		\item New sections include interior point methods for linear programming, Monte Carlo Markov Chains, spectral \& pseudospectral methods for PDEs, \& many new statistical distributions
		\item An expanded treatment of ODEs with completely new routines
	\end{itemize}
	Plus comprehensive coverage of
	\begin{itemize}
		\item linear algebra, interpolation, special functions, random numbers, nonlinear sets of equations, optimization, eigensystems, Fourier methods \& wavelets, statistical tests, ODEs \& PDEs, integral equations, \& inverse theory
	\end{itemize}
	The essential text \& reference for modern scientific computing now also covers computational geometry, classification \& inference, \& much more.
	
	{\sf Editorial reviews.}
	\begin{itemize}
		\item ``This monumental \& classic work is beautifully produced \& of literary as well as mathematical quality. It is an essential component of any serious scientific or engineering library.'' -- Computing Reviews
		\item ``$\ldots$ an instant `classic,' a book that should be purchased \& read by anyone who uses numerical methods $\ldots$'' -- American Journal of Physics
		\item ``$\ldots$ replete with the standard spectrum of mathematically pretreated \& coded{\tt/}numerical routines for linear equations, matrices \& arrays, curves, splines, polynomials, functions, roots, series, integrals, eigenvectors, FFT, \& other transforms, distributions, statistics, \& on to ODE's \& PDE's $\ldots$ delightful.'' -- Physics in Canada
		\item ``$\ldots$ if you were to have only a single book on numerical methods, this is the one I would recommend.'' -- EEE Computational Science \& Engineering
		\item ``This encyclopedic book should be read (or at least owned) not only by those who must roll their own numerical methods, but by all who mus use prepackaged programs.'' -- New Scientist
		\item ``These books are a must for anyone doing scientific computing.'' -- Journal of the American Chemical Society
		\item ``The authors are to be congratulated for providing the scientific community with a valuable resource.'' -- The Scientist
		\item ``I think this is an incredibly valuable book for both learning \& reference \& I recommend it for any scientists or student in a numerate discipline who need to understand \&{\tt/}or program numerical algorithms.'' -- International Association for Pattern Recognition
		\item ``The attractive style of the text \& the availability of the codes ensured the popularity of the previous editions \& also recommended this recent volume to different categories of readers, more or less experienced in numerical computation.'' -- {\sc Octavian Pastravanu}, Zentralblatt MATH
	\end{itemize}
	{\sf About the Author.} {\sc William H. Press} holds the Raymer Chair in Computer Sciences \& Integrative Biology at the University of Texas at Austin. {\sc Saul A. Teukolsky} is H. A. Bethe Professor in Physics in the Radiophysics \& Space Research Department of Cornell University.	{\sc William Vetterling} is a Research Fellow \& Director of the Image Science Laboratory at ZINK Imaging, LLC in Waltham, MA. His career includes eight years on the physics faculty at Harvard \& 20 years of numerical modeling \& laboratory research on digital imaging at Polaroid Corporation. {\sc Brian P. Flannery} is Science, Strategy \& Programs Manager at Exxon Mobil Corporation.
	
	{\bf Preface to 3e (2007).} ``I was just going to say, when I was interrupted $\ldots$'' begins {\sc Oliver Wendell Holmes} in the 2nd series of his famous essays, {\it The Autocrat of the Breakfast Table}. The interruption referred to was a gap of 25 years. In our case, as the autocrats of {\it Numerical Recipes}, the gap between our 2nd \& 3rd editions has been ``only'' 15 years. Scientific computing has changed enormously in that time.
	
	The 1e of {\it Numerical Recipes} was roughly coincident with the 1st commercial success of the personal computer. The 2e came at about the time that the Internet, as we know it today, was created. Now, as we launch the 3e, the practice of science \& engineering, \& thus scientific computing, has been profoundly altered by the mature Internet \& Web. It is no longer difficult to find {\it somebody}'s algorithm, \& usually free code, for almost any conceivable scientific application. The critical questions have instead become, ``How does it work?'' \& ``Is it any good?'' Correspondingly, the 2e of {\it Numerical Recipes} has come to be valued more \& more for its text explanations, concise mathematical derivations, critical judgments, \& advice, \& less for its code implementations per se.
	
	Recognizing the change, we have expanded \& improved the text in many places in this edition \& added many completely new sections. Seriously considered leaving the code out entirely, or making it available only on the Web. However, in the end, we decided that without code, it wouldn't be {\it Numerical Recipes}. I.e., without code you, the reader, could never know whether our advice was in fact honest, implementable, \& practical. Many discussions of algorithms in the literature \& on the Web omit crucial details that can only be uncovered by actually coding (our job) or reading compilable code (your job). Also, we needed actual code to teach \& illustrate the large number of lessons about object-oriented programming that are implicit \& explicit in this edition.
	
	Our wholehearted embrace of a style of object-oriented computing for scientific applications should be evident throughout this book. We say ``{\it a} style,'' because, contrary to the claims of various self-appointed experts, there can be no one rigid style of programming that serves all purposes, not even all scientific purposes. Our style is ecumenical. If a simple, global, C-style function will fill the need, then we use it. On the other hand, you will fin us building some fairly complicated structures for something as complicated as, e.g., integrating ODEs.
	
	In bringing the text up to date, we have luckily not had to bridge a full 15-year gap. Significant modernizations were incorporated into 2e versions in Fortran 90 (1996)\footnote{``Alas, poor Fortran 90! We knew him, Horatio: a programming language of infinite jest, of most excellent fancy: he hath borne us on his back 1000 times.''
	
	-- Than ôi, Fortran tội nghiệp 90! Chúng tôi biết anh ấy, Horatio: 1 ngôn ngữ lập trình vô cùng hài hước, tuyệt vời nhất: anh ấy đã cõng chúng tôi trên lưng 1000 lần.} \& C++ (2002), in which, notably, the last vestiges of unit-based arrays were expunged in favor of C-style 0-based indexing. Only with this 3e, however, have we incorporated a substantial amount (several hundred pages!) of completely new material. Highlights include:
	\begin{itemize}
		\item a new chapter on classification \& inference, including such topics as Gaussian mixture models, hidden Markov modeling, hierarchical clustering (phylogenetic trees), \& support vector machines
		\item a new chapter on computational geometry, including topics like KD trees, quad- \& octrees, Delaunay triangulation \& applications, \& many useful algorithms for lines, polygons, triangles, spheres, etc.
		\item many new statistical distributions, with pdfs, cdfs, \& inverse cdfs
		\item an expanded treatment of ODEs, emphasizing recent advances, \& with completely new routines
		\item much expanded sections on uniform random deviates \& on deviates from many other statistical distributions
		\item an introduction to spectral \& pseudospectarl methods for PDEs
		\item interior point methods for linear programming
		\item more on sparse matrices
		\item interpolation on scattered data in multidimensions
		\item curve interpolation in multidimensions
		\item quadrature by variable transformation \& adaptive quadrature
		\item more on Gaussian quadratures \& orthogonal polynomials
		\item more on accelerating the convergence of series
		\item improved incomplete gamma \& beta functions \& new inverse functions
		\item improved spherical harmonics \& fast spherical harmonic transforms
		\item generalized Fermi-Dirac integrals
		\item multivariate Gaussian deviates
		\item algorithms \& implementations for hash memory functions
		\item incremental quantile estimation
		\item chi-square with small numbers of counts
		\item dynamic programming
		\item hard \& soft error correction \& Viterbi decoding
		\item eigensystem routines for real, nonsymmetric matrices
		\item multitaper methods for power spectral estimation
		\item wavelets on the interval
		\item information-theoretic properties of distributions
		\item Markov chain Monte Carlo
		\item Gaussian process regression \& kriging
		\item stochastic simulation of chemical reaction networks
		\item code for plotting simple graphs from within programs
	\end{itemize}
	The Numerical Recipes Web site \url{https://numerical.recipes/}, is 1 of the oldest active sites on Internet. Go there to find the latest bug reports, to purchase the machine-readable source code, or to participate in our readers' forum. With this 3rd edition, also plan to offer, by subscription, a completely electronic version of {\it Numerical Recipes} -- accessible via the Web, downloadable, printable, \&, unlike any paper version, always up to date with the latest corrections. Since the electronic version does not share the page limits of the print version, it will grow over time by the addition of completely new sections, available only electronically. This, we think, is the future of {\it Numerical Recipes} \& perhaps of technical reference books generally.
	
	This edition also incorporates some ``user-friendly'' typographical \& stylistic improvements: Color is used for headings \& to highlight executable code. For code, a label in the margin gives the name of the source file in the machine-readable distribution. Instead of printing repetitive \verb|#include| statements, we provide a convenient Web tool \url{https://numerical.recipes/dependencies/} that will generate exactly the statements you need for any combination of routines. Subsections are now numbered \& referred to by number. References to journal articles now include, in most cases, the article title, as an aid to easy Web searching. Many references have been updated; but we have kept references to the grand old literature of classical numerical analysis when we think that books \& articles deserve to be remembered.
	
	{\sf Acknowledgments.} Regrettably, over 15 years, we were not able to maintain a systematic record of the many dozens of colleagues \& readers who have made important suggestions, pointed us to new material, corrected errors, \& otherwise improved the {\it Numerical Recipes} enterprise. A tired clich\'e to say that ``you know who you are.'' Actually, in most cases, {\it we} know who you are, \& we are grateful. But a list of names would be incomplete, \& therefore offensive to those whose contributions are no less important than those listed. Prepared this book for publication on Windows \& Linux machines, generally with Intel Pentium processors, using \LaTeX\ in the Te\TeX\ \& MiK\TeX\ implementations. Packages used include {\tt amsmath, amsfonts, txfonts, graphicx}, among others. Our principal development environments were Microsoft Visual Studio{\tt/}Microsoft Visual C++ \& GNU C++. We used the SourceJammer cross-platform source control system. Many tasks were automated with Perl scripts. Could not live without GNU Emacs. To all the developers: ``You know who you are,'' \& thank you.
	
	{\bf Preface to 2e (1992).} Aim in writing the original edition of {\it Numerical Recipes} was to provide a book that combined general discussion, analytical mathematics, algorithmics, \& actual working programs. The success of 1e puts us now in a difficult, though hardly unenviable, position. Wanted, then \& now, to write a book that is informal, fearlessly editorial, unesoteric, \& above all useful. There is a danger that, if we are not careful, we might produce a 2e that is weighty, balanced, scholarly, \& boring.
	
	A mixed blessing that we know more now than we did 6 years ago. Then, we were making educated guesses, based on existing literature \& our own research, about which numerical techniques were the most important \& robust. Now, have benefit of direct feedback from a large reader community. Letters to our alter-ego enterprise, Numerical Recipes Software, are in the thousands per year. (Please, {\it don't telephone} us.\footnote{Hyper introverted?}) Our post office box has become a magnet for letters pointing out that we have omitted some particular technique, well known to be important in a particular field of science or engineering. We value such letters \& digest them carefully, especially when they point us to specific references in the literature.
	
	The inevitable result of this input is that this 2e of {\it Numerical Recipes} is substantially larger than its predecessor, in fact $\approx50\%$ larger in both words \& number of included programs (the latter now numbering well $> 300$). ``Don't let the book grow in size,'' is the advice that we received from several wise colleagues. We have tried to follow the intended spirit of that advice, even as we violate the letter of it. Have not lengthened, or increased in difficulty, the book's principal discussions of mainstream topics. Many new topics are presented at this same accessible level. Some topics, both from the earlier edition \& new to this one, are now set in smaller type that labels them as being ``advanced.'' Reader who ignores such advanced sections completely will not, we think, find any lack of continuity in the shorter volume that results. Here are some highlights of the new material in 2e:
	\begin{itemize}
		\item a new chapter on integral equations \& inverse methods
		\item a detailed treatment of multigrid methods for solving elliptic PDEs
		\item routines for band-diagonal linear systems
		\item improved routines for linear algebra on sparse matrices
		\item Cholesky \& QR decomposition
		\item orthogonal polynomials \& Gaussian quadratures for arbitrary weight functions
		\item methods for calculating numerical derivatives
		\item Pad\'e approximations \& rational Chebyshev approximation
		\item Bessel functions, \& modified Bessel functions, of fractional order \& several other new special functions
		\item improved random number routines
		\item quasi-random sequences
		\item routines for adaptive \& recursive Monte Carlo integration in high-dimensional spaces
		\item globally convergent methods for sets of nonlinear equations
		\item simulated annealing minimization for continuous control spaces
		\item fast Fourier transform (FFT) for real data in 2D \& 3D
		\item fast Fourier transform using external storage
		\item improved fast cosine transform routines
		\item wavelet transforms
		\item Fourier integrals with upper \& lower limits
		\item spectral analysis on unevenly sampled data
		\item Savitzky-Golay smoothing filters
		\item fitting straight line data with errors in both coordinates
		\item a 2D Kolmogorov-Smirnoff test
		\item statistical bootstrap method
		\item embedded Runge--Kutta--Fehlberg methods for differential equations
		\item high-order methods for stiff differential equations
		\item a new chapter on ``less-numerical'' algorithms, including Huffman \& arithmetic coding, arbitrary precision arithmetic, \& several other topics
	\end{itemize}
	Special acknowledgment is due to programming consultant {\sc Seth Finkelstein}, who wrote, rewrote, or influenced many of routines in this book, as well as in its Fortran-language twin \& the companion Example books. Our project has benefited enormously from {\sc Seth}'s talent for detecting, \& following the trail of, even very slight anomalies (often compiler bugs, but occasionally our errors), \& from his good programming sense. To the extent that this edition of {\it Numerical Recipes in C} has a more graceful \& ``C-like'' programming style than its predecessor, most of the credit goes to {\sc Seth}. (Of course, we accept the blame for the Fortranish lapses that still remain.)
	
	Prepared this book for publication on DEC \& Sun workstations running UNIX operating system \& on a 486{\tt/}33 PC compatible running MS-DOS 5.0{\tt/}Windows 3.0. Enthusiastically recommend the principal software used: GNU Emacs, TEX, Perl, Adobe Illustrator, \& PostScript. Also used were a variety of C compilers -- too numerous (\& sometimes too buggy) for individual acknowledgment. It is a sobering fact that our standard test suite (exercising all routines in this book) has uncovered compiler bugs in many of the compilers tried. When possible, work with developers to see that such bugs get fixed; encourage interested compiler developers to contact about such arrangements.

	{\bf Preface to 1e (1985).} Call this book {\it Numerical Recipes} for several reasons. In 1 sense, this book is indeed a ``cookbook'' on numerical computation. However, there is an important distinction between a cookbook \& a restaurant menu. The latter presents choices among complete dishes in each of which the individual flavors are blended \& disguised. The former -- \& this book -- reveals the individual ingredients \& explains how they are prepared \& combined.
	
	Another purpose of the title is to connote an eclectic mixture of presentational techniques. This book is unique in offering, for each topic considered, a certain amount of general discussion, a certain amount of analytical mathematics, a certain amount of discussion of algorithmics, \& (most important) actual implementations of these ideas in the form of working computer routines. Task has been to \fbox{find the right balance among these ingredients} for each topic. You will find that for some topics we have tilted quite far to the analytic side; this where we have felt there to be gaps in the ``standard'' mathematical training. For other topics, where
	the mathematical prerequisites are universally held, we have tilted toward more in-depth discussion of the nature of the computational algorithms, or toward practical questions of implementation.
	
	We admit, therefore, to some unevenness is the ``level'' of this book. About half ot it is suitable for an advanced undergraduate course on numerical computation for science or engineering majors. The other half ranges from the level of a graduate course to that of a professional reference. Most cookbooks have, after all, recipes at varying levels of complexity. An attractive feature of this approach, we think, is that the reader can use the book at increasing levels of sophistication as his{\tt/}her experience grows. Even inexperienced readers should be able to use our most advanced routines as black boxes. Having done so, hope that these readers will subsequently go back \& learn what secrets are inside.
	
	If there is a single dominant theme in this book:
	\begin{center}
		\fbox{practical methods of numerical computation can be \fbox{simultaneously efficient, clever}, \& -- important -- \fbox{clear}.}
	\end{center}
	The alternative viewpoint, that efficient computational methods must necessarily be so arcane \& complex as to be useful only in ``black box'' form, we firmly reject.
	
	Purpose: open up a large number of computational black boxes to your scrutiny. Want to teach you to take part these black boxes \& to put them back together again, modifying them to suit your specific needs. Assume that you are mathematically literature, i.e., that you have the normal mathematical preparation associated with an undergraduate degree in a physical science, or engineering, or economics, or a quantitative social science. Assume that know how to program a computer. Do not assume that you have any prior formal knowledge of numerical analysis or numerical methods.
	
	The scope of {\it Numerical Recipes} is supposed to be ``everything up to, but not including, PDEs.'' Honor this in the breach: 1st, we {\it do} have 1 introductory chapter on methods for PDEs. 2nd, obviously cannot include {\it everything} else. All ``standard'' topics of a numerical analysis course have been included in this book: linear equation, interpolation \& extrapolation, integration, nonlinear root finding, eigensystems, \& ODEs. Most of these topics have been taken beyond their standard treatments into some advanced material that we have felt to be particularly important or useful.
	
	Some other subjects covered in detail are not usually found in the standard numerical analysis texts. These include the evaluation of functions \& of particular special functions of higher mathematics; random numbers \& Monte Carlo methods; sorting; optimization, including multidimensional methods; Fourier transform methods, including FFT methods \& other spectral methods; 2 chapters on statistical description \& modeling of data; \& 2-point BVPs, both shooting \& relaxation methods.
	
	{\bf Acknowledgments.} Many colleagues have been generous in giving us the benefit of their numerical \& computational experience, in providing us with programs, in commenting on the manuscript, or with general encouragement. Also wish to acknowledge 2 individuals whom we have never met: {\sc Forman Acton}, whose 1970 textbook {\it Numerical Methods That Work} has surely left its stylistic mark on us; \& {\sc Donald Knuth}, both for his series of books on {\it The Art of Computer Programming}, \& for \TeX, the computer typesetting language that immensely aided production of this book. [$\ldots$]
	
	\begin{itemize}
		\item {\sf1. Preliminaries.}
		\begin{itemize}
			\item {\sf Introduction.} Supposed to teach you methods of numerical computing that are practical, efficient, \& (insofar as possible) elegant. Presume throughout this book that the reader have particular tasks that you want to get done. View our job as educating you on how to proceed. Occasionally we may try to reroute you briefly onto a particularly beautiful side road; but by \& large, will guide along main highways that lead you to practical destinations.
			
			Throughout this book, you will find us fearlessly editorializing, telling you what you should \& shouldn't do. This prescriptive tone results from a conscious decision on our part, \& we hope that you will not find it irritating. Do not claim that our advice is infallible! Rather, we are reacting against a tendency, in the textbook literature of computation, to discuss every possible method that has ever been invented, without ever offering a practical judgment on relative merit. We do, therefore, offer you our practical judgments whenever we can. As you gain experience, you will form your own opinion of how reliable our advice is. Be assured that it is not perfect!
			
			Presume that you are able to read computer programs in C++. The question, ``Why C++?'', is a complicated one. For now, suffice it to say that we wanted a language with a C-like syntax in the small (because that is most universally readable by our audience), which had a rich set of facilities for OOP (because that is an emphasis of this 3d), \& which was highly backward-compatible with some old, but established \& well-tested, tricks in numerical programming. That pretty much led us to C++, although Java (\& the closely related C\#) were close contenders.
			
			Honesty compels us to point out that in the 20-year history of {\it Numerical Recipes}, have never been correct in our predictions about the future of programming languages for scientific programming, {\it not once}! At various times we convinced ourselves that the wave of the scientific future would be $\ldots$ Fortran $\ldots$ Pascal $\ldots$ C $\ldots$ Fortran 90 (or 95 or 2000) $\ldots$ Mathematica $\ldots$ Matlab $\ldots$ C++ or Java $\ldots$ Indeed, several of these enjoy continuing success \& have significant followings (not including Pascal!). None, however, currently command a majority, or even a large plurality, of scientific users.
			
			With this edition, no longer try to predict the future of programming languages. Rather, want a serviceable way of communicating ideas about scientific programming. Hope that these ideas transcend the language, C++, in which we are expressing them.
			
			Routines begin with an introductory comment summarizing their purpose \& explaining their calling sequence. Convention of handling all errors \& exceptional cases with a statement like \verb|throw("some error message");|. Since C++ has no built-in exception class for type {\tt char*}, executing this statement results in a fairly rude program abort.
		\end{itemize}
		\item {\sf2. Solution of Linear Algebraic Equations.}
		\item {\sf3. Interpolation \& Extrapolation.}
		\item {\sf4. Integration of Functions.}
		\item {\sf5. Evaluation of Functions.}
		\item {\sf6. Special Functions.}
		\item {\sf7. Random Numbers.}
		\item {\sf8. Sorting \& Selection.}
		\item {\sf9. Root Finding \& Nonlinear Sets of Equation.}
		\item {\sf10. Minimization or Maximization of Functions.}
		\item {\sf11. Eigensystems.}
		\item {\sf12. Fast Fourier Transform.}
		\item {\sf13. Fourier \& Spectral Applications.}
		\item {\sf14. Statistical Description of Data.}
		\item {\sf15. Modeling of Data.}
		\item {\sf16. Classification \& Inference.}
		\item {\sf17. Integration of ODEs.}
		\item {\sf18. 2-Point BVPs.}
		\item {\sf19. Integral Equations \& Inverse Theory.}
		\item {\sf20. PDEs.}
		\item {\sf21. Computational Geometry.}
		\item {\sf22. Less-Numerical Algorithms.}
	\end{itemize}
	
	\item {\sc William H. Press}. {\it More Than Curious: A Science Memoir}.
	
	\item \cite{Press_Teukolsky_Vetterling_Flannery_recipe_C}. {\sc William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery}. {\it Numerical Recipes in C: The Art of Scientific Computing}. {\sf[76 Amazon ratings][255 Goodreads ratings]}
	
	{\sf Amazon review.} The product of a unique collaboration among 4 leading scientists in academic research \& industry, Numerical Recipes is a complete text \& reference book on scientific computing. In a self-contained manner it proceeds from mathematical \& theoretical considerations to actual practical compute routines. With $> 100$ new routines bringing the total to well $> 300$, plus upgraded versions of the original routines, the new edition remains the most practical, comprehensive handbook of scientific computing available today.
	
	{\bf Editorial reviews.}
	\begin{itemize}
		\item ``$\ldots$ an instant `classic,' a book that should be purchased \& read by anyone who uses numerical methods $\ldots$'' -- American Journal of Physics
		\item ``No matter what language you program in, these packages are classics, both as a textbook or reference. They are an essential \& valuable addition to the academic, professional, or personal library.'' -- Internet
		\item ``The new book exceeds, if possible, the excellence of its predecessor: it is $\approx50\%$ longer \& has been thoroughly updated $\ldots$ The bibliographical material has been considerably extended \& updated $\ldots$ For new users, it is sufficient to say that practically every aspect of numerical analysis is covered $\ldots$ This monumental \& classic work is beautifully produced \& of literary as well as mathematical quality. It is an essential component of any serious scientific or engineering library.'' -- {\sc A. D. Booth}, Computing Reviews
		\item ``If you already have the 1st edition, will you want or need the 2nd? The answer is a definitive yes $\ldots$ a book that should be on your desk (not your shelf) if you have any interest in the analysis of data or the formulation of models.'' -- {\sc  Lyle W. Konigsberg}, Human Biology
		\item ``$\ldots$ the 2nd [edition] expands the scope of coverage \& continues the standard of excellence achieved in the 1st. If you were to have only a single book on numerical methods, this is the one I would recommend.'' -- {\sc Edmund Miller}, IEEE Computational Science \& Engineering
		\item ``$\ldots$ remarkably complete $\ldots$ it contains many more routines than many commercial mathematics packages $\ldots$'' -- Byte
		\item ``The authors are to be congratulated for providing the scientific community with a valuable resource.'' -- The Scientist
		\item ``$\ldots$ replete with the standard spectrum of mathematically pretreated \& coded{\tt/}numerical routines for linear equations, matrices, \& arrays, curves, splines, polynomials, functions, roots, series, integrals, eigenvectors, FFT, \& other transforms, distributions, statistics, \& on to ODE's \& PDE's $\ldots$ such an education $\ldots$ is delightful $\ldots$'' -- Physics in Canada
	\end{itemize}
	
	\item \cite{Press_Teukolsky_Vetterling_Flannery_recipe_Fortran77}. {\sc William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery}. {\it Numerical Recipes in Fortran 77: The Art of Scientific Computing}. {\sf[41 Amazon ratings][38 Goodreads ratings]}
	
	{\sf Amazon review.} This is the greatly revised \& greatly expanded 2e of the hugely popular Numerical Recipes: The Art of Scientific Computing. The product of a unique collaboration among 4 leading scientists in academic research \& industry Numerical Recipes is a complete text \& reference book on scientific computing. In a self-contained manner it proceeds from mathematical \& theoretical considerations to actual practical computer routines. With $> 100$ new routines bringing the total to well $> 300$, plus upgraded versions of the original routines, this new edition remains the most practical, comprehensive handbook of scientific computing available today. Highlights of the new material include:
	\begin{itemize}
		\item A new chapter on integral equations \& inverse methods
		\item Multigrid \& other methods for solving PDEs
		\item Improved random number routines
		\item Wavelet transforms
		\item The statistical bootstrap method
		\item A new chapter on ``less-numerical'' algorithms including compression coding \& arbitrary precision arithmetic.
	\end{itemize}
	The book retains the informal easy-to-read style that made the 1st edition so popular, while introducing some more advanced topics. It is an ideal textbook for scientists \& engineers \& an indispensable reference for anyone who works in scientific computing. The 2e is available in FORTRAN, the traditional language for numerical calculations \& in the increasingly popular C language.
	
	{\sf Editorial reviews.}
	\begin{itemize}
		\item ``This is a phenomenal effort. Virtually anyone involved in scientific computing, from engineers, to physicists, to social scientists, will find information \& methods applicable to their specific needs, or helpful subroutines that can be inserted into the reader's existing programs $\ldots$ No matter what language you program in, these packages are classics, both as a textbook or reference. They are an essential \& valuable addition to the academic, professional, or personal library.'' Internet
		\item ``Anyone who writes (or is curious about) computer codes to solve many of the common numerical problems in science \& engineering will want to own this large book. The writing is authoritative (2 of the authors have published 1st-rate research in writing code for astrophysics problems), but never dull. Flashes of humor appear at regular intervals, in the appropriate places, \& as hard as it may be to believe, this book is interesting even as casual reading! I recommend this book highly, \& both the authors \& the publisher are to be commended for an outstanding piece of work.'' -- {\sc Paul J. Nahin}, Science Books \& Films
		\item ``This encyclopedic book should be read (or at least owned) not only by those who must roll their own numerical methods, but by all who must use prepackaged programs.'' -- {\sc Mike Holderness}, New Scientist
		\item ``This reviewer knows of no other single source of so much material of this nature. Highly recommended.'' -- {\sc R. J. Wernick}, Choice
		\item ``$\ldots$ will be appreciated by anyone involved in the numerical solution of engineering problems $\ldots$ the authors have successfully blended tutorial discussion, fundamental mathematics, explanation of algorithms, \& working computer programs into neatly packaged chapters covering all of the basic topics in numerical methods. What sets this book apart, in the reviewer's opinion, is the versatility of the book $\ldots$ indispensable.'' -- {\sc Ben H. Thacker}, Applied Mechanics Review
		\item ``If you already have the 1e, will you want or need the 2nd? The answer is a definitive yes $\ldots$ a book that should be on your desk (not your shelf) if you have any interest in the analysis of data or the formulation of models $\ldots$ The 2e contains numerous additions of important material, e.g., a section on Cholesky decomposition (which is critical for simulating multivariate distributions), discussions of the boostrap method, \& the addition \& expansion of other numerical methods too numerous to mention here.'' -- {\sc Lyle W. Konigsberg}, Human Biology
		\item ``$\ldots$ a valuable resource for those with a specific need for numerical software. The routines are prefaced with lucid, self-contained explanations $\ldots$ highly recommended for those who require the use \& understanding of numerical software.'' -- {\sc Elizabeth Greenwell Yanik}, SIAM Review
		\item ``$\ldots$ the 2nd [edition] expands the scopes of covereage \& continues the standard of excellence achieved in the 1st. If you were to have only a single book on numerical methods, this is the one I would recommend.'' -- {\sc Edmund Miller}, IEEE Computational Science \& Engineering
	\end{itemize}
	
	\item \cite{Press_Teukolsky_Vetterling_Flannery_recipe_Fortran90}. {\sc William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery}. {\it Numerical Recipes in Fortran 90: Volume 2, Volume 2 of Fortran Numerical Recipes: The Art of Parallel Scientific Computing}. {\sf[16 Amazon ratings]}
	
	{\sf Amazon review.} The 2nd volume of Fortran Numerical Recipes series, Numerical Recipes in Fortran 90 contains a detailed introduction to the Fortran 90 language \& to the basic concepts of parallel programming, plus source code for all routines from 2e of Numerical Recipes. This volume does not repeat any of the discussion of what individual programs actually do, the mathematical methods they utilize, or how to use them.
	
	This book gives a detailed introduction to Fortran 90 and to parallel programming, with all 350+ routines from the second edition of Numerical Recipes.
	
	{\sf Editorial reviews.}
	\begin{itemize}
		\item ``$\ldots$ this present volume will contribute decisively to a significant breakthrough, as it provides models not only of the numerical algorithms for which previous editions are already famed, but also of an excellent Fortran 90 style $\ldots$'' -- From the Foreword by {\sc Michael Metcalf}, 1 of Fortran 90's original designers and author of FORTRAN 90 Explained
		\item ``As with previous volumes in this series, this book is a classical \& is essential reading for anyone concerned with the future of numerical calculation. It is beautifully produced, inexpensive for its content, \& a must for any serious worker or student.'' -- {\sc A. D. Booth}, Computing Reviews
		\item ``$\ldots$ very useful for graduate \& postgraduate courses \& also for all specialists who are interested in parallel scientific computing.'' -- {\sc Mikhail P. Levin}, IEEE Concurrency
	\end{itemize}
	
	\item \cite{Press_Teukolsky_Vetterling_Flannery_recipe_Fortran90}. {\sc William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery}. {\it Numerical Recipes in Pascal: The Art of Scientific Computing}. {\sf[22 Amazon ratings]}
	
	{\sf Amazon review.} This version of the 1st edition of Numerical Recipes contains the original 200 routines translated into Pascal along with the tutorial text. In a single volume, Numerical Recipes in Pascal provides lucid, easy-to-read discussions of the most important practical numerical techniques for science and engineering. The programs contained in this book are also available as machine-readable code on the Numerical Recipes Code CD-ROM with Windows{\tt/}Macintosh Single Screen License. Numerical Recipes in Pascal fills a long-recognized need for a practical, comprehensive handbook of scientific computing in the Pascal language.
	
	{\sf Editorial reviews.}
	\begin{itemize}
		\item ``This book is indispensable to anyone who wishes to employ numerical techniques quickly \& confidently without becoming an expert in applied mathematics.'' --  
		Journal of Nuclear Medicine
		\item ``Anyone who is numerate will read it with profit; anyone who is literate will read it with satisfaction; \& anyone who has a sense of humor will read it with real enjoyment.'' -- Observatory
		\item ``Truly impressive is the insight the authors offer throughout into various aspects of the numerical methods presented.'' -- Physics Today
		\item ``There is no way that this review can even begin to convey the truly immense amount of material that is in this book.'' -- Technometrics
		\item ``Splendid text \& reference on the art of scientific programming. As a sourcebook of important algorithms \& their background information, proceeds effortlessly from the math \& theory to the $> 200$ practical Pascal routines.'' -- Computer Book Review
		\item ``It really still remains a gold mine for those who need ready solutions to computing problems $\ldots$ You might well ask, `do we really need another version whose text is unchanged but where the algorithms are presented in Pascal rather than in FORTRAN?' The answer is `yes' if you, like me, are a Pascal programmer.'' -- Geological Magazine
		\item ``$\ldots$ a `toolbox' for people in the sciences \& engineering who frequently work with numbers.'' -- American Scientist
		\item ``I would recommend this text, or any of the series, to scientific programmers.'' -- Physics in Canada
		\item ``The book's virtues are that it lists important topics from numerical analysis that may be of interest to scientists \& engineers. It gives a summary of the philosophy behind each of the methods discussed \& a bibliography so that one can find out more.'' -- Computing Reviews
		\item ``This is a phenomenal effort. Virtually anyone involved in scientific computing, from engineers, to physicists, to social scientists, will find information \& methods applicable to their specific needs, or helpful subroutines that can be inserted into the reader's existing programs $\ldots$ No matter what language you program in, these packages are classics, both as a textbook or reference. They are an essential \& valuable addition to the academic, professional, or personal library.'' -- Internet
	\end{itemize}
	
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Sobolev Spaces -- Không Gian Sobolev}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Adams_Fournier2003}. {\sc Robert A. Adams, John J. F. Fournier}. {\it Sobolev Spaces}.
	
	{\bf Preface.} ``This monograph presents an introductory study of properties of certain Banach spaces of weakly differentiable functions of several real variables arsing in connection with numerous problems in theory of PDEs, approximation theory, \& many other areas of pure \& applied mathematics. These spaces have become associated with name of late Russian mathematician {\sc S. L. Sobolev}, although their origins predate his major contributions to their development in late 1930s.
	
	Even by 1975 when 1e of this monograph was published, there was a great deal of material on these spaces \& their close relatives, though most of it was available only in research papers published in a wide variety of journals. Wrote monograph to fill a perceived need for a single source where grad students \& researchers in a wide variety of disciplines could learn essential features of Sobolev spaces that they needed for their particular applications. No attempt was made even at that time for complete coverage. 1e: The existing mathematical literature on Sobolev spaces \& their generalizations is vast, \& it would be neither easy nor particularly desirable to include everything known about such spaces between covers of 1 book. An attempt has been made in this monograph to present all the core material in sufficient generality to cover most applications, to give reader an overview of subject difficult to obtain by reading research papers, \& finally to provide a ready ref for some requiring a result about Sobolev spaces for use in some application.
	
	During intervening 27 years research literature has grown exponentially, \& there are now several other books in English dealing in whole or in part with Sobolev spaces. However, there is still a need for students in other disciplines than mathematics, \& in other areas of mathematics than just analysis to have available a book describing these spaces \& their core properties based only a background in mathematical analysis at senior undergraduate level. Organization:
	\begin{itemize}
		\item Chap. 1 remains a potpourri of standard topics from real \& functional analysis, included, mainly without proofs, because they provide a necessary background for what follows.
		\item Chap. 2 on Lebesgue spaces $L^p(\Omega)$ is much expanded \& reworked from 1e. Provide, in addition to standard results about these spaces, a brief treatment of mixed-norm $L^p$ spaces, weak-$L^p$-spaces, \& Marcinkiewicz interpolation theorem, all of which will be used in a new treatment of Sobolev imbedding theorem in Chap. 4.
		\item Chap. 3 provides basic defs \& properties of Sobolev spaces $W^{m,p}(\Omega),W_0^{m,p}(\Omega)$.
		\item Chap. 4 is now completely concerned with imbedding properties of Sobolev spaces. 1st half gives a more streamlined presentation \& proof of various imbeddings of Sobolev spaces into $L^p$ spaces, including traces on subspaces of lower dimension, \& spaces of continuous \& uniformly continuous functions. Because approach to Sobolev imbedding theorem has changed, roles of Chaps. 4--5 have switched from 1e. Latter part of Chap. 4 deals with situations where regularity conditions on domain $\Omega$ necessary for full Sobolev imbedding theorem do not apply, but some weaker imbedding results are still possible.
		\item Chap. 5 now deals with interpolation, extension, \& approximation results for Sobolev spaces. Part of it is expanded from material in Chap. 4 of 1e with newer results \& methods of proof.
		\item Chap. 6 deals with establishing compactness of Sobolev imbeddings.
		\item Chap. 7 is concerned with defining \& developing properties of scales of spaces with fractional orders of smoothness, rather than the integer orders of Sobolev spaces themselves. Completely rewritten \& bears little resemblance to corresponding chapter in 1e. Much emphasis is placed on real interpolation methods. The J-method \& K-method are fully presented \& used to develop theory of Lorentz spaces \& Besov spaces \& their imbeddings, but both families of spaces are also provided with intrinsic characterizations. A key theorem identifies lower dimensional traces of functions in Sobolev spaces as constituting certain Besov spaces. Complex interpolation is used to introduce Sobolev spaces of fractional order (also called spaces of Bessel potentials) \& Fourier transform methods are used to characterize \& generalize these spaces to yield Triebel Lizorkin spaces \& illuminate their relationship with Besov spaces.
		\item Chap. 8 is very similar to its 1e counterpart. Deal with Orlicz \& Orlicz-Sobolev spaces which generalize $L^p$ \& $W^{m,p}$ spaces by allowing role of function $t^p$ to be assumed by a more general convex function $A(t)$. An important result identifies a certain Orlicz space as a target for an imbedding of $W^{m,p}(\Omega)$ in a limiting case where there is an imbedding into $L^p(\Omega)$ for $1\le p < \infty$ but not into $L^\infty(\Omega)$.
	\end{itemize}
	
	\begin{itemize}
		\item {\sf1. Preliminaries.} Sobolev spaces are vector spaces whose elements are functions defined on domains in $d$-dimensional Euclidean space $\mathbb{R}^d$ \& whose partial derivatives satisfy certain integrability conditions. To develop \& elucidate properties of these space \& mappings between them require some of machinery of general topology \& real \& functional analysis. Assume readers are familiar with concept of a vector space over real or complex scalar field, \& with related notions of dimension, subspace, linear transformation, \& convex set, also expect reader have some familiarity with concept of topology on a set, at least to extent of understanding concepts of an open set \& continuity of a function.
		
		Outline, mainly without any proofs, those aspects of theories of topological vector spaces (TVS), Lebesgue measure \& integral, \& Schwartz distributions. {\it Domain} $\Omega$: a nonempty open set in $d$-dimensional real Euclidean space $\mathbb{R}^d$. Concern with differentiability \& integrability of functions defined on $\Omega$; these functions are allowed to be complex-valued unless contrary is explicitly stated.
		
		If $X$ is a Hilbert space, it can be identified with its normed dual.
		\begin{theorem}[Riesz representation]
			Let $X$ be a Hilbert space. A linear functional $x'$ on $X$ belongs to $X'$ iff there exists $x\in X$ s.t. $x'(y) = (y,x)_X$, $\forall y\in X$ \& in this case $\|x';X'\| = \|x;X\|$. Moreover, $x$ is uniquely determined by $x'\in X'$.
		\end{theorem}
		A vector subspace $M$ of a normed space $X$ is itself a normed space under the norm of $X$, \& so normed is called a {\it subspace} of $X$. A closed subspace of a Banach space is itself a Banach space.
		
		\begin{theorem}[Hahn--Banach extension]
			Let $M$ be a subspace of the normed space $X$. If $m'\in M'$, then there exists $x'\in X'$ s.t. $\|x';X'\| = \|m';M'\|$ \& $x'(m) = m'(m)$, $\forall m\in M$.
		\end{theorem}
		
		\item {\sf2. Lebesgue Spaces $L^p(\Omega)$.}
		\item {\sf3. Sobolev Spaces $W^{m,p}(\Omega)$.}
		\item {\sf4. Sobolev imbedding theorem.}
		\item {\sf5. Interpolation, extension, \& approximation theorems.}
		\item {\sf6. Compact imbeddings of Sobolev spaces.}
		\item {\sf7. Fractional order spaces.}
		\item {\sf8. Orlicz spaces \& Orlicz-Sobolev spaces.}
	\end{itemize}
	
	
	\item \cite{Gagliardo1957}. {\sc Emilio Gagliardo}. {\it Caratterizzazioni delle tracce sulla frontiera relative ad alcune classi di funzioni in {$n$} variabili}.
	\item {\sc Nec\v{a}s}.
	\item \cite{Tartar2006}. {\sc Luc Tartar}. {\it An Introduction to Sobolev Spaces \& Interpolation Spaces}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Finite Difference Methods FDMs -- Phương Pháp Sai Phân Hữu Hạn}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{LeVeque2007}. {\sc Randall J. LeVeque}. {\it FDMs for ODE \& PDEs: Steady-State \& Time-Dependent Problems}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Finite Element Methods FEMs -- Phương Pháp Phần Tử Hữu Hạn}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Brenner_Scott2008}. {\sc Susanne C. Brenner, L. Ridgway Scott}. {\it The Mathematical Theory of FEMs}.
	\item \cite{Ern_Guermond2004}. {\sc Alexandre Ern, Jean-Luc Guermond}. {\it Theory \& Practice of Finite Elements}.
	\item \cite{Girault_Raviart1986}. {\sc Vivette Girault, Pierre-Arnaud Raviart}. {\it FEMs for NSEs}.
	\item \cite{Gunzburger1989}. {\sc Max D. Gunzburger}. {\it FEMs for Viscous Incompressible Flows}.
	\item \cite{John2016}. {\sc Volker John}. {\it FEMs for Incompressible Flow Problems}.
\end{enumerate}
I met {\sc Volker John}, lead of Research Group 3 in WIAS in 2020 to discuss on turbulence models, e.g., Smagonrinsky, $k$-$\epsilon$ \& their simulations.

%------------------------------------------------------------------------------%

\section{Finite Volume Methods FVMs -- Phương Pháp Thể Tích Hữu Hạn}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Barth_Jespersen1989}. {\sc Timothy J. Barth, Dennis C. Jespersen}. {\it The Design \& Application of Upwind Schemes on Unstructured Meshes}.
	\item \cite{Darwish_Asmar_Moukalled2004}. {\sc M. Darwish, D. Asmar, F. Moukalled}. {\it A comparative assessment within a multigrid environment of segregated pressure-based algorithms for fluid flow at all speeds}.
	\item \cite{Darwish_Moukalled1996}. {\sc M. Darwish, F. Moukalled}. {\it A new approach for building bounded skew-upwind schemes}.
	\item \cite{Darwish_Moukalled1996a}. {\sc M. Darwish, F. Moukalled}. {\it The normalized weighting factor method: a novel technique for accelerating the convergence of high-resolution convective schemes}.
	\item \cite{Darwish_Moukalled2006}. {\sc M. Darwish, F. Moukalled}. {\it Convective Schemes for Capturing Interfaces of Free-Surface Flows on Unstructured Grids}.
	\item \cite{Darwish_Moukalled_Sekar2001}. {\sc M. Darwish, F. Moukalled, B. Sekar}. {\it A unified formulation of the segregated class of algorithms for multifluid flow at all speeds}.
	\item \cite{Demirdzic2015}. {\sc I. Demird\v{z}i\'c}. {\it On the Discretization of the Diffusion Term in Finite-Volume Continuum Mechanics}.
	\item \cite{Demirdzic_Muzaferija1995}. {\sc I. Demird\v{z}i\'c, S. Muzaferija}. {\it Numerical method for coupled fluid flow, heat transfer \& stress analysis using unstructured moving meshes with cells of arbitrary topology},
	\item \cite{Denner_vanWachem2014}. {\sc Fabian Denner, Berend G. M. van Wachem}. {\it Compressive VOF method with skewness correction to capture sharp interfaces on arbitrary meshes}.
	\item \cite{Eymard_Gallouet_Herbin2019}. {\sc Robert Eymard, Thierry Gallou\"et, Rapha\`ele Herbin}. {\it Finite Volume Methods}.
	\item \cite{Gallouet_Herbin_Latche_Mallem2018}. {\sc T. Gallou\"{e}t, R. Herbin, J.-C. Latch\'{e},  K. Mallem}. {\it Convergence of the marker-and-cell scheme for the incompressible NSEs on non-uniform grids}.
	\item {\sc T. Gallou\"{e}t, R. Herbin, J.-C. Latch\'{e}, Nguyễn Tấn Trung}. {\it Playing with Burger's Equation}. {\sf[4 citations]}
	
	{\bf Abstract.} use 1D Burgers equation as a toy model to mimick resulting behavior of numerical schemes when replacing a conservation law by a form which is equivalent for smooth solutions, e.g., total energy by internal energy balance in Euler equations. If initial Burgers equation is replaced by a balance equation for 1 of its entropies (square of unknown) \& discretized by a standard scheme, numerical solution converges, as expected; to a function which is not a weak solution to initial problem. However, if 1st add to Burger's equation a diffusion term scaled by a small positive parameter $\epsilon$ before deriving entropy balance (this yields a non conservative diffusion term in resulting equation), \& then choose $\epsilon$ \& discretization parameters adequately \& let them $\to0$, observe that we recover a convergence to the correct solution.
	
	{\bf Keywords.} Burgers equation, compressible flows, Euler equations, finite volumes.
	\begin{itemize}
		\item {\sf1. Introduction.} Computer codes developed for simulation of inviscid \& non heat-conducting compressible flows are in general based on conservative form of Euler equations, in 1D:
		\begin{equation}
			\label{1D Burgers}
			\partial_t\rho + \partial_x(\rho u) = 0,\ \partial_t(\rho u) + \partial_x(\rho u^2) + \partial_xp = 0,\ \partial_tE + \partial_x((E + p)u) = 0,
		\end{equation}
		where $\rho$: density, $u$: velocity, $p$: pressure in the flow, $E$: total energy $E = \rho\left(\frac{1}{2}u^2 + e\right)$ with $e$: internal energy. This system must be complemented by an equation of state, giving e.g. pressure as a function of density \& internal energy $p = \mathcal{P}(\rho,e)$. For physical reasons, density \& internal energy must be nonnegative (in usual applications, positive). For the continuous problem \&, at the discrete level, for a wide range of schemes (the so-called {\it conservative schemes}), the nonnegative of these variables allows a (weak) control on the solution; assuming that $\rho,E$ are known on the parts of the boundary where the flow is entering computational domain, 1st \& 3rd eqns of \eqref{1D Burgers} indeed yield an $L^\infty(0,T;L^1(\Omega))$-estimate with $(0,T)\times\Omega$: space-time domain of computation for density \& total energy, resp. Positivity of density at the discrete level is easily obtained from a convenient discretization of 1st eqn. Positivity of internal energy does not seem easily obtained other than by replacing 3rd eqn by a balance equation for the internal energy in the discrete problem; this balance equation is formally derived (i.e., supposing solution is regular) reads:
		\begin{equation}
			\label{1D Burgers 1}
			\partial_t(\rho e) + \partial_x(\rho eu) + p\partial_xu = 0.
		\end{equation}
		In this relation, discrete convection operator may be built so as to respect the positivity of $e$: provided that equation of state is s.t. for any value of $\rho$, $p$ vanishes for $e = 0$, testing discrete counterpart of \eqref{1D Burgers 1} by negative part of $e$ proves $e\ge0$ ([4] in framework of compressible NSEs).
		
		Instead of 3rd eqn, one may also prefer to use a conservation equation for physical entropy $s$, because this equation (derived for regular solutions) is a simple transport equation
		\begin{equation}
			\label{1D Burgers 2}
			\partial_t(\rho s) + \partial_x(\rho su) = 0.
		\end{equation}
		Consider \eqref{1D Burgers 1} or \eqref{1D Burgers 2} instead of 3rd, for computational efficiency or robustness reasons. Since these are derived from 3rd assuming a regular solution, there is no reason for their discretization to yield correct weak solutions in presence of shocks. Nevertheless, may reasonably expect to recover correct shock solutions if use strategy: (i) regularize problem by adding a small diffusion term, (ii) derive counterpart of \eqref{1D Burgers 1} or \eqref{1D Burgers 2} taking into account diffusion terms, (iii) solve these equations numerically, (iv) let $\epsilon\to0$. Perform step (iii) numerically, \& convergence is monitored by the space \& time discretization steps $h,k$, question: find a convenient way to let $\epsilon$ \& numerical parameters $h,k$ tend to 0. Aim: perform numerical experiments to investigate this issue on a toy problem, namely inviscid Burgers equation. Only consider explicit schemes.
		\item {\sf2. Equations \& Numerical Schemes.} Inviscid Burgers equation:
		\begin{equation}
			\left\{\begin{split}
				\partial_tu + \partial_x(u^2) &= 0&&\mbox{ in }(0,T)\times\mathbb{R},\\
				u(0,x) &= u_0(x)&&\mbox{ in }\mathbb{R}.
			\end{split}\right.			 
		\end{equation}
		1st add a viscous term to obtain $\partial_tu + \partial_x(u^2) - \epsilon\partial_x^2u = 0$, multiply this relation by $2u$ yields perturbed equation:
		\begin{equation}
			\partial_tu^2 + \frac{4}{3}\partial_xu^3 - 2u\epsilon\partial_x^2u = 0.
		\end{equation}
		For $\epsilon = 0$, get ``Burgers square entropy'' equation:
		\begin{equation}
			\partial_tu^2 + \frac{4}{3}\partial_xu^3 = 0,
		\end{equation}
		which also reads, setting $v\coloneqq u^2$:
		\begin{equation}
			\partial_tv + \frac{4}{3}\partial_x\left(v^{\frac{3}{2}}\right) = 0.
		\end{equation}
		
		\item {\sf3. Numerical Solution of Perturbed Equation.}
		\item {\sf4. Conclusion.}
	\end{itemize}
	
	\item \cite{Gallouet_Herbin_Maltese_Novotny2017}. {\sc T. Gallou\"{e}t, R. Herbin, D. Maltese, A.Novotny}. {\it onvergence of the marker-and-cell scheme for the semi-stationary compressible Stokes problem}.
	\item \cite{Gaskell_Lau1988}. {\sc P. H. Gaskell, A. K. C. Lau}. {\it Curvature-compensated convective transport: SMART, a new boundedness-preserving transport algorithm}.
	\item \cite{Harten1983}. {\sc Ami Harten}. {\it High resolution schemes for hyperbolic conservation laws}.
	\item \cite{Harten1997}. {\sc Ami Harten}. {\it High resolution schemes for hyperbolic conservation laws [{MR}0701178 (84g:65115)]}.
	\item \cite{Issa1986}. {\sc R. I. Issa}. {\it Solution of the Implicit Discretized Fluid Flow Equations by Operator Splitting}.
	\item \cite{Jang_Jetli_Acharya1986}. {\sc D. S. Jang, R. Jetli, S. Acharya}. {\it Comparison of the PISO, SIMPLER, \& SIMPLEC algorithms for the treatment of the pressure-velocity coupling in steady flow problems}.
	\item \cite{Jasak1996}. {\sc H. Jasak}. {\it Error Analysis \& Estimation for the Finite Volume Method with Applications for Fluid Flow}.
	\item \cite{Jasak_Gosman2000}. {\sc H. Jasak,  A. D. Gosman}. {\it Automatic Resolution Control for the Finite Volume  Method, Part 1}.
	\item \cite{Leonard1979}. {\sc B. P. Leonard}. {\it A stable \& accurate convective modelling procedure based on quadratic upstream interpolation}.
	\item \cite{Leonard1987}. {\sc B. P. Leonard}. {\it SHARP Simulation of Discontinuities in Highly Convective Steady Flow}.
	\item \cite{Leonard1988}. {\sc B. P. Leonard}. {\it Universal Limiter for Transient Interpolation Modeling of the Advective Transport Equations: The ULTIMATE Conservative Difference Scheme}.
	\item \cite{LeVeque2002}. {\sc Randall J. LeVeque}. {\it FEMs for Hyperbolic Problems}.
	\item \cite{Mathur_Murthy1997}. {\sc S. R. Mathur, J. Y. Murthy}. {\it A Pressure-Based Method for Unstructured Meshes}.
	\item \cite{Moukalled_Darwish2000}. {\sc F. Moukalled, M. Darwish}. {\it A unified formulation of the segregated class of algorithms for fluid flow at all speeds}.
	\item \cite{Moukalled_Darwish2012}. {\sc F. Moukalled, M. Darwish}. {\it Transient Schemes for Capturing Interfaces of Free-Surface Flows}.
	\item \cite{Moukalled_Mangani_Darwish2016}. {\sc F. Moukalled, L. Mangani, M. Darwish}. {\it The FVM in CFD}.
	\item \cite{Muzaferija1994}. {\sc S. Muzaferija}. {\it Adaptive Finite Volume Method for Flow Predictions Using Unstructured Meshes \& Multigrid Approach}.
	\item \cite{Muzaferija_Gosman1997}. {\sc S. Muzaferija, A. D. Gosman}. {\it Finite Volume CFD Procedure \& Adaptive Error Control Strategy for Grids of Arbitrary Topology}.
	\item \cite{Nicolaides1992}. {\sc R. A. Nicolaides}. {\it Analysis \& convergence of the {MAC} scheme. I. The linear problem}.
	\item \cite{Nicolaides_Wu1996}. {\sc R. A. Nicolaides, X. Wu}. {\it Analysis \& convergence of the MAC scheme. II. NSEs}.
	\item \cite{Ollivier-Gooch_Altena2002}. {\sc Carl Ollivier-Gooch, Michael Van Altena}. {\it A High-Order-Accurate Unstructured Mesh Finite-Volume Scheme for the Advection--Diffusion Equation}.
	\item \cite{Perron_Boivin_Herard2004}. {\sc S\'{e}bastien Perron, Sylvain Boivin, Jean-Marc H\'{e}rard}. {\it A FVM to solve the 3D NSEs on unstructured collocated meshes}.
	\item \cite{Rhie_Chow1983}. {\sc C. M. Rhie, W. L. Chow}. {\it Numerical Study of the Turbulent Flow Past an Airfoil with Trailing Edge Separation}.
	\item \cite{Sweby1984}. {\sc Peter K. Sweby}. {\it High resolution schemes using flux limiters for hyperbolic conservation laws}.
	\item \cite{Sweby1985}. {\sc Peter K. Sweby}. {\it High resolution TVD schemes using flux limiters}.
	\item \cite{Versteeg_Malalasekera2007}. {\sc H. K. Versteeg, W. Malalasekera}. {\it An Introduction to CFD: The FVM}.
	\item \cite{Yen_Liu1993}. {\sc Ruey-Hor Yen, Chen-Hua Liu}. {\it Enhancement of the SIMPLE algorithm by an additional explicit corrector step}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Mathematicians \& Their Legacies -- Các Nhà Toán Học \& Các Di Sản}

\subsection{\href{https://en.wikipedia.org/wiki/Mathematician}{Wikipedia\texttt{/}Mathematician}}
\textbf{Mathematician.} \href{https://en.wikipedia.org/wiki/Euclid}{Euclid} (holding \href{https://en.wikipedia.org/wiki/Calipers}{calipers}), Greek mathematician, known as the ``Father of Geometry''

\noindent
\textbf{Occupation.}
\begin{itemize}
	\item \textbf{Occupation type.} \href{https://en.wikipedia.org/wiki/Academic}{Academic}
\end{itemize}
\textbf{Description.}
\begin{itemize}
	\item \textbf{Competencies.} \href{https://en.wikipedia.org/wiki/Mathematics}{Mathematics}, \href{https://en.wikipedia.org/wiki/Analytical_skill}{analytical skills} \& \href{https://en.wikipedia.org/wiki/Critical_thinking}{critical thinking} skills.
	\item \textbf{Education required.} \href{https://en.wikipedia.org/wiki/Doctoral_degree}{Doctoral degree}, occasionally \href{https://en.wikipedia.org/wiki/Master's_degree}{master's degree}.
	\item \textbf{Fields of employment.}
	\begin{itemize}
		\item universities,
		\item private corporations,
		\item financial industry,
		\item government
	\end{itemize}
	\item \textbf{Related jobs.} \href{https://en.wikipedia.org/wiki/Statistician}{statistician}, \href{https://en.wikipedia.org/wiki/Actuary}{actuary}.
\end{itemize}
A \textit{mathematician} is someone who uses an extensive knowledge of \href{https://en.wikipedia.org/wiki/Mathematics}{mathematics} in their work, typically to solve \href{https://en.wikipedia.org/wiki/Mathematical_problem}{mathematical problems}.

Mathematicians are concerned with \href{https://en.wikipedia.org/wiki/Number}{numbers}, \href{https://en.wikipedia.org/wiki/Data}{data}, \href{https://en.wikipedia.org/wiki/Quantity}{quantity}, \href{https://en.wikipedia.org/wiki/Mathematical_structure}{structure}, \href{https://en.wikipedia.org/wiki/Space}{space}, \href{https://en.wikipedia.org/wiki/Mathematical_model}{models}, \& \href{https://en.wikipedia.org/wiki/Mathematics#Change}{change}.

\subsubsection{History}
For broader coverage of this topic, see \href{https://en.wikipedia.org/wiki/History_of_mathematics}{History of mathematics}.

%
1 of the earliest known mathematicians was \href{https://en.wikipedia.org/wiki/Thales_of_Miletus}{Thales of Miletus} (c. 624--c.546 BC); he has been hailed as the 1st true mathematician \& the 1st known individual to whom a mathematical discovery has been attributed.[Boyer (1991), \textit{A History of Mathematics}, p. 43]

He is credited with the 1st use of deductive reasoning applied to geometry, by deriving 4 corollaries to \href{https://en.wikipedia.org/wiki/Thales%27_Theorem}{Thales' Theorem}.

%
The number of known mathematicians grew when \href{https://en.wikipedia.org/wiki/Pythagoras_of_Samos}{Pythagoras of Samos} (c. 582--c. 507 BC) established the \href{https://en.wikipedia.org/wiki/Pythagoreans}{Pythagorean School}, whose doctrine it was that mathematics ruled the universe \& whose motto was ``All is number''.[Boyer 1991, ``\textit{Ionia \& the Pythagoreans}'', p. 49]

It was the Pythagoreans who coined the term ``mathematics'', \& with whom the study of mathematics for its own sake begins.

%
The 1st woman mathematician recorded by history was \href{https://en.wikipedia.org/wiki/Hypatia}{Hypatia} of Alexandria (AD 350--415).

She succeeded her father as Librarian at the Great Library \& wrote many works on applied mathematics.

Because of a political dispute, the Christian community in Alexandria punished her, presuming she was involved, by stripping her naked \& scraping off her skin with clamshells (some say roofing tiles).[``\textit{Ecclesiastical History}, Bk VI: Chap. 15''. Archived from the original on 2014-08-14. Retrieved 2014-11-19.]

%
Science \& mathematics in the Islamic world during the Middle Ages followed various models \& modes of funding varied based primarily on scholars.

It was extensive patronage \& strong intellectual policies implemented by specific rulers that allowed scientific knowledge to develop in many areas.

Funding for translation of scientific texts in other languages was ongoing throughout the reign of certain caliphs,[Abattouy, M., Renn, J. \& Weinig, P., 2001. \textit{Transmission as Transformation: The Translation Movements in the Medieval East \& West in a Comparative Perspective}. Science in Context, 14(1-2), 1-12.] \& it turned out that certain scholars became experts in the works they translated \& in turn received further support for continuing to develop certain sciences.

As these sciences received wider attention from the elite, more scholars were invited \& funded to study particular sciences.

An example of a translator \& mathematician who benefited from this type of support was \href{https://en.wikipedia.org/wiki/Al-Khawarizmi}{al-Khawarizmi}.

A notable feature of many scholars working under Muslim rule in medieval times is that they were often polymaths.

Examples include the work on \href{https://en.wikipedia.org/wiki/Optics}{optics}, maths \& \href{https://en.wikipedia.org/wiki/Astronomy}{astronomy} of \href{https://en.wikipedia.org/wiki/Ibn_al-Haytham}{Ibn al-Haytham}.

%
The \href{https://en.wikipedia.org/wiki/Renaissance}{Renaissance} brought an increased emphasis on mathematics \& science to Europe.

During this period of transition from a mainly feudal \& ecclesiastical culture to a predominantly secular one, many notable mathematicians had other occupations: \href{https://en.wikipedia.org/wiki/Luca_Pacioli}{Luca Pacioli} (founder of \href{https://en.wikipedia.org/wiki/Accounting}{accounting}); \href{https://en.wikipedia.org/wiki/Niccol%C3%B2_Fontana_Tartaglia}{Niccolò Fontana Tartaglia} (notable engineer \& bookkeeper); \href{https://en.wikipedia.org/wiki/Gerolamo_Cardano}{Gerolamo Cardano} (earliest founder of probability \& binomial expansion); \href{https://en.wikipedia.org/wiki/Robert_Recorde}{Robert Recorde} (physician) \& \href{https://en.wikipedia.org/wiki/Fran%C3%A7ois_Vi%C3%A8te}{François Viète}s (lawyer). 

%
As time passed, many mathematicians gravitated towards universities.

An emphasis on free thinking \& experimentation had begun in Britain's oldest universities beginning in the 17th century at Oxford with the scientists \href{https://en.wikipedia.org/wiki/Robert_Hooke}{Robert Hooke} \& \href{https://en.wikipedia.org/wiki/Robert_Boyle}{Robert Boyle}, \& at Cambridge where \href{https://en.wikipedia.org/wiki/Isaac_Newton}{Isaac Newton} was \href{https://en.wikipedia.org/wiki/Lucasian_Professor_of_Mathematics}{Lucasian Professor of Mathematics \& Physics}.

Moving into the 19th century, the objective of universities all across Europe evolved from teaching the ``\textit{regurgitation of knowledge}'' to ``\textit{encourag[ing] productive thinking}.''[Röhrs, ``\textit{The Classical Idea of the University},'' Tradition \& Reform of the University under an International Perspective p. 20]

In 1810, Humboldt convinced the King of Prussia to build a university in Berlin based on \href{https://en.wikipedia.org/wiki/Friedrich_Schleiermacher}{Friedrich Schleiermacher}'s liberal ideas; the goal was to demonstrate the process of the discovery of knowledge \& to teach students to ``\textit{take account of fundamental laws of science in all their thinking}.''

Thus, seminars \& laboratories started to evolve.[Rüegg, ``Themes'', \textit{A History of the University in Europe, Vol. III}, p. 5--6]

%
British universities of this period adopted some approaches familiar to the Italian \& German universities, but as they already enjoyed substantial freedoms \& \href{https://en.wikipedia.org/wiki/Autonomy}{autonomy} the changes there had begun with the \href{https://en.wikipedia.org/wiki/Age_of_Enlightenment}{Age of Enlightenment}, the same influences that inspired Humboldt.

The Universities of \href{https://en.wikipedia.org/wiki/University_of_Oxford}{Oxford} \& \href{https://en.wikipedia.org/wiki/University_of_Cambridge}{Cambridge} emphasized the importance of \href{https://en.wikipedia.org/wiki/Research}{research}, arguably more authentically implementing Humboldt's idea of a university than even German universities, which were subject to state authority.[Rüegg, ``Themes'', \textit{A History of the University in Europe, Vol. III}, p. 12]

Overall, science (including mathematics) became the focus of universities in the 19th \& 20th centuries.

Students could conduct research in \href{https://en.wikipedia.org/wiki/Seminars}{seminars} or \href{https://en.wikipedia.org/wiki/Laboratories}{laboratories} \& began to produce doctoral theses with more scientific content.[Rüegg, ``Themes'', \textit{A History of the University in Europe, Vol. III}, p. 13]

According to Humboldt, the mission of the \href{https://en.wikipedia.org/wiki/University_of_Berlin}{University of Berlin} was to pursue scientific knowledge.[Rüegg, ``Themes'', \textit{A History of the University in Europe, Vol. III}, p. 16]

\textit{The German university system fostered professional, bureaucratically regulated scientific research performed in well-equipped laboratories, instead of the kind of research done by private \& individual scholars in Great Britain \& France}.[Rüegg, ``Themes'', \textit{A History of the University in Europe, Vol. III}, p. 17--18]

In fact, Rüegg asserts that the \textit{German system is responsible for the development of the modern research university because it focused on the idea of ``freedom of scientific research, teaching \& study.''}[Rüegg, ``Themes'', \textit{A History of the University in Europe, Vol. III}, p. 31]

\subsubsection{Required education}
Mathematicians usually cover a breadth of topics within mathematics in their \href{https://en.wikipedia.org/wiki/Undergraduate_education}{undergraduate education}, \& then proceed to specialize in topics of their own choice at the \href{https://en.wikipedia.org/wiki/Graduate-level}{graduate level}.

In some universities, a \href{https://en.wikipedia.org/wiki/Qualifying_exam}{qualifying exam} serves to test both the breadth \& depth of a student's understanding of mathematics; the students, who pass, are permitted to work on a \href{https://en.wikipedia.org/wiki/Doctoral_dissertation}{doctoral dissertation}.

\subsubsection{Activities}
\textsf{\href{https://en.wikipedia.org/wiki/Emmy_Noether}{Emmy Noether}, mathematical theorist \& teacher.}

\paragraph{Applied mathematics.} Main article: \href{https://en.wikipedia.org/wiki/Applied_mathematics}{Applied mathematics}. Mathematicians involved with solving problems with applications in real life are called \href{https://en.wikipedia.org/wiki/Applied_mathematician}{applied mathematicians}.

Applied mathematicians are mathematical scientists who, with their specialized knowledge \& \href{https://en.wikipedia.org/wiki/Professional}{professional} methodology, approach many of the imposing problems presented in related scientific fields.

With professional focus on a wide variety of problems, theoretical systems, \& localized constructs, applied mathematicians work regularly in the study \& formulation of \href{https://en.wikipedia.org/wiki/Mathematical_models}{mathematical models}.

Mathematicians \& applied mathematicians are considered to be 2 of the STEM (science, technology, engineering, \& mathematics) careers.

%
The discipline of \href{https://en.wikipedia.org/wiki/Applied_mathematics}{applied mathematics} concerns itself with mathematical methods that are typically used in science, engineering, business, \& industry; thus, ``applied mathematics'' is a \href{https://en.wikipedia.org/wiki/Mathematical_science}{mathematical science} with specialized knowledge.

The term ``applied mathematics'' also describes the professional specialty in which mathematicians work on problems, often concrete but sometimes abstract.

As professionals focused on problem solving, \textit{applied mathematicians} look into the \textit{formulation, study}, \& \textit{use of mathematical models} in \href{https://en.wikipedia.org/wiki/Science}{science}, \href{https://en.wikipedia.org/wiki/Engineering}{engineering}, \href{https://en.wikipedia.org/wiki/Business}{business}, \& other areas of mathematical practice.

\paragraph{Abstract mathematics.} Main article: \href{https://en.wikipedia.org/wiki/Pure_mathematics}{Pure mathematics}. \href{https://en.wikipedia.org/wiki/Pure_mathematics}{Pure mathematics} is mathematics that studies entirely abstract \href{https://en.wikipedia.org/wiki/Concept}{concepts}.

From the 18th century onwards, this was a recognized category of mathematical activity, sometimes characterized as \textit{speculative mathematics},[See for example titles of works by Thomas Simpson from the mid-18th century: \textit{Essays on Several Curious \& Useful Subjects in Speculative \& Mixed Mathematics, Miscellaneous Tracts on Some Curious \& Very Interesting Subjects in Mechanics, Physical Astronomy \& Speculative Mathematics. Chisholm}, Hugh, ed. (1911). ``Simpson, Thomas''. Encyclop\ae dia Britannica. 25 (11th ed.). Cambridge University Press. p. 135.] \& at variance with the trend towards meeting the needs of \href{https://en.wikipedia.org/wiki/Navigation}{navigation}, \href{https://en.wikipedia.org/wiki/Astronomy}{astronomy}, \href{https://en.wikipedia.org/wiki/Physics}{physics}, \href{https://en.wikipedia.org/wiki/Economics}{economics}, \href{https://en.wikipedia.org/wiki/Engineering}{engineering}, \& other applications.

%
Another insightful view put forth is that \textit{pure mathematics is not necessarily \href{https://en.wikipedia.org/wiki/Applied_mathematics}{applied mathematics}}: it is possible to study abstract entities w.r.t. their intrinsic nature, \& not be concerned with how they manifest in the real world.[Andy Magid, \textit{Letter from the Editor, in Notices of the AMS}, Nov 2005, American Mathematical Society, p. 1173. [1] Archived 2016-03-03 at the Wayback Machine]

\textit{Even though the pure \& applied viewpoints are distinct philosophical positions, in practice there is much overlap in the activity of pure \& applied mathematicians}.

%
\textit{To develop accurate models for describing the real world, many applied mathematicians draw on tools \& techniques that are often considered to be ``pure'' mathematics}.

\textit{On the other hand, many pure mathematicians draw on natural \& social phenomena as inspiration for their abstract research}.

\paragraph{Mathematics teaching.} Many professional mathematicians also engage in the teaching of mathematics.

Duties may include:
\begin{itemize}
	\item teaching university mathematics courses;
	\item supervising undergraduate \& graduate research; and
	\item serving on academic committees.
\end{itemize}

\paragraph{Consulting.} Many careers in mathematics outside of universities involve consulting.

E.g., actuaries assemble \& analyze data to estimate the probability \& likely cost of the occurrence of an event such as death, sickness, injury, disability, or loss of property.

Actuaries also address financial questions, including those involving the level of pension contributions required to produce a certain retirement income \& the way in which a company should invest resources to maximize its return on investments in light of potential risk.

Using their broad knowledge, actuaries help design \& price insurance policies, pension plans, \& other financial strategies in a manner which will help ensure that the plans are maintained on a sound financial basis.

%
As another example, mathematical finance will derive \& extend the \href{https://en.wikipedia.org/wiki/Mathematical_model}{mathematical} or \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerical} models without necessarily establishing a link to \textit{financial theory}, taking observed market prices as input.

Mathematical consistency is required, not compatibility with \textit{economic theory}.

Thus, e.g., while a financial economist might study the structural reasons why a company may have a certain \href{https://en.wikipedia.org/wiki/Share_price}{share price}, a financial mathematician may take the share price as a given, \& attempt to use \href{https://en.wikipedia.org/wiki/Stochastic_calculus}{stochastic calculus} to obtain the corresponding value of \href{https://en.wikipedia.org/wiki/Derivative_(finance)}{derivatives} of the \href{https://en.wikipedia.org/wiki/Stock}{stock} (see: \href{https://en.wikipedia.org/wiki/Valuation_of_options}{Valuation of options}; \href{https://en.wikipedia.org/wiki/Financial_modeling#Quantitative_finance}{Financial modeling}).

\subsubsection{Occupations}
\textsf{In 1938 in the United States, mathematicians were desired as teachers, calculating machine operators, mechanical engineers, accounting auditor bookkeepers, \& actuary statisticians.}

According to the \href{https://en.wikipedia.org/wiki/Dictionary_of_Occupational_Titles}{Dictionary of Occupational Titles} occupations in mathematics include the following.[``020 OCCUPATIONS IN MATHEMATICS''. \textit{Dictionary Of Occupational Titles}. Archived from the original on 2012-11-02. Retrieved 2013-01-20.]
\begin{itemize}
	\item Mathematician
	\item Operations-Research Analyst
	\item Mathematical Statistician
	\item Mathematical Technician
	\item \href{https://en.wikipedia.org/wiki/Actuary}{Actuary}
	\item Applied Statistician
	\item Weight Analyst
\end{itemize}

\subsubsection{Quotations about mathematicians}
The following are quotations about mathematicians, or by mathematicians.
\begin{quotation}
	``\textit{A mathematician is a device for turning coffee into theorems}.'' - Attributed to both \href{https://en.wikipedia.org/wiki/Alfr%C3%A9d_R%C3%A9nyi}{Alfréd Rényi}[15] \& \href{https://en.wikipedia.org/wiki/Paul_Erd%C5%91s}{Paul Erd\"os}
\end{quotation}

\begin{quotation}
	``\textit{Die Mathematiker sind eine Art Franzosen; redet man mit ihnen, so übersetzen sie es in ihre Sprache, und dann ist es alsobald ganz etwas anderes}.''
	
	(Mathematicians are [like] a sort of Frenchmen; if you talk to them, they translate it into their own language, \& then it is immediately something quite different.) - \href{https://en.wikipedia.org/wiki/Johann_Wolfgang_von_Goethe}{Johann Wolfgang von Goethe}[16]
\end{quotation}

\begin{quotation}
	``\textit{Each generation has its few great mathematicians$\ldots$ \& [the others'] research harms no one}.'' - Alfred W. Adler ($\sim$1930), ``\textit{Mathematics \& Creativity}''[17]
\end{quotation}

\begin{quotation}
	``In short, I never yet encountered the mere mathematician who could be trusted out of equal roots, or one who did not clandestinely hold it as a point of his faith that x squared + px was absolutely \& unconditionally equal to q. Say to one of these gentlemen, by way of experiment, if you please, that you believe occasions may occur where x squared + px is not altogether equal to q, and, having made him understand what you mean, get out of his reach as speedily as convenient, for, beyond doubt, he will endeavor to knock you down.'' - \href{https://en.wikipedia.org/wiki/Edgar_Allan_Poe}{Edgar Allan Poe}, \textit{The purloined letter}
\end{quotation}

\begin{quotation}
	``A mathematician, like a painter or poet, is a maker of patterns. If his patterns are more permanent than theirs, it is because they are made with ideas.'' - \href{https://en.wikipedia.org/wiki/G._H._Hardy}{G. H. Hardy}, \textit{A Mathematician's Apology}
\end{quotation}

\begin{quotation}
	``\textit{Some of you may have met mathematicians \& wondered how they got that way}.'' - \href{https://en.wikipedia.org/wiki/Tom_Lehrer}{Tom Lehrer}
\end{quotation}

\begin{quotation}
	``\textit{It is impossible to be a mathematician without being a poet in soul}.'' - \href{https://en.wikipedia.org/wiki/Sofia_Kovalevskaya}{Sofia Kovalevskaya}
\end{quotation}

\begin{quotation}
	``\textit{There are 2 ways to do great mathematics. The first is to be smarter than everybody else. The second way is to be stupider than everybody else - but persistent.}'' - \href{https://en.wikipedia.org/wiki/Raoul_Bott}{Raoul Bott}
\end{quotation}

\begin{quotation}
	``\textit{Mathematics is the queen of the sciences \& arithmetic the queen of mathematics}.'' - \href{https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss}{Carl Friedrich Gauss} [18]
\end{quotation}

\subsubsection{Prizes in mathematics}
There is no Nobel Prize in mathematics, though sometimes mathematicians have won the Nobel Prize in a different field, such as economics.

Prominent prizes in mathematics include the \href{https://en.wikipedia.org/wiki/Abel_Prize}{Abel Prize}, the \href{https://en.wikipedia.org/wiki/Chern_Medal}{Chern Medal}, the \href{https://en.wikipedia.org/wiki/Fields_Medal}{Fields Medal}, the \href{https://en.wikipedia.org/wiki/Gauss_Prize}{Gauss Prize}, the \href{https://en.wikipedia.org/wiki/Frederic_Esser_Nemmers_Prize}{Nemmers Prize}, the \href{https://en.wikipedia.org/wiki/Balzan_Prize}{Balzan Prize}, the \href{https://en.wikipedia.org/wiki/Crafoord_Prize}{Crafoord Prize}, the \href{https://en.wikipedia.org/wiki/Shaw_Prize}{Shaw Prize}, the \href{https://en.wikipedia.org/wiki/Steele_Prize}{Steele Prize}, the \href{https://en.wikipedia.org/wiki/Wolf_Prize}{Wolf Prize}, the \href{https://en.wikipedia.org/wiki/Schock_Prize}{Schock Prize}, \& the \href{https://en.wikipedia.org/wiki/Nevanlinna_Prize}{Nevanlinna Prize}.

%
The \href{https://en.wikipedia.org/wiki/American_Mathematical_Society}{American Mathematical Society}, \href{https://en.wikipedia.org/wiki/Association_for_Women_in_Mathematics}{Association for Women in Mathematics}, \& other mathematical societies offer several prizes aimed at increasing the representation of women \& minorities in the future of mathematics.

\subsubsection{Mathematical autobiographies}
Several well known mathematicians have written autobiographies in part to explain to a general audience what it is about mathematics that has made them want to devote their lives to its study.

These provide some of the best glimpses into what it means to be a mathematician.

The following list contains some works that are not autobiographies, but rather essays on mathematics \& mathematicians with strong autobiographical elements.
\begin{itemize}
	\item \textit{The Book of My Life} - \href{https://en.wikipedia.org/wiki/Girolamo_Cardano}{Girolamo Cardano}[19]
	\item \href{https://en.wikipedia.org/wiki/A_Mathematician's_Apology}{A Mathematician's Apology} - \href{https://en.wikipedia.org/wiki/G.H._Hardy}{G.H. Hardy}[20]
	\item \href{https://en.wikipedia.org/wiki/A_Mathematician's_Miscellany}{A Mathematician's Miscellany} (republished as Littlewood's miscellany) - \href{https://en.wikipedia.org/wiki/J._E._Littlewood}{J. E. Littlewood}[Littlewood, J. E. (1990) [Originally \textit{A Mathematician's Miscellany} published in 1953], Béla Bollobás (ed.), \textit{Littlewood's miscellany}, Cambridge University Press, ISBN 0-521-33702 X]
	\item \textit{I Am a Mathematician} - \href{https://en.wikipedia.org/wiki/Norbert_Wiener}{Norbert Wiener}[Wiener, Norbert (1956), \textit{I Am a Mathematician / The Later Life of a Prodigy}, The M.I.T. Press, ISBN 0-262-73007-3]
	\item \textit{I Want to be a Mathematician} - \href{https://en.wikipedia.org/wiki/Paul_R._Halmos}{Paul R. Halmos}
	\item \textit{Adventures of a Mathematician} - \href{https://en.wikipedia.org/wiki/Stanislaw_Ulam}{Stanislaw Ulam}[Ulam, S. M. (1976), \textit{Adventures of a Mathematician}, Charles Scribner's Sons, ISBN 0-684-14391-7]
	\item \textit{Enigmas of Chance} - \href{https://en.wikipedia.org/wiki/Mark_Kac}{Mark Kac}[Kac, Mark (1987), \textit{Enigmas of Chance/An Autobiography}, University of California Press, ISBN 0-520-05986-7]
	\item \textit{Random Curves} - \href{https://en.wikipedia.org/wiki/Neal_Koblitz}{Neal Koblitz}
	\item \href{https://en.wikipedia.org/wiki/Edward_Frenkel#Love_and_Math}{\textit{Love \& Math}} - \href{https://en.wikipedia.org/wiki/Edward_Frenkel}{Edward Frenkel}
	\item \textit{Mathematics Without Apologies} - \href{https://en.wikipedia.org/wiki/Michael_Harris_(mathematician)}{Michael Harris}[Harris, Michael (2015), \textit{Mathematics without apologies/portrait of a problematic vocation}, Princeton University Press, ISBN 978-0-691-15423-7]
\end{itemize}

\subsubsection{See also}
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Lists_of_mathematicians}{Lists of mathematicians}
	\item \href{https://en.wikipedia.org/wiki/Human_computer}{Human computer}
	\item \href{https://en.wikipedia.org/wiki/Mathematical_joke}{Mathematical joke}
	\item \href{https://en.wikipedia.org/wiki/A_Mathematician's_Apology}{A Mathematician's Apology}
	\item \href{https://en.wikipedia.org/wiki/Men_of_Mathematics}{Men of Mathematics} (book)
	\item \href{https://en.wikipedia.org/wiki/Mental_calculator}{Mental calculator}\hfill$\square$
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{\href{https://en.wikipedia.org/wiki/Henri_Berestycki}{Wikipedia{\tt/}Henri Berestycki}}
\textit{Henri Berestycki} (born Mar 25, 1951, in Paris)[1] is a French mathematician who obtained his PhD from Université Paris VI - \href{https://en.wikipedia.org/wiki/Universit\%C3\%A9_Pierre_et_Marie_Curie}{Université Pierre et Marie Curie} in 1975.

His Dissertation was titled \textit{Contributions à l'étude des problèmes elliptiques non linéaires}, \& his doctoral advisor was \href{https://en.wikipedia.org/wiki/Haim_Brezis}{Haim Brezis}.[2]

He was an \href{https://en.wikipedia.org/wiki/Leonard_Eugene_Dickson}{L.E. Dickson} Instructor in Mathematics at the \href{https://en.wikipedia.org/wiki/University_of_Chicago}{University of Chicago} from 1975--77, after which he returned to France to continue his research.

He has made many contributions in \textit{nonlinear analysis}, ranging from \textit{nonlinear elliptic equations, hamiltonian systems, spectral theory of elliptic operators}, \& with applications to the description of \textit{mathematical modelling of fluid mechanics \& combustion}.

His current research interests include the mathematical modelling of financial markets, mathematical models in biology \& especially in ecology, \& modelling in social sciences (in particular, urban planning \& criminology).

For these latter topics, he obtained an \href{http://erc.europa.eu/advanced-grants}{ERC Advanced grant} in 2012.

%
He worked at the French National Center of Scientific Research (\href{https://en.wikipedia.org/wiki/CNRS}{CNRS}), then moved to an appointment as Professor at Univ. Paris XIII (1983--1985).

He became a Professor of Mathematics in 1988 at Université Pierre et Marie Curie, Paris VI (1988--2001 of ``exceptional class'' since 1993), \& became Professor at \href{https://en.wikipedia.org/wiki/Ecole_normale_sup%C3%A9rieure}{Ecole normale supérieure}, Paris (1994--1999), \& part-time professor \href{https://en.wikipedia.org/wiki/Ecole_Polytechnique}{Ecole Polytechnique} (1987--1999).

He is also a visiting Professor in the Department of Mathematics at the University of Chicago, \& was also co-director of the Stevanovich Center of Financial Mathematics in Chicago.

He is currently the Directeur d'études (Research Professor) at \href{https://en.wikipedia.org/wiki/School_for_Advanced_Studies_in_the_Social_Sciences}{École des hautes études en sciences sociales} (\href{https://en.wikipedia.org/wiki/EHESS}{EHESS}), since 2001.

\subsubsection{Services}
\begin{itemize}
	\item National Committee of French universities (1992--1995).
	\item Since 2002 director of Centre d'analyse et mathématique sociales (CAMS), CNRS -EHESS.
	\item Vice-president, EHESS (2004--2006).
	\item Member of the thesis prize committee of the universities of Paris (since 2006).
\end{itemize}

\subsubsection{Awards}
\begin{itemize}
	\item Carrière Prize(1988)
	\item \href{https://en.wikipedia.org/wiki/Sophie_Germain#Sophie_Germain_Prize}{Prix Sophie Germain} of the \href{https://en.wikipedia.org/wiki/French_Academy_of_Sciences}{French Academy of Sciences} (2004),
	\item \href{https://en.wikipedia.org/wiki/Humboldt_Prize}{Humboldt Prize} in Germany (2004)
	\item \href{https://en.wikipedia.org/wiki/French_Legion_of_Honor}{French Legion of Honor} in 2010.
	\item \href{https://en.wikipedia.org/wiki/American_Mathematical_Society}{American Mathematical Society} Fellowship (2012).[3]
	\item Foreign honorary member of the \href{https://en.wikipedia.org/wiki/American_Academy_of_Arts_and_Sciences}{American Academy of Arts \& Sciences}, 2013.[4]
\end{itemize}

\subsubsection{Articles}
\begin{itemize}
	\item Berestycki, Henri; Roquejoffre, Jean-Michel; Rossi, Luca; The influence of a line with fast diffusion on Fisher-KPP propagation. \textit{J. Math. Biol.} 66 (2013), no. 4-5, 743--766.
	\item Barthélemy, Marc; Nadal, Jean-Pierre; Berestycki, Henri Disentangling collective trends from local dynamics. \textit{Proc. Natl. Acad. Sci. USA} 107 (2010), no. 17, 7629--7634.
	\item Berestycki, Henri; Hamel, François; Nadirashvili, Nikolai Elliptic eigenvalue problems with large drift \& applications to nonlinear propagation phenomena. \textit{Comm. Math. Phys.} 253 (2005), no. 2, 451--480.
	\item Berestycki, Henri; Hamel, François Front propagation in periodic excitable media. \textit{Comm. Pure Appl. Math.} 55 (2002), no. 8, 949--1032.
	\item Berestycki, H.; Caffarelli, L. A.; Nirenberg, L. Inequalities for second-order elliptic equations with applications to unbounded domains. I. A celebration of John F. Nash, Jr. \textit{Duke Math. J.} 81 (1996), no. 2, 467--494.
	\item Berestycki, H.; Nirenberg, L.; Varadhan, S. R. S. The principal eigenvalue \& maximum principle for 2nd-order elliptic operators in general domains. \textit{Comm. Pure Appl. Math.} 47 (1994), no. 1, 47--92.
	\item Berestycki, H.; Lions, P.-L. Nonlinear scalar field equations. I. Existence of a ground state. \textit{Arch. Rational Mech. Anal.} 82 (1983), no. 4, 313--345; II. Existence of infinitely many solutions, \textit{Arch. Rational Mech. Anal.} 82 (1983), no. 4, 347--375.
	\item Bahri, Abbas; Berestycki, Henri A perturbation method in critical point theory \& applications. \textit{Trans. Amer. Math. Soc.} 267 (1981), no. 1, 1--32.\hfill$\square$
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{\href{https://en.wikipedia.org/wiki/Haim_Brezis}{Wikipedia{\tt/}Ha\"im Brezis}}
\textbf{Haïm Brezis.}
\begin{itemize}
	\item \textbf{Born.} Jun 1m 1944 (age 76). Riom-ès-Montagnes, Cantal, France.
	\item \textbf{Nationality.} French.
	\item \textbf{Alma mater.} \href{https://en.wikipedia.org/wiki/University_of_Paris}{University of Paris}.
	\item \textbf{Known for.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Brezis-Gallouet_inequality}{Brezis-Gallouet inequality}
		\item \href{https://en.wikipedia.org/wiki/Bony-Brezis_theorem}{Bony-Brezis theorem}
		\item \href{https://en.wikipedia.org/wiki/Brezis-Lieb_lemma}{Brezis-Lieb lemma}
	\end{itemize}
\end{itemize}
\textbf{Scientific career.}
\begin{itemize}
	\item \textbf{Fields.} Mathematics.
	\item \textbf{Institutions.} \href{https://en.wikipedia.org/wiki/Pierre_and_Marie_Curie_University}{Pierre \& Marie Curie University}.
	\item \textbf{Doctoral advisor.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Gustave_Choquet}{Gustave Choquet}
		\item \href{https://en.wikipedia.org/wiki/Jacques-Louis_Lions}{Jacques-Louis Lions}
	\end{itemize}
	\item \textbf{Doctoral students.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Abbas_Bahri}{Abbas Bahri}
		\item \href{https://en.wikipedia.org/wiki/Jean-Michel_Coron}{Henri Berestycki}
		\item \href{https://en.wikipedia.org/wiki/Jean-Michel_Coron}{Jean-Michel Coron}
		\item \href{https://en.wikipedia.org/wiki/Jes%C3%BAs_Ildefonso_D%C3%ADaz}{Jes\'us Ildefonso D\'iaz}
		\item \href{https://en.wikipedia.org/wiki/Pierre-Louis_Lions}{Pierre-Louis Lions}
		\item \href{https://en.wikipedia.org/wiki/Juan_Luis_V%C3%A1zquez_Su%C3%A1rez}{Juan Luis V\'azquez Su\'arez}
	\end{itemize}
\end{itemize}
\textit{Haïm Brezis} (born Jun 1, 1944) is a French mathematician who works in \href{https://en.wikipedia.org/wiki/Functional_analysis}{functional analysis} \& \href{https://en.wikipedia.org/wiki/Partial_differential_equation}{partial differential equations}.

\subsubsection{Biography}
Born in \href{https://en.wikipedia.org/wiki/Riom-%C3%A8s-Montagnes}{Riom-ès-Montagnes}, \href{https://en.wikipedia.org/wiki/Cantal}{Cantal}, France.

Brezis is the son of a Romanian immigrant father, who came to France in the 1930s, \& a Jewish mother who fled from the Netherlands.

His wife, \href{https://en.wikipedia.org/wiki/Michal_Govrin}{Michal Govrin}, a native Israeli, works as a novelist, poet, \& theater director.[1]

Brezis received his Ph.D. from the \href{https://en.wikipedia.org/wiki/University_of_Paris}{University of Paris} in 1972 under the supervision of \href{https://en.wikipedia.org/wiki/Gustave_Choquet}{Gustave Choquet}.

He is currently a Professor at the \href{https://en.wikipedia.org/wiki/Pierre_and_Marie_Curie_University}{Pierre \& Marie Curie University} \& a Visiting Distinguished Professor at \href{https://en.wikipedia.org/wiki/Rutgers_University}{Rutgers University}.

He is a member of the \href{https://en.wikipedia.org/wiki/Academia_Europaea}{Academia Europaea} (1988) \& a foreign associate of the \href{https://en.wikipedia.org/wiki/United_States_National_Academy_of_Sciences}{United States National Academy of Sciences} (2003).

In 2012 he became a fellow of the \href{https://en.wikipedia.org/wiki/American_Mathematical_Society}{American Mathematical Society}.[2]

He holds honorary doctorates from several universities including \href{https://en.wikipedia.org/wiki/National_Technical_University_of_Athens}{National Technical University of Athens}.[3]

Brezis is listed as an \href{https://en.wikipedia.org/wiki/ISI_highly_cited_researcher}{ISI highly cited researcher}.[4]

\subsubsection{Works}
\begin{itemize}
	\item \textit{Opérateurs maximaux monotones et semi-groupes de contractions dans les espaces de Hilbert} (1973)
	\item \textit{Analyse Fonctionnelle}. Théorie et Applications (1983)
	\item \textit{Haïm Brezis. Un mathématicien juif}. Entretien Avec Jacques Vauthier. Collection Scientifiques \& Croyants. Editions Beauchesne, 1999. ISBN 978-2-7010-1335-0, ISBN 2-7010-1335-6
	\item \textit{Functional Analysis, Sobolev Spaces \& Partial Differential Equations}, Springer; 1st Edition. edition (November 10, 2010), ISBN 978-0-387-70913-0, ISBN 0-387-70913-4
\end{itemize}

\subsubsection{See also}
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Bony%E2%80%93Brezis_theorem}{Bony-Brezis theorem}
	\item \href{https://en.wikipedia.org/wiki/Brezis%E2%80%93Gallouet_inequality}{Brezis-Gallouet inequality}
	\item \href{https://en.wikipedia.org/wiki/Brezis%E2%80%93Lieb_lemma}{Brezis-Lieb lemma}\hfill$\square$
\end{itemize}

%------------------------------------------------------------------------------%

%------------------------------------------------------------------------------%

\subsection{Lawrence Chris Evans}

%------------------------------------------------------------------------------%

\subsection{\href{https://en.wikipedia.org/wiki/Herbert_Federer}{Wikipedia{\tt/}Herbert Federer}}
\textit{Herbert Federer} (Jul 23, 1920 -- Apr 21, 2010)[``NAS Membership Directory: Federer, Herbert''. National Academy of Sciences. Retrieved Jun 15, 2010.] was an American mathematician.

He is 1 of the creators of \href{https://en.wikipedia.org/wiki/Geometric_measure_theory}{geometric measure theory}, at the meeting point of \href{https://en.wikipedia.org/wiki/Differential_geometry}{differential geometry} \& \href{https://en.wikipedia.org/wiki/Mathematical_analysis}{mathematical analysis}.[Parks, H. (2012) \href{http://www.ams.org/notices/201205/rtx120500622p.pdf}{\textit{Remembering Herbert Federer (1920--2010)}}, NAMS 59(5), 622--631.]

\subsubsection{Career}
Federer was born Jul 23, 1920, in \href{https://en.wikipedia.org/wiki/Vienna}{Vienna}, \href{https://en.wikipedia.org/wiki/Austria}{Austria}.

After emigrating to the US in 1938, he studied mathematics \& physics at the \href{https://en.wikipedia.org/wiki/University_of_California,_Berkeley}{University of California, Berkeley}, earning the Ph.D. as a student of \href{https://en.wikipedia.org/wiki/Anthony_Morse}{Anthony Morse} in 1944.

He then spent virtually his entire career as a member of the \href{https://en.wikipedia.org/wiki/Brown_University}{Brown University} Mathematics Department, where he eventually retired with the title of Professor Emeritus.

%
Federer wrote more than 30 research papers in addition to his book \textit{Geometric measure theory}.

The \href{https://en.wikipedia.org/wiki/Mathematics_Genealogy_Project}{Mathematics Genealogy Project} assigns him 9 Ph.D. students \& well over a hundred subsequent descendants.

His most productive students include the late \href{https://en.wikipedia.org/wiki/Frederick_J._Almgren,_Jr.}{Frederick J. Almgren, Jr.} (1933--1997) a professor at Princeton for 35 years, \& his last student, \href{https://en.wikipedia.org/wiki/Robert_Miller_Hardt}{Robert Hardt}, now at Rice University.

%
Federer was a member of the \href{https://en.wikipedia.org/wiki/United_States_National_Academy_of_Sciences}{National Academy of Sciences}.

In 1987, he \& his Brown colleague \href{https://en.wikipedia.org/wiki/Wendell_Fleming}{Wendell Fleming} won the American Mathematical Society's \href{https://en.wikipedia.org/wiki/Steele_Prize}{Steele Prize} ``for their pioneering work in \textit{Normal \& Integral currents}.''

\subsubsection{Normal \& integral currents}
Federer's mathematical work separates thematically into the periods before \& after his watershed 1960 paper \textit{Normal \& integral currents}, co-authored with Fleming.

That paper provided the \textit{1st satisfactory general solution to \href{https://en.wikipedia.org/wiki/Plateau's_problem}{Plateau's problem}} - the problem of finding a $(k + 1)$-dimensional least-area surface spanning a given $k$-dimensional boundary cycle in $n$-dimensional Euclidean space.

Their solution inaugurated a new \& fruitful period of research on a large class of \textit{geometric variational problems} - especially \textit{minimal surfaces} - via what came to be known as \textit{Geometric Measure Theory}.

\subsubsection{Earlier work}
During the 15 or so years prior to that paper, Federer worked at the technical interface of geometry \& measure theory.

He focused particularly on surface area, rectifiability of sets, \& the extent to which one could substitute rectifiability for smoothness in the analysis of surfaces.

His 1947 paper on the \textit{rectifiable subsets of $n$-space} characterized purely unrectifiable sets by their ``invisibility'' under almost all projections.

\href{https://en.wikipedia.org/wiki/Abram_Samoilovitch_Besicovitch}{A. S. Besicovitch} had proven this for 1-dimensional sets in the plane, but Federer's generalization, valid for subsets of arbitrary dimension in any Euclidean space, was a major technical accomplishment, \& later played a key role in \textit{Normal \& Integral Currents}.

%
In 1958, Federer wrote \textit{Curvature Measures}, a paper that took some early steps toward understanding 2nd-order properties of surfaces lacking the differentiability properties typically assumed in order to discuss curvature.

He also developed \& named what he called the \href{https://en.wikipedia.org/wiki/Coarea_formula}{coarea formula} in that paper.

That formula has become a standard analytical tool.

\subsubsection{Geometric measure theory}
Federer is perhaps best known for his treatise \textit{Geometric Measure Theory}, published in 1969.[Goffman, Casper (1971). ``\href{http://www.ams.org/journals/bull/1971-77-01/S0002-9904-1971-12603-4/S0002-9904-1971-12603-4.pdf}{Review: Geometric measure theory, by Herbert Federer}'' (PDF). Bull. Amer. Math. Soc. 77 (1): 27--35. doi:10.1090/s0002-9904-1971-12603-4.]

Intended as both a text \& a reference work, the book is unusually complete, general \& authoritative: its nearly 600 pages cover a substantial amount of linear \& multilinear algebra, give a profound treatment of measure theory, integration \& differentiation, \& then move on to rectifiability, theory of currents, \& finally, variational applications.

Nevertheless, the book's unique style exhibits a rare \& artistic economy that still inspires admiration, respect - \& exasperation.

A more accessible introduction may be found in F. Morgan's book listed below.

\subsubsection{See also}
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Integral_current}{Integral current}
	\item \href{https://en.wikipedia.org/wiki/Federer-Morse_theorem}{Federer-Morse theorem}
\end{itemize}

\subsubsection{External links}
\begin{itemize}
	\item \href{https://web.archive.org/web/20070426204453/http://www.math.brown.edu/faculty/federer.html}{Federer's page a Brown}\hfill$\square$
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Godfrey Harold Hardy}
``{\sc Godfrey Harold Hardy} \href{https://en.wikipedia.org/wiki/Fellow_of_the_Royal_Society}{FRS} (Feb 7, 1877 -- Dec 1, 1947) was an English mathematician, known for his achievements in \href{https://en.wikipedia.org/wiki/Number_theory}{number theory} \& \href{https://en.wikipedia.org/wiki/Mathematical_analysis}{mathematical analysis}. In \href{https://en.wikipedia.org/wiki/Biology}{biology}, he is known for the \href{https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle}{Hardy--Weinberg principle}, a basic principle of \href{https://en.wikipedia.org/wiki/Population_genetics}{population genetics}.

{\sc G. H. Hardy} is usually known by those outside the field of mathematics for his 1940 essay \href{https://en.wikipedia.org/wiki/A_Mathematician%27s_Apology}{\it A Mathematician's Apology}, often considered 1 of the best insights into the mind of a working mathematician written for the layperson\footnote{1. a person who does not have expert knowledge of a particular subject; 2. a person who is a member of a Church but is not a priest or member of the clergy.}.

Starting in 1914, {\sc Hardy} was the mentor of the Indian mathematician \href{https://en.wikipedia.org/wiki/Srinivasa_Ramanujan}{\sc Srinivasa Ramanujan}, a relationship that has become celebrated. {\sc Hardy} almost immediately recognized {\sc Ramanujan}'s extraordinary albeit untutored brilliance, \& {\sc Hardy \& Ramanujan} became close collaborators. In an interview by \href{https://en.wikipedia.org/wiki/Paul_Erd%C5%91s}{\sc Paul Erd\H{o}s}, when {\sc Hardy} was asked what his greatest contribution to mathematics was, {\sc Hardy} unhesitatingly replied that it was the discovery of {\sc Ramanujan}. In a lecture on {\sc Ramanujan}, {\sc Hardy} said that ``my association with him is the 1 romantic incident in my life''.

\subsubsection{Biography}
{\sc G. H. Hardy} was born on Feb 7, 1877, in \href{https://en.wikipedia.org/wiki/Cranleigh}{Cranleigh}, Surrey, England, into a teaching family. His father was \href{https://en.wikipedia.org/wiki/Bursar}{Bursar} \& Art Master at \href{https://en.wikipedia.org/wiki/Cranleigh_School}{Cranleigh School}; his mother had been a senior mistress at Lincoln Training College for teachers. Both of his parents were mathematically inclined, though neither had a university education. He \& his sister Gertrude ``Gertie'' Emily Hardy (1878--1963) were brought up by their educationally enlightened parents in a typical Victorian nursery attended by a nurse. At an early age, he argued with his nurse about the existence of Santa Clause \& the efficacy of prayer. He read aloud to his sister books e.g., \href{https://en.wikipedia.org/wiki/Don_Quixote}{\it Don Quixote}, \href{https://en.wikipedia.org/wiki/Gulliver%27s_Travels}{\it Gulliver's Travels}, \& \href{https://en.wikipedia.org/wiki/Robinson_Crusoe}{\it Robinson Crusoe}.

{\sc Hardy}'s own natural affinity for mathematics was perceptible at an early age. When just 2 years old, he wrote numbers up to millions, \& when taken to church he amused himself by \href{https://en.wikipedia.org/wiki/Factorize}{factorizing} the numbers of the hymns.

After schooling at \href{https://en.wikipedia.org/wiki/Cranleigh_School}{Cranleigh}, {\sc Hardy} was awarded a scholarship to \href{https://en.wikipedia.org/wiki/Winchester_College}{Winchester College} for his mathematical work. In 1896, he entered \href{https://en.wikipedia.org/wiki/Trinity_College,_Cambridge}{Trinity College, Cambridge}. He was 1st tutored under \href{https://en.wikipedia.org/wiki/Robert_Rumsey_Webb}{\sc Robert Rumsey Webb}, but found it unsatisfying, \& briefly considered switching to history. He then was tutored by \href{https://en.wikipedia.org/wiki/Augustus_Edward_Hough_Love}{\sc Augustus Love}, who recommended him to read \href{https://en.wikipedia.org/wiki/Camille_Jordan}{\sc Camille Jordan}'s {\it Cours d'analyse}, which taught him for the 1st time ``what mathematics really meant''. After only 2 years of preparation under his coach, \href{https://en.wikipedia.org/wiki/Robert_Alfred_Herman}{\sc Robert Alfred Herman}, {\sc Hardy} was 4th in the \href{https://en.wikipedia.org/wiki/Cambridge_Mathematical_Tripos}{Mathematics Tripos} examination. Years later, he sought to abolish the Tripos system, as he felt that it was becoming more an end in itself than a means to an end. While at university, {\sc Hardy} joined the \href{https://en.wikipedia.org/wiki/Cambridge_Apostles}{Cambridge Apostles}, an elite, intellectual secret society.

{\sc Hardy} cited as his most important influence his independent study of {\it Cours d'analyse de l'École Polytechnique} by the French mathematician \href{https://en.wikipedia.org/wiki/Camille_Jordan}{\sc Camille Jordan}, through which he became acquainted with the more precise mathematics tradition in continental Europe. In 1900 he passed part II of the Tripos, \& in the same year he was elected to a Prize Fellowship at Trinity College. In 1903 he earned his M.A., which was the highest academic degree at English universities at that time. When his Prize Fellowship expired in 1906 he was appointed to the Trinity staff as a lecturer in mathematics, where teaching 6 hours per week left him time for research.

On Jan 16, 1913, \href{https://en.wikipedia.org/wiki/Srinivasa_Ramanujan}{\sc Ramanujan} wrote to {\sc Hardy}, who Ramanujan had known from studying {\it Orders of Infinity} (1910). {\sc Hardy} read the letter in the morning, suspected it was a crank or a prank, but thought it over \& realized in the evening that it was likely genuine because ``great mathematicians are commoner than thieves or humbugs of such incredible skills''. He then invited {\sc Ramanujan} to Cambridge \& began ``the 1 romantic incident in my life''.

In the aftermath of the \href{https://en.wikipedia.org/wiki/Bertrand_Russell#First_World_War}{Bertrand Russell affair} during \href{https://en.wikipedia.org/wiki/World_War_I}{World War I}, in 1919 he left Cambridge to take the \href{https://en.wikipedia.org/wiki/Savilian_Chair_of_Geometry}{Savilian Chair of Geometry} (\& thus become a Fellow of \href{https://en.wikipedia.org/wiki/New_College,_Oxford}{New College}) at \href{https://en.wikipedia.org/wiki/Oxford_University}{Oxford}. {\sc Hardy} spent the academic year 1928--1929 at \href{https://en.wikipedia.org/wiki/Princeton_University}{Princeton University} in an academic exchange with \href{https://en.wikipedia.org/wiki/Oswald_Veblen}{Oswald Veblen}, who spent the year at Oxford. {\sc Hardy} gave the \href{https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs_Lectureship}{Josiah Willard Gibbs lecture} for 1928. {\sc Hardy} left Oxford \& returned to Cambridge in 1931, becoming again a fellow of Trinity College \& holding the \href{https://en.wikipedia.org/wiki/Sadleirian_Professor_of_Pure_Mathematics}{Sadleirian Professorship} until 1942. It is believed that he left Oxford for Cambridge to avoid the compulsory retirement at 65.

He was on the governing body of \href{https://en.wikipedia.org/wiki/Abingdon_School}{Abingdon School} from 1922--1935.

In 1939, he suffered a \href{https://en.wikipedia.org/wiki/Coronary_thrombosis}{coronary thrombosis}, which prevented him from playing tennis, squash, etc. He also lost his creative powers in mathematics. He was constantly bored \& distracted himself by writing a privately circulated memoir about the {\sc Bertrand Russell} affair. In the early summer of 1947, he attempted suicide by \href{https://en.wikipedia.org/wiki/Barbiturate_overdose}{barbiturate overdose}. After that, he resolved to simply wait for death. He died suddenly 1 early morning while listening to his sister read out from a book of the history of Cambridge University cricket.

\subsubsection{Work}
{\sc Hardy} is credited with reforming British mathematics by bringing \href{https://en.wikipedia.org/wiki/Rigour#Mathematical_rigour}{rigor} into it, which was previously a characteristic of French, Swiss, \& German mathematics. British mathematicians had remained largely in the tradition of \href{https://en.wikipedia.org/wiki/Applied_mathematics}{applied mathematics}, in thrall to the reputation of \href{https://en.wikipedia.org/wiki/Isaac_Newton}{\sc Isaac Newton} (see \href{https://en.wikipedia.org/wiki/Cambridge_Mathematical_Tripos}{Cambridge Mathematical Tripos}). {\sc Hardy} was more in tune with the {\it cours d'analyse} methods dominant in France, \& aggressively promoted his conception of \href{https://en.wikipedia.org/wiki/Pure_mathematics}{pure mathematics}, in particular against the \href{https://en.wikipedia.org/wiki/Hydrodynamics}{hydrodynamics} that was an important part of Cambridge mathematics.

{\sc Hardy} preferred to work only 4 hours every day on mathematics, spending the rest of the day talking, playing cricket, \& other gentlemanly activities.

From 1911, he collaborated with \href{https://en.wikipedia.org/wiki/John_Edensor_Littlewood}{\sc John Edensor Littlewood}, in extensive work in \href{https://en.wikipedia.org/wiki/Mathematical_analysis}{mathematical analysis} \& \href{https://en.wikipedia.org/wiki/Analytic_number_theory}{analytic number theory}. This (along with much else) led to quantitative progress on \href{https://en.wikipedia.org/wiki/Waring%27s_problem}{Waring's problem}, as part of the \href{https://en.wikipedia.org/wiki/Hardy%E2%80%93Littlewood_circle_method}{Hardy--Littlewood circle method}, as it became known. In \href{https://en.wikipedia.org/wiki/Prime_number}{prime number} theory, they proved results \& some notable \href{https://en.wikipedia.org/wiki/Conditional_result}{conditional results}. This was a major factor in the development of number theory as a system of \href{https://en.wikipedia.org/wiki/Conjecture}{conjectuers}; e.g., the \href{https://en.wikipedia.org/wiki/First_Hardy%E2%80%93Littlewood_conjecture}{1st Hardy--Littlewood conjecture} \& \href{https://en.wikipedia.org/wiki/Second_Hardy%E2%80%93Littlewood_conjecture}{2nd Hardy--Littlewood conjecture}. {\sc Hardy}'s collaboration with {\sc Littlewood} is among the most successful \& famous collaborations in mathematical history. In a 1947 lecture, the Danish mathematician \href{https://en.wikipedia.org/wiki/Harald_Bohr}{\sc Harald Bohr} reported a colleague as saying, ``Nowadays, there are only 3 really great English mathematicians: {\sc Hardy, Littlewood, \& Hardy--Littlewood}.''

{\sc Hardy} is also known for formulating the \href{https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle}{Hardy--Weinberg principle}, a basic principle of \href{https://en.wikipedia.org/wiki/Population_genetics}{population principle}, a basic principle of \href{https://en.wikipedia.org/wiki/Population_genetics}{population genetics}, independently from \href{https://en.wikipedia.org/wiki/Wilhelm_Weinberg}{\sc Wilhelm Weinberg} in 1908. He played \href{https://en.wikipedia.org/wiki/Cricket}{cricket} with the geneticist \href{https://en.wikipedia.org/wiki/Reginald_Punnett}{\sc Reginald Punnett}, who introduced the problem to him in purely mathematical terms. {\sc Hardy}, who had no interest in genetics \& described the mathematical argument as ``very simple'', may never have realized how important the result became.

{\sc Hardy} was elected an international honorary member of the \href{https://en.wikipedia.org/wiki/American_Academy_of_Arts_and_Sciences}{American Academy of Arts \& Sciences} in 1921, an international member of the United States \href{https://en.wikipedia.org/wiki/National_Academy_of_Sciences}{National Academy of Sciences} in 1927, \& an international member of the \href{https://en.wikipedia.org/wiki/American_Philosophical_Society}{American Philosophical Society} in 1939.

{\sc Hardy}'s collected papers have been published in 7 volumes by \href{https://en.wikipedia.org/wiki/Oxford_University_Press}{Oxford University Press}.

\paragraph{Pure mathematics.} {\sc Hardy} preferred his work to be considered \href{https://en.wikipedia.org/wiki/Pure_mathematics}{\it pure mathematics}, perhaps because of his \href{https://en.wikipedia.org/wiki/Pacifism}{detestation of war} \& the military uses to which mathematics had been applied. He made several statements similar to that in his \href{https://en.wikipedia.org/wiki/A_Mathematician%27s_Apology}{\it Apology}:
\begin{quote}
	``I have never done anything ``useful''. No discovery of mine has made, or is likely to make, directly or indirectly, for good or ill, the least difference to the amenity of the world.''
\end{quote}
However, aside from formulating the \href{https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle}{Hardy--Weinberg principle} in \href{https://en.wikipedia.org/wiki/Population_genetics}{population genetics}, his famous work on integer partitions with his collaborator {\sc Ramanujan}, known as the \href{https://en.wikipedia.org/wiki/Partition_function_(number_theory)#Approximation_formulas}{Hardy--Ramanujan asymptotic formula}, has been widely applied in physics to find quantum partition functions of atomic nuclei (1st used by \href{https://en.wikipedia.org/wiki/Niels_Bohr}{\sc Niels Bohr}) \& to derive thermodynamic functions of non-interacting \href{https://en.wikipedia.org/wiki/Bose%E2%80%93Einstein_statistics}{Bose--Einstein} systems. Though {\sc Hardy} wanted his maths to be ``pure'' \& devoid\footnote{{\it devoid of something} completely without something.} of any application, much of his work has found applications in other branches of science.

Moreover, {\sc Hardy} deliberately pointed out in his {\it Apology} that mathematicians generally do not ``glory in the uselessness of their work'', but rather -- because science can be used for evil ends as well as good -- ``mathematicians may be justified in rejoicing that there is 1 science at any rate, \& that their own, whose very remoteness from ordinary human activities should keep it gentle \& clean.'' {\sc Hardy} also rejected as a ``delusion'' the belief that the difference between pure \& applied mathematics had anything to do with their utility. {\sc Hardy} regards as ``pure'' the kinds of mathematics that are independent of the physical world, but also considers some ``applied'' mathematicians, e.g. physicists \href{https://en.wikipedia.org/wiki/James_Clerk_Maxwell}{\sc Maxwell} \& \href{https://en.wikipedia.org/wiki/Albert_Einstein}{\sc Einstein}, to be among the ``real'' mathematicians, whose work ``has permanent aesthetic value'' \& ``is eternal because the best of it may, like the best literature, continue to cause intense emotional satisfaction to thousands pf people after thousands of years.'' Although he admitted that what he called ``real'' mathematics may someday become useful, he asserted that, at the time in which the {\it Apology} was written, only the ``dull \& elementary parts'' of either pure or applied mathematics could ``work for good or ill''.

\subsubsection{Personality}
{\sc Hardy} was extremely shy as a child \& was socially awkward, cold, \& eccentric\footnote{considered by other people to be strange or unusual.} throughout his life. During his school years, he was top of his class in most subjects, \& won many prizes \& awards but hated having to receive them in front of the entire school. He was uncomfortable being introduced to new people, \& could not bear to look at his own reflection in a mirror. It is said that, when staying in hotels, he would cover all the mirrors with towels.

Socially, {\sc Hardy} was associated with the \href{https://en.wikipedia.org/wiki/Bloomsbury_Group}{Bloomsbury Group} \& the \href{https://en.wikipedia.org/wiki/Cambridge_Apostles}{Cambridge Apostles}; \href{https://en.wikipedia.org/wiki/G._E._Moore}{\sc G. E. Moore}, \href{https://en.wikipedia.org/wiki/Bertrand_Russell}{Bertrand Russell} \& \href{https://en.wikipedia.org/wiki/J._M._Keynes}{J. M. Keynes} were friends. Apart from close friendships, he had a few platonic relationships with young men who shared his sensibilities, \& often his love of cricket. A mutual interest in cricket led him to befriend the young \href{https://en.wikipedia.org/wiki/C._P._Snow}{\sc C. P. Snow}. {\sf Hardy} was a lifelong bachelor \& in his final years he was cared for by his sister.

He was an avid cricket fan. {\sc Maynard Keynes} observed that if {\sc Hardy} had read the \href{https://en.wikipedia.org/wiki/Stock_exchange}{stock exchange} for half an hour every day with as much interest \& attention as he did the day's cricket scores, he would have become a rich man. He liked to speak of the best class of mathematician research as ``the \href{https://en.wikipedia.org/wiki/Jack_Hobbs}{Hobbs} class'', \& later, after Bradman appeared as an even greater batsman, ``the \href{https://en.wikipedia.org/wiki/Don_Bradman}{Bradman} class''.

Around the age of 20, he decided that he \href{https://en.wikipedia.org/wiki/Atheism}{did not believe in God}, which proved a minor issue as attending the chapel was compulsory at Cambridge University. He wrote a letter to his parents explaining that, \& from then on he refused to go into any college chapel, even for purely ritualistic duties.

He was at times politically involved, if not an activist. He took part in the \href{https://en.wikipedia.org/wiki/Union_of_Democratic_Control}{Union of Democratic Control} during World War I, \& for Intellectual Liberty in the late 1930s. He admired America \& Soviet Union roughly equally. He found both sides of the 2nd World War objectionable.

\href{https://en.wikipedia.org/wiki/Paul_Hoffman_(science_writer)}{\sc Paul Hoffman} writes that ``His concerns were wide-ranging, as evidenced by 6 New Year's resolutions he set in a postcard to a friend:
\begin{enumerate}
	\item prove the \href{https://en.wikipedia.org/wiki/Riemann_hypothesis}{Riemann hypothesis}
	\item make 211 not out in the 4th innings of the last \href{https://en.wikipedia.org/wiki/The_Oval}{Test Match at the Oval}
	\item find an argument for the nonexistence of God which shall convince the general public
	\item be the 1st man at the top of \href{https://en.wikipedia.org/wiki/Mount_Everest}{Mount Everest}
	\item be proclaimed the 1st president of the U.S.S.R. of Great Britain \& Germany
	\item murder \href{https://en.wikipedia.org/wiki/Benito_Mussolini}{Mussolini}.
\end{enumerate}

\subsubsection{Cultural references}
{\sc Hardy} is a key character, played by \href{https://en.wikipedia.org/wiki/Jeremy_Irons}{Jeremy Irons}, in the 2015 film \href{https://en.wikipedia.org/wiki/The_Man_Who_Knew_Infinity_(film)}{\it The Man Who Knew Infinity}, based on the biography of {\sc Ramanujan} with the same title. {\sc Hardy} is a major character in \href{https://en.wikipedia.org/wiki/David_Leavitt}{\sc David Leavitt}'s historical fiction novel \href{https://en.wikipedia.org/wiki/The_Indian_Clerk}{\it The Indian Clerk} (2007), which depicts his Cambridge years \& his relationship with \href{https://en.wikipedia.org/wiki/John_Edensor_Littlewood}{John Edensor Littlewood} \& {\sc Ramanujan}. {\sc Hardy} is a secondary character in \href{https://en.wikipedia.org/wiki/Uncle_Petros_and_Goldbach%27s_Conjecture}{\it Uncle Petros \& Goldbach's Conjecture} (1992), a mathematics novel by \href{https://en.wikipedia.org/wiki/Apostolos_Doxiadis}{\sc Apostolos Doxiadis}. {\sc Hardy} is also a character in the 2014 Indian film, \href{https://en.wikipedia.org/wiki/Ramanujan_(film)}{\it Ramanujan}, played by {\sc Kevin McGowan}.'' -- \href{https://en.wikipedia.org/wiki/G._H._Hardy}{Wikipedia{\tt/}G. H. Hardy}

%------------------------------------------------------------------------------%

\subsection{Peter Lax}

%------------------------------------------------------------------------------%

\subsection{Jacques-Louis Lions}
\begin{itemize}
	\item \textbf{Born.} May 3, 1928. \href{https://en.wikipedia.org/wiki/Grasse}{Grasse}, \href{https://en.wikipedia.org/wiki/Alpes-Maritimes}{Alpes-Maritimes}, \href{https://en.wikipedia.org/wiki/France}{France}.
	\item \textbf{Died.} May 17, 2001 (aged 73).
	\item \textbf{Nationality.} French.
	\item \textbf{Alma mater.} \href{https://en.wikipedia.org/wiki/University_of_Nancy}{University of Nancy}.
	\item \textbf{Known for.} PDEs.
	\item \textbf{Awards.} \href{https://en.wikipedia.org/wiki/Japan_Prize}{Japan Prize} (1991).
\end{itemize}
\textbf{Scientific career.}
\begin{itemize}
	\item \textbf{Fields.} Mathematics.
	\item \textbf{Institutions.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/%C3%89cole_Polytechnique}{\'Ecole Polytechnique}
		\item \href{https://en.wikipedia.org/wiki/Coll%C3%A8ge_de_France}{Coll\`ege de France}
	\end{itemize}
	\item \textbf{\href{https://en.wikipedia.org/wiki/Doctoral_advisor}{Doctoral advisor}.} \href{https://en.wikipedia.org/wiki/Laurent_Schwartz}{Laurent Schwartz}.
	\item \textbf{Doctoral students.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Alain_Bensoussan}{Alain Bensoussan}
		\item \href{https://en.wikipedia.org/wiki/Jean-Michel_Bismut}{Jean-Michel Bismut}
		\item \href{https://en.wikipedia.org/wiki/Ha%C3%AFm_Brezis}{Ha\"im Brezis}
		\item \href{https://en.wikipedia.org/wiki/Erol_Gelenbe}{Erol Gelenbe}
		\item \href{https://en.wikipedia.org/wiki/Roland_Glowinski}{Roland Glowinski}
		\item \href{https://en.wikipedia.org/wiki/Roger_Temam}{Roger Temam}
	\end{itemize}
\end{itemize}
\textit{Jacques-Louis Lions} ([1] 3 May 1928 - May 17, 2001) was a French mathematician who made contributions to the theory of \href{https://en.wikipedia.org/wiki/Partial_differential_equation}{partial differential equations} \& to \href{https://en.wikipedia.org/wiki/Stochastic_processes}{stochastic control}, among other areas.

He received the \href{https://en.wikipedia.org/wiki/Society_for_Industrial_and_Applied_Mathematics}{SIAM}'s \href{https://en.wikipedia.org/wiki/John_von_Neumann_Lecture}{John von Neumann Lecture} prize in 1986 \& numerous other distinctions.[2][3]

Lions is listed as an \href{https://en.wikipedia.org/wiki/ISI_highly_cited_researcher}{ISI highly cited researcher}.[4] 

\subsubsection{Biography}
After being part of the French Résistance in 1943 \& 1944, J.-L. Lions entered the \href{https://en.wikipedia.org/wiki/%C3%89cole_Normale_Sup%C3%A9rieure}{École Normale Supérieure} in 1947.

He was a professor of mathematics at the Université of Nancy, the Faculty of Sciences of Paris, \& the \href{https://en.wikipedia.org/wiki/%C3%89cole_polytechnique}{École polytechnique}.

%
In 1966 he sent an invitation to \href{https://en.wikipedia.org/wiki/Gury_Marchuk}{Gury Marchuk}, the soviet mathematician to visit Paris.

This was hand delivered by \href{https://en.wikipedia.org/wiki/General_De_Gaulle}{General De Gaulle} during his visit to \href{https://en.wikipedia.org/wiki/Akademgorodok}{Akademgorodok} in June of that year.[5]

%
He joined the prestigious \href{https://en.wikipedia.org/wiki/Coll%C3%A8ge_de_France}{Collège de France} as well as the French Academy of Sciences in 1973.

In 1979, he was appointed director of the Institut National de la Recherche en Informatique et Automatique (\href{https://en.wikipedia.org/wiki/INRIA}{INRIA}), where he taught \& promoted the use of numerical simulations using finite elements integration.

Throughout his career, Lions insisted on the \textit{use of mathematics in industry}, with a particular involvement in the French space program, as well as in domains such as energy \& the environment.

This eventually led him to be appointed director of the Centre National d'Etudes Spatiales (\href{https://en.wikipedia.org/wiki/CNES}{CNES}) from 1984 to 1992.

%
Lions was elected President of the \href{https://en.wikipedia.org/wiki/International_Mathematical_Union}{International Mathematical Union} in 1991 \& also received the \href{https://en.wikipedia.org/wiki/Japan_Prize}{Japan Prize} \& the \href{https://en.wikipedia.org/wiki/Harvey_Prize}{Harvey Prize} that same year.[3]

In 1992, the \href{https://en.wikipedia.org/wiki/University_of_Houston}{University of Houston} awarded him an honorary doctoral degree.

He was elected president of the \href{https://en.wikipedia.org/wiki/French_Academy_of_Sciences}{French Academy of Sciences} in 1996 \& was also a Foreign Member of the \href{https://en.wikipedia.org/wiki/Royal_Society}{Royal Society} (ForMemRS)[6] \& numerous other foreign academies.[2][3]

%
He has left a considerable body of work, among this more than 400 scientific articles, 20 volumes of mathematics that were translated into English \& Russian, \& major contributions to several collective works, including the 4000 pages of the monumental \textit{Mathematical analysis \& numerical methods for science \& technology} (in collaboration with Robert Dautray), as well as the \textit{Handbook of numerical analysis} in 7 volumes (with \href{https://en.wikipedia.org/wiki/Philippe_G._Ciarlet}{Philippe G. Ciarlet}).

%
His son \href{https://en.wikipedia.org/wiki/Pierre-Louis_Lions}{Pierre-Louis Lions} is also a well-known mathematician who was awarded a \href{https://en.wikipedia.org/wiki/Fields_Medal}{Fields Medal} in 1994.[7]

Both father \& son have received honorary doctorates from \href{https://en.wikipedia.org/wiki/Heriot-Watt_University}{Heriot-Watt University} in 1986 \& 1995 respectively.[8]

\subsubsection{Books}
\begin{itemize}
	\item with Enrico Magenes: \textit{Problèmes aux limites non homogènes et applications}. 3 vols., 1968, 1970
	\item \textit{Contrôle optimal de systèmes gouvernés par des équations aux dérivées partielles}. 1968
	\item with L. Cesari: \textit{Quelques méthodes de résolution des problèmes aux limites non linéaires}. 1969
	\item with Roger Dautray: \textit{Mathematical analysis \& numerical methods for science \& technology}. 9 vols., 1984/5
	\item with Philippe Ciarlet: \textit{Handbook of numerical analysis}. 7 vols.
	\item with Alain Bensoussan, Papanicolaou: \textit{Asymptotic analysis of periodic structures}. North Holland 1978
	\item \textit{Controlabilité exacte, perturbations et stabilisation de systèmes distribués}[9]
	\item with John E. Lagnese: \textit{Modelling Analysis \& Control of Thin Plates}.\hfill$\square$
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Andrew Joseph Majda}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{memory_Andrew_Joseph_Majda}. {\sc Bjorn Engquist, Panagiotis Souganidis, Samuel N. Stechmann, Vlad Vicol}. {\it In memory of Andrew J. Majda}.
	
	``He was hard working until the end even though he suffered from serious health issues for quite some time.''
	
	``He advocated a philosophy for applied mathematics research that involves the interaction of math theory, asymptotic modeling, numerical modeling, \& observed \& experimental data $\ldots$ Andy Majda's modus operandi of modern applied mathematics, as a symbiotic relationship between (i) rigorous mathematical theory, (ii) numerical analysis \& numerical modeling, (iii) observed phenomena \& experimental data, \& (iv) qualitative and/or asymptotic modeling [Maj00].''
	
	``Andy's legacy lives on in the mathematical science he created, but also in the many students \& postdocs he so enthusiastically taught \& mentored.''
	
	``The period at UCLA was followed by 5 years at Berkeley, 1979--1984. During this productive time, he developed ``Majda's model'' for combustion in reactive flows, \& together with Tosio Kato \& Tom Beale derived ``Beale-Kato-Majda criterion,'' which characterizes a putative incompressible Euler singularity in terms of the accumulation of vorticity [BKM84].''
	
	``At Courant, Andy shifted his research efforts to cross-disciplinary research in modern applied mathematics with climate--atmosphere--ocean science.''
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Vladimir Mazya}


%------------------------------------------------------------------------------%

\subsection{Phan Thành Nam}
``2008, sang Đan Mạch \& làm TS tại ĐH Copenhagen dưới sự hướng dẫn của Prof. {\sc Jan Philip Solovej}. Bảo vệ luận văn về ngành Vật Lý Toán năm 2011 với nhan đề {\it``Contributions to the Rigorous Study of the Structure of Atoms''}. 2011--2013: làm nghiên cứu viên sau tiến sĩ tại Đại học Cergy-Pontoise (Pháp) dưới sự hướng dẫn của Prof. {\sc Mathieu Lewin}. 2013--2016,  làm nghiên cứu viên sau tiến sĩ tại Viện khoa học \& công nghệ Áo (IST) dưới sự hướng dẫn của Prof. {\sc Robert Seiringer}. 2016: sang Cộng hòa Séc làm giáo sư trợ giảng tại Đại học Masaryk. 2017--now: GS tại Đại học Ludwig Maximilian Munich, CHLB Đức. 2020: đạt giải thưởng Hội Toán học Châu Âu EMS Prize.
\begin{quotation}
	``{\sc Phan Thành Nam} (1985--?) đã có những công trình đáng chú ý về toán học của hệ đa vật lượng tử (quantum many-body system) bao gồm hệ nguyên tử, phân tử cũng như các khí Bose \& Fermi. Kết quả của anh anh liên quan đến sự cân bằng \& tính chất động lực học của những hệ như vậy. Nhiều kết quả nổi tiếng trong lãnh vực này là do công của Nam. Chúng bao gồm những chặn tốt nhất cho ion hóa cực đại của các nguyên tử \& những hằng số nổi tiếng của của bất đẳng thức Lieb--Thirring lừng danh. Hơn nữa, Nam \& các cộng sự đã phát triển 1 cách tiếp cận tổng quát để thiết lập giới hạn trường trung bình (mean-field limit) của các hệ boson dựa trên định lý de Finetti lượng tử. Đó là thứ mà bây giờ trở tiêu chuẩn vàng trong lãnh vực này.'' -- Prof. {\sc Jan Philip Solovej}
\end{quotation}
Các lĩnh vực nghiên cứu của GS Phan Thành Nam là giải tích \& vật lý toán, đặc biệt là cơ học lượng tử nhiều hạt, lý thuyết phổ, phép tính biến phân \& phương trình đạo hàm riêng, giải tích số.'' -- \href{https://vi.wikipedia.org/wiki/Phan_Th%C3%A0nh_Nam}{Wikipedia{\tt/}Phan Thành Nam}

%------------------------------------------------------------------------------%

\subsection{Jind\v{r}ich Ne\v{c}as}

%------------------------------------------------------------------------------%

\subsection{Louis Nirenberg}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Vazquez_remember_Nirenberg}. {\sc Juan Luis V\'{a}zquez}. {\it Remembering Louis Nirenberg \& His Mathematics}.
\end{enumerate}

\subsubsection*{Abstract}
The article is dedicated to recalling the life \& mathematics of Louis Nirenberg, a distinguished Canadian mathematician who recently died in New York, where he lived.

An emblematic figure of analysis \& PDEs in the last century, he was awarded the Abel Prize in 2015.

From this watchtower at the Courant Institute in New York, he was for many years a global teacher \& master.

He was a good friend of Spain.
\begin{quotation}\it
	1 of the wonders of mathematics is you go somewhere in the world \& you meet other mathematicians, \& it is like 1 big family.
	
	This large family is a wonderful joy.\footnote{From an interview with Louis Nirenberg appeared in \textit{Notices of the AMS}, 2002, [43]}
\end{quotation}

\subsubsection{Introduction}
This article is dedicated to remembering the life \& work of the prestigious Canadian mathematician Louis Nirenberg, born in Hamilton, Ontario, in 1925, who died in New York on Jan 26, 2020, at the age of 94.

Professor for much of his life at the mythical Courant Institute of New York University, he was considered 1 of the best mathematical analysts of the 20th century, a specialist in the analysis of PDEs.

%
When the news of his death was received, it was a very sad moment for many mathematicians, but it was also the opportunity of reviewing an exemplary life \& underlining some of its landmarks.

His work unites diverse fields between what is considered Pure Mathematics \& Applied Mathematics, \& in particular he was cult figure in the discipline of PDEs, a key theory \& tool in the mathematical formulation of many processes in science, in engineering, \& in other branches of mathematics.

\textit{His work is a prodigy of sharpness \& logical perfection, \& at the same time its applications span today multiple scientific areas.}

%
In recognition of his work, in 2015 he received the Abel Prize along with the another great mathematician, John Nash.

The Abel Prize is 1 of the greatest awards in Mathematics, comparable to the Nobel prizes in other sciences.

At that time, the Courant Institute, where he was for so many decades a renowned professor, published an article called \textit{Beautiful Minds}\footnote{\href{https://www.nyu.edu/about/news-publications/news/2015/march/beautiful-minds-courantsnirenberg-princetons-john-nash-win-abel-prize-in-mathematics-.html}{Beautiful Minds: Courant's Nirenberg, Princeton's John Nash Win Abel Prize in Mathematics }.} which is quite enjoyable reading.

%
He was a distinguished member of the AMS (American Mathematical Society).

Throughout his life, he received many other honors \& awards, e.g. the AMS B\^ocher Memorial Prize (1959), the Jeffery-Williams Prize (1987), the Steele Prize for Lifetime Achievement (1994 \& 2014), the National Medal of Science (1995), the inaugural Crafoord Prize from the Royal Swedish Academy (1982), \& the 1st Chern medal at the 2010 International Congress of Mathematicians, awarded by the International Mathematical Union \& the Chern Foundation.

He was a plenary speaker at the International Congress of Mathematicians held in Stockholm in Aug 1962; the title of the conference was \textit{``Some Aspects of Linear \& Nonlinear PDE''}.

In 1969 he was elected Member of the U.S. National Academy of Sciences.

%
It was not honors that concerned him most, but rather his profession \& the mathematical community that surrounded him.

In his long career at the Courant Institute he discovered many mathematical talents \& collaborated in numerous relevant works with distinguished colleagues.

A wise man in science \& life, he was 1 of the most influential \& beloved mathematicians of the last century, \& the current century too.

His teaching extended 1st to the international centers that he loved to visit, \& then to the entire world.

Indeed, we live at this height of time in a world-wide scientific society whose close connection brings so many benefits to the pursuit of knowledge.

Many of his articles are among the most cited in the world.\footnote{Topic 35, PDEs, from the mathematical database Mathscinet, includes 3 articles by L. Nirenberg among the 10 most cited ever.}

\subsubsection{Starting}
In order to start the tour of his mathematics, nothing better than to quote a few paragraphs from the mention of the Abel Prize Committee in 2015:\footnote{\href{https://www.abelprize.no/nyheter/vis.html?tid=63589}{John F. Nash, Jr. \& Louis Nirenberg share the Abel Prize}.}

\textsf{Fig. Louis Nirenberg receiving the Abel Prize from King Harald V of Norway in the presence of John Nash (photo: Berit Roald{\tt/}NTB scanpix).}

\textbf{Mathematical giants:}
\begin{quotation}\it
	Nash \& Nirenberg are 2 mathematical giants of the 20th century.
	
	They are being recognized for their contributions to the field of PDEs, which are equations involving rates of change that originally arose to describe physical phenomena but, as they showed, are also helpful in analyzing abstract geometrical objects.
\end{quotation}
The Abel committee writes:
\begin{quotation}\it
	``Their breakthroughs have developed into versatile \& robust techniques that have become essential tools for the study of nonlinear PDEs.
	
	Their impact can be felt in all branches of the theory.''
\end{quotation}
About Louis they say:
\begin{quotation}\it
	``Nirenberg has had 1 of the longest \& most f\^eted careers in mathematics, having produced important results right up until his 70s.
	
	Unlike Nash, who wrote papers alone, Nirenberg preferred to work in collaboration with others, with more than 90\% of his papers written jointly.
	
	Many results in the world of elliptic PDEs are named after him \& his collaborators, e.g. the Gagliardo--Nirenberg inequalities, the John--Nirenberg inequality \& the Kohn--Nirenberg theory of pseudo-differential operators.''
\end{quotation}
They conclude:
\begin{quotation}\it
	``Far from being confined to the solutions of the problems for which they were devised, the results proven by Nash \& Nirenberg have become very useful tools \& have found tremendous applications in further contexts.''
\end{quotation}
To be precise, Nirenberg made fundamental contributions to both linear \& nonlinear PDEs, functional analysis, \& their application in geometry \& complex analysis.

Among the most famous contributions we will discuss are the Gagliardo-Nirenberg interpolation inequality, which is important in solving the elliptic PDEs that arise within many areas of mathematics; the formalization of the BMO spaces of bounded mean oscillation, \& others that we will be seeing.

%
A work of utmost relevance was the work with Luis Caffarelli \& Robert Kohn aimed at solving the big open problem of existence \& smoothness of the solutions of the Navier-Stokes system of fluid mechanics.

This work was described by the AMS in 2002 as ``1 of the best ever done.''

The problem is on the Millennium Problems List (the list compiled by the Clay Foundation), \& is 1 of the most appealing open problems of mathematical physics, raised nearly 2 centuries ago.

Fermat's Last Theorem \& the Poincar\'e Conjecture have been defeated at the turn of the century, but the Navier-Stokes enigma (and in some sense its companion about the Euler's system) keep defying us.

We will deal with the issue in detail in Section 4.

\paragraph{The beginnings. From Canada to New York.} Louis Nirenberg grew up in Montr\'eal, where his fatehr was a Hebrew teacher.

After graduating\footnote{With a degree in mathematics \& physics, also in mathematics being bilingual counts.} in 1945 at McGill University, Montréal, Louis found a summer job at the National Research Council of Canada, where he met the physicist Ernest Courant, the son of Richard Courant, a famous professor at New York University.

Ernest mentioned to Nirenberg that he was going to New York to see his father \& Louis begged him for advice on a good place to apply for a master study in physics.

He returned with Richard Courant's invitation for Louis to go to New York University (NYU) for a master's degree in mathematics, after which he would be prepared for a physics program.

%
But once Louis began studying Mathematics at NYU, he never changed.

He defended his doctoral thesis under James Stoker in 1949, solving a problem in differential geometry.

The dice were cast.

We reach a crucial moment in Louis's life.

Breaking with the golden rule\footnote{which is an essential part of the American professional practice.} according to which ``a recent doctor should move to a different environment'', Richard Courant kept his best students around him, including Louis Nirenberg, \& he thus created the NYU Mathematical Institute, the famous Courant Institute, which has become a world benchmark for high mathematics, comparable only to the Princeton Institute for Advanced Study on the East Coast of the USA.

Louis was 1st a postdoc \& then a permanent member of the faculty.

There he thrived \& spent his life.

\paragraph{Equations \& Geometry.} The problem Stoker gave to Louis for his thesis, entitled \textit{``The Determination of a Closed Convex Surface Having Given Line Elements''}, is called ``the embedding problem'' or ``Weyl Problem''.

It can be stated as follows: Given a 2D sphere with a Riemannian metric s.t. the Gaussian curvature is positive everywhere, the question is whether a surface can be constructed in 3D space so that the Riemannian distance function coincides with the distance inherited from the usual Euclidean distance in the 3D space (in other words, whether there is an isometric embedding as a convex surface in $\mathbb{R}^3$).

The great German mathematician Hermann Weyl had taken a significant 1st step to solve the problem in 1916, \& Nirenberg, as a student, completed Weyl's construction.

The work to do was to solve a system of nonlinear PDEs of the so-called ``elliptic type''.

It is the kind of equation \& application that Louis Nirenberg has been working on ever since.

Progress has been slow but continued over time \& is impressive at this moment.\footnote{Isometrically embedding low dimensional manifolds into higher dimensional Euclidean spaces is the contents of a famous paper by J. Nash in 1956.}

\subsubsection{The power \& beauty of inequalities}
Focus on 1 of the most relevant topics in Louis Nirenberg's broad legacy, at the same time closest to our mathematical interest.

(Almost) every career in PDEs begin with the study of linear elliptic equations.

These form nowadays a well-established theory which combines Functional Analysis, Calculus of Variations, \& explicit representations to produce solutions in suitable functional spaces.

For the classical equilibrium equations in the mechanics of continuous media, known as Laplace's \& Poisson's equations, in symbols $\Delta u = f$, there is a classical ``maximum principle'' that provides the necessary estimates that guarantee the existence \& uniqueness of solutions.

When combined with skillful tricks of the trade, it makes possible to obtain finer estimates, e.g. regularity \& other properties.

Let us mention the estimates known under the names Harnack \& Schauder, cf. \cite{Evans2010, Gilbarg_Trudinger2001}.

In this regard, Nirenberg is quoted as saying, either jokingly or seriously,
\begin{quotation}\it
	``I made a living off the maximum principle.''\footnote{Curiously, it applies to V\'azquez too.
		
		V\'azquez's most read article deals with the ``Strong Maximum Principle'', [74].}
\end{quotation}
Many of the interesting problems that are proposed in Physics \& other sciences \& involve PDEs are \textbf{nonlinear}, e.g. the fluid equations or the curvature problems in geometry.

These nonlinear problems can seldom be solved by explicit formulas.

Because of that difficulty, the mathematical study of these problems has attracted increasing attention from the best mathematical minds of the past century, with remarkable success stories.

The usual approach goes as follows: the solution has to be obtained by some kind of approximation, \& an essential technical point is usually to show that the proposed approximation procedure (or procedures) converge to a solution\footnote{Taken in some sense acceptable to physics, e.g., the solution in the weak sense or the solution in the distributional sense.}.

A complicated topology \& functional analysis machinery has been developed over time \& is available to test such convergence, provided certain estimates are fulfilled; their role is to allow for the approximation to be controlled.

See in this sense the book that many of us have studied as young people \cite{Brezis2011}.

%
Much of the work of an ``EDP Analyst''\footnote{\textit{Analysis of PDEs} is an area of Mathematics in the US that perfectly describes our specialty which is neither pure nor applied, \& does not need to declare itself in either direction.
	
	Such a denomination is not much used in Spain \& other countries; i.e., in V\'azquez's opinion, the source of some persistent malfunctions.} consists in finding estimates that control the passage to the limit that has to be applied, or to find a convenient fixed point theorem.

A common saying in our trade goes as follows: \textit{Existence theorems come from a priori estimates \& suitable functional analysis}.

Estimate, this is the key word in the world that Louis Nirenberg \& his colleagues bequeathed us.

``Estimate'' means the same thing as ``inequality'', \& here V\'azquez refers of course to a functional or numerical inequality.

%
It may look surprising to the reader, even weird, to find it so clearly stated: Inequalities, \& not equalities (or identities), are the technical core of such a central theory of mathematics as PDEs.

However, this is precisely the mathematical revolution that was in the making when Louis was young.

Indeed, when he arrived at NYU, the most active \& renowned researcher was probably Kurt Otto Friedrichs, who decisively influenced Nirenberg's future research career.

Friedrichs loved inequalities, as Louis put it:
\begin{quotation}\it
	``Friedrichs was a great lover of inequalities \& that affected me very much.
	
	The point of view was that the inequalities are more interesting than the equalities.''
\end{quotation}
Carrying forward on that idea, Nirenberg has been unanimously recognized as a world master of inequalities''.

Here is another saying by Louis:
\begin{quotation}\it
	``I love inequalities.
	
	So if somebody shows me a new inequality, I say: ``Oh, that's beautiful, let me think about it,'' \& I may have some ideas connected to it.''
\end{quotation}
For many years, mathematicians from all over the world came to the Courant Institute to seek his advice on issues involving inequalities.

%
And there we are.

We do not reject or despise the beauty of the exact solution if there is one, but functional inequalities are our firm support in an uncertain world that is yet to be discovered \& described.

The key technical point of modern PDE theory is to establish the most needed \& appropriate estimates in the strongest possible way.

\paragraph{Sobolev, Gagliardo \& Nirenberg.} There are many types of estimates the researcher needs in the study of nonlinear PDEs, but some have turned out to be much more relevant than others.

V\'azquez will talk here about a type that has become particularly famous \& useful.

They are often collectively called ``Sobolev estimates'' in honor of the great Russian mathematician Sergei Lvovich Sobolev because of his seminal work [68], 1938.

Briefly stated, they estimate the norms of functions belonging to the Lebesgue spaces $L^p(\Omega)$, $1\le p\le\infty$, in terms of their (weak) derivatives of various orders.

In 1959 Emilio Gagliardo [35] \& Louis Nirenberg [59] gave an independent \& very simple proof of the following inequality:

\textsf{Fig. The Talenti profile for different values of the parameters.}

\begin{theorem}[Gagliardo-Nirenberg-Sobolev Inequality]
	Let $1\le p < n$. There exists a constant $C > 0$ s.t. the following inequality
	\begin{align*}
		\|u\|_{L^{p^*}(\mathbb{R}^n)}\le C\|Du\|_{L^p(\mathbb{R}^n)},\ p^*\coloneqq\frac{np}{n - p},
	\end{align*}
	holds true for all functions $u\in C_c^1(\mathbb{R}^n)$. The constant $C$ depends only on $p$ \& $n$. The exponent $p^*$ is called the \emph{Sobolev conjugate} of $p$. $Du$ denotes the gradient vector.
\end{theorem}
Gagliardo \& Nirenberg included as their starting point the important case of exponent $p = 1$, left out by Sobolev.

The inequality implies the continuous inclusion of the Banach space called $W^{1,p}(\mathbb{R}^n)$ into $L^{p^*}(\mathbb{R}^n)$ (immersion theorem).

Versions for functions defined in bounded open sets $\mathbb{R}^n$ followed naturally.

This inequality soon attracted multiple applications \& a wide array of variants \& improvements.

Very interesting versions deal with functions defined on Riemannian manifolds.

V\'azquez comments below 4 additional aspects that he finds appropriate for the curious reader.
\begin{itemize}
	\item[(i)] Thierry Aubin [3] \& Giorgio Talenti [72] obtained in 1976 the \textit{best constant} in this inequality, finding the functions that exhibit the \textit{worst behavior}\footnote{This is an apparent grammatical contradiction that gives rise to beautiful functions.}
	
	Indeed, when $1 < p < n$ the maximum quotient $\frac{\|u\|_{L^{p^*}(\mathbb{R}^n)}}{\|Du\|_{L^p(\mathbb{R}^n)}}$ is optimally realized by the function
	\begin{align*}
		U({\bf x}) = \left(a + b|{\bf x}|^{\frac{p}{p - 1}}\right)^{-\frac{n - p}{p}},
	\end{align*}
	where $a,b > 0$ are arbitrary constants.\footnote{Consider the simple case $a = b = 1$, $p = 2$ in dimension $n = 4$.
		
		The function looks a bit like Gaussian but it is not at all.}
	
	It is the famous \textit{Talenti profile}.
	
	Note that $\frac{n - p}{p} = \frac{n}{p^*}$.
	
	It happens that $U$ is a probability density (integrable) if $\frac{n - p}{p - 1} > n$, i.e., if $1 < p < p_c = \frac{2n}{n + 1}$.
	
	The $U$ profile \& its power appear recurrently in PDEs.
	
	Thus, in nonlinear diffusion we find it as a power of the Barenblatt profile in fast diffusion, see Chap. 11 of [75], \& the curiously critical exponent $p_c$ also appears, but with consequences that go in the converse direction.
	\item Gagliardo \& Nirenberg's work extends to the famous \textit{Gagliardo-Nirenberg interpolation inequality}, a result in Sobolev's theory of spaces that estimates a certain norm of a function in terms of a product of norms of functions \& derivatives thereof.
	
	We enter here a realm of higher complexity.\footnote{V\'azquez will avoid further details on these inequalities that can be found in the cited references.}
	
	See details in [10].
	\item[(iii)] In 1984 Luis Caffarelli, Bob Kohn \& Louis Nirenberg needed inequalities of the previous type in functional Lebesgue spaces but with the novelty of including so-called \textit{weights}, \& this motivated the article [18], on the famous \textit{CKN estimates originated} for spaces with power weights.
	
	This was the beginning of an extensive literature.
	
	A very striking effect arose in those studies: unlike GNS inequalities, there exists a phenomenon of symmetry breaking in the CKN inequalities, i.e., minimizers of such inequalities need not be symmetric functions, even when posed in the whole space or in balls.
	
	The exact range of parameters for the symmetry breaking was found by J. Dolbeault, M. J. Esteban \& M. Loss in [29].
	\item[(iv)] In 2004 D. Cordero-Erausquin, B. Nazareth \& C. Villani [24] used mass transport methods to obtain sharp versions of the Sobolev-Gagliardo-Nirenberg inequalities.
	
	Mass transport is 1 of the most powerful new instruments used in PDE research.
	
	This topic is related to the isoperimetric inequalities of ancient fame.\footnote{See \href{https://en.wikipedia.org/wiki/Isoperimetric-inequality}{Wikipedia{\tt/}Isoperimetric Inequality}.} that now live moments of fruitful coincidence with Sobolev theory.
	
	The survey [15] talks about this relationship.
\end{itemize}
The world of estimates that we have outlined has came to be an enormous space presided over by quite distinguished names, like H. Poincar\'e, J. Nash, G. H. Hardy, C. Morrey, J. Moser, N. Trudinger \& other remarkable figures.

Hardy-Littlewood-P\'olya's book [41] had a great influence on generations of analysts.

A commendable book on the importance of inequalities in Physics is the 2nd volume of Elliott Lieb's selected works, [53].

%
As a representative example chosen from among the numerous recent works, V\'azquez mentions the arcile by M. del Pino \& Jean Dolbeault [25].

It establishes a new optimal version of the Euclidean Gagliardo-Nirenberg inequalities.

This allows the authors to obtain the convergence rates to the equilibrium profiles of some nonlinear diffusion equations, e.g. those of the ``porous media'' type, 1 of the leitmotifs of V\'azquez's research.

The authors completed the study \& application with 2 new articles in 2003.

New functional inequalities based on entropy, maximum principles, \& symmetrization processes allowed a group of V\'azquez to find convergence rates for very fast diffusion equations in [7], thus solving in 2009 a much studied open problem.

It was almost 3 years of work by a team of 5 people.

Plus the work of previous authors.

%
Finally, there is a great deal of activity in the world of Sobolev spaces of fractional order (also called \textit{Slobodeckii spaces}), \& the associated fractional diffusions, cf. [21, 27].

It is a topic in full swing, a part of V\'azquez's current mathematical efforts.\footnote{There is a wide representation of Spanish mathematicians active in these subjects with remarkable results that would be well worth a review.}

\paragraph{New Spaces. John-Nirenberg space.} Go back for a moment to the origins.

The limiting case of the Gagliardo-Nirenberg-Sobolev inequality happens for $p = n$.

Thanks to new inequalities due to C. Morrey, we know that for $p > n$ the resulting functions are H\"older continuous functions, \cite{Evans2010}.

But the $p = n$ case was bizarre \& it was left to Fritz John \& Louis Nirenberg to solve the puzzle in 1961 by introducing the new BMO space of functions of \textit{bounded mean oscillation}, see [44].

Actually, BMO is not a function space but rather a space of function classes modulo constants.

For this space there is the appropriate inequality.

\begin{theorem}[John-Nirenberg]
	If $u\in W^{1,n}(\mathbb{R}^n)$ then $u$ belongs to $BMO$ and
	\begin{align*}
		\|u\|_{BMO}\le C\|Du\|_{L^n(\mathbb{R}^n)},
	\end{align*}
	for a constant $C > 0$ depending only on $n$.\footnote{The curious reader will wonder which function optimizes the constant. So?}
\end{theorem}
The BMO spaces are once a very popular new object in functional \& harmonic analysis, they replace $L^\infty$ when it turns out so.

They were characterized by Charles Fefferman in [32].

The BMO spaces are slightly larger than $L^\infty$.

The possible inequality (and functional immersion) of John-Nirenberg type using $L^\infty$ instead of BMO as image space may seem reasonable but it is false.\footnote{Find an elementary counterexample.}

We ought to be very careful then with the critical cases, that Louis treated with utmost attention.

The John-Nirenberg spaces are used in analysis, in PDEs, in stochastic processes, \& in multiple applications.

The reader may use the references [49] \& [8] for some updates to recent work.

\subsubsection{Navier-Stokes Equations}
The Navier-Stokes system of equations describes the dynamics of an incompressible viscous fluid.

It was proposed in the 19th century to correct Euler's equations of ideal fluids, \& adapt them to the more realistic viscous real world, [4].

The system reads \textbf{(1)}
\begin{equation*}
	\left\{\begin{split}
		\partial_t{\bf u} + ({\bf u}\cdot\nabla){\bf u} + \frac{1}{\rho}\nabla p &= \nu\Delta{\bf u} + \frac{1}{\rho}{\bf f},\\
		\nabla\cdot{\bf u} = 0,
	\end{split}\right.
\end{equation*}
where ${\bf u}$ is the \textit{velocity vector}, $p$ is the \textit{pressure}, both variable, while $\rho$ (the \textit{density}) \& $\nu$ (the \textit{viscosity}) can be taken as positive constants.

It has had a spectacular success in practical science \& engineering, but its essential mathematical aspects (existence, uniqueness, \& regularity) have offered a stubborn resistance in the physical case of 3 space dimensions (3 or $> 3$ for the mathematician).

\textsf{Nirenberg on the blackboard (photo: Courant Institute, NYU).}

%
Fundamental works to cast the theory in a modern functional framework are due to Jean Leray [50, 51], who already in 1934 speaks of weak derivatives in spaces of integrable functions.

Using the new methods of functional analysis, authors soon obtained estimates that proved to be good enough to establish the existence \& uniqueness of Leray solutions in 2 space dimensions, $n = 2$.

Furthermore, for regular initial data the solution is classical.

But the advance stopped sharply in higher dimensions, $n\ge 3$.

V\'azquez gives the word to Charles Fefferman, of Princeton University, in his description of the open problem as the Clay Foundation Millennium Problem.

It is about proving or refuting the following Conjecture:
\begin{quotation}\it
	(A) Existence \& smoothness of Navier-Stokes solutions on $\mathbb{R}^3$.
	
	Take viscosity $\nu > 0$ \& $n = 3$.
	
	Let ${\bf u}_0({\bf x})$ be any smooth, divergence-free vector field satisfying the regularity \& decay conditions (\emph{specified}).
	
	Take external force $f(t,{\bf x})$ to be identically zero.
	
	Then there exists smooth functions $p(t,{\bf x})$, $u_i(t,{\bf x})$ on $[0,\infty)\times\mathbb{R}^3$ that satisfy the Navier-Stokes system with initial conditions in the whole space.\footnote{See full details of the presentation in \url{https://www.claymath.org/sites/default/files/navierstokes.pdf}.}
\end{quotation}
The most significant advance in this field is in V\'azquez's opinion the article [17] in which L. Caffarelli, R. Kohn \& L. Nirenberg attached the problem of regularity \& showed that if a solution with classical data develops singularities in a finite time, the set of such singularities must be in any case quite small in size.

More specifically, ``the 1D measure, in the Hausdorff sense, of the set of possible singularities (located in space-time) is zero.''

This implies that if the singular set is not empty, it cannot contain any line or filament.

In 1998 F. H. Lin [54] gave an interesting new proof of this result.

%
V\'azquez is talking about 1 of the milestones of the authors' career; it happened during the stay of a young Luis Caffarelli at the Courant Institute at Louis's invitation, \& was published in 1982.

The topic Fluids is completely different from the previous sections, but the functional estimates in Sobolev spaces play an essential role, along with the machinery of geometric measure theory.

%
The possible presence of these singularities was conjectured by Leray as a possible explanation for the phenomenon of \textit{turbulence}.

According to this hypothesis, even for regular data, solutions in 3 or more dimensions can develop singularities in finite time in the form of points where the so-called \textit{vorticity} becomes infinite.

%
In the elapsed time, it has not been possible to prove or refute Conjecture (A).

Many efforts have been invested \& V\'azquez believes that will bear fruit 1 day.

An account of the state of affairs in the Euler \& NSEs around 2008 is due to P. Constantin [23].

At the present moment V\'azquez is entertained by a number of trials \& false proofs (some of them quite well published).

There are excellent general texts on Navier-Stokes, e.g. [36] \& [73].

2 very recent texts are [66] \& [67].

\subsubsection{Elliptic Equations \& the Calculus of Variations}
For reasons of selection \& space, V\'azquez will be quite brief on a subject in which Louis made so many contributions.

V\'azquez mentions 1st of all the article [11] by Haim Brezis \& Louis Nirenberg, which figures among the most widely read among the works of both authors.

It deals with the existence of solutions of semilinear elliptic equations with critical exponent (once again!)
\begin{align*}
	\Delta u + f({\bf x},u) + u^{\frac{n + 2}{n - 2}} = 0.
\end{align*}
2 further articles that had great impact are work in collaboration with Shmuel Agmon \& Avron Douglis [1], year 1959, \& [2], year 1964.

They are near-the-boundary estimates for solutions of elliptic equations that satisfy general boundary conditions.

Behavior near the boundary of nonlinear or degenerate PDE solutions, or in domains with nonsmooth boundaries, is a really delicate issue.

Indeed, it is a topic of permanent interest in our community, in theory \& also because of its practical interest\footnote{Think about the behavior of fluids in domains with corners.}.

%
The article [6]with Henri Berestycki \& S. R. S. Varadhan links the study of the 1st eigenvalue with the maximum principle, a subject that Louis enjoyed so much.

In this context V\'azquez finds the famous article on the method of the ``moving planes'' of 1991 [5] in collaboration with Henri Berestycki, which V\'azquez consider a gem.

%
In the Calculus of Variations, V\'azquez quotes the article [11] with Haim Brezis, about the difference between local minimizers in the spaces $H^1$ \& $C^1$. See also [12].

%
A topic of great interest for Louis was the study of geometric properties e.g. symmetry.

The articles [37, 38] with Vasilis Gidas \& Wei-Ming Ni deal with the radial symmetry of certain positive solutions of nonlinear elliptic equations that is imposed by the equation \& the shape of the domain.

\subsubsection{Other contributions}
V\'azquez collects here brief comments on important results obtained by Louis \& his collaborators on various topics that would deserve a more extensive treatment.

\paragraph{Operator theory.} Nirenberg \& Joseph J. Kohn\footnote{J. J. Kohn is a brilliant Princeton analyst, not to be confused with R. Kohn from Courant.
	
	J. J. Kohn speaks perfect Spanish with an Ecuadorian accent.} introduced of a \textit{pseudo-differential operator} that helped generate a huge amount of later work in the brilliant school of harmonic analysis.

In a 1965 article, [48], they dealt with pseudo-differential operators with a complete \& algebraic view.

The operators in question act on the space of tempered distributions at $\mathbb{R}^n$, \& are estimated in terms of Fourier transform norms.

The importance of these results is that they take into account all the ``lower order terms'', difficult to deal with in previous articles.

See also the volume [61] edited by Louis.

\paragraph{Free boundary problems.} This is 1 of the favorite topics of this reviewer.

In 1977 Louis published with David Kinderlehrer the article [45] on the regularity of free boundary problems for elliptic equations, at the beginning of an era that was to witness great progress.

To put it clearly, let us assume that $u$ is a solution to the problem
\begin{align*}
	\Delta u\le f,\ u\ge 0,\ (\Delta u - f)u = 0,
\end{align*}
defined in a domain $D\subset\mathbb{R}^n$.

Boundary data are also given at the fixed boundary $\partial D$.

These data are intended to determine not only $u$ but also the positivity domain $\Omega = \{{\bf x}\in D;u({\bf x}) > 0\}$, or still better the boundary of $\Omega$ that lies within $D$, called the \textit{free boundary}:
\begin{align*}
	\Gamma(u) = \partial\Omega\cap D.
\end{align*}
This is properly called an \textit{obstacle problem}.

To get a physical idea, we can imagine a membrane in space $\mathbb{R}^3$ of height $z = U(x,y)$ that is subject to boundary conditions $U = h\ge 0$ in $\partial D$ \& must lie above a stable (obstacle) of height $U_{\rm obst}(x,y) = 0$.

\textsf{Fig. Free boundaries \& obstacles (pictures: X. Ros-Oton).}

%
Often, we want to consider a nontrivial obstacle $\varphi$, usually a concave function as in the figure.

This leads to an interesting equivalent formulation.

If we put $u = U + \varphi$, we arrive at the problem
\begin{align*}
	\Delta u\le g,\ u\ge\varphi,\ (\Delta u - g)(U - \varphi) = 0,
\end{align*}
with \textit{driving term} $g = f + \Delta\varphi$, \& then we usually take $g = 0$.

In this formulation, $u$ is constrained to stay above the obstacle $u_{\rm obst}({\bf x}) = var\phi$.

%
In any case, in the ``free part'', $\{{\bf x}\in\mathbb{R}^n;U({\bf x}) > 0\} = \{{\bf x}\in\mathbb{R}^n;u({\bf x}) > \varphi\}$, an elastic equation $\Delta U = f$ is satisfied, but a priori we do not know where that part could be located.

It is therefore a problem that combines PDEs \& Geometry (again!).

%
This problem was known to have a unique \textit{solution pair}, $(u,\Gamma)$.

The attentive reader will have observed that once $\Gamma$ is known, \& with it $\Omega$, the PDE problem to find $u$ is rather elementary.

Therefore, the difficulty lies in principle in the geometry.

However, the solution to the puzzle was rather found in nonlinear analysis, [47], which also produces efficient numerical methods.

%
We then encounter a big theoretical problem: determining how regular is the set $\Gamma$, that we have found by abstract methods, \& also determining how regular is $u$ near $\Gamma$.

Even the simplest question: ``is $\Gamma$ a surface?'' has to be answered.

D. Kinderlehrer \& L. Nirenberg gave local conditions on $f$ \& assumed a certain initial regularity of $u$ to conclude that then $\Gamma$ is a very regular, even analytical, hyper-surface.

The study of free boundaries extends to problems evolving in time, e.g. the very famous Stefan problem discussed by Louis in [46].

The 1980s were years of great progress in the mathematical understanding of free boundaries, with reference books e.g. [28, 34].

%
This is a field of very intense activity, both theoretical \& applied, in which V\'azquez has worked with great delight for decades.

A required reference for in-depth study of the regularity of the free boundaries is the book [20] by L. Caffarelli \& S. Salsa, see also A. Petrosyan et al. [64].

A study of tumor growth modeling, seen as a free boundary problem, was done by B. Perthame et al. in [63], it is just an example from a vast literature.

\paragraph{Geometric Equations.} The article [55] with Charles Loewner in 1974 deals with PDEs that are invariant under conformal or projective transformations.

The reader will recall in this context the current relevance of PDEs linked to problems of Riemannian geometry, e.g. the Yamabe problem.

V\'azquez refers to the lengthy overview [52] due to Yan Yan Li, Louis's doctoral student that has been for many years professor at Rutgers.

\paragraph{Complex geometry.} The topic interested Louis a lot in his beginnings.

A Newlander \& L. Nirenberg wrote in 1965 an article published in Annals of Mathematics [56] on analytical coordinates in quasi-complex manifolds.

The Newlander-Nirenberg Theorem states that any integrable quasi-complex structure is induced by a complex structure.

Integrability is expressed through a list of differential conditions.

%
V\'azquez puts an end here to the mathematical journey, unfortunately unfair in many aspects due to the brevity of space \& his ignorance in so many subjects.

V\'azquez hopes that the extensive cited literature will serve as an indication of the profound influence of Louis Nirenberg \& his world on the mathematicians \& mathematics that have followed him.

For the curious reader, there are excellent articles dealing with the work \& life of Louis Nirenberg: a congress in his honor on the occasion of the 75th anniversary was organized by Alice Chang et al. \& is collected in [22].

He was interviewed by Allyn Jackson for the \textit{AMS Notices} in 2002, [43], \& Simon Donaldson, Fields Medal, wrote about him in the same journal in 2011, [30].

Yan-Yan Li's [52] 2010 article focuses on the analysis of geometric problems.

On the occasion of the Abel Prize, Xavier Cabré wrote a review in Catalan in [14] \& Tristan Rivi\`ere reviews his work in PDEs in [65].

A mathematical description of the influence of his ideas appeared in 2016 in [69] with contributions of a number of experts: X. Cabr\'e (symmetries of solutions), A. Chang (Gauss curvature problem), G. Seregin (Navier-Stokes problem), E. Carlen \& A. Figalli (stability of the GNS inequality), M. T. Wang \& S. T. Yau (Weyl problem \& general relativity).

Finally, the book [42] presents the laureates of the Abel Prize in the period 2013--2017.

In it Robert V. Kohn devotes to L. Nirenberg the article \textit{``A few of Louis Nirenberg's many contributions to the theory of PDEs''}.

By the way, there is a beautiful quotation from Abel as motto for the book:
\begin{quotation}
	``Au reste il me para\^{\i}t que si l'on veut faire des progr\`es dans les math\'ematiques il faut \'etudier les maîtres et non pas les \'ecoliers.''\footnote{In English: \textit{``Finally, it appears to me that if one wants to make progress in mathematics, one should study the masters, not the students.''} Taken from the book.}
\end{quotation}
\textbf{Update.} the article \textit{``A personal tribute to Louis Nirenberg''}, posted by Prof. Joel Spruck in the Arxiv repository in May 2021, [70].

As a person who met Louis Nirenberg in 1972 \& became a Courant Instructor, his detailed report on a selection of Louis's works is a very commendable reading.

He concentrates on the work inspired by geometric problems beginning around 1974, especially the method of moving planes, \& implicit fully nonlinear elliptic equations, \& makes comments on Louis' personality.

\textsf{Fig. Nirenberg in Barcelona in 2017 (photo: Jordi Play).}

\subsubsection{The quiet wise man \& Spain}
V\'azquez's 1st memory of Louis Nirenberg sets them in Lisbon in the spring of 1982.\footnote{At the International Symposium in Homage to Prof. J. Sebati\~ao e Silva.}

Louis was already famous \& V\'azquez was a novice in the art.

In Lisbon V\'azquez listened to 1 of his talks, which brought together the depth of the mathematics, the simplicity of the exposition \& a grace to add some comment as timely as it was nice, characteristic features of Louis that delighted the public.

%
In the fall of that same year V\'azquez set foot in the US, headed for the University of Minnesota,\footnote{This American university was very popular with young Spanish graduates \& doctors for the excellence of its studies in Mathematics \& Economics.} to work on free boundary problems with Don Aronson \& with Luis Caffarelli, who was back from his visit to Courant Institute.

Then V\'azquez saw, through the group of great professor V\'azquez had access to, that mathematical research offered a much better way of life.

Among that group of friends V\'azquez counts Haim Brezis \& Luis Caffarelli who have been V\'azquez's masters, Louis Nirenberg, Constantine Dafermos, Donald Aronson, Mike Crandall, Hans Weinberger,$\ldots$ V\'azquez will never cease from thanking them for that vision.

%
A few years later, V\'azquez had the honor of participating in the organization of a summer course at the UIMP\footnote{Men\'endez Pelayo International University, the course took place in 1987 at the Palacio de la Magdalena in Santander.} which included Louis as lecturer along with Don G. Aronson (Minnesota), Philippe Bénilan (Besançon), Luis A. Caffarelli (IAS Princeton) \& Constantine Dafermos (Brown Univ.).

These courses were inspired by Luis Caffarelli, close collaborator \& friend of Louis, with the support of the Rector of the UIMP, Prof. Ernest Lluch,\footnote{Scholar of indelible memory, great protector of science \& great conversationalist, he died tragically for being a good person at a very turbulent time.} \& somehow they transmitted a certain spirit of mathematics that was being done around the Courant Institute.

The course had a remarkable consequence.

A young mathematician from Barcelona, Xavier Cabr\'e, a student in the course, went to the Courant Institute with Louis Nirenberg \& thus began an international mathematical career, like the ones that so many young people crave today.

His thesis, directed by Louis, dealt with ``Estimates for Solutions of Elliptic \& Parabolic Equations'' (NYU, 1994).

Following his stay in New York, he published with Luis Caffarelli the beautiful book [16] on the so-called \textit{completely nonlinear elliptic equations}.

Xavier Cabr\'e is now an ICREA Professor at the UPC in Barcelona.

Louis Nirenberg visited Spain several times, specially Barcelona, \& had many Spanish friends \& admirers.

%
Although V\'azquez did not become a collaborator of Louis, V\'azquez had the opportunity of seeing him \& talking to him on several occasions.

V\'azquez highlights a stay at the Courant Institute in the winter of 1996 where V\'azquez could appreciate the day-to-day life of the ``quiet wise man'', or a congress in Argentina in 2009 when Louis was already very senior but loved life as the 1st day.

The last event in which V\'azquez saw him took place at Columbia University, New York, in May of last year (2019), in a congress in honor of Luis Caffarelli.

He went to some talks in his wheelchair at 94 years old, and, with his proverbial good humor he told them that it was a bit difficult for him to follow the lectures!

%
Impressed by his personality, the young mathematician David Fern\'andez \& V\'azquez wrote a portrait of him in 2 entries in the blog \textit{``The Republic of Mathematics''} that they edit in ``Investigaci\'on y Ciencia'' (Spanish partner of ``Sciencific American'').

They called the essays ``Louis Nirenberg, the quiet wise man'' (I) \& (II).\footnote{\url{https://www.investigacionyciencia.es/blogs/matematicas/75/posts}.}

He was a teacher \& master of science as those described by George Steiner in [71], where the relationship between teacher \& pupil, master \& disciple, is what matters.

Louis had 46 doctoral students, many of them well-known mathematicians.\footnote{The 1st was Walter Littman (in 1956), whom V\'azquez treated so much in Minnesota.}

It was not his style to write long textbooks, he was the author of [60] \& the recently published [62].

%
We will miss the teacher, master \& senior friend who always looked gentle \& kind, who loved Italy (\textit{il bel paese}), culture, good food \& talking about movies \& friends, \& with whom mathematics was easy \& exciting.

Nirenberg lived in New York since 1949, in the Upper West Side, he was a perfect New Yorker \& at the same time a citizen of the wide world.

He worked until the end of his life, frequently visiting ``his'' Institute.

Lucky soul, how V\'azquez envies him, now \& here the ``elders'' seem expendable for public utility.

%
V\'azquez is proud to bear his name Louis $=$ Luis, like Luis Caffarelli or Jacques Louis Lions or Luigi Ambrosio.

He is already a great name in mathematics \& it is an honor that carries the burden of working as Louis Nirenberg, only for the best \& always in a good mood, \& that is not easy.

Rest in eternal peace, beloved Master.

In the Elysian fields you will have time to think about new functional inequalities, the beautiful functions that optimize them, \& their surprising fruits.

In our own small way, we also follow them, as in [26].\hfill$\square$

%------------------------------------------------------------------------------%

%------------------------------------------------------------------------------%

\subsection{Stanley Osher}

%------------------------------------------------------------------------------%

%------------------------------------------------------------------------------%

\subsection{Laurent Schwartz}
\textbf{Laurent Schwartz.}
\begin{itemize}
	\item \textbf{Born.} Mar 5, 1915. \href{https://en.wikipedia.org/wiki/Paris}{Paris}, France.
	\item \textbf{Died.} Jul 4, 2002 (aged 87). Paris, France.
	\item \textbf{Nationality.} French.
	\item \textbf{Alma mater.} \href{https://en.wikipedia.org/wiki/%C3%89cole_Normale_Sup%C3%A9rieure}{Ecole Normale Sup\'erieure}.
	\item \textbf{Known for.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Distribution_(mathematics)}{Theory of Distributions}
		\item \href{https://en.wikipedia.org/wiki/Schwartz_kernel_theorem}{Schwartz kernel theorem}
		\item \href{https://en.wikipedia.org/wiki/Schwartz_space}{Schwartz space}
		\item \href{https://en.wikipedia.org/wiki/Schwartz-Bruhat_function}{Schwartz-Bruhat function}
		\item \href{https://en.wikipedia.org/wiki/Radonifying_function}{Radonifying operator}
		\item \href{https://en.wikipedia.org/wiki/Cylinder_set_measure}{Cylinder set measure}
	\end{itemize}
	\item \textbf{Awards.} \href{https://en.wikipedia.org/wiki/Fields_Medal}{Fields Medal} (1950).
\end{itemize}
\textbf{Scientific career.}
\begin{itemize}
	\item \textbf{Fields.} Mathematics.
	\item \textbf{Institutions.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/University_of_Strasbourg}{University of Strashbourg}
		\item \href{https://en.wikipedia.org/wiki/University_of_Nancy}{University of Nancy}
		\item \href{https://en.wikipedia.org/wiki/University_of_Grenoble}{University of Grenoble}
		\item \href{https://en.wikipedia.org/wiki/%C3%89cole_Polytechnique}{\'Ecole Polytechnique}
		\item \href{https://en.wikipedia.org/wiki/Universit%C3%A9_de_Paris_VII}{Universit\'e de Paris VII}
	\end{itemize}
	\item \textbf{Doctoral advisor.} \href{https://en.wikipedia.org/wiki/Georges_Valiron}{Georges Valiron}.
	\item \textbf{Doctoral students.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Maurice_Audin}{Maurice Audin}
		\item \href{https://en.wikipedia.org/wiki/Georges_Glaeser}{Georges Glaeser}
		\item \href{https://en.wikipedia.org/wiki/Alexander_Grothendieck}{Alexander Grothendieck}
		\item \href{https://en.wikipedia.org/wiki/Jacques-Louis_Lions}{Jacques-Louis Lions}
		\item \href{https://en.wikipedia.org/wiki/Bernard_Malgrange}{Bernard Malgrange}
		\item \href{https://en.wikipedia.org/wiki/Andr%C3%A9_Martineau}{Andr\'e Martineau}
		\item \href{https://en.wikipedia.org/wiki/Bernard_Maurey}{Bernard Maurey}
		\item \href{https://en.wikipedia.org/wiki/Leopoldo_Nachbin}{Leopoldo Nachbin}
		\item \href{https://en.wikipedia.org/wiki/Henri_Hogbe_Nlend}{Henri Hogbe Nlend}
		\item \href{https://en.wikipedia.org/wiki/Gilles_Pisier}{Gilles Pisier}
		\item \href{https://en.wikipedia.org/wiki/Fran%C3%A7ois_Treves}{Fran\c{c}ois Treves}
	\end{itemize}
	\item \textbf{Influenced.} \href{https://en.wikipedia.org/wiki/Per_Enflo}{Per Enflo}.
\end{itemize}
\textit{Laurent-Moïse Schwartz} (Mar 5, 1915 - Jul 4, 2002) was a French mathematician.

He pioneered the \href{https://en.wikipedia.org/wiki/Theory}{theory} of \href{https://en.wikipedia.org/wiki/Distribution_(mathematics)}{distributions}, which gives a well-defined meaning to objects such as the \href{https://en.wikipedia.org/wiki/Dirac_delta_function}{Dirac delta function}.

He was awarded the \href{https://en.wikipedia.org/wiki/Fields_Medal}{Fields Medal} in 1950 for his work on the \href{https://en.wikipedia.org/wiki/Distribution_(mathematics)}{theory of distributions}.

For several years he taught at the \href{https://en.wikipedia.org/wiki/%C3%89cole_polytechnique}{École polytechnique}.

\subsubsection{Biography}

\paragraph{Family}
Laurent Schwartz came from a Jewish family of \href{https://en.wikipedia.org/wiki/Alsace}{Alsatian} origin, with a strong scientific background: his father was a well-known \href{https://en.wikipedia.org/wiki/Surgeon}{surgeon}, his uncle \href{https://en.wikipedia.org/wiki/Robert_Debr%C3%A9}{Robert Debré} (who contributed to the creation of \href{https://en.wikipedia.org/wiki/UNICEF}{UNICEF}) was a famous \href{https://en.wikipedia.org/wiki/Pediatrics}{pediatrician}, \& his great-uncle-in-law, \href{https://en.wikipedia.org/wiki/Jacques_Hadamard}{Jacques Hadamard}, was a famous mathematician.

%
During his training at \href{https://en.wikipedia.org/wiki/Lyc%C3%A9e_Louis-le-Grand}{Lycée Louis-le-Grand} to enter the \href{https://en.wikipedia.org/wiki/%C3%89cole_Normale_Sup%C3%A9rieure}{École Normale Supérieure}, he fell in love with \href{https://en.wikipedia.org/wiki/Marie-H%C3%A9l%C3%A8ne_Schwartz}{Marie-Hélène Lévy}, daughter of the probabilist \href{https://en.wikipedia.org/wiki/Paul_L%C3%A9vy_(mathematician)}{Paul Lévy} who was then teaching at the \href{https://en.wikipedia.org/wiki/%C3%89cole_polytechnique}{École polytechnique}.

Later they would have 2 children, Marc-André \& Claudine.

Marie-Hélène was gifted in mathematics as well, as she contributed to the geometry of singular analytic spaces \& taught at the \href{https://en.wikipedia.org/wiki/Universit%C3%A9_Lille_Nord_de_France}{University of Lille}.

%
Angelo Guerraggio describes ``Mathematics, politics \& butterflies'' as his ``3 great loves''.[1]

\paragraph{Education}
According to his teachers, Schwartz was an exceptional student.

He was particularly gifted in Latin, Greek \& mathematics.

1 of his teachers told his parents: ``\textit{Beware, some will say your son has a gift for languages, but he is only interested in the scientific \& mathematical aspect of languages: he should become a mathematician}.''

%
In 1934, he was admitted at the École Normale Supérieure, \& in 1937 he obtained the \href{https://en.wikipedia.org/wiki/Agr%C3%A9gation}{agrégation} (with rank 2).

\paragraph{World War II}
As a man of \href{https://en.wikipedia.org/wiki/Trotskyism}{Trotskyist} affinities \& \href{https://en.wikipedia.org/wiki/Jew}{Jewish} descent, life was difficult for Schwartz during \href{https://en.wikipedia.org/wiki/World_War_II}{World War II}.

He had to hide \& change his identity to avoid being \href{https://en.wikipedia.org/wiki/Deportation}{deported} after Nazi Germany overran France.

He worked for the \href{https://en.wikipedia.org/wiki/University_of_Strasbourg}{University of Strasbourg} (which had been relocated in \href{https://en.wikipedia.org/wiki/Clermont-Ferrand}{Clermont-Ferrand} because of the war) under the name of Laurent-Marie Sélimartin, while Marie-Hélène used the name Lengé instead of Lévy.

Unlike other mathematicians at Clermont-Ferrand such as \href{https://en.wikipedia.org/wiki/Jacques_Feldbau}{Feldbau}, the couple managed to escape the Nazis.

\paragraph{Later career}
Schwartz taught mainly at \href{https://en.wikipedia.org/wiki/%C3%89cole_Polytechnique}{École Polytechnique}, from 1958 to 1980.

At the end of the war, he spent one year in \href{https://en.wikipedia.org/wiki/Grenoble}{Grenoble} (1944), then in 1945 joined the University of \href{https://en.wikipedia.org/wiki/Nancy,_France}{Nancy} on the advice of \href{https://en.wikipedia.org/wiki/Jean_Delsarte}{Jean Delsarte} \& \href{https://en.wikipedia.org/wiki/Jean_Dieudonn%C3%A9}{Jean Dieudonné}, where he spent 7 years.

He was both an influential researcher \& teacher, with students such as \href{https://en.wikipedia.org/wiki/Bernard_Malgrange}{Bernard Malgrange}, \href{https://en.wikipedia.org/wiki/Jacques-Louis_Lions}{Jacques-Louis Lions}, \href{https://en.wikipedia.org/wiki/Fran%C3%A7ois_Bruhat}{François Bruhat} \& \href{https://en.wikipedia.org/wiki/Alexander_Grothendieck}{Alexander Grothendieck}.

He joined the science faculty of the \href{https://en.wikipedia.org/wiki/University_of_Paris}{University of Paris} in 1952.

In 1958 he became a teacher at the \href{https://en.wikipedia.org/wiki/%C3%89cole_polytechnique}{École polytechnique} after having at 1st refused this position.

From 1961 to 1963 the École polytechnique suspended his right to teach, because of his having signed the \href{https://en.wikipedia.org/wiki/Manifesto_of_the_121}{Manifesto of the 121} about the \href{https://en.wikipedia.org/wiki/Algerian_war}{Algerian war}, a gesture not appreciated by Polytechnique's military administration.

However, Schwartz had a lasting influence on mathematics at the École polytechnique, having reorganized both teaching \& research there.

In 1965 he established the \href{https://en.wikipedia.org/wiki/Centre_de_math%C3%A9matiques_Laurent-Schwartz}{Centre de mathématiques Laurent-Schwartz} (CMLS) as its 1st director.

%
In 1973 he was elected corresponding member of the \href{https://en.wikipedia.org/wiki/French_Academy_of_Sciences}{French Academy of Sciences}, \& was promoted to full membership in 1975.

\subsubsection{Mathematical legacy}
In 1950 at the \href{https://en.wikipedia.org/wiki/International_Congress_of_Mathematicians}{International Congress of Mathematicians}, Schwartz was a plenary speaker[Schwartz, Laurent (1950). ``\textit{Théorie des noyaux}'' (PDF). In: Proceedings of the International Congress of Mathematicians, Cambridge, Massachusetts, U.S.A., Aug 30--Sep 6, 1950. vol. 1. pp. 220--230.] \& was awarded the \href{https://en.wikipedia.org/wiki/Fields_Medal}{Fields Medal} for his work on \href{https://en.wikipedia.org/wiki/Distribution_(mathematics)}{distributions}.

He was the 1st French mathematician to receive the Fields medal.

Because of his sympathy for \href{https://en.wikipedia.org/wiki/Trotskyism}{Trotskyism}, Schwartz encountered serious problems trying to enter the United States to receive the medal; however, he was ultimately successful.

%
The theory of distributions clarified the (then) mysteries of the \href{https://en.wikipedia.org/wiki/Dirac_delta_function}{Dirac delta function} \& \href{https://en.wikipedia.org/wiki/Heaviside_step_function}{Heaviside step function}.

It helps to extend the theory of \href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier transforms} \& is now of critical importance to the theory of \href{https://en.wikipedia.org/wiki/Partial_differential_equation}{partial differential equations}.

\subsubsection{Popular science}
Throughout his life, Schwartz actively worked to promote science \& bring it closer to the general audience.

Schwartz said:
\begin{quotation}\it
	``What are mathematics helpful for? Mathematics are helpful for physics.
	
	Physics helps us make fridges.
	
	Fridges are made to contain spiny lobsters, \& spiny lobsters help mathematicians who eat them \& have hence better abilities to do mathematics, which are helpful for physics, which helps us make fridges which$\ldots$''[3]
\end{quotation}

\subsubsection{Entomology}
\textsf{\href{https://en.wikipedia.org/wiki/Clanis_schwartzi}{Clanis schwartzi} Paratype \href{https://en.wikipedia.org/wiki/MHNT}{MHNT}.}

His mother, who was passionate about natural science, passed on her taste for \href{https://en.wikipedia.org/wiki/Entomology}{entomology} to Laurent.

His personal collection of 20,000 \href{https://en.wikipedia.org/wiki/Lepidoptera}{Lepidoptera} specimens, collected during his various travels was bequeathed to the \href{https://en.wikipedia.org/wiki/National_Museum_of_Natural_History_(France)}{Muséum national d'histoire naturelle}), the \href{https://en.wikipedia.org/wiki/Mus%C3%A9e_des_Confluences}{Science Museum of Lyon}, the \href{https://en.wikipedia.org/wiki/Mus%C3%A9um_de_Toulouse}{Museum of Toulouse} \& the Museo de Historia Natural Alcide d'Orbigny in \href{https://en.wikipedia.org/wiki/Cochabamba}{Cochabamba} (Bolivia).

Several species discovered by Schwartz bear his name.

\subsubsection{Personal ideology}
Apart from his scientific work, Schwartz was a well-known outspoken \href{https://en.wikipedia.org/wiki/Intellectual}{intellectual}.

As a young socialist influenced by \href{https://en.wikipedia.org/wiki/Leon_Trotsky}{Leon Trotsky}, Schwartz opposed the \href{https://en.wikipedia.org/wiki/Totalitarianism}{}{totalitarianism} of the \href{https://en.wikipedia.org/wiki/Soviet_Union}{Soviet Union}, particularly under \href{https://en.wikipedia.org/wiki/Joseph_Stalin}{Joseph Stalin}.

Schwartz ultimately rejected \href{https://en.wikipedia.org/wiki/Trotskyism}{Trotskyism} for \href{https://en.wikipedia.org/wiki/Democratic_socialism}{democratic socialism}.

%
On his religious views, Schwartz called himself an atheist.[4]

\subsubsection{Books}

\paragraph{Research articles}
\begin{itemize}
	\item \textit{Œuvres scientifiques. I}.
	
	With a general introduction to the works of Schwartz by Claude Viterbo \& an appreciation of Schwartz by Bernard Malgrange.
	
	With 1 DVD.
	
	Documents Mathématiques (Paris), 9. Société Mathématique de France, Paris, 2011. x+523 pp. ISBN 978-2-85629-317-1
	\begin{quotation}
		the 1st half of his works in analysis \& partial differential equations.
		
		After a preface by Claude Viterbo, which includes a few photos, one will find a note by Schwartz himself about his works, followed by a few original documents (letters, course notes), a presentation by Bernard Malgrange of the theory of distributions for which Schwartz received the Fields Medal in 1950, \& a selection of articles covering the period 1944--1954.
	\end{quotation}
	\item \textit{Œuvres scientifiques. II}.
	
	With an appreciation of Schwartz by Alain Guichardet.
	
	With 1 DVD.
	
	Documents Mathématiques (Paris), 10.
	
	Société Mathématique de France, Paris, 2011. x+507 pp. ISBN 978-2-85629-318-8
	\begin{quotation}
		the 2nd half of his works in analysis \& partial differential equations.
		
		After a note by Alain Guichardet on Schwartz \& his seminars, one will find a selection of articles covering the period 1954--1966.
	\end{quotation}
	\item \textit{Œuvres scientifiques. III}.
	
	With appreciations of Schwartz by Gilles Godefroy \& Michel Émery.
	
	With 1 DVD.
	
	Documents Mathématiques (Paris), 11. Société Mathématique de France, Paris, 2011. x+619 pp. ISBN 978-2-85629-319-5
	\begin{quotation}
		his works on Banach space theory (1968--1987), introduced by Gilles Godefroy, \& on probability theory (1970--1996), presented by Michel Émery, as well as some articles of a historical nature (1955--1994).
	\end{quotation}
\end{itemize}

\paragraph{Technical books}
\begin{itemize}
	\item \textit{Analyse hilbertienne}. Collection Méthodes. Hermann, Paris, 1979. ii+297 pp. ISBN 2-7056-5897-1
	\item \textit{Application of distributions to the theory of elementary particles in quantum mechanics}. Gordon \& Breach, New York, NY, 1968. 144pp. ISBN 9780677300900
	\item \textit{Cours d'analyse. 1}. 2nd edition. Hermann, Paris, 1981. xxix+830 pp. ISBN 2-7056-5764-9
	\item \textit{Cours d'analyse. 2}. 2nd edition. Hermann, Paris, 1981. xxiii+475+21+75 pp. ISBN 2-7056-5765-7
	\item [5] \textit{Étude des sommes d'exponentielles. 2ième éd}. Publications de l'Institut de Mathématique de l'Université de Strasbourg, V. Actualités Sci. Ind., Hermann, Paris 1959 151 pp.
	\item \textit{Geometry \& probability in Banach spaces}. Based on notes taken by Paul R. Chernoff. Lecture Notes in Mathematics, 852. Springer-Verlag, Berlin-New York, 1981. x+101 pp. ISBN 3-540-10691-X
	\item \textit{Lectures on complex analytic manifolds}. With notes by M. S. Narasimhan. Reprint of the 1955 edition. Tata Institute of Fundamental Research Lectures on Mathematics \& Physics, 4. Published for the Tata Institute of Fundamental Research, Bombay; by Springer-Verlag, Berlin, 1986. iv+182 pp. ISBN 3-540-12877-8
	\item \textit{Mathematics for the physical sciences}. Hermann, Paris; Addison-Wesley Publishing Co., Reading, Mass.-London-Don Mills, Ont. 1966 358 pp.
	\item \textit{Radon measures on arbitrary topological spaces \& cylindrical measures}. Tata Institute of Fundamental Research Studies in Mathematics, No. 6. Published for the Tata Institute of Fundamental Research, Bombay by Oxford University Press, London, 1973. xii+393 pp.
	\item \textit{Semimartingales \& their stochastic calculus on manifolds}. Edited \& with a preface by Ian Iscoe. Collection de la Chaire Aisenstadt. Presses de l'Université de Montréal, Montreal, QC, 1984. 187 pp. ISBN 2-7606-0660-0
	\item \textit{Semi-martingales sur des variétés, et martingales conformes sur des variétés analytiques complexes}. Lecture Notes in Mathematics, 780. Springer, Berlin, 1980. xv+132 pp. ISBN 3-540-09749-X
	\item Les tenseurs. \textit{Suivi de ``Torseurs sur un espace affine'' by Y. Bamberger \& J.-P. Bourguignon}. 2nd edition. Hermann, Paris, 1981. i+203 pp. ISBN 2-7056-1376-5
	\item [6] \textit{Théorie des distributions}. Publications de l'Institut de Mathématique de l'Université de Strasbourg, No. IX-X. Nouvelle édition, entiérement corrigée, refondue et augmentée. Hermann, Paris 1966 xiii+420 pp.
\end{itemize}

\paragraph{Seminar notes}
\begin{itemize}
	\item \textit{Séminaire Schwartz in Paris 1953 bis 1961}. Online edition: [1]
\end{itemize}

\paragraph{Popular books}
\begin{itemize}
	\item \textit{Pour sauver l'université.} Editions du Seuil, 1983. 122 pp. ISBN 2020065878
	\item \textit{A mathematician grappling with his century}. Translated from the 1997 French original by Leila Schneps. Birkhäuser Verlag, Basel, 2001. viii+490 pp. ISBN 3-7643-6052-6
\end{itemize}

\subsubsection{See also}
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Schwartz_distribution}{Schwartz distribution}
	\item \href{https://en.wikipedia.org/wiki/Schwartz_kernel_theorem}{Schwartz kernel theorem}
	\item \href{https://en.wikipedia.org/wiki/Schwartz_space}{Schwartz space}
	\item \href{https://en.wikipedia.org/wiki/Schwartz-Bruhat_function}{Schwartz-Bruhat function}
	\item \href{https://en.wikipedia.org/wiki/Nicolas_Bourbaki}{Nicolas Bourbaki}'' -- \href{https://en.wikipedia.org/wiki/Laurent_Schwartz}{Wikipedia{\tt/}Laurent Schwartz}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Roger Temam}
\textbf{Roger Meyer Temam.}
\begin{itemize}
	\item \textbf{Born.} May 19, 1940 (age 80).
	\item \textbf{Nationality.} French.
	\item \textbf{Alma mater.} \href{https://en.wikipedia.org/wiki/University_of_Paris}{University of Paris}.
	\item \textbf{Known for.} \href{https://en.wikipedia.org/wiki/Navier-Stokes_equations}{Navier-Stokes equations}.
\end{itemize}
\textbf{Scientific career.}
\begin{itemize}
	\item \textbf{Fields.} \href{https://en.wikipedia.org/wiki/Applied_mathematics}{Applied mathematics.}
	\item \textbf{Institutions.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Paris-Sud_University}{Paris-Sud University} (\href{https://en.wikipedia.org/wiki/Orsay}{Orsay})
		\item \href{https://en.wikipedia.org/wiki/Indiana_University_Bloomington}{Indiana University}
	\end{itemize}
	\item \textbf{Doctoral advisor.} \href{https://en.wikipedia.org/wiki/Jacques-Louis_Lions}{Jacques-Louis Lions}.
	\item \textbf{Doctoral students.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Etienne_Pardoux}{Etienne Pardoux}
		\item \href{https://en.wikipedia.org/wiki/Denis_Serre}{Denis Serre}
	\end{itemize}
\end{itemize}
\textit{Roger Meyer Temam} (born May 19, 1940) is a French applied mathematician working in \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerical analysis}, \href{https://en.wikipedia.org/wiki/Nonlinear_partial_differential_equations}{nonlinear partial differential equations} \& \href{https://en.wikipedia.org/wiki/Fluid_mechanics}{fluid mechanics}.

He graduated from the \href{https://en.wikipedia.org/wiki/University_of_Paris}{University of Paris} - the \href{https://en.wikipedia.org/wiki/Sorbonne}{Sorbonne} in 1967, completing a doctorate (\textit{thèse d'Etat}) under the direction of \href{https://en.wikipedia.org/wiki/Jacques-Louis_Lions}{Jacques-Louis Lions}.

He has published over 400 articles, as well as 12 (authored or co-authored) books.

\subsubsection{Scientific work}
The 1st work of Temam in his thesis dealt with the \textit{fractional steps method}.

Thereafter, ``he has continually explored \& developed new directions \& techniques'':[2]
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Calculus_of_variations}{calculus of variations}, \& the notion of \textit{duality} (book \#7), developing the mathematical framework for \textit{discontinuous} (in displacement) \textit{solutions}; a concept later used for his works on the \textit{mathematical theory of plasticity} (book \#5);
	\item mathematical formulation of the equilibrium of a plasma in a cavity, expressed as a nonlinear \href{https://en.wikipedia.org/wiki/Free_boundary_problem}{free boundary problem};[R. Temam, A nonlinear eigenvalue problem: the shape at equilibrium of a confined plasma, \textit{Arch. Rational Mech. Anal.}, 60, 1975, 51--73.]
	\item \href{https://en.wikipedia.org/wiki/Korteweg-de_Vries_equation}{Korteweg-de Vries equation};[R. Temam, Sur un problème non linéaire, \textit{J. Math. Pures Appl.}, 48, 1969, 159--172.]
	\item \href{https://en.wikipedia.org/wiki/Kuramoto%E2%80%93Sivashinsky_equation}{Kuramoto-Sivashinsky equation};[5]
	\item \href{https://en.wikipedia.org/wiki/Euler_equations}{Euler equations} in a bounded domain;[R. Temam, On the Euler equations of incompressible perfect fluids, \textit{J. Funct. Anal.}, 20, 1975, 32--43.]
	\item infinite-dimensional \href{https://en.wikipedia.org/wiki/Dynamical_systems}{dynamical systems} theory.
	
	In particular, he studied the existence of the finite-dimensional global \href{https://en.wikipedia.org/wiki/Attractor}{attractor} for many dissipative equations of mathematical physics, including the incompressible \href{https://en.wikipedia.org/wiki/Navier-Stokes_equations}{Navier-Stokes equations}.[P. Constantin, C. Foias, O. Manley \& R. Temam, Determining modes \& fractal dimension of turbulent flows, \textit{J. Fluid Mech.}, 150, 1985, 427--440.][C. Foias, O.P. Manley \& R. Temam, Physical estimates of the number of degrees of freedom in free convection, \textit{Phys. Fluids}, 29, 1986, 3101--3103.]
	
	He was also the co-founder of the notion of \textit{inertial manifolds}[C. Foias, G.R. Sell \& R. Temam, Inertial manifolds for nonlinear evolutionary equations, \textit{J. Diff. Equ.}, 73, 1988, 309--353.] together with Ciprian Foias \& \href{https://en.wikipedia.org/wiki/George_R._Sell}{George R. Sell} \& of exponential attractors[A. Eden, C. Foias, B. Nicolaenko \& R. Temam, \textit{Exponential attractors for dissipative evolution equations}, Collection Recherches en Mathématiques Appliquées, Masson, Paris, \& John Wiley, England, 1994.] together with Alp Eden, Ciprian Foias \& Basil Nicolaenko;[2]
	\item \href{https://en.wikipedia.org/wiki/Optimal_control}{optimal control} of the incompressible Navier-Stokes equations as a tool for the \textit{control of turbulence};[F. Abergel \& R. Temam, On some control problems in fluid mechanics, \textit{Theoret. Comput. Fluid Dynamics}, 1, 1990, 303--325.]
	\item \href{https://en.wikipedia.org/wiki/Boundary_layer}{boundary layer} phenomena for incompressible flows.[12]
\end{itemize}
Temam's main activities concern the study of \href{https://en.wikipedia.org/wiki/Geophysical_fluid_dynamics}{geophysical flows}, the atmosphere \& oceans.[2]

This started in the 1990s by collaboration with Jacques-Louis Lions \& Shouhong Wang.[J.L. Lions, R. Temam \& S. Wang, New formulations of the primitive equations of the atmosphere \& applications, \textit{Nonlinearity}, 5, 1992, 237--288.][J.L. Lions, R. Temam \& S. Wang, On the equations of the large-scale ocean, \textit{Nonlinearity}, 5, 1992, 1007--1053.][M. Coti Zelati, M. Frémond, R. Temam \& J. Tribbia, Uniqueness, regularity \& maximum principles for the equations of the atmosphere with humidity \& saturation, \textit{Physica D}, 264, 2013, 49-65, https://doi.org/10.1016/j.physd.2013.08.007][Y. Cao, M. Hamouda, R. Temam, J. Tribbia \& X. Wang, The equations of the multi-phase humid atmosphere expressed as a quasi variational inequality, \textit{Nonlinearity}, 31, 2018, 4692-4723, https://doi.org/10.1088/1361-6544/aad525.]

%
According to the \href{https://en.wikipedia.org/wiki/Mathematical_Genealogy_Project}{Mathematical Genealogy Project} database,[17][18] he holds the first position in the top 50 advisors.

More than 30 of his students are now full professors all over the world, \& have themselves many descendants.[19]

\subsubsection{Administrative activities}
Temam became a professor at the \href{https://en.wikipedia.org/wiki/Paris-Sud_University}{Paris-Sud University} at Orsay in 1968.

There, he co-founded the Laboratory of Numerical \& Functional Analysis which he directed from 1972 to 1988.

He was also a \textit{Maître de Conférences} at the \href{https://en.wikipedia.org/wiki/Ecole_Polytechnique}{Ecole Polytechnique} in Paris from 1968 to 1986.[20]

%
In 1983, Temam co-founded the French \href{https://en.wikipedia.org/wiki/Soci%C3%A9t%C3%A9_de_Math%C3%A9matiques_Appliqu%C3%A9es_et_Industrielles}{Société de Mathématiques Appliquées et Industrielles} (SMAI), analogous to the \href{https://en.wikipedia.org/wiki/Society_for_Industrial_and_Applied_Mathematics}{Society for Industrial \& Applied Mathematics} (SIAM), \& served as its 1st president.[21]

He was also 1 of the founders of the \href{https://en.wikipedia.org/wiki/International_Congress_on_Industrial_and_Applied_Mathematics}{International Congress on Industrial \& Applied Mathematics} (ICIAM) series \& was the chair of the steering committee of the 1st ICIAM meeting held in Paris in 1987; \& the chair of the standing committee of the 2nd ICIAM meeting held in Washington, D.C., in 1991.[22]

He was the Editor-in-Chief of the mathematical journal M2AN[23] from 1986 to 1997.

%
Temam has been the Director of the Institute for Scientific Computing \& Applied Mathematics (ISCAM)[24] at \href{https://en.wikipedia.org/wiki/Indiana_University_Bloomington}{Indiana University} since 1986 (co-director with Ciprian Foias from 1986 to 1992).

He is also a College Professor (part-time till 2003) \& he has been a Distinguished Professor since 2014.[25]

\subsubsection{Books}
\begin{enumerate}
	\item (with G.-M. Gie, M. Hamouda \& C.-Y. Jung): \textit{Singular perturbations \& boundary layers}, Springer-Verlag, New-York, 2018.
	\item (with A. Miranville): \textit{Mathematical Modelling in Continuum Mechanics}, Cambridge University Press, 2001. French Translation, Springer-Verlag France, 2002. Chinese Translation, Tsinghua University Press, 2004. 2nd English Edition 2005. Russian translation, Moskva Linom, 2013.
	\item (with T. Dubois \& F. Jauberteau): \textit{Dynamic, multilevel methods \& the numerical simulation of turbulence}; Cambridge University Press, 1999.
	\item \textit{Infinite Dimensional Dynamical Systems in Mechanics \& Physics}, Springer-Verlag, New-York, Applied Mathematical Sciences Series, vol. 68, 1988. 2nd augmented edition, 1997. Reprinted in China by Beijing World Publishing Corp., 2000.
	\item \textit{Mathematical Problems in Plasticity}, Gauthier-Villars, Paris, 1983 (in French). English Transl., Gauthier-Villars, New-York, 1985. Russian Transl., Nauk, Moscow, 1991. ``Republished by Dover books in Physics, 2018.''
	\item \textit{Navier-Stokes Equations}, North-Holland Pub. Company, in English, 1977, 500 pages. Revised editions 1979, 1984 \& 1985. Russian Translation, Mir, Moscow, 1981. ``Republished in the AMS-Chelsea Series, AMS, Providence, 2001.''
	\item (with I. Ekeland): \textit{Convex Analysis \& Variational Problems}. Dunod, Paris, 1974, 350 pages (in French). English Translation, North-Holland, Amsterdam, 1976. Russian Translation, Mir, Moscow, 1979. ``English version republished in the Series 'Classics in Applied Mathematics', SIAM, Philadelphia, 1999.''
\end{enumerate}

\subsubsection{Awards \& honors}
\begin{itemize}
	\item Fellow of the \href{https://en.wikipedia.org/wiki/American_Academy_of_Arts_and_Sciences}{American Academy of Arts \& Sciences} (2015),[26] of the \href{https://en.wikipedia.org/wiki/American_Mathematical_Society}{American Mathematical Society} (2013),[27] of the American Association for the Advancement of Science (2011),[28] of the Society for Industrial \& Applied Mathematics (2009).[29]
	\item Knight of the \href{https://en.wikipedia.org/wiki/Legion_of_Honour}{Legion of Honor}, France, 2012.[30]
	\item Member of the \href{https://en.wikipedia.org/wiki/French_Academy_of_Sciences}{French Academy of Sciences} since 2007.[31]'' -- \href{https://en.wikipedia.org/wiki/Roger_Temam}{Wikipedia{\tt/}Roger Temam}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Karl Weierstrass}
\textbf{Karl Weierstrass/Karl Weierstraß.}
\begin{itemize}
	\item \textbf{Born.} Oct 31, 1815. \href{https://en.wikipedia.org/wiki/Ennigerloh}{Ostenfelde}, \href{https://en.wikipedia.org/wiki/Province_of_Westphalia}{Province of Westphalia}, \href{https://en.wikipedia.org/wiki/Kingdom_of_Prussia}{Kingdom of Prussia}.
	\item \textbf{Died.} Feb 19, 1897 (aged 81). Berlin, \href{https://en.wikipedia.org/wiki/Province_of_Brandenburg}{Province of Brandenburg}, \href{https://en.wikipedia.org/wiki/Kingdom_of_Prussia}{Kingdom of Prussia}.
	\item \textbf{Nationality.} German.
	\item \textbf{Alma mater.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/University_of_Bonn}{University of Bonn}
		\item \href{https://en.wikipedia.org/wiki/University_of_M%C3%BCnster}{Münster Academy}
	\end{itemize}
	\item \textbf{Known for.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Weierstrass_function}{Weierstrass function}
		\item \href{https://en.wikipedia.org/wiki/Weierstrass_product_inequality}{Weierstrass product inequality}
		\item \href{https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit}{$(\varepsilon,\delta)$-definition of limit}
		\item \href{https://en.wikipedia.org/wiki/Weierstrass%E2%80%93Erdmann_condition}{Weierstrass-Erdmann condition}
		\item \href{https://en.wikipedia.org/wiki/Weierstrass_theorem_(disambiguation)}{Weierstrass theorems}
		\item \href{https://en.wikipedia.org/wiki/Bolzano-Weierstrass_theorem}{Bolzano-Weierstrass theorem}
	\end{itemize}
	\item \textbf{Awards.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/PhD_(Hon)}{PhD (Hon)}: \href{https://en.wikipedia.org/wiki/University_of_K%C3%B6nigsberg}{University of Königsberg} (1854)
		\item \href{https://en.wikipedia.org/wiki/Copley_Medal}{Copley Medal} (1895)
	\end{itemize}
\end{itemize}
\textbf{Scientific career.}
\begin{itemize}
	\item \textbf{Fields.} Mathematics.
	\item \textbf{Institutions.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Technical_University_of_Berlin}{Gewerbeinstitut}
		\item \href{https://en.wikipedia.org/wiki/Humboldt_University_of_Berlin}{Friedrich Wilhelm University}
	\end{itemize}
	\item \textbf{Academic advisors.} \href{https://en.wikipedia.org/wiki/Christoph_Gudermann}{Christoph Gudermann}.
	\item \textbf{Doctoral students.}
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Nikolai_Bugaev}{Nikolai Bugaev}
		\item \href{https://en.wikipedia.org/wiki/Georg_Cantor}{Georg Cantor}
		\item \href{https://en.wikipedia.org/wiki/Georg_Frobenius}{Georg Frobenius}
		\item \href{https://en.wikipedia.org/wiki/Lazarus_Fuchs}{Lazarus Fuchs}
		\item \href{https://en.wikipedia.org/wiki/Wilhelm_Killing}{Wilhelm Killing}
		\item \href{https://en.wikipedia.org/wiki/Leo_K%C3%B6nigsberger}{Leo Königsberger}
		\item \href{https://en.wikipedia.org/wiki/Sofia_Kovalevskaya}{Sofia Kovalevskaya}
		\item \href{https://en.wikipedia.org/wiki/Mathias_Lerch}{Mathias Lerch}
		\item \href{https://en.wikipedia.org/wiki/Hans_von_Mangoldt}{Hans von Mangoldt}
		\item \href{https://en.wikipedia.org/wiki/Eugen_Netto}{Eugen Netto}
		\item \href{https://en.wikipedia.org/wiki/Adolf_Piltz}{Adolf Piltz}
		\item \href{https://en.wikipedia.org/wiki/Carl_Runge}{Carl Runge}
		\item \href{https://en.wikipedia.org/wiki/Arthur_Schoenflies}{Arthur Schoenflies}
		\item \href{https://en.wikipedia.org/wiki/Friedrich_Schottky}{Friedrich Schottky}
		\item \href{https://en.wikipedia.org/wiki/Hermann_Schwarz}{Hermann Schwarz}
		\item \href{https://en.wikipedia.org/wiki/Ludwig_Stickelberger}{Ludwig Stickelberger}
		\item \href{https://en.wikipedia.org/wiki/Ernst_K%C3%B6tter}{Ernst Kötter}
	\end{itemize}
\end{itemize}
\textit{Karl Theodor Wilhelm Weierstrass} (German: \textit{Weierstraß};[Duden. \textit{Das Aussprachewörterbuch}. 7. Auflage. Bibliographisches Institut, Berlin 2015, ISBN 978-3-411-04067-4] Oct 31, 1815 - Feb 19, 1897) was a German mathematician often cited as the \fbox{``\textit{father of modern \href{https://en.wikipedia.org/wiki/Mathematical_analysis}{analysis}}''}.

Despite leaving university without a degree, he studied mathematics \& trained as a school teacher, eventually teaching mathematics, physics, \href{https://en.wikipedia.org/wiki/Botany}{botany} \& gymnastics.[Weierstrass, Karl Theodor Wilhelm. (2018). In Helicon (Ed.), \textit{The Hutchinson unabridged encyclopedia with atlas \& weather guide}. [Online]. Abington: Helicon. Available from: \href{http://libezproxy.open.ac.uk/login?url=https://search.credoreference.com/content/entry/heliconhe/weierstrass_karl_theodor_wilhelm/0?institutionId=292}{link} [Accessed Jul 8, 2018].]

He later received an honorary doctorate \& became professor of mathematics in Berlin.

%
Among many other contributions, Weierstrass formalized the definition of the \href{https://en.wikipedia.org/wiki/Continuous_function}{continuity of a function}, proved the \href{https://en.wikipedia.org/wiki/Intermediate_value_theorem}{intermediate value theorem} \& the \href{https://en.wikipedia.org/wiki/Bolzano-Weierstrass_theorem}{Bolzano-Weierstrass theorem}, \& used the latter to study the properties of continuous functions on closed bounded intervals.

\subsubsection{Biography}
Weierstrass was born in Ostenfelde, part of \href{https://en.wikipedia.org/wiki/Ennigerloh}{Ennigerloh}, \href{https://en.wikipedia.org/wiki/Province_of_Westphalia}{Province of Westphalia}.[O'Connor, J. J.; Robertson, E. F. (October 1998). ``\textit{Karl Theodor Wilhelm Weierstrass}''. School of Mathematics \& Statistics, University of St Andrews, Scotland. Retrieved Sep 7, 2014.]

%
Weierstrass was the son of Wilhelm Weierstrass, a government official, \& Theodora Vonderforst.

His interest in mathematics began while he was a \href{https://en.wikipedia.org/wiki/Gymnasium_(Germany)}{gymnasium} student at the \href{https://en.wikipedia.org/wiki/Gymnasium_Theodorianum}{Theodorianum} in \href{https://en.wikipedia.org/wiki/Paderborn}{Paderborn}.

He was sent to the \href{https://en.wikipedia.org/wiki/University_of_Bonn}{University of Bonn} upon graduation to prepare for a government position.

Because his studies were to be in the fields of law, economics, \& finance, he was immediately in conflict with his hopes to study mathematics.

He resolved the conflict by paying little heed to his planned course of study but continuing private study in mathematics.

The outcome was that he left the university without a degree.

He then studied mathematics at the \href{https://en.wikipedia.org/wiki/University_of_M%C3%BCnster}{Münster Academy} (which was even then famous for mathematics) \& his father was able to obtain a place for him in a teacher training school in \href{https://en.wikipedia.org/wiki/M%C3%BCnster}{Münster}.

Later he was certified as a teacher in that city.

During this period of study, Weierstrass attended the lectures of \href{https://en.wikipedia.org/wiki/Christoph_Gudermann}{Christoph Gudermann} \& became interested in \href{https://en.wikipedia.org/wiki/Elliptic_function}{elliptic functions}.

%
In 1843 he taught in \href{https://en.wikipedia.org/wiki/Wa%C5%82cz}{Deutsch Krone} in \href{https://en.wikipedia.org/wiki/West_Prussia}{West Prussia} \& since 1848 he taught at the \href{https://en.wikipedia.org/wiki/Collegium_Hosianum}{Lyceum Hosianum} in \href{https://en.wikipedia.org/wiki/Braunsberg}{Braunsberg}.

Besides mathematics he also taught physics, botany, \& gymnastics.[3]

%
Weierstrass may have had an illegitimate child named Franz with the widow of his friend \href{https://en.wikipedia.org/wiki/Carl_Wilhelm_Borchardt}{Carl Wilhelm Borchardt}.[Biermann, Kurt-R.; Schubring, Gert (1996). ``Einige Nachträge zur Biographie von Karl Weierstraß. (German) [Some postscripts to the biography of Karl Weierstrass]''. \textit{History of mathematics}. San Diego, CA: Academic Press. pp. 65--91.]

%
After 1850 Weierstrass suffered from a long period of illness, but was able to publish mathematical articles that brought him fame \& distinction.

The \href{https://en.wikipedia.org/wiki/University_of_K%C3%B6nigsberg}{University of Königsberg} conferred an \href{https://en.wikipedia.org/wiki/Honorary_doctor%27s_degree}{honorary doctor's degree} on him on Mar 31, 1854.

In 1856 he took a chair at the \textit{Gewerbeinstitut} in Berlin (an institute to educate technical workers which would later merge with the \textit{Bauakademie} to form the \href{https://en.wikipedia.org/wiki/Technical_University_of_Berlin}{Technical University of Berlin}).

In 1864 he became professor at the Friedrich-Wilhelms-Universität Berlin, which later became the \href{https://en.wikipedia.org/wiki/Humboldt_University_of_Berlin}{Humboldt Universität zu Berlin}.

%
In 1870, at the age of 55, Weierstrass met \href{https://en.wikipedia.org/wiki/Sofia_Kovalevskaya}{Sofia Kovalevsky} whom he tutored privately after failing to secure her admission to the University.
They had a fruitful intellectual, but troubled personal, relationship that ``far transcended the usual teacher-student relationship''.

The misinterpretation of this relationship \& Kovalevsky's early death in 1891 was said to have contributed to Weierstrass' later ill-health.

He was immobile for the last 3 years of his life, \& died in Berlin from \href{https://en.wikipedia.org/wiki/Pneumonia}{pneumonia}.[\textit{Dictionary of scientific biography}. Gillispie, Charles Coulston,, American Council of Learned Societies. New York. p. 223. ISBN 978-0-684-12926-6. OCLC 89822.]

\subsubsection{Mathematical contributions}

\paragraph{Soundness of calculus}
Weierstrass was interested in the \href{https://en.wikipedia.org/wiki/Soundness}{soundness} of calculus, \& at the time there were somewhat ambiguous definitions of the foundations of calculus so that important theorems could not be proven with sufficient rigor.

Although \href{https://en.wikipedia.org/wiki/Bernard_Bolzano}{Bolzano} had developed a reasonably rigorous definition of a \href{https://en.wikipedia.org/wiki/Limit_of_a_function}{limit} as early as 1817 (and possibly even earlier) his work remained unknown to most of the mathematical community until years later, \& many mathematicians had only vague definitions of \href{https://en.wikipedia.org/wiki/Limit_of_a_function}{limits} \& \href{https://en.wikipedia.org/wiki/Continuous_function}{continuity} of functions.

%
The basic idea behind \href{https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit}{Delta-epsilon} proofs is, arguably, 1st found in the works of \href{https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy}{Cauchy} in the 1820s.
\begin{itemize}
	\item Grabiner, Judith V. (March 1983), ``Who Gave You the Epsilon? Cauchy \& the Origins of Rigorous Calculus'' (PDF), \textit{The American Mathematical Monthly}, 90 (3): 185--194, doi:10.2307/2975545, JSTOR 2975545
	\item Cauchy, A.-L. (1823), ``Septième Leçon – Valeurs de quelques expressions qui se présentent sous les formes indéterminées $\frac{\infty}{\infty},\infty^0,\ldots$ Relation qui existe entre le rapport aux différences finies et la fonction dérivée'', \textit{Résumé des leçons données à l'école royale polytechnique sur le calcul infinitésimal}, Paris, archived from the original on 2009-05-04, retrieved 2009-05-01, p. 44.
\end{itemize}
Cauchy did not clearly distinguish between continuity \& uniform continuity on an interval.

Notably, in his 1821 \textit{Cours d'analyse}, Cauchy argued that the (pointwise) limit of (pointwise) continuous functions was itself (pointwise) continuous, a statement interpreted as being incorrect by many scholars.

The correct statement is rather that the \href{https://en.wikipedia.org/wiki/Uniform_limit}{uniform limit} of continuous functions is continuous (also, the uniform limit of uniformly continuous functions is uniformly continuous).

This required the concept of \href{https://en.wikipedia.org/wiki/Uniform_convergence}{uniform convergence}, which was 1st observed by Weierstrass's advisor, \href{https://en.wikipedia.org/wiki/Christoph_Gudermann}{Christoph Gudermann}, in an 1838 paper, where Gudermann noted the phenomenon but did not define it or elaborate on it.

Weierstrass saw the importance of the concept, \& both formalized it \& applied it widely throughout the foundations of calculus.

%
The formal definition of continuity of a function, as formulated by Weierstrass, is as follows:
\begin{quotation}
	$f(x)$ is continuous at $x = x_0$ if $\forall\varepsilon > 0$, $\exists\delta > 0$ s.t. for every $x$ in the domain of $f$, $|x - x_0| < \delta\Rightarrow|f(x) - f(x_0)| < \varepsilon$.
	
	In simple English, $f(x)$ is continuous at a point $x = x_0$ if for each $x$ close enough to $x_0$, the function value $f(x)$ is very close to $f(x_0)$, where the ``close enough'' restriction typically depends on the desired closeness of $f(x_0)$ to $f(x)$.
\end{quotation}
Using this definition, he proved the \href{https://en.wikipedia.org/wiki/Intermediate_value_theorem}{Intermediate Value Theorem}.

He also proved the \href{https://en.wikipedia.org/wiki/Bolzano-Weierstrass_theorem}{Bolzano-Weierstrass theorem} \& used it to study the properties of continuous functions on closed \& bounded intervals.

\paragraph{Calculus of variations}
Weierstrass also made advances in the field of \href{https://en.wikipedia.org/wiki/Calculus_of_variations}{calculus of variations}.

Using the apparatus of analysis that he helped to develop, Weierstrass was able to give a complete reformulation of the theory that paved the way for the modern study of the calculus of variations.

Among several axioms, Weierstrass established a necessary condition for the existence of \href{https://en.wikipedia.org/wiki/Strong_extrema}{strong extrema} of variational problems.

He also helped devise the \href{https://en.wikipedia.org/wiki/Weierstrass-Erdmann_condition}{Weierstrass-Erdmann condition}, which gives sufficient conditions for an extremal to have a corner along a given extremum \& allows one to find a minimizing curve for a given integral.

\paragraph{Other analytical theorems}
See also: \href{https://en.wikipedia.org/wiki/List_of_things_named_after_Karl_Weierstrass}{List of things named after Karl Weierstrass}.
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Stone-Weierstrass_theorem}{Stone-Weierstrass theorem}
	\item Casorati-Weierstrass-Sokhotski theorem
	\item \href{https://en.wikipedia.org/wiki/Weierstrass's_elliptic_functions}{Weierstrass's elliptic functions}
	\item \href{https://en.wikipedia.org/wiki/Weierstrass\_function}{Weierstrass function}
	\item \href{https://en.wikipedia.org/wiki/Weierstrass_M-test}{Weierstrass M-test}
	\item \href{https://en.wikipedia.org/wiki/Weierstrass_preparation_theorem}{Weierstrass preparation theorem}
	\item \href{https://en.wikipedia.org/wiki/Lindemann-Weierstrass_theorem}{Lindemann-Weierstrass theorem}
	\item \href{https://en.wikipedia.org/wiki/Weierstrass_factorization_theorem}{Weierstrass factorization theorem}
	\item \href{https://en.wikipedia.org/wiki/Enneper-Weierstrass_parameterization}{Enneper-Weierstrass parameterization}
\end{itemize}

\subsubsection{Students}
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Edmund_Husserl}{Edmund Husserl}
	\item \href{https://en.wikipedia.org/wiki/Sofia_Kovalevskaya}{Sofia Kovalevskaya}
	\item \href{https://en.wikipedia.org/wiki/G%C3%B6sta_Mittag-Leffler}{Gösta Mittag-Leffler}
	\item \href{https://en.wikipedia.org/wiki/Hermann_Schwarz}{Hermann Schwarz}
	\item \href{https://en.wikipedia.org/wiki/Carl_Johannes_Thomae}{Carl Johannes Thomae}
	\item \href{https://en.wikipedia.org/wiki/Georg_Cantor}{Georg Cantor}
\end{itemize}

\subsubsection{Honors \& awards}
The lunar \href{https://en.wikipedia.org/wiki/Impact_crater}{crater} \href{https://en.wikipedia.org/wiki/Weierstrass_(crater)}{Weierstrass} \& the \href{https://en.wikipedia.org/wiki/Asteroid}{asteroid} \href{https://en.wikipedia.org/wiki/14100_Weierstrass}{14100 Weierstrass} are named after him.

Also, there is the \href{https://en.wikipedia.org/wiki/Weierstrass_Institute_for_Applied_Analysis_and_Stochastics}{Weierstrass Institute for Applied Analysis \& Stochastics} in Berlin.

\subsubsection{Selected works}
\begin{itemize}
	\item \textit{Zur Theorie der Abelschen Funktionen} (1854)
	\item \textit{Theorie der Abelschen Funktionen} (1856)
	\item \href{http://name.umdl.umich.edu/AAN8481.0001.001}{\textit{Abhandlungen-1}}, Math. Werke. Bd. 1. Berlin, 1894
	\item \href{http://name.umdl.umich.edu/AAN8481.0002.001}{\textit{Abhandlungen-2}}, Math. Werke. Bd. 2. Berlin, 1895
	\item \href{http://name.umdl.umich.edu/AAN8481.0003.001}{\textit{Abhandlungen-3}}, Math. Werke. Bd. 3. Berlin, 1903
	\item \href{http://name.umdl.umich.edu/AAN8481.0004.001}{\textit{Vorl. ueber die Theorie der Abelschen Transcendenten}}, Math. Werke. Bd. 4. Berlin, 1902
	\item \href{http://name.umdl.umich.edu/AAN8481.0007.001}{\textit{Vorl. ueber Variationsrechnung}}, Math. Werke. Bd. 7. Leipzig, 1927
\end{itemize}

\subsubsection{External links}
\begin{itemize}
	\item O'Connor, John J.; Robertson, Edmund F., ``Karl Weierstrass'', \textit{MacTutor History of Mathematics archive}, University of St Andrews.
	\item \href{http://bibliothek.bbaw.de/bibliothek-digital/digitalequellen/schriften/autoren/weierstr/}{Digitalized versions of Weierstrass's original publications} are freely available online from the library of the \textit{Berlin Brandenburgische Akademie der Wissenschaften}.
	\item \href{https://www.gutenberg.org/author/Weierstrass,+Karl}{Works by Karl Weierstrass} at Project Gutenberg
	\item Works by or about Karl Weierstrass at Internet Archive'' -- \href{https://en.wikipedia.org/wiki/Karl_Weierstrass}{Wikipedia{\tt/}Karl Weierstrass}
\end{itemize}

%------------------------------------------------------------------------------%

\section{Miscellaneous}

%------------------------------------------------------------------------------%

\appendix

\section{Wikipedia}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Lieb_Loss2001}. {\sc Elliott Lieb, Michael Loss}. {\it Analysis}.
	\item \cite{Rudin1976}. {\sc Walter Rudin}. {\it Principles Principles of Mathematical Analysis}.
	\item \cite{Rudin1973,Rudin1987}. {\sc Walter Rudin}. {\it Real \& Complex Analysis}.
	\item \cite{Tao_analysis_1}. {\sc Terence Tao}. {\it Analysis I}.
	\item \cite{Tao_analysis_2}. {\sc Terence Tao}. {\it Analysis II}.
\end{enumerate}
``Analysis is the art of taking limits, \& the constraint of having to deal with an integration theory that does not allow taking limits is much like having to do mathematics only with rational numbers \& excluding the irrational ones.'' -- \cite[Chap. 1, p. 1]{Lieb_Loss2001}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}A Mathematician's Apology}
``{\it A Mathematician's Apology} \cite{Hardy1940,Hardy1992,Hardy2022} is a 1940 essay by British mathematician \href{https://en.wikipedia.org/wiki/G._H._Hardy}{\sc G. H. Hardy} which defends the pursuit of mathematics for its own sake. Central to {\sc Hardy}'s ``\href{https://en.wikipedia.org/wiki/Apologetics}{apology}'' -- in the sense of a formal justification or defence (as in {\sc Plato}'s \href{https://en.wikipedia.org/wiki/Apology_(Plato)}{\it Apology of Socrates}) -- is an argument that mathematics has value independent of its applications. {\sc Hardy} located this value in what he called the \href{https://en.wikipedia.org/wiki/Mathematical_beauty}{beauty of mathematics} \& gave some examples of \& criteria for mathematical beauty. The book also includes a brief autobiography which gives insight into the mind of a working mathematician.

\subsubsection{Background}
{\sc Hardy} wished to justify his life's work in mathematics for 2 reasons. 1stly, having survived a heart attack \& being at the age of 62, {\sc Hardy} knew that he was approaching old age \& that his mathematical creativity \& skills were declining. By devoting time to writing the Apology, {\sc Hardy} was admitting that his own time as a creative mathematician was finished. In his foreword to the 1967 edition of the book, \href{https://en.wikipedia.org/wiki/C._P._Snow}{\sc C. P. Snow} describes the Apology as ``a passionate lament for creative powers that used to be \& that will never come again''. In {\sc Hardy}'s words, ``Exposition, criticism, appreciation, is work for 2nd-rate mind. [$\ldots$] It is a melancholy experience for a professional mathematician to find himself writing about mathematics. The function of a mathematician is to do something, to prove new theorems, to add to mathematics, \& not to talk about what he or other mathematicians have done.''

2ndly, at the start of \href{https://en.wikipedia.org/wiki/World_War_II}{World War II}, {\sc Hardy}, a committed \href{https://en.wikipedia.org/wiki/Pacifist}{pacifist}, wanted to justify his belief that mathematics should be pursued for its own sake rather than for the sake of its applications. He began writing on this subject when he was invited to contribute an article to {\it Eureka}, the journal of \href{https://en.wikipedia.org/wiki/The_Archimedeans}{The Archimedeans} (the Cambridge University student mathematical society). 1 of the topics the editor suggested was ``something about mathematics \& the war'', \& the result was the article ``Mathematics in war-time''. {\sc Hardy} later incorporated his article into {\it A Mathematician's Apology}.

{\sc Hardy} wanted to write a book in which he would explain his mathematical philosophy to the next generation of mathematicians. He hoped that in this book he could inspire future generations about the importance of mathematics without appealing to its applied uses.

{\sc Hardy} initially submitted {\it A Mathematician's Apology} to \href{https://en.wikipedia.org/wiki/Cambridge_University_Press}{Cambridge University Press} with the intention of personally paying for its printing, but the Press decided to fund publication with an initial run of 4000 copies. For the 1940 1st edition, {\sc Hardy} sent postcards to the publisher requesting that presentation copies be sent to his sister {\sc Gertrude Emily Hardy} (1878--1963), \href{https://en.wikipedia.org/wiki/C._D._Broad}{\sc C. D. Broad}, \href{https://en.wikipedia.org/wiki/John_Edensor_Littlewood}{\sc John Edensor Littlewood}, Sir \href{https://en.wikipedia.org/wiki/Arthur_Eddington}{\sc Arthur Eddington}, \href{https://en.wikipedia.org/wiki/C._P._Snow}{C. P. Snow}, the cricketer \href{https://en.wikipedia.org/wiki/John_Lomas_(cricketer)}{\sc John Lomas} (to whom {\sc G. H. Hardy} dedicated the book), \& others.

\subsubsection{Summary}
1 of the main themes of the book is the beauty that mathematics possesses, which {\sc Hardy} compares to painting \& poetry. For {\sc Hardy}, the most beautiful mathematics was that which had no practical applications (pure mathematics) \&, in particular \href{https://en.wikipedia.org/wiki/Number_theory}{number theory}, {\sc Hardy}'s own field. {\sc Hardy} contends that if useful knowledge is defined as knowledge which is likely to contribute to material comfort without respect to mere intellectual satisfaction, then most of higher mathematics is useless. He justifies the pursuit of pure mathematics with the argument that its very ``uselessness'' means that it cannot be misused to cause harm. On the other hand, {\sc Hardy} denigrates much of the applied mathematics as either being ``trivial'', ``ugly'', or ``dull'' \& contrasts it with ``real mathematics'', which is how he describes pure mathematics.

{\sc Hardy} comments about a phrase attributed to \href{https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss}{\sc Carl Friedrich Gauss}: ``Mathematics is the queen of the sciences \& number theory is the queen of mathematics.'' One may believe that it is the relative sparseness of number theory in applied mathematics that led {\sc Gauss} to the above statement; however, {\sc Hardy} points out that this is certainly not the case. If an application of number theory were to be found, then certainly no one would try to dethrone the ``queen of mathematics'' by it. What {\sc Gauss} meant, according to {\sc Hardy}, is that the underlying concepts that constitute number theory are deeper \& more elegant compared to those of any other branch of mathematics.

Another theme is that mathematics is a ``young man's game''. {\sc Hardy} believed that anyone with a talent for mathematics should develop \& use that talent while they are young, before their ability to create original mathematics starts to decline in middle age. This view reflects {\sc Hardy}'s increasing depression at the waning of his own mathematical skill. For {\sc Hardy}, real mathematics was essentially a creative activity, rather than an explanatory or expository one.

\subsubsection{Critiques}
{\sc Hardy}'s opinions were heavily influenced by the \href{https://en.wikipedia.org/wiki/Academia}{academia} culture of the universities \href{https://en.wikipedia.org/wiki/Cambridge}{Cambridge} \& \href{https://en.wikipedia.org/wiki/Oxford}{Oxford} between \href{https://en.wikipedia.org/wiki/World_War_I}{World War I} \& \href{https://en.wikipedia.org/wiki/World_War_II}{World War II}.

Some of {\sc Hardy}'s examples seem unfortunate in retrospect. E.g., he writes, ``No one has yet discovered many warlike purpose to be served by the theory of numbers or relativity, \& it seems unlikely that anyone will do so for many years.'' Since then number theory was used to crack German \href{https://en.wikipedia.org/wiki/Enigma_machine}{Enigma codes}, \& much later figured prominently in \href{https://en.wikipedia.org/wiki/Public-key_cryptography}{public-key cryptography}; furthermore, the inter-convertability of mass \& energy predicted by \href{https://en.wikipedia.org/wiki/Special_relativity}{special relativity} forms the physical basis for nuclear weapons.

Applicability itself is not the reason that {\sc Hardy} considered applied mathematics inferior to pure mathematics; it is the simplicity \& vulgarity that belong to applied mathematics that led him to describe it as he did. He considered that \href{https://en.wikipedia.org/wiki/Rolle%27s_theorem}{Rolle's theorem}, e.g., cannot be compared to the elegance \& preeminence of the mathematics produced by \href{https://en.wikipedia.org/wiki/%C3%89variste_Galois}{\sc\'Evasriste Galois} \& other pure mathematicians, although it is of some importance for \href{https://en.wikipedia.org/wiki/Calculus}{calculus}.'' -- \href{https://en.wikipedia.org/wiki/A_Mathematician%27s_Apology}{Wikipedia{\tt/}A Mathematician's Apology}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}algebraic function}
``In mathematics, an {\it algebraic function} is a function that can be defined as the \href{https://en.wikipedia.org/wiki/Zero_of_a_function}{root} of an \href{https://en.wikipedia.org/wiki/Irreducible_polynomial}{irreducible} \href{https://en.wikipedia.org/wiki/Polynomial_equation}{polynomial equation}. Algebraic functions are often \href{https://en.wikipedia.org/wiki/Algebraic_expression}{algebraic expressions} using a finite number of terms, involving only the \href{https://en.wikipedia.org/wiki/Algebraic_operations}{algebraic operations} addition, subtraction, multiplication, division, \& raising to a fractional power. Examples of such functions: $f(x) = \frac{1}{x},f(x) = \sqrt{x},f(x) = \dfrac{\sqrt{1 + x^3}}{x^{\frac{3}{7}} - \sqrt{7}x^{\frac{1}{3}}}$. Some algebraic functions, however, cannot be expressed by such finite expressions (\href{https://en.wikipedia.org/wiki/Abel%E2%80%93Ruffini_theorem}{Abel--Ruffini theorem}). This is the case, e.g., for the \href{https://en.wikipedia.org/wiki/Bring_radical}{Bring radical}, which is the function \href{https://en.wikipedia.org/wiki/Implicit_function}{implicitly} defined by $f(x)^5 + f(x) + x = 0$. In more precise terms, an algebraic function of degree $n$ in 1 variable $x$ is a function $y = f(x)$, that is continuous in its domain \& satisfies a \href{https://en.wikipedia.org/wiki/Polynomial_equation}{polynomial equation} of positive degree: $a_n(x)y^n + a_{n-1}(x)y^{n-1} + \cdots + a_0(x) = 0$ where the coefficients $a_i(x)$ are \href{https://en.wikipedia.org/wiki/Polynomial_function}{polynomial functions} of $x$, with integer coefficients. It can be shown that the same class of functions is obtained if \href{https://en.wikipedia.org/wiki/Algebraic_numbers}{algebraic numbers} are accepted for the coefficients of the $a_i(x)$'s. If \href{https://en.wikipedia.org/wiki/Transcendental_number}{transcendental numbers} occur in the coefficients the function is, in general, not algebraic, but it is {\it algebraic over the \href{https://en.wikipedia.org/wiki/Field_(mathematics)}{field} generated by these coefficients}.

The value of an algebraic function at a \href{https://en.wikipedia.org/wiki/Rational_number}{rational number}, \& more generally, at an \href{https://en.wikipedia.org/wiki/Algebraic_number}{algebraic number} is always an algebraic number. Sometimes, coefficients $a_i(x)$ that are polynomial over a \href{https://en.wikipedia.org/wiki/Ring_(mathematics)}{ring} $R$ are considered, \& one then talks about ``functions algebraic over $R$''.

A function which is not algebraic is called a \href{https://en.wikipedia.org/wiki/Transcendental_function}{transcendental function}, as it is e.g. the case of $\exp x,\tan x,\ln x,\Gamma(x)$. A composition of transcendental functions can give an algebraic function: $f(x) = \cos\arcsin x = \sqrt{1 - x^2}$.

As a polynomial equation of degree $n$ has up to $n$ roots (\& exactly $n$ roots over an \href{https://en.wikipedia.org/wiki/Algebraically_closed_field}{algebraically closed field}, e.g., $\mathbb{C}$), a polynomial equation does not implicitly define a single function, but up to $n$ functions, sometimes also called \href{https://en.wikipedia.org/wiki/Branch_cut}{branches}. Consider e.g. the equation of the \href{https://en.wikipedia.org/wiki/Unit_circle}{unit circle} $x^2 + y^2 = 1$. This determines $y$, except only \href{https://en.wikipedia.org/wiki/Up_to}{up to} an overall sign; accordingly, it has 2 branches: $y = \pm\sqrt{1 - x^2}$.

An {\it algebraic function in $m$ variables} is similarly defined as a function $y = f(x_1,\ldots,x_m)$ which solves a polynomial equation in $m + 1$ variables: $p(y,x_1,\ldots,x_m) = 0$. It is normally assumed that $p$ should be an \href{https://en.wikipedia.org/wiki/Irreducible_polynomial}{irreducible polynomial}. The existence of an algebraic function is then guaranteed by the \href{https://en.wikipedia.org/wiki/Implicit_function_theorem}{implicit function theorem}. Formally, an algebraic function in $m$ variables over the field $K$ is an element of the \href{https://en.wikipedia.org/wiki/Algebraic_closure}{algebraic closure} of the field of \href{https://en.wikipedia.org/wiki/Rational_function}{rational functions} $K(x_1,\ldots,x_m)$.

\subsubsection{Algebraic functions in 1 variable}

\begin{itemize}
	\item {\sf Introduction \& overview.} The informal definition of an algebraic function provides a number of clues about their properties. To gain an intuitive understanding, it may be helpful to regard algebraic functions as functions which can be formed by the usual \href{https://en.wikipedia.org/wiki/Algebraic_operations}{algebraic operations}: addition, multiplication, division, \& taking an \href{https://en.wikipedia.org/wiki/Nth_root}{$n$th root}. This is something of an oversimplification; because of the \href{https://en.wikipedia.org/wiki/Fundamental_theorem_of_Galois_theory}{fundamental theorem of Galois theory}, algebraic functions need not be expressible by radicals.
	
	1st, note that any \href{https://en.wikipedia.org/wiki/Polynomial_function}{polynomial function} $y = p(x)$ is an algebraic function, since it simply the solution $y$ to the equation $y - p(x) = 0$. More generally, any \href{https://en.wikipedia.org/wiki/Rational_function}{rational function} $y = \frac{p(x)}{q(x)}$ is algebraic, being the solution to $q(x)y - p(x) = 0$. Moreover, the $n$th root of any polynomial $y = \sqrt[n]{p(x)}$ is an algebraic function, solving the equation $y^n - p(x) = 0$. Surprisingly, the \href{https://en.wikipedia.org/wiki/Inverse_function}{inverse function} of an algebraic function is an algebraic function. For supposing that $y$ is a solution to $a_n(x)y^n + \cdots + a_0(x) = 0$ for each value of $x$, then $x$ is also a solution of this equation for each value of $y$. Indeed, interchanging the roles of $x,y$ \& gathering terms, $b_m(y)x^m + b_{m-1}(y)x^{m-1} + \cdots + b_0(y) = 0$. Writing $x$ as a function of $y$ gives the inverse function, also an algebraic function.
	
	However, not every function has an inverse. E.g., $y = x^2$ fails the \href{https://en.wikipedia.org/wiki/Horizontal_line_test}{horizontal line test}: it fails to be 1-1. The inverse is the algebraic ``function'' $x = \pm\sqrt{y}$. Another way to understand this, is that the set of branches of the polynomial equation defining our algebraic function is the graph of an \href{https://en.wikipedia.org/wiki/Algebraic_curve}{algebraic curve}.
	\item {\sf Role of complex numbers.} From an algebraic perspective, complex numbers enter quite naturally into the study of algebraic functions. 1st of all, by the \href{https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra}{fundamental theorem of algebra}, the complex numbers are an \href{https://en.wikipedia.org/wiki/Algebraically_closed_field}{algebraically closed field}. Hence any polynomial relation $p(y,x) = 0$ is guaranteed to have at least 1 solution (\& in general a number of solutions not exceeding the degree of $p$ in $y$) for $y$ at each point $x$, provided we allow $y$ to assume complex as well as real values. Thus, problems to do with the domain of an algebraic function can safely be minimized.
	
	{\sf A graph of 3 branches of the algebraic function $y$, where $y^3 - xy + 1 = 0$, over the domain $1.5^{\frac{2}{3}} < x < 50$.} Furthermore, even if one is ultimately interested in real algebraic functions, there may be no means to express the function in terms of addition, multiplication, division, \& taking $n$th roots without restoring to complex numbers (see \href{https://en.wikipedia.org/wiki/Casus_irreducibilis}{casus irreducibilis}). E.g., consider the algebraic function determined by the equation $y^3 - xy + 1 = 0$. Using the \href{https://en.wikipedia.org/wiki/Cubic_formula}{cubic formula}, get
	\begin{equation}
		y = -\frac{2x}{\sqrt[3]{-108 + 12\sqrt{81 - 12x^3}}} + \frac{\sqrt[3]{-108 + 12\sqrt{81 - 12x^3}}}{6}.
	\end{equation}
	For $x\le\frac{3}{\sqrt[3]{4}}$, the square root is real \& the cubic root is thus well defined, providing the unique real root. On the other hand, for $x > \frac{3}{\sqrt[3]{4}}$, the square root is not real, \& one has to choose, for the square root, either non-real square root. Thus the cubic root has to be chosen among 3 non-real numbers. If the same choices are done in the 2 terms of the formula, the 3 choices for the cubic root provide the 3 branches shown, in the accompanying image.
	
	It may be proven that there is no way to express this function in terms of $n$th roots using real numbers only, even though the resulting function is real-valued on the domain of the graph shown.
	
	On a more significant theoretical level, using complex numbers allows one to use the powerful techniques of \href{https://en.wikipedia.org/wiki/Complex_analysis}{complex analysis} to discuss algebraic functions. In particular, the \href{https://en.wikipedia.org/wiki/Argument_principle}{argument principle} can be used to show that any algebraic function is in fact an \href{https://en.wikipedia.org/wiki/Analytic_function}{analytic function}, at least in the multiple-valued sense.
	
	Formally, let $p(x,y)$ be a complex polynomial in the complex variables $x,y$. Suppose that $x_0\in\mathbb{C}$ is s.t. the polynomial $p(x_0,y)$ of $y$ has $n$ distinct zeroes. Show: the algebraic function is analytic in a neighborhood of $x_0$. Choose a system of $n$ non-overlapping discs $\Delta_i$ containing each of these zeros. Then by the argument principle $\dfrac{1}{2\pi i}\oint_{\partial\Delta_i} \dfrac{p_y(x_0,y)}{p(x_0,y)}\,{\rm d}y = 1$. By continuity, this also holds for all $x$ in a neighborhood of $x_0$. In particular, $p(x,y)$ has only 1 root in $\Delta_i$, given by the \href{https://en.wikipedia.org/wiki/Residue_theorem}{residue theorem}: $f_i(x) = \dfrac{1}{2\pi i}\oint_{\partial\Delta_i} y\dfrac{p_y(x,y)}{p(x,y)}\,{\rm d}y$ which is an analytic function.
	\item {\sf Monodromy.} Note that the foregoing proof is analyticity derived an expression for a system of $n$ different {\it function elements} $f_i(x)$, provided that $x$ is not a {\it critical point} of $p(x,y)$. A {\it critical point} is a point where the number of distinct zeros is smaller than the degree of $p$, \& this occurs only where the highest degree term of $p$ or the \href{https://en.wikipedia.org/wiki/Discriminant}{discriminant} vanish. Hence there are only finitely many such points $c_1,\ldots,c_m$.
	
	A close analysis of the properties of the function elements $f_i$ near the critical points can be used to show that the \href{https://en.wikipedia.org/wiki/Monodromy_theorem}{monodromy cover} is \href{https://en.wikipedia.org/wiki/Ramification_(mathematics)}{ramified} over the critical points (\& possibly the \href{https://en.wikipedia.org/wiki/Riemann_sphere}{point at infinity}). Thus the \href{https://en.wikipedia.org/wiki/Holomorphic_function}{holomorphic} extension of the $f_i$ has at worst algebraic poles \& ordinary algebraic branchings over the critical points.
	
	Away from the critical points, we have $p(x,y) = a_n(x)(y - f_1(x))(y - f_2(x))\cdots(y - f_n(x))$ since the $f_i$ are by definition the distinct zeros of $p$. The \href{https://en.wikipedia.org/wiki/Monodromy_group}{monodromy group} acts by permuting the factors, \& thus forms the {\it monodromy representation} of the \href{https://en.wikipedia.org/wiki/Galois_group}{Galois group} of $p$. (The \href{https://en.wikipedia.org/wiki/Monodromy_action}{monodromy action} on the \href{https://en.wikipedia.org/wiki/Universal_covering_space}{universal covering space} is related but different notion in the theory of \href{https://en.wikipedia.org/wiki/Riemann_surface}{Riemann surfaces}.)
\end{itemize}

\subsubsection{History}
The ideas surrounding algebraic functions go back at least as far as \href{https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes}{\sc Ren\'e Descartes}. The 1st discussion of algebraic functions appears to have been in \href{https://en.wikipedia.org/wiki/Edward_Waring}{Edward Waring}'s 1794 {\it An Essay on the Principles of Human Knowledge} in which he writes:
\begin{quote}
	let a quantity denoting the ordinate, be an algebraic function of the abscissa $x$, by the common methods of division \& extraction of roots, reduce it into an infinite series ascending or descending according to the dimensions of $x$, \& then find the integral of each of the resulting terms.
\end{quote}
'' -- \href{https://en.wikipedia.org/wiki/Algebraic_function}{Wikipedia{\tt/}algebraic function}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Burgers' equation}
``{\sf Solutions of the Burgers equation starting from a Gaussian initial condition $u(0,x) = e^{-\frac{x^2}{2}}$. \href{https://en.wikipedia.org/wiki/N-wave}{N-wave} type solutions of Burgers equation, starting from the initial condition $u(0,x) = e^{-\frac{(x - 1)^2}{2}} - e^{-\frac{(x + 1)^2}{2}}$.} {\it Burgers' equation} or {\it Bateman--Burgers equation} is a fundamental PDE \& \href{https://en.wikipedia.org/wiki/Convection%E2%80%93diffusion_equation}{convection--diffusion equation} occurring in various areas of applied mathematics, e.g., \href{https://en.wikipedia.org/wiki/Fluid_mechanics}{fluid mechanics}, \href{https://en.wikipedia.org/wiki/Nonlinear_acoustics}{nonlinear acoustics}, \href{https://en.wikipedia.org/wiki/Gas_dynamics}{gas dynamics}, \& \href{https://en.wikipedia.org/wiki/Traffic_flow}{traffic flow}. The equation was 1st introduced by \href{https://en.wikipedia.org/wiki/Harry_Bateman}{\sc Harry Bateman} in 1915 \& later studied by \href{https://en.wikipedia.org/wiki/Johannes_Martinus_Burgers}{\sc Johannes Martinus Burgers} in 1948. For a given field $u(t,x)$ \& \href{https://en.wikipedia.org/wiki/Diffusion_coefficient}{diffusion coefficient} (or {\it kinematic viscosity}, as in the original fluid mechanical context) $\nu$, the general form of Burgers' equation (also known as {\it viscous Burgers' equation}) in 1 space dimension is the \href{https://en.wikipedia.org/wiki/Dissipative_system}{dissipative system}: $\partial_tu + u\partial_xu = \nu\partial_x^2u$. The term $u\partial_xu$ can also rewritten as $\partial_x\left(\frac{u^2}{2}\right)$. When the diffusion term is absent, i.e., $\nu = 0$, Burgers' equation becomes the {\it inviscid Burgers' equation} $\partial_tu + u\partial_xu = 0$, which is a prototype for \href{https://en.wikipedia.org/wiki/Conservation_law}{conservation equations} that can develop discontinuities (\href{https://en.wikipedia.org/wiki/Shock_wave}{shock waves}).

The reason for the formation of sharp gradients for small values of $\nu$ becomes intuitively clear when one examines the LHS of the equation. The term $\partial_t + u\partial_x$ is evidently a wave operator describing a wave propagating in the positive $x$-direction with a speed $u$. Since the wave speed is $u$, regions exhibiting large values of $u$ will be propagated rightwards quicker than regions exhibiting smaller values of $u$; i.e., if $u$ is decreasing in the $x$-direction, initially, then larger $u$'s that lie in the backside will catch up with smaller $u$'s on the front side. The role of the right-side diffusive term is essentially to stop the gradient becoming infinite.

\subsubsection{Inviscid Burgers' equation}
The inviscid Burgers' equation is a conservation equation, more generally a 1st order quasilinear \href{https://en.wikipedia.org/wiki/Hyperbolic_equation}{hyperbolic equation}. The solution to the equation \& along with the initial condition
\begin{equation}
	\label{inviscid Burgers}
	\partial_tu + u\partial_xu = 0,\ u(0,x) = f(x)
\end{equation}
can be constructed by the \href{https://en.wikipedia.org/wiki/Method_of_characteristics}{method of characteristics}. Let $t$ be the parameter characterizing any given characteristics in the $x$-$t$ plane, then the characteristic equations are given by $\frac{dx}{dt} = u$, $\frac{du}{dt} = 0$. Integration of 2nd equation tells us that $u$ is constant along the characteristic \& integration of 1st equation shows that the characteristics are straight lines, i.e., $u = c$, $x = ut + \xi$ where $\xi$ is the point (or parameter) on the $x$-axis ($t = 0$) of the $x$-$t$ plane from which the characteristic curve is drawn. Since $u$ at $x$-axis is known from the initial condition \& the fact that $u$ is unchanged as we move along the characteristic emanating from each point $x = \xi$, we write $u = c = f(\xi)$ on each characteristic. Therefore, the family of trajectories of characteristic parameterized by $\xi$ is $x = f(\xi)t + \xi$. Thus, the solution is given by $u(t,x) = f(\xi) = f(x - ut)$, $\xi = x - f(\xi)t$. This is an implicit relation that determines the solution of the inviscid Burgers' equation provided characteristic don't intersect. If the characteristics do intersect, then a classical solution to the PDE does not exist \& leads to the formation of a \href{https://en.wikipedia.org/wiki/Shock_wave}{shock wave}. Whether characteristics can intersect or not depends on the initial condition. In fact, the {\it breaking time} before a shock wave can be formed is given by $t_b = \frac{-1}{\inf_x f'(x)}$.

{\bf Complete integral of inviscid Burgers' equation.} The implicit solution described above containing an arbitrary function $f$ is called the {\it general integral}. However, the inviscid Burgers' equation, being a \href{https://en.wikipedia.org/wiki/First-order_partial_differential_equation}{1st-order PDE}, also has a \href{https://en.wikipedia.org/wiki/First-order_partial_differential_equation#general_integral_and_complete_integral}{complete integral} which contains 2 arbitrary constants (for the 2 independent variables). \href{https://en.wikipedia.org/wiki/Subrahmanyan_Chandrasekhar}{\sc Subrahmanyan Chandrasekhar} provided the complete integral in 1943, given by $u(t,x) = \frac{ax + b}{at + 1}$, where $a,b$ are arbitrary constants. The complete integral satisfies a linear initial condition, i.e., $f(x) = ax + b$. One can also construct the general integral using the above complete integral.

\subsubsection{Viscous Burgers' equation}
The viscous Burgers' equation can be converted to a linear equation by the \href{https://en.wikipedia.org/wiki/Cole%E2%80%93Hopf_transformation}{Cole-Hopf transformation} $u(t,x) = -2\nu\partial_x\ln\varphi(t,x)$, which turns it into the equation $2\nu\partial_x\left[\frac{1}{\varphi}(\partial_t\varphi - \nu\partial_x^2\varphi)\right] = 0$, which can be integrated w.r.t. $x$ to obtain $\partial_t\varphi - \nu\partial_x^2\varphi = \varphi\frac{df(t)}{dt}$, where $\frac{df}{dt}$ is an arbitrary function of time. Introducing the transformation $\varphi\mapsto\varphi e^f$, which does not affect the function $u(t,x)$, the required equation reduces to that of the \href{https://en.wikipedia.org/wiki/Heat_equation}{heat equation} $\partial_t\varphi = \nu\partial_x^2\varphi$. The diffusion equation \href{https://en.wikipedia.org/wiki/Solving_the_heat_equation_using_Fourier_series}{can be solved}, i.e., if $\varphi(0,x) = \varphi_0(x)$, then
\begin{equation*}
	\varphi(t,x) = \frac{1}{\sqrt{4\pi\nu t}}\int_\mathbb{R} \varphi_0(x')\exp\left(-\frac{(x - x')^2}{4\nu t}\right)\,{\rm d}x'.
\end{equation*}
The initial function $\varphi_0(x)$ is related to the initial function $u(0,x) = f(x)$ by $\ln\varphi_0(x) = -\frac{1}{2\nu}\int_0^x f(x')\,{\rm d}x'$, where the lower limit is chosen arbitrarily. Invert the Cole-Hopf transformation:
\begin{equation*}
	u(t,x) = -2\nu\partial_x\ln\left\{\frac{1}{\sqrt{4\pi\nu t}}\int_\mathbb{R} \exp\left[-\frac{(x - x')^2}{4\nu t} - \frac{1}{2\nu}\int_0^{x'} f(x'')\,{\rm d}x''\right]\,{\rm d}x'\right\},
\end{equation*}
which simplifies, by getting rid of the time-dependent prefactor in the argument of the logarithm, to 
\begin{equation*}
	u(t,x) = -2\nu\partial_x\ln\left\{\int_\mathbb{R} \exp\left[-\frac{(x - x')^2}{4\nu t} - \frac{1}{2\nu}\int_0^{x'} f(x'')\,{\rm d}x''\right]\,{\rm d}x'\right\},
\end{equation*}
This solution is derived from the solution of the heat equation for $\varphi$ that decays to 0 as $x\to\pm\infty$; other solutions for $u$ can be obtained starting from solutions of $\varphi$ that satisfying different boundary conditions.

\subsubsection{Some explicit solutions of viscous Burgers' equation}
Explicit expressions for the viscous Burgers' equation are available. Some of the physically relevant solutions are given below:
\begin{enumerate}
	\item {\bf Steadily propagating traveling wave.} If $u(0,x) = f(x)$ s.t. $f(-\infty) f^+,f(+\infty) = f^-$ \& $f'(x) < 0$, then we have a traveling-wave solution (with a constant speed $c = \frac{f^+ + f^-}{2}$) given by
	\begin{equation}
		u(t,x) = c - \frac{f^+ - f^-}{2}\tanh\left[\frac{f^+ - f^-}{2\nu}(x - ct)\right].
	\end{equation}
	This solution, originally derived by \href{https://en.wikipedia.org/wiki/Harry_Bateman}{\sc Harry Bateman} in 1915, is used to describe the variation of pressure across a \href{https://en.wikipedia.org/wiki/Becker%E2%80%93Morduchow%E2%80%93Libby_solution#Taylor's_solution:_Weak_shock_waves}{weak shock wave}. When $f^+ = 2,f^- = 0$ to $u(t,x) = \frac{2}{1 + e^{\frac{x - t}{\nu}}}$ with $c = 1$.
	\item {\bf Delta function as an initial condition.} If $u(0,x) = 2\nu{\rm Re}\delta(x)$, where the \href{https://en.wikipedia.org/wiki/Reynolds_number}{Reynolds number} ${\rm Re}$ is a constant, then
	\begin{equation}
		u(t,x) = \sqrt{\frac{\nu}{\pi t}}\frac{(e^{\rm Re} - 1)e^{-\frac{x^2}{4\nu t}}}{1 + \frac{e^{\rm Re} - 1}{\sqrt{2}}{\rm erfc}\frac{x}{\sqrt{4\nu t}}}.
	\end{equation}
	In the limit ${\rm Re}\to0$, the limiting behavior is a diffusional spreading of a source \& therefore is given by
	\begin{equation}
		u(t,x) = \frac{2\nu{\rm Re}}{\sqrt{4\pi\nu t}}e^{-\frac{x^2}{4\nu t}}.
	\end{equation}
	In the limit ${\rm Re}\to\infty$, the solution approaches that of the aforementioned Chandrasekhar's shock-wave solution of the inviscid Burgers' equation and is given by
	\begin{equation*}
		\left\{\begin{split}
			&\frac{x}{t}&&0< x < \sqrt{2\nu{\rm Re}t},\\
			&0&&\mbox{else}.
		\end{split}\right.
	\end{equation*}
	The shock wave location \& its speed are given by $x = \sqrt{2\nu{\rm Re}t}$ \& $\sqrt{\frac{\nu{\rm Re}}{t}}$.
	\item {\bf N-wave solution.} The \href{https://en.wikipedia.org/wiki/N-wave}{N-wave} solution comprises a compression wave followed by a rarefaction wave. A solution of this type is given by
	\begin{equation*}
		u(t,x) = \frac{x}{t}\left[1 + \frac{1}{e^{{\rm Re}_0 - 1}}\sqrt{\frac{t}{t_0}}\exp\left(-\frac{{\rm Re}(t)x^2}{4\nu{\rm Re}_0t}\right)\right]^{-1},
	\end{equation*}
	where $R_0$ may be regarded as an initial Reynolds number at time $t = t_0$ \& ${\rm Re}(t) = \frac{1}{2\nu}\int_0^\infty u\,{\rm d}x = \ln\left(1 + \sqrt{\frac{\tau}{t}}\right)$ with $\tau = t_0\sqrt{e^{{\rm Re}_0} - 1}$, may be regarded as the time-varying Reynold number.
\end{enumerate}

\subsubsection{Other forms}

\begin{enumerate}
	\item {\bf Multi-dimensional Burgers' equation.} In 2 or more dimensions, the Burgers' equation becomes $\partial_tu + u\cdot\nabla u = \nu\Delta u$. One can also extend the equation for the vector field ${\bf u}$ as in $\partial_t{\bf u} + {\bf u}\cdot\nabla{\bf u} = \nu\Delta{\bf u}$.
	\item {\bf Generalized Burgers' equation.} The generalized Burgers' equation extends the quasilinear convective to more general form, i.e., $\partial_tu + c(u)\partial_xu = \nu\partial_x^2u$, where $c(u)$ is any arbitrary function of $u$. The inviscid $\nu = 0$ equation is still a quasilinear hyperbolic equation for $c(u) > 0$ \& its solution can be constructed using \href{https://en.wikipedia.org/wiki/Method_of_characteristics}{method of characteristics} as before.
	\item {\bf Stochastic Burgers' equation.} Added space-time noise $\eta(t,x) = \dot{W}(t,x)$, where $W$ is an $L^2(\mathbb{R})$ \href{https://en.wikipedia.org/wiki/Wiener_process}{Wiener process}, forms a stochastic Burgers' equation $\partial_tu + u\partial_xu = \nu\partial_x^2u - \lambda\partial_x\eta$. This \href{https://en.wikipedia.org/wiki/Stochastic_PDE}{stochastic PDE} is the 1D version of \href{https://en.wikipedia.org/wiki/Kardar%E2%80%93Parisi%E2%80%93Zhang_equation}{Kardar--Parisi--Zhang equation} in a field $h(t,x)$ upon substituting $u(t,x) = -\lambda\partial_xh$.'' -- \href{https://en.wikipedia.org/wiki/Burgers%27_equation}{Wikipedia{\tt/}Burgers' equation}
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}$C_0$-semigroup}
``In mathematical analysis, a {\it $C_0$-semigroup}, also known as a {\it strongly continuous 1-parameter semigroup}, is a generalization of the \href{https://en.wikipedia.org/wiki/Exponential_function}{exponential function}. Just as exponential functions provide solutions of scalar linear constant ODEs, strongly continuous semigroups provide solutions of linear constant coefficient ODEs in \href{https://en.wikipedia.org/wiki/Banach_space}{Banach spaces}. Such differential equations in Banach spaces arise from e.g. \href{https://en.wikipedia.org/wiki/Delay_differential_equation}{delay differential equations} \& PDEs. Formally, a strongly continuous semigroup is a representation of the \href{https://en.wikipedia.org/wiki/Semigroup}{semigroup} $(\mathbb{R}_+,+)$ on some Banach space $X$ that is continuous in the \href{https://en.wikipedia.org/wiki/Strong_operator_topology}{strong toperator topology}.'' -\href{https://en.wikipedia.org/wiki/C0-semigroup}{Wikipedia{\tt/}$C_0$-semigroup}

\subsubsection{Formal definition}

\subsubsection{Infinitesimal generator}

\subsubsection{Uniformly continuous semigroup}

\subsubsection{Examples}

\subsubsection{Abstract Cauchy problems}

\subsubsection{Generation theorems}

\subsubsection{Special classes of semigroups}

\subsubsection{Stability}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}curvature}
{\sf A migrating wild-type \href{https://en.wikipedia.org/wiki/Dictyostelium_discoideum}{\it Dictyostelium discoideum} cell whose boundary is colored by curvature. Scale bar: $5\mu{\rm m}$.} ``In mathematics, {\it curvature} is any of several strongly related concepts in geometry that intuitively measure the amount by which a \href{https://en.wikipedia.org/wiki/Curve}{curve} deviates from being a \href{https://en.wikipedia.org/wiki/Straight_line}{straight line} or by which a \href{https://en.wikipedia.org/wiki/Surface_(mathematics)}{surface} deviates from being a \href{https://en.wikipedia.org/wiki/Plane_(geometry)}{plane}. If a curve or surface is contained in a larger space, curvature can be defined {\it extrinsically} relative to the ambient space. \href{https://en.wikipedia.org/wiki/Curvature_of_Riemannian_manifolds}{Curvature of Riemannian manifolds} of dimension at least 2 can be defined {\it intrinsically} without reference to a larger space.

For curves, the canonical example is that of a circle, which has a curvature equal to $\frac{1}{R}$. Smaller circles bend more sharply, \& hence have higher curvature. The curvature {\it at a point} of a \href{https://en.wikipedia.org/wiki/Differentiable_curve}{differentiable curve} is the curvature of its \href{https://en.wikipedia.org/wiki/Osculating_circle}{osculating circle} -- i.e., the circle that best approximates the curve near this point. The curvature of a straight line is zero. In contrast to the \href{https://en.wikipedia.org/wiki/Tangent}{tangent}, which is a vector quantity, the curvature at a point is typically a scalar quantity, i.e., it is expressed by a single real number.

For surfaces (\&, more generally for higher-dimensional \href{https://en.wikipedia.org/wiki/Manifold}{manifolds}), that are \href{https://en.wikipedia.org/wiki/Embedding}{embedded} in a \href{https://en.wikipedia.org/wiki/Euclidean_space}{Euclidean space}, the concept of curvature is more complex, as it depends on the choice of a direction on the surface or manifold. This leads to the concepts of {\it maximal curvature}, \href{https://en.wikipedia.org/wiki/Minimal_surface}{minimal curvature}, \& \href{https://en.wikipedia.org/wiki/Mean_curvature}{mean curvature}.'' -- \href{https://en.wikipedia.org/wiki/Curvature}{Wikipedia{\tt/}curvature}

\subsubsection{History}
In {\it Tractatus de configurationibus qualitatum et motuum}, the 14th-century philosopher \& mathematician \href{https://en.wikipedia.org/wiki/Nicole_Oresme}{\sc Nicole Oresme} introduces the concept of curvature as a measure of departure from straightness; for circles he has the curvature as being inversely proportional to the radius; \& he attempts to extend this idea to other curves as a continuously varying magnitude.

The curvature of a \href{https://en.wikipedia.org/wiki/Differentiable_curve}{differentiable curve} was originally defined through \href{https://en.wikipedia.org/wiki/Osculating_circle}{osculating circles}. In this setting, \href{https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy}{\sc Augustin-Louis Cauchy} showed that the center of curvature is the intersection point of 2 infinitely close \href{https://en.wikipedia.org/wiki/Normal_(geometry)}{normal lines} to the curve.

\subsubsection{Plane curves}
Intuitively, the curvature describes for any part of a curve how much the curve direction changes over a small distance traveled (e.g., angle in rad{\tt/}m), so it is a measure of the \href{https://en.wikipedia.org/wiki/Instantaneous_rate_of_change}{instantaneous rate of change} of {\it direction} of a point that moves on the curve: the larger the curvature, the larger this rate of change. In other words, the curvature measures how fast the unit tangent vector to the curve at point $p$ rotates when point $p$ moves at unit speed along the curve. In fact, it can be proved that this instantaneous rate of change is exactly the curvature. More precisely, suppose that the point is moving on the curve at a constant speed of 1 unit, i.e., the position of the point $P(s)$ is a function of the parameter $s$, which may be thought as the time or as the \href{https://en.wikipedia.org/wiki/Arc_length}{arc length} from a given origin. Let ${\bf T}(s)$ be a \href{https://en.wikipedia.org/wiki/Unit_tangent_vector}{unit tangent vector} of the curve at $P(s)$, which is also the derivative of $P(s)$ w.r.t. $s$. Then, the derivative of ${\bf T}(s)$ w.r.t. $s$ is a vector that is normal to the curve \& whose length is the curvature.

To be meaningful, the definition of the curvature \& its different characterizations require that the curve is \href{https://en.wikipedia.org/wiki/Continuously_differentiable}{continuously differentiable} near $P$, for having a tangent that varies continuously; it requires also that the curve is twice differentiable at $P$, for insuring the existence of the involved limits, \& the derivative of ${\bf T}(s)$.

The characterization of the curvature in terms of the derivative of the unit tangent vector is probably less intuitive than the definition in terms of the osculating circle, but formulas for computing the curvature are easier to deduce. Therefore, \& also because of its use in \href{https://en.wikipedia.org/wiki/Kinematics}{kinematics}, this characterization is often given as a definition of the curvature.
\begin{enumerate}
	\item {\bf Osculating circle.} Historically, the curvature of a differentiable curve was defined through the \href{https://en.wikipedia.org/wiki/Osculating_circle}{osculating circle}, which is the circle that best approximates the curve at a point. More precisely, given a point $P$ on a curve, every other point $Q$ of the curve defines a circle (or sometimes a line) passing through $Q$ \& \href{https://en.wikipedia.org/wiki/Tangent_(geometry)}{tangent} to the curve at $P$. The osculating circle is the \href{https://en.wikipedia.org/wiki/Limit_(mathematics)}{limit}, if it exists, of this circle when $Q$ tends to $P$. Then the {\it center} \& the {\it radius of curvature} of the curve at $P$ are the center \& the radius of the osculating circle. The curvature is the reciprocal of radius of curvature. I.e., the curvature is $\kappa = \frac{1}{R}$, where $R$ is the radius of curvature (the whole circle has this curvature, it can be read as turn $\pi$ over the length $2\pi R$). This definition is difficult to manipulate \& to express in formulas. Therefore, other equivalent definitions have been introduced.
	\item {\bf In terms of arc-length parametrization.}
	\item {\bf In terms of general parametrization.}
	\item {\bf Graph of a function.} The \href{https://en.wikipedia.org/wiki/Graph_of_a_function}{graph of a function} $y = f(x)$, is a special case of a parameterized curve, of the form $x = t,y = f(t)$. As the 1st \& 2nd derivatives of $x$ are 1 \& 0, previous formulas simplify to $\kappa = \frac{|y''|}{(1 + y'^2)^{\frac{3}{2}}}$ for the curvature, \& to $k = \frac{y''}{(1 + y'^2)^{\frac{3}{2}}}$, for the signed curvature.
	
	In the general case of a curve, the sign of the signed curvature is somewhat arbitrary, as it depends on the orientation of the curve. In the case of the graph of a function, there is a natural orientation by increasing values of $x$. This makes significant the sign of the signed curvature.
	
	The sign of the signed curvature is the same as the sign of the 2nd derivative of $f$. If it is positive then the graph has an upward concavity, \&, if it is negative the graph has a downward concavity. If it is zero, then one has an \href{https://en.wikipedia.org/wiki/Inflection_point}{inflection point} or an \href{https://en.wikipedia.org/wiki/Undulation_point}{undulation point}.
	
	When the \href{https://en.wikipedia.org/wiki/Slope}{slope} of the graph (i.e., the derivative of the function) is small, the signed curvature is well approximated by the 2nd derivative. More precisely, using \href{https://en.wikipedia.org/wiki/Big_O_notation}{big O notation}, one has $k(x) = y''(1 + O(y'^2))$. It is common in physics \& engineering to approximate the curvature with the 2nd derivative, e.g., in \href{https://en.wikipedia.org/wiki/Beam_theory}{beam theory} or for deriving the \href{https://en.wikipedia.org/wiki/Wave_equation}{wave equation} of a string under tension, \& other applications where small slopes are involved. This often allows systems that are otherwise \href{https://en.wikipedia.org/wiki/Nonlinear_system}{nonlinear} to be treated approximately as linear.
	\item {\bf Polar coordinates.} If a curve is defined in \href{https://en.wikipedia.org/wiki/Polar_coordinates}{polar coordinates} by the radius expressed as a function of the polar angle, i.e. $r$ is a function of $\theta$, then its curvature is $\kappa(\theta) = \dfrac{|r^2 + 2r'^2 - rr''|}{(r^2 + r'^2)^{\frac{3}{2}}}$ where the prime refers to differentiation w.r.t. $\theta$. This results from the formula for general parameterizations, by considering the parametrization $(x,y) = (r(\theta)\cos\theta,r(\theta)\sin\theta)$.
	\item {\bf Implicit curve.} For a curve defiend by an \href{https://en.wikipedia.org/wiki/Implicit_equation}{implicit equation} $F(x,y) = 0$ with \href{https://en.wikipedia.org/wiki/Partial_derivatives}{partial derivatives} denoted $F_x,F_y,F_{xx},F_{xy},F_{yy}$, the curvature is given by $\kappa = \dfrac{|F_y^2F_{xx} - 2F_xF_yF_{xy} + F_x^2F_{yy}|}{(F_x^2 + F_y^2)^{\frac{3}{2}}}$. The signed curvature is not defined, as it depends on an orientation of the curve that is not provided by the implicit equation. Note that changing $F$ into $-F$ would not change the curve defined by $F(x,y) = 0$, but it would change the sign of the numerator if the absolute value were omitted in the preceding formula.
	
	A point of the curve where $F_x = F_y = 0$ is a \href{https://en.wikipedia.org/wiki/Singular_point_of_a_curve}{singular point}, which means that the curve is not differentiable at this point, \& thus that the curvature is not defined (most often, the point is either a crossing point or a \href{https://en.wikipedia.org/wiki/Cusp_(singularity)}{cusp}). The above formula for the curvature can be derived from the expression of the curvature of the graph of a function by using the \href{https://en.wikipedia.org/wiki/Implicit_function_theorem}{implicit function theorem} \& the fact that, on such a curve, one has $\frac{dy}{dx} = -\frac{F_x}{F_y}$.
	\item {\bf Examples.} It can be useful to verify on simple examples that the different formulas given in the preceding sections give the same result.
	\begin{enumerate}
		\item {\bf Circle.} A common parametrization of a circle of radius $r$ is $\boldsymbol{\gamma}(t) = (r\cos t,r\sin t)$. The formula for the curvature gives $k(t) = \dfrac{r^2\sin^2t + r^2\cos^2t}{(r^2\sin^2t + r^2\cos^2t)^{\frac{3}{2}}} = \frac{1}{r}$. It follows, as expected, that the radius of curvature is the radius of the circle, \& that the center of curvature is the center of the circle. The circle is a rare case where the arc-length parametrization is easy to compute, as it is $\boldsymbol{\gamma}(s) = \left(r\cos\frac{s}{r},r\sin\frac{s}{r}\right)$. It is an arc-length paramtrization, since the norm of $\boldsymbol{\gamma}'(s) =\left(-\sin\frac{s}{r},\cos\frac{s}{r}\right)$ is $= 1$. This parametrization gives the same value for the curvature, as it amounts to division by $r^3$ in both the numerator \& the denominator in the preceding formula.
		
		The same circle can also be defined by the implicit equation $F(x,y) = 0$ with $F(x,y) = x^2 + y^2 - r^2$. Then, the formula for the curvature in this case gives $\kappa = \dfrac{|F_y^2F_{xx} - 2F_xF_yF_{xy} + F_x^2F_{yy}|}{(F_x^2 + F_y^2)^{\frac{3}{2}}} = \dfrac{8y^2 + 8x^2}{(4x^2 + 4y^2)^{\frac{3}{2}}} = \dfrac{8r^2}{(4r^2)^{\frac{3}{2}}} = \dfrac{1}{r}$.
		\item {\bf Parabola.} Consider the \href{https://en.wikipedia.org/wiki/Parabola}{parabola} $y = ax^2 + bx + c$. It is the graph of a function, with derivative $2ax + b$, \& the 2nd derivative $2a$. So, the signed curvature is $k(x) = \frac{2a}{(1 + (2ax + b)^2)^{\frac{3}{2}}}$. It has the sign of $a$ for all values of $x$. I.e., if $a > 0$, the concavity is upward directed everywhere; if $a < 0$, the concavity is downward directed; for $a = 0$, the curvature is zero everywhere, confirming that the parabola degenerates into a line in this case.
		
		The (unsigned) curvature is maximal for $x = -\frac{b}{2a}$, i.e., at the \href{https://en.wikipedia.org/wiki/Stationary_point}{stationary point} (zero derivative) of the function, which is the \href{https://en.wikipedia.org/wiki/Vertex_(curve)}{vertex} of the parabola.
		
		Consider the parametrization $\boldsymbol{\gamma}(t) = (t,at^2 + bt + c) = (x,y)$. The 1st derivative of $x$ is 1, \& the 2nd derivative is 0. Substituting into the formula for general parametrization gives exactly the same result as above, with $x$ replaced by $t$. If we use primes for derivatives w.r.t. the parameter $t$.
		
		The same parabola can also be defined by the implicit equation $F(x,y) = 0$ with $F(x,y) = ax^2 + bx + c - y$. As $F_y = -1$, $F_{yy} = F_{xy} = 0$, one obtains exactly the same value for the (unsigned) curvature. However, the signed curvature is meaningless here, as $-F(x,y) = 0$ is a valid implicit equation for the same parabola, which gives the opposite sign for the curvature.
	\end{enumerate}	
	\item {\bf Frenet--Serret formulas for plane curves.} {\sf The vectors ${\bf T},{\bf N}$ at 2 points on a plane curve, a translated version of the 2nd frame, \& $\delta{\bf T}$ the change in ${\bf T}$. Here $\delta s$ is the distance between the points. In the limit $\frac{d{\bf T}}{ds}$ will be in the direction ${\bf N}$. The curvature describes the rate of rotation of the frame.} The expression of the curvature \href{https://en.wikipedia.org/wiki/Curvature#In_terms_of_arc-length_parametrization}{in terms of arc-length parametrization} is essentially the \href{https://en.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas}{1st Frenet--Serret formula} ${\bf T}'(s) = \kappa(s){\bf N}(s)$, where the primes refer to the derivatives w.r.t. the arc length $s$, \& ${\bf N}(s)$ is the normal unit vector in the direction of ${\bf T}'(S)$. As planar curves have zero \href{https://en.wikipedia.org/wiki/Torsion_of_curves}{torsion}, the 2nd Frenet--Serret formula provides the relation $\frac{d{\bf N}}{ds} = -\kappa{\bf T} = -\kappa\frac{d\boldsymbol{\gamma}}{ds}$. For a general parametrization by a parameter $t$, one needs expressions involving derivatives w.r.t. $t$. As these are obtained by multiplying by $\frac{ds}{dt}$ the derivatives w.r.t. $s$, one has, for any proper parametrization ${\bf N}'(t) = \kappa(t)\boldsymbol{\gamma}'(T)$.
	\item {\bf Curvature comb.} A {\it curvature comb} can be used to represent graphically the curvature of every point on a curve. If $t\mapsto x(t)$ is a parameterized curve its comb is defined as the parametrized curve $t\mapsto x(t) + d\kappa(t)n(t)$ where $\kappa,n$ are the curvature \& normal vector \& $d$ is a scaling factor (to be chosen as to enhance the graphical representation).
\end{enumerate}

\subsubsection{Space curves}

\subsubsection{Surfaces}

\subsubsection{Curvature of space}

\subsubsection{Generalizations}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}cusp (singularity)}
``In mathematics, a {\it cusp}, sometimes called {\it spinode} in old texts, is a point on a \href{https://en.wikipedia.org/wiki/Curve}{curve} where a moving point must reverse direction. A typical example is given in the figure. A cusp is thus a type of \href{https://en.wikipedia.org/wiki/Singular_point_of_a_curve}{singular point of a curve}. For a \href{https://en.wikipedia.org/wiki/Plane_curve}{plane curve} defined by an \href{https://en.wikipedia.org/wiki/Analytic_function}{analytic}, \href{https://en.wikipedia.org/wiki/Parametric_equation}{parametric equation} $x = f(t),y = g(t)$, a cusp is a point where both derivatives of $f,g$ are zero, \& the \href{https://en.wikipedia.org/wiki/Directional_derivative}{directional derivative}, in the direction of the \href{https://en.wikipedia.org/wiki/Tangent}{tangent}, changes sign (the direction of the tangent is the direction of the slope $\lim \frac{g'(t)}{f'(t)}$). Cusps are {\it local singularities} in the sense that they involve only 1 value of the parameter $t$, in contrast to self-interaction points that involve more than 1 value. In some contexts, the condition on the directional derivative may be omitted, although, in this case, the singularity may look like a regular point.

For a curve defined by an \href{https://en.wikipedia.org/wiki/Implicit_equation}{implicit equation} $F(x,y) = 0$, which is smooth, cusps are points where the terms of lowest degree of the \href{https://en.wikipedia.org/wiki/Taylor_expansion}{Taylor expansion} of $F$ are a power of a \href{https://en.wikipedia.org/wiki/Linear_polynomial}{linear polynomial}; however, not all singular points that have this property are cusps. The theory of \href{https://en.wikipedia.org/wiki/Puiseux_series}{Puiseux series} implies that, if $F$ is an \href{https://en.wikipedia.org/wiki/Analytic_function}{analytic function} (e.g., a \href{https://en.wikipedia.org/wiki/Polynomial}{polynomial}), a linear change of coordinates allow the curve to be \href{https://en.wikipedia.org/wiki/Parametrization_(geometry)}{parametrized}, in a \href{https://en.wikipedia.org/wiki/Neighbourhood_(mathematics)}{neighborhood} of the cusps, as $x = at^m,y = S(t)$ where $a\in\mathbb{R}$, $m$ is a positive even integer, \& $S(t)$ is a \href{https://en.wikipedia.org/wiki/Power_series}{power series} of \href{https://en.wikipedia.org/wiki/Power_series#Order_of_a_power_series}{order} $k > m$ (degree of the nonzero term of the lowest degree). The number $m$ is sometimes called the {\it order} or the {\it multiplicity} of the cusp, \& is equal to the degree of the nonzero part of lowest degree of $F$. In some contexts, the definition of a cusp is restricted to the case of cusps of order 2 -- i.e., the case where $m = 2$.

The definitions for plane curves \& implicitly-defined curves have been generalized by \href{https://en.wikipedia.org/wiki/Ren%C3%A9_Thom}{\sc Ren\'e Thom} \& \href{https://en.wikipedia.org/wiki/Vladimir_Arnold}{\sc Vladimir Arnold} to curves defined by \href{https://en.wikipedia.org/wiki/Differentiable_function}{differentiable functions}: a curve has a cusp at a point if there is a \href{https://en.wikipedia.org/wiki/Diffeomorphism}{diffeomorphism} of a \href{https://en.wikipedia.org/wiki/Neighborhood_(topology)}{neighborhood} of the point in the ambient space, which maps the curve onto 1 of the above-defined cusps.

\subsubsection{Classification in differential geometry}
Consider a smooth \href{https://en.wikipedia.org/wiki/Real-valued_function}{real-valued function} of 2 variables, say $f(x,y)$ where $x,y\in\mathbb{R}$. So $f$ is a function from the plane to the line. The space of all such smooth functions is \href{https://en.wikipedia.org/wiki/Group_action_(mathematics)}{acted} upon by the \href{https://en.wikipedia.org/wiki/Group_(mathematics)}{group} of \href{https://en.wikipedia.org/wiki/Diffeomorphism}{diffeomorphisms} of the plane \& the diffeomorphisms of the line, i.e., diffeomorphic changes of \href{https://en.wikipedia.org/wiki/Coordinate}{coordinate} in both the \href{https://en.wikipedia.org/wiki/Domain_of_a_function}{source} \& the \href{https://en.wikipedia.org/wiki/Range_of_a_function}{target}. This action splits the whole \href{https://en.wikipedia.org/wiki/Function_space}{function space} up into \href{https://en.wikipedia.org/wiki/Equivalence_class}{equivalence classes}, i.e., \href{https://en.wikipedia.org/wiki/Group_orbit#Orbits_and_stabilizers}{orbits} of the \href{https://en.wikipedia.org/wiki/Group_action_(mathematics)}{group action}.

1 such family of equivalence classes is denoted by \href{https://en.wikipedia.org/wiki/Ak_singularity}{$A_k^\pm$}, where $k\in\mathbb{N}$. A function $f$ is said to be of type $A_k^\pm$ if it lies in the orbit of $x^2\pm y^{k+1}$, i.e., there exists a diffeomorphic change of coordinate in source \& target which takes $f$ into 1 of these forms. These simple forms $x^2\pm y^{k+1}$ are said to give \href{https://en.wikipedia.org/wiki/Canonical_form}{normal forms} for the type $A_k^\pm$-singularities. Notice that the $A_{2n}^+$ are the same as the $A_{2n}^-$ since the diffeomorphic change of coordinate $(x,y)\to(x,-y)$ in the source takes $x^2 + y^{k+1}$ to $x^2 - y^{2n + 1}$. So we can drop the $\pm$ from $A_{2n}^\pm$ notation. The cusps are then given by the zero-level-sets of the representatives of the $A_{2n}$ equivalence classes, where $n\in\mathbb{N}^\star$.

\subsubsection{Examples}
{\sf A cusp in the \href{https://en.wikipedia.org/wiki/Semicubical_parabola}{semicubical parabola} $y^2 = x^3$.}
\begin{itemize}
	\item An {\it ordinary cusp} is given by $x^2 - y^3 = 0$, i.e., the zero-level-set of a type $A_2$-singularity. Let $f(x,y)$ be a smooth function of $x$ \& $y$ \& assume, for simplicity, that $f(0,0) = 0$. Then a type $A_2$-singularity of $f$ at $(0,0)$ can be characterized by:
	\begin{enumerate}
		\item Having a degenerate quadratic part, i.e., the quadratic terms in the \href{https://en.wikipedia.org/wiki/Taylor_series}{Taylor series} of $f$ form a perfect square, say $L(x,y)^2$, where $L(x,y)$ is linear in $x,y$, \&
		\item $L(x,y)$ does not divide the cubic terms in the Taylor series of $f(x,y)$.
	\end{enumerate}
	\item A {\it rhamphoid cusp} (from Greek `beak-like') denoted originally a cusp s.t. both branches are on the same side of the tangent, such as for the curve of equation $x^2 - x^4 - y^5 = 0$. As such a singularity is in the same differential class as the cusp of equation $x^2 - y^5 = 0$, which is a singularity of type $A_4$, the term has been extended to all such singularities. These cusps are non-generic as \href{https://en.wikipedia.org/wiki/Caustic_(mathematics)}{caustics} \& \href{https://en.wikipedia.org/wiki/Wave_front}{wave fronts}. The rhamphoid cusp \& the ordinary cusp are non-diffeomorphic. A parametric form is $x = t^2,y = ax^4 + x^5$.
\end{itemize}
For a type $A_4$-singularity we need $f$ to have a degenerate quadratic part (this gives type $A_{\ge2}$), that $L$ does divide the cubic terms (this gives type $A_{\ge3}$), another divisibility condition (giving type $A_{\ge4}$), \& a final non-divisibility condition (giving type exactly $A_4$).

To see where these extra divisibility conditions come from, assume that $f$ has a degenerate quadratic part $L^2$ \& that $L$ divides the cubic terms. It follows that the 3d order Taylor series of $f$ is given by $L^2\pm LQ$, where $Q$ is quadratic in $x,y$. We can \href{https://en.wikipedia.org/wiki/Complete_the_square}{complete the square} to show that $L^2\pm LQ = \left(L\pm\frac{Q}{2}\right)^2 - \frac{Q^2}{4}$. We can now make a diffeomorphic change of variable (in this case we simply substitute polynomials with \href{https://en.wikipedia.org/wiki/Linearly_independent}{linearly independent} linear parts) so that $\left(L\pm\frac{Q}{2}\right)^2 - \frac{Q^2}{4}\to x_1^2 + P_1$ where $P_1$ is \href{https://en.wikipedia.org/wiki/Quartic_polynomial}{quartic} (order 4) in $x_1,y_1$. The divisibilty condition for type $A_{\ge4}$ is that $x_1$ divides $P_1$. If $x_1$ does not divide $P_1$ then we have type exactly $A_3$ (the zero-level-set here is a \href{https://en.wikipedia.org/wiki/Tacnode}{tacnode}). If $x_1$ divides $P_1$ we complete the square on $x_1^2 + P_1$ \& change coordinates so that we have $x_2^2 + P_2$ where $P_2$ is \href{https://en.wikipedia.org/wiki/Quintic_polynomial}{quintic} (order 5) in $x_2,y_2$. If $x_2$ does not divide $P_2$ then we have exactly type $A_4$, i.e., the zero-level-set will be a rhamphoid cusp.

\subsubsection{Applications}
{\sf An ordinary cusp occurring as the \href{https://en.wikipedia.org/wiki/Caustic_(optics)}{caustic} of light rays in the bottom of a teacup.} Cusps appear naturally when \href{https://en.wikipedia.org/wiki/Projection_(mathematics)}{projecting} into a plane a \href{https://en.wikipedia.org/wiki/Smooth_curve}{smooth curve} in 3D \href{https://en.wikipedia.org/wiki/Euclidean_space}{Euclidean space}. In general, such a projection is a curve whose singularities are self-crossing points \& ordinary cusps. Self-crossing points appear when 2 different points of the curves have the same projection. Ordinary cusps appear when the tangent to the curve is parallel to the direction of projection (i.e., when the tangent projects on a single point). More complicated singularities occur when several phenomena occur simultaneously. E.g., rhamphoid cusps occur for \href{https://en.wikipedia.org/wiki/Inflection_point}{inflection points} (\& for \href{https://en.wikipedia.org/wiki/Undulation_point}{undulation points}) for which the tangent is parallel to the direction of projection.

In many cases, \& typically in \href{https://en.wikipedia.org/wiki/Computer_vision}{computer vision} \& \href{https://en.wikipedia.org/wiki/Computer_graphics}{computer graphics}, the curve that is projected is the curve of the \href{https://en.wikipedia.org/wiki/Critical_point_(mathematics)}{critical points} of the restriction to a (smooth) spatial object of the projection. A cusp appears thus as a singularity of the contour of the image of the object (vision) or of its shadow (computer graphics). \href{https://en.wikipedia.org/wiki/Caustic_(mathematics)}{Caustics} \& \href{https://en.wikipedia.org/wiki/Wave_front}{wave fronts} are other examples of curves having cusps that are visible in the real world.'' -- \href{https://en.wikipedia.org/wiki/Cusp_(singularity)}{Wikipedia{\tt/}cusp (singularity)}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}elementary function}
``In mathematics, an {\it elementary function} is a \href{https://en.wikipedia.org/wiki/Function_(mathematics)}{function} of a single \href{https://en.wikipedia.org/wiki/Variable_(mathematics)}{variable} (typically real or complex) that is defined as taking sums, products, \href{https://en.wikipedia.org/wiki/Algebraic_function}{roots}, \& \href{https://en.wikipedia.org/wiki/Composition_of_functions}{compositions} of finitely many \href{https://en.wikipedia.org/wiki/Polynomial#Polynomial_functions}{polynomial}, \href{https://en.wikipedia.org/wiki/Rational_function}{rational}, \href{https://en.wikipedia.org/wiki/Trigonometric_functions}{trigonometric}, \href{https://en.wikipedia.org/wiki/Hyperbolic_functions}{hyperbolic}, \& \href{https://en.wikipedia.org/wiki/Exponential_function}{exponential} functions, \& their \href{https://en.wikipedia.org/wiki/Inverse_function}{inverses}, e.g., \href{https://en.wikipedia.org/wiki/Inverse_trigonometric_functions}{arsin}, \href{https://en.wikipedia.org/wiki/Natural_logarithm}{log}, $x^{1\frac{1}{n}}$. All elementary functions are continuous on their \href{https://en.wikipedia.org/wiki/Domain_of_a_function}{domains}.

Elementary functions were introduced by \href{https://en.wikipedia.org/wiki/Joseph_Liouville}{\sc Joseph Liouville} in a series of papers from 1833 to 1841. An \href{https://en.wikipedia.org/wiki/Abstract_algebra}{algebraic} treatment of elementary functions was started by \href{https://en.wikipedia.org/wiki/Joseph_Fels_Ritt}{\sc Joseph Fels Ritt} in the 1930s. Many textbooks \& dictionaries do not give a precise definition of the elementary functions, \& mathematicians differ on it.

\subsubsection{Examples}

\begin{itemize}
	\item {\sf Basic examples.} Elementary functions of a single variable $x$ include:
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Constant_function}{Constant functions}: $2,\pi,e$, etc.
		\item \href{https://en.wikipedia.org/wiki/Exponentiation#Rational_exponents}{Rational powers of $x$}: $x,x^2,\sqrt{x} = x^{\frac{1}{2}},x^{\frac{2}{3}}$, etc.
		\item \href{https://en.wikipedia.org/wiki/Exponential_function}{Exponential functions}: $e^x,a^x$.
		\item \href{https://en.wikipedia.org/wiki/Logarithm}{Logarithms}: $\log x,\log_ax$.
		\item \href{https://en.wikipedia.org/wiki/Trigonometric_function}{Trigonometric functions}: $\sin x,\cos x,\tan x,\cot x$, etc.
		\item \href{https://en.wikipedia.org/wiki/Inverse_trigonometric_function}{Inverse trigonometric functions}: $\arcsin x,\arccos x,\arctan x,\operatorname{arccot} x$, etc.
		\item \href{https://en.wikipedia.org/wiki/Hyperbolic_function}{Hyperbolic functions}: $\sinh x,\cosh x$, etc.
		\item \href{https://en.wikipedia.org/wiki/Inverse_hyperbolic_function}{Inverse hyperbolic functions}: $\operatorname{arsinh}x,\operatorname{arcosh}x$, etc.
		\item All functions obtained by adding, subtracting, multiplying or dividing a finite number of any of the previous function
		\item All functions obtained by root extraction of a polynomial with coefficients in elementary functions
		\item All functions obtained by \href{https://en.wikipedia.org/wiki/Function_composition}{composing} a finite number of any of the previously listed functions
	\end{itemize}
	Certain elementary functions of a single complex variable $z$, e.g. $\sqrt{z},\log z$, may be \href{https://en.wikipedia.org/wiki/Multivalued_function}{multivalued}. Additionally, certain classes of functions may be obtained by others using the final 2 rules. E.g., the exponential function $e^z$ composed with addition, subtraction, \& division provides the hyperbolic functions, while initial composition with $iz$ instead provides the trigonometric functions.
	\item {\sf Composite examples.} Examples of elementary functions include: addition, e.g., $x + 1$, multiplication, e.g., $2x$, polynomial functions, $\dfrac{e^{\tan x}}{1 + x^2}\sin\sqrt{1 + (\log x)^2},-i\log\left(x + i\sqrt{1 - x^2}\right)$. The last function is equal to $\arccos x$, the \href{https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Logarithmic_forms}{inverse cosine}, in the entire \href{https://en.wikipedia.org/wiki/Complex_plane}{complex plane}. All \href{https://en.wikipedia.org/wiki/Monomial}{monomials}, \href{https://en.wikipedia.org/wiki/Polynomial}{polynomials}, \href{https://en.wikipedia.org/wiki/Rational_function}{rational functions}, \& \href{https://en.wikipedia.org/wiki/Algebraic_function}{algebraic functions} are elementary. The \href{https://en.wikipedia.org/wiki/Absolute_value}{absolute value function}, for real $x$, is also elementary as it can be expressed as the composition of a power \& root of $x$: $|x| = \sqrt{x^2}$.
	\item {\sf Non-elementary functions.} Many mathematicians exclude non-\href{https://en.wikipedia.org/wiki/Analytic_function}{analytic functions} e.g. the \href{https://en.wikipedia.org/wiki/Absolute_value}{absolute value function} or discontinuous functions e.g. the \href{https://en.wikipedia.org/wiki/Step_function}{step function}, but others allow them. Some have proposed extending the set to include, e.g., the \href{https://en.wikipedia.org/wiki/Lambert_W_function}{Lambert W function}. Some examples of functions that are {\it not} elementary:
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Tetration}{tetration}
		\item the \href{https://en.wikipedia.org/wiki/Gamma_function}{gamma function}
		\item no-elementary \href{https://en.wikipedia.org/wiki/Liouvillian_function#Examples}{Liouvillian functions}, including:
		\begin{itemize}
			\item the \href{https://en.wikipedia.org/wiki/Exponential_integral}{exponential integral} ($Ei$), \href{https://en.wikipedia.org/wiki/Logarithmic_integral}{logarithmic integral} ($Li$ or $li$) \& \href{https://en.wikipedia.org/wiki/Fresnel_integral}{Fresnel integrals} ($S,C$).
			\item the \href{https://en.wikipedia.org/wiki/Error_function}{error function} $\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2}\,{\rm d}t$, a fact that may not be immediately obvious, but can be proven using the \href{https://en.wikipedia.org/wiki/Risch_algorithm}{Risch algorithm}.
		\end{itemize}
		\item other \href{https://en.wikipedia.org/wiki/Nonelementary_integral}{nonelementary integrals}, including the \href{https://en.wikipedia.org/wiki/Dirichlet_integral}{Dirichlet integral} \& \href{https://en.wikipedia.org/wiki/Elliptic_integral}{elliptic integral}.
	\end{itemize}
\end{itemize}

\subsubsection{Closure}
It follows directly from the definition that the set of elementary functions is \href{https://en.wikipedia.org/wiki/Closure_(mathematics)}{closed} under arithmetic operations, root extraction \& composition. The elementary functions are closed under \href{https://en.wikipedia.org/wiki/Derivative}{differentiation}. They are not closed under \href{https://en.wikipedia.org/wiki/Series_(mathematics)}{limits \& infinite sums}. Importantly, the elementary functions are {\it not} closed under \href{https://en.wikipedia.org/wiki/Antiderivative}{integration}, as shown by \href{https://en.wikipedia.org/wiki/Liouville%27s_theorem_(differential_algebra)}{nonelementary integral}. The \href{https://en.wikipedia.org/wiki/Liouvillian_function}{Liouvillian functions} are defined as the elementary functions \&, recursively, the integrals of the Liouvillian functions.

\subsubsection{Differential algebra}
The mathematical definition of an {\it elementary function}, or a function in elementary form, is considered in the context of \href{https://en.wikipedia.org/wiki/Differential_algebra}{differential algebra}. A differential algebra is an algebra with the extra operation of derivation (algebraic version of differentiation). Using the derivation operation new equations can be written \& their solutions used in \href{https://en.wikipedia.org/wiki/Field_extension}{extensions} of the algebra. By starting with the \href{https://en.wikipedia.org/wiki/Field_(mathematics)}{field} of \href{https://en.wikipedia.org/wiki/Rational_function}{rational functions}, 2 special types of transcendental extensions (the logarithm \& the exponential) can be added to the field building a tower containing elementary functions.

A {\it differential field} $F$ is a field $F_0$ (rational functions over the rationals $\mathbb{Q}$ e.g.) together with a derivation map $u\to\partial u$. (Here $\partial u$ is a new function. Sometimes the notation $u'$ is used.) The derivation captures the properties of differentiation, so that for any 2 elements of the base field, the derivation is linear $\partial(u + v) = \partial u + \partial v$ \& satisfies the \href{https://en.wikipedia.org/wiki/Product_rule}{Leibniz product rule} $\partial(u\cdot v) = \partial u\cdot v + u\cdot\partial v$. An element $h$ is a constant if $\partial h = 0$. If the base field is over the rationals, care must be taken when extending the field to add the needed transcendental constants.

A function $u$ of a differential extension $F[u]$ of a differential field $F$ is an {\it elementary function} over $F$ if the function $u$:
\begin{itemize}
	\item is \href{https://en.wikipedia.org/wiki/Algebraic_function}{algebraic} over $F$, or
	\item is an {\it exponential}, i.e., $\partial u = u\partial a$ for $a\in F$, or
	\item is a {\it logarithm}, i.e., $\partial u = \frac{\partial a}{a}$ for $a\in F$.
\end{itemize}
See also \href{https://en.wikipedia.org/wiki/Liouville%27s_theorem_(differential_algebra)}{Liouville's theorem}.'' -- \href{https://en.wikipedia.org/wiki/Elementary_function}{Wikipedia{\tt/}elementary function}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}elementary recursive function}
``In \href{https://en.wikipedia.org/wiki/Recursion_theory}{recursion theory}, an {\it elementary recursive function}, also called an {\it elementary function}, or a {\it Kalm\'ar elementary function}, is a restricted form of a \href{https://en.wikipedia.org/wiki/Primitive_recursive_function}{primitive recursive function}, allowing bounded applications of \href{https://en.wikipedia.org/wiki/Exponentiation}{exponentiation}, e.g., $O(2^{2^n})$.

The name was coined by \href{https://en.wikipedia.org/wiki/L%C3%A1szl%C3%B3_Kalm%C3%A1r}{\sc L\'aszl\'o Kalm\'ar}, in the context of \href{https://en.wikipedia.org/wiki/Computable_function}{recursive functions} \& \href{https://en.wikipedia.org/wiki/Undecidable_problem}{undecidability}; most elementary recursive functions are far from elementary. Not all primitive recursive problems are elementary; e.g., \href{https://en.wikipedia.org/wiki/Tetration}{tetration} is not elementary. The corresponding class of \href{https://en.wikipedia.org/wiki/Decision_problem}{decision problems} is denoted {\sf ELEMENTARY}.

\subsubsection{Definition}
The definitions of elementary recursive functions are the same as for \href{https://en.wikipedia.org/wiki/Primitive_recursive_function}{primitive recursive functions}, except that primitive recursive is replaced bounded summation \& bounded product. All functions work over $\mathbb{N}$. The basic functions, all of them elementary recursive, are:
\begin{enumerate}
	\item {\sf Zero function.} Return zero: $f(x) = 0$.
	\item {\sf Successor function.} $f(x) = x + 1$. Often this is denoted by $S$, as in $S(x)$. Via repeated application of a successor function, one can achieve function.
	\item {\sf Projection functions.} these are used for ignoring arguments, e.g., $f(a,b) = a$ is a projection function.
	\item {\sf Subtraction function.} $f(x,y) = x - y$ if $y\le x$, or 0 if $y\ge x$. This function is used to define conditionals \& iteration.
\end{enumerate}
From these basic functions, we can build other elementary recursive functions.
\begin{enumerate}
	\item {\sf Composition.} applying values from some elementary recursive function as an argument to another elementary recursive function. In $f(x_1,\ldots,x_n) = h(g_1(x_1,\ldots,x_n),\ldots,g_m(x_1,\ldots,x_n))$ is elementary recursive if $h$ is elementary recursive \& each $g_i$ is elementary recursive.
	\item {\sf Bounded summation.} $f(m,x_1,\ldots,x_n) = \sum_{i=0}^m g(i,x_1,\ldots,x_n)$ is elementary recursive if $g$ is elementary recursive.
	\item {\sf Bounded product.} $f(m,x_1,\ldots,x_n) = \prod_{i=0}^m g(i,x_1,\ldots,x_n)$ is elementary recursive if $g$ is elementary recursive.
\end{enumerate}

\subsubsection{Basis for ELEMENTARY}
The class of elementary functions coincides with the closure w.r.t. composition of the projections \& 1 of the following function sets: $\{n + 1,(n - m)_+,\lfloor\frac{n}{m}\rfloor,n^m\},\{n + m,(n - m)_+,\lfloor\frac{n}{m}\rfloor,2^n\},\{n + m,n^2,n\mod m,2^n\}$.

\subsubsection{Lower elementary recursive functions}
{\it Lower elementary recursive} functions follow the definitions as above, except that bounded product is disallowed. I.e., a lower elementary recursive function must be a zero, successor, or projection function, a composition of other lower elementary recursive functions, or the bounded sum of another lower elementary recursive function. Lower elementary recursive functions are also known as Skolem elementary functions.

Whereas elementary recursive functions have potentially more than exponential growth, the lower elementary recursive functions have polynomial growth.

The class of lower elementary functions has a description in terms of composition of simple functions analogous to that we have for elementary functions. Namely, a polynomial-bounded function is lower elementary iff it can be expressed using a composition of the following functions: projections, $n + 1,nm,(n - m)_+,n\land m,\lfloor\frac{n}{m}\rfloor$, 1 exponential function $2^n$ or $n^m$ with the following restriction on the structure of formulas: the formula can have $\le2$ floors w.r.t. an exponent, e.g., $xy(z + 1)$ has 1 floor, $(x + y)^{yz + x} + z^{x + 1}$ has 2 floors, $2^{2^x}$ has 3 floors. Here $n\land m$ is a bitwise AND of $n,m$.

\subsubsection{Descriptive characterization}
In \href{https://en.wikipedia.org/wiki/Descriptive_complexity}{descriptive complexity}, ELEMENTARY is equal to the class \href{https://en.wikipedia.org/wiki/HO_(complexity)}{HO} of \href{https://en.wikipedia.org/wiki/Language_(computer_science)}{languages} that can be described by a formula of \href{https://en.wikipedia.org/wiki/Higher-order_logic}{higher-order logic}. I.e., every language in the ELEMENTARY complexity class corresponds to as a higher-order formula that is true for, \& only for, the elements on the language. More precisely, ${\sf NTIME}\left(2^{2^{\cdots^{O(n)}}}\right) = \exists{\rm HO}^i$, where $\cdots$ indicates a tower of $i$ exponentiations \& $\exists{\rm HO}^i$ is the class of queries that begin with existential quantifiers of $i$th order \& then a formula of $(i - 1)$th order.'' -- \href{https://en.wikipedia.org/wiki/Elementary_recursive_function}{Wikipedia{\tt/}elementary recursive function}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}functional analysis}
``{\sf 1 of the possible modes of vibration of an idealized circular \href{https://en.wikipedia.org/wiki/Drum_head}{drum head}. These modes are \href{https://en.wikipedia.org/wiki/Eigenfunction}{eigenfunctions} of a linear operator on a function space, a common construction in functional analysis.} {\sf Functional analysis} is a branch of \href{https://en.wikipedia.org/wiki/Mathematical_analysis}{mathematical analysis}, the core of which is formed by the study of \href{https://en.wikipedia.org/wiki/Vector_space}{vector spaces} endowed with some kind of limit-related structure (e.g., \href{https://en.wikipedia.org/wiki/Inner_product_space#Definition}{inner product}, \href{https://en.wikipedia.org/wiki/Norm_(mathematics)#Definition}{norm}, or \href{https://en.wikipedia.org/wiki/Topological_space#Definition}{topology}) \& the \href{https://en.wikipedia.org/wiki/Linear_transformation}{linear funcitons} defined on these spaces \& suitably respecting these structures. The historical roots of functional analysis lie in the study of \href{https://en.wikipedia.org/wiki/Function_space}{spaces of functions} \& the formulation of properties of transformations of functions e.g. \href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier transform} as transformations defining, e.g., continuous or \href{https://en.wikipedia.org/wiki/Unitary_operator}{unitary} operators between function spaces. This point of view turned out to be particularly useful for the study of \href{https://en.wikipedia.org/wiki/Differential_equations}{differential equation} \& \href{https://en.wikipedia.org/wiki/Integral_equations}{integral equation}.

The usage of the word \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{\it functional} as a noun goes back to the \href{https://en.wikipedia.org/wiki/Calculus_of_variations}{calculus of variations}, implying a \href{https://en.wikipedia.org/wiki/Higher-order_function}{function whose argument is a function}. The term was 1st used in \href{https://en.wikipedia.org/wiki/Jacques_Hadamard}{\sc Hadamard}'s 1910 book on that subject. However, the general concept of a functional had previously been introduced in 1887 by the Italian mathematician \& physicist \href{https://en.wikipedia.org/wiki/Vito_Volterra}{\sc Vito Volterra}. The theory of nonlinear functionals was continued by students of {\sc Hadamard}, in particular \href{https://en.wikipedia.org/wiki/Ren%C3%A9_Maurice_Fr%C3%A9chet}{\sc Fr\'echet} \& \href{https://en.wikipedia.org/wiki/Paul_L%C3%A9vy_(mathematician)}{\sc L\'evy}. {\sc Hadamard} also found the modern school of linear functional analysis further developed by \href{https://en.wikipedia.org/wiki/Frigyes_Riesz}{\sc Riesz} \& the \href{https://en.wikipedia.org/wiki/Lw%C3%B3w_School_of_Mathematics}{group} of Polish mathematicians around \href{https://en.wikipedia.org/wiki/Stefan_Banach}{\sc Stefan Banach}.

In modern introductory texts on functional analysis, the subject is seen as the study of vector spaces endowed with a topology, in particular \href{https://en.wikipedia.org/wiki/Dimension_(vector_space)}{infinite-dimensional spaces}. In contrast, \href{https://en.wikipedia.org/wiki/Linear_algebra}{linear algebra} deals mostly with finite-dimensional spaces, \& does not use topology. An important part of functional analysis is the extension of the theories of \href{https://en.wikipedia.org/wiki/Measure_(mathematics)}{measure}, \href{https://en.wikipedia.org/wiki/Integral}{integration}, \& \href{https://en.wikipedia.org/wiki/Probability}{probability} to infinite-dimensional spaces, also known as {\it infinite dimensional analysis}.

\subsubsection{Normed vector spaces}
The basic \& historically 1st class of spaces studied in functional analysis are \href{https://en.wikipedia.org/wiki/Complete_space}{complete} \href{https://en.wikipedia.org/wiki/Normed_vector_space}{normed vector spaces} over the $\mathbb{R}$ or $\mathbb{C}$, called \href{https://en.wikipedia.org/wiki/Banach_space}{Banach spaces}. An important example is a \href{https://en.wikipedia.org/wiki/Hilbert_space}{Hilbert space}, where the norm arises from an inner product. These spaces are of fundamental importance in many areas, including the \href{https://en.wikipedia.org/wiki/Mathematical_formulation_of_quantum_mechanics}{mathematical formulation of quantum mechanics}, machine learning ML, PDEs, \& \href{https://en.wikipedia.org/wiki/Fourier_analysis}{Fourier analysis}.

More generally, functional analysis includes the study of \href{https://en.wikipedia.org/wiki/Fr%C3%A9chet_space}{Fr\'echet spaces} \& other \href{https://en.wikipedia.org/wiki/Topological_vector_space}{topological vector spaes} not endowed with a norm.

An important object of study in functional analysis are the \href{https://en.wikipedia.org/wiki/Continuous_function_(topology)}{continuous} \href{https://en.wikipedia.org/wiki/Linear_transformation}{linear operators} defined on Banach \& Hilbert spaces. These lead naturally to the definition of \href{https://en.wikipedia.org/wiki/C*-algebra}{$C^\star$-algebras} \& other \href{https://en.wikipedia.org/wiki/Operator_algebra}{operator algebras}.
\begin{itemize}
	\item {\sf Hilbert spaces.} \href{https://en.wikipedia.org/wiki/Hilbert_space}{Hilbert spaces} can be completely classified: there is a unique Hilbert space \href{https://en.wikipedia.org/wiki/Up_to}{upto} \href{https://en.wikipedia.org/wiki/Isomorphism}{isomorphism} for every \href{https://en.wikipedia.org/wiki/Cardinal_number}{cardinality} of the \href{https://en.wikipedia.org/wiki/Orthonormal_basis}{orthonormal basis}. Finite-dimensional Hilbert spaces are fully understood in \href{https://en.wikipedia.org/wiki/Linear_algebra}{linear algebra}, \& infinite-dimensional \href{https://en.wikipedia.org/wiki/Separable_space}{separable} Hilbert spaces are isomorphic to $l^2(\aleph_0)$. Separability being important for applications, functional analysis of Hilbert spaces consequently mostly deals with this space. 1 of the open problems in functional analysis is to prove that every bounded linear operator on a Hilbert space has a proper \href{https://en.wikipedia.org/wiki/Invariant_subspace}{invariant subspace}. Many special cases of this \href{https://en.wikipedia.org/wiki/Invariant_subspace_problem}{invariant subspace problem} have already been proven.
	\item {\sf Banach spaces.} General \href{https://en.wikipedia.org/wiki/Banach_space}{Banach spaces} are more complicated than Hilbert spaces, \& cannot be classified in such a simple manner as those. In particular, many Banach spaces lack a notion analogous to an \href{https://en.wikipedia.org/wiki/Orthonormal_basis}{orthonormal basis}. Examples of Banach spaces are \href{https://en.wikipedia.org/wiki/Lp_space}{$L^p$-spaces} for $p\in[1,\infty)$. Given also a measure $\mu$ on set $X$, then $L^p(X)$, sometimes also denoted $L^p(X,\mu)$ or $L^p(\mu)$, has as its vectors equivalence classes $[f]$ of \href{https://en.wikipedia.org/wiki/Lebesgue-measurable_function}{measurable functions} whose \href{https://en.wikipedia.org/wiki/Absolute_value}{absolute value}'s $p$th power has finite integral, i.e., functions $f$ for which one has $\int_X |f(x)|^p\,{\rm d}\mu(x) < \infty$. If $\mu$ is the \href{https://en.wikipedia.org/wiki/Counting_measure}{counting measure}, then the integral may be replaced by a sum, i.e., require $\sum_{x\in X} |f(x)|^p < \infty$. Then it is not necessary to deal with equivalence classes, \& the space is denoted $l^p(X)$, written more simply $l^p$ in the case when $X = \mathbb{N}$.
	
	In Banach spaces, a large part of the study involves the \href{https://en.wikipedia.org/wiki/Continuous_dual}{dual space}: the space of all continuous linear maps from the space into its underlying field, so-called functionals. A Banach space can be canonically identified with a subspace of its bidual, which is the dual of its dual space. The corresponding map is an \href{https://en.wikipedia.org/wiki/Isometry}{isometry} but in general not onto. A general Banach space \& its bidual need not even be isometrically isomorphic in any way, contrary to the finite-dimensional situation. This s explained in the dual space article. Also, the notion of \href{https://en.wikipedia.org/wiki/Derivative}{derivative} can be extended to arbitrary functions between Banach spaces, see, e.g., \href{https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative}{Wikipedia{\tt/}Fr\'echet derivative}.
\end{itemize}

\subsubsection{Linear functional analysis}

\subsubsection{Major \& foundational results}
There are 4 major theorems which are sometimes called the 4 pillars of functional analysis:
\begin{enumerate}
	\item \href{https://en.wikipedia.org/wiki/Hahn%E2%80%93Banach_theorem}{Hahn--Banach theorem}
	\item \href{https://en.wikipedia.org/wiki/Open_mapping_theorem_(functional_analysis)}{opening mapping theorem}
	\item \href{https://en.wikipedia.org/wiki/Closed_graph_theorem_(functional_analysis)}{closed graph theorem}
	\item \href{https://en.wikipedia.org/wiki/Uniform_boundedness_principle}{uniform boundedness principle}, also known as the \href{https://en.wikipedia.org/wiki/Banach%E2%80%93Steinhaus_theorem}{Banach--Steinhaus theorem}.
\end{enumerate}
Important results of functional analysis include:
\begin{enumerate}
	\item {\bf Uniform bounded principle.} Main article: \href{https://en.wikipedia.org/wiki/Banach-Steinhaus_theorem}{Wikipedia{\tt/}Banach--Steinhause theorem}. The \href{https://en.wikipedia.org/wiki/Uniform_boundedness_principle}{uniform boundedness principle} or \href{https://en.wikipedia.org/wiki/Banach%E2%80%93Steinhaus_theorem}{Banach--Steinhaus theorem} is 1 of the fundamental results in functional analysis. Together with the \href{https://en.wikipedia.org/wiki/Hahn%E2%80%93Banach_theorem}{Hahn--Banach theorem} \& the \href{https://en.wikipedia.org/wiki/Open_mapping_theorem_(functional_analysis)}{opening mapping theorem}, it is considered 1 of the cornerstones of the field. In its basic form, it asserts that for a family of \href{https://en.wikipedia.org/wiki/Continuous_linear_operator}{continuous linear operators} (\& thus bounded operators) whose domain is a \href{https://en.wikipedia.org/wiki/Banach_space}{Banach space}, pointwise boundedness is equivalent to uniform boundedness in operator form. The theorem was 1st published in 1927 by \href{https://en.wikipedia.org/wiki/Stefan_Banach}{\sc Stefan Banach} \& \href{https://en.wikipedia.org/wiki/Hugo_Steinhaus}{\sc Hugo Steinhaus} but it was also proven independently by \href{https://en.wikipedia.org/wiki/Hans_Hahn_(mathematician)}{\sc Hans Hahn}.
	
	\begin{theorem}[Uniform Boundedness Principle]
		Let $X$ be a Banach space \& $Y$ be a \href{https://en.wikipedia.org/wiki/Normed_vector_space}{normed vector space}. Suppose that $F$ is a collection of continuous linear operators from $X\to Y$. If $\forall x\in X$, one has $\sup_{T\in F} \|T(x)\|_Y < \infty$, then $\sup_{T\in F} \|T\|_{B(X,Y)} < \infty$.
	\end{theorem}	
	\item {\bf Spectral theorem.} Main article: \href{https://en.wikipedia.org/wiki/Spectral_theorem}{Wikipedia{\tt/}spectral theorem}. There are many theorems known as the spectral theorem, but one in particular has many applications in functional analysis.
	
	\begin{theorem}[Spectral theorem]
		Let $A$ be a bounded self-adjoint operator on a Hilbert space $H$. Then there is a \href{https://en.wikipedia.org/wiki/Measure_space}{measure space} $(X,\Sigma,\mu)$ \& a real-valued \href{https://en.wikipedia.org/wiki/Ess_sup}{essentially bounded} measurable function $f$ on $X$ \& a unitary operator $U:H\to L_\mu^2(X)$ s.t. $U^\star TU = A$ where $T$ is the \href{https://en.wikipedia.org/wiki/Multiplication_operator}{multiplication operator}: $[T\varphi](x) = f(x)\varphi(x)$, \& $\|T\| = \|f\|_\infty$.
	\end{theorem}
	This is the beginning of the vast research area of functional analysis called \href{https://en.wikipedia.org/wiki/Operator_theory}{operator theory}, see also \href{https://en.wikipedia.org/wiki/Spectral_measure#Spectral_measure}{spectral measure}. There is also an analogous spectral theorem for bounded \href{https://en.wikipedia.org/wiki/Normal_operator}{normal operators} on Hilbert spaces. The only difference in the conclusion is that now $f$ may be complex-valued.
	\item {\bf Hahn--Banach theorem.} Main article: \href{https://en.wikipedia.org/wiki/Hahn%E2%80%93Banach_theorem}{Wikipedia{\tt/}Hahn--Banach theorem}. The Hahn--Banach theorem is a central tool in functional analysis. It allows the extension of \href{https://en.wikipedia.org/wiki/Bounded_operator}{bounded linear functionals} defined on a subspace of some vector space to the whole space, \& it also shows that there are ``enough'' continuous linear functionals defined on every \href{https://en.wikipedia.org/wiki/Normed_vector_space}{normed vector space} to make the study of the \href{https://en.wikipedia.org/wiki/Dual_space}{dual space} ``interesting''.
	
	\begin{theorem}[Hahn--Banach theorem]
		If $p:V\to\mathbb{R}$ is a \href{https://en.wikipedia.org/wiki/Sublinear_function}{sublinear function}, \& $\varphi:U\to\mathbb{R}$ is a \href{https://en.wikipedia.org/wiki/Linear_functional}{linear functional} on a \href{https://en.wikipedia.org/wiki/Linear_subspace}{linear subspace} $U\subseteq V$ which is dominated by $p$ on $U$, i.e., $\varphi(x)\le p(x)$, $\forall x\in U$, then there exists a linear extension $\psi:V\to\mathbb{R}$ of $\varphi$ to the whole space $V$ which is dominated by $p$ on $V$, i.e., there exists a linear functional $\psi$ s.t. $\psi(x) = \varphi(x)$, $\forall x\in U$, $\psi(x)\le p(x)$, $\forall x\in V$.
	\end{theorem}
	\item {\bf Open mapping theorem.} Main article: \href{https://en.wikipedia.org/wiki/Open_mapping_theorem_(functional_analysis)}{Wikipedia{\tt/}open mapping theorem (functional analysis)}. The open mapping theorem, also known as the Banach--Schauder theorem (named after \href{https://en.wikipedia.org/wiki/Stefan_Banach}{\sc Stefan Banach} \& \href{https://en.wikipedia.org/wiki/Juliusz_Schauder}{\sc Juliusz Schauder}), is a fundamental result which states that if a \href{https://en.wikipedia.org/wiki/Bounded_linear_operator}{continuous linear operator} between Banach spaces is surjective then it is an \href{https://en.wikipedia.org/wiki/Open_map}{open map}. More precisely,
	
	\begin{theorem}[Open mapping theorem]
		If $X,Y$ are Banach spaces \& $A:X\to Y$ i a surjective continuous linear operator, then $A$ is an open map (i.e., if $U$ is an open set in $X$, then $A(U)$ is open in $Y$).
	\end{theorem}
	The proof uses the \href{https://en.wikipedia.org/wiki/Baire_category_theorem}{Baire category theorem}, \& completeness of both $X,Y$ is essential to the theorem. The statement of the theorem is no longer true if either space is just assumed to be a \href{https://en.wikipedia.org/wiki/Normed_space}{normed space}, but is true if $X,Y$ are taken to be \href{https://en.wikipedia.org/wiki/Fr%C3%A9chet_space}{Fr\'echet spaces}.
	\item {\bf Closed graph theorem.} Main article: \href{https://en.wikipedia.org/wiki/Closed_graph_theorem}{Wikipedia{\tt/}closed graph theorem}
	
	\begin{theorem}[Closed graph theorem]
		If $X$ is a \href{https://en.wikipedia.org/wiki/Topological_space}{topological space} \& $Y$ is a \href{https://en.wikipedia.org/wiki/Compact_space}{compact} \href{https://en.wikipedia.org/wiki/Hausdorff_space}{Hausdorff space}, then the graph of a linear map $T:X\to Y$ is closed iff $T$ is continuous.
	\end{theorem}
	\item Other topics, see \href{https://en.wikipedia.org/wiki/List_of_functional_analysis_topics}{Wikipedia{\tt/}list of functional analysis topics}.
\end{enumerate}

\subsubsection{Foundations of mathematics considerations}
Most spaces considered in functional analysis have infinite dimension. To show the existence of a \href{https://en.wikipedia.org/wiki/Vector_space_basis}{vector space basis} for such spaces may require \href{https://en.wikipedia.org/wiki/Zorn%27s_lemma}{Zorn's lemma}. However, a somewhat different concept, the \href{https://en.wikipedia.org/wiki/Schauder_basis}{Schauder basis}, is usually more relevant in functional analysis. Many theorems require the Hahn--Banach theorem, usually proved using the \href{https://en.wikipedia.org/wiki/Axiom_of_choice}{axiom of choice}, although the strictly weaker \href{https://en.wikipedia.org/wiki/Boolean_prime_ideal_theorem}{Boolean prime ideal theorem} suffices. The \href{https://en.wikipedia.org/wiki/Baire_category_theorem}{Baire category theorem}, needed to prove many important theorems, also requires a form of axiom of choice.

\subsubsection{Point of view}
Functional analysis includes the following tendencies:
\begin{itemize}
	\item {\it Abstract analysis.} An approach to analysis based on \href{https://en.wikipedia.org/wiki/Topological_group}{topological groups}, \href{https://en.wikipedia.org/wiki/Topological_ring}{topological rings}, \& \href{https://en.wikipedia.org/wiki/Topological_vector_space}{topological vector spaces}.
	\item {\it Geometry of \href{https://en.wikipedia.org/wiki/Banach_space}{Banach spaces}} contains many topics. One is \href{https://en.wikipedia.org/wiki/Combinatorial}{combinatorial} approach connected with \href{https://en.wikipedia.org/wiki/Jean_Bourgain}{\sc Jean Bourgain}, another is a characterization of Banach spaces in which various forms of the \href{https://en.wikipedia.org/wiki/Law_of_large_numbers}{law of large numbers} hold.
	\item \href{https://en.wikipedia.org/wiki/Noncommutative_geometry}{\it Noncommutative geometry}. Developed by \href{https://en.wikipedia.org/wiki/Alain_Connes}{\sc Alain Connes}, partly building on earlier notions, e.g. \href{https://en.wikipedia.org/wiki/George_Mackey}{\sc George Mackey}'s approach to \href{https://en.wikipedia.org/wiki/Ergodic_theory}{ergodic theory}.
	\item {\it Connection with \href{https://en.wikipedia.org/wiki/Quantum_mechanics}{quantum mechanics}.} Either narrowly defined as in \href{https://en.wikipedia.org/wiki/Mathematical_physics}{mathematical physics}, or broadly interpreted by, e.g., \href{https://en.wikipedia.org/wiki/Israel_Gelfand}{\sc Israel Gelrand}, to include most types of \href{https://en.wikipedia.org/wiki/Representation_theory}{representation theory}.'' -- \href{https://en.wikipedia.org/wiki/Functional_analysis}{Wikipedia{\tt/}functional analysis}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}heat equation}
``{\sf Animated plot of the evolution of the temperature in a square metal plate as predicted by the heat equation. The height \& redness indicate the temperature at each point. The initial state has a uniformly hot hoof-shaped region (red) surrounded by uniformly cold region (yellow). As time passes the heat diffuses into the cold region.} In mathematics \& physics, the {\it heat equation} is a certain PDE. Solutions of the heat equation are sometimes known as {\it caloric functions}. The theory of the heat equation was 1st developed by \href{https://en.wikipedia.org/wiki/Joseph_Fourier}{\sc Joseph Fourier} in 1822 for the purpose of modeling how a quantity e.g. \href{https://en.wikipedia.org/wiki/Heat}{heat} diffuses through a given region. Since then, the heat equation \& its variants have been found to be fundamental in many parts of both pure \& applied mathematics.

\subsubsection{Statement of equation}
In mathematics, if given an open subsets $U$ of $\mathbb{R}^d$ \& a subinterval $I$ of $\mathbb{R}$, one says that a function $u:I\times U\to\mathbb{R}$ is a solution of the {\it heat equation} if
\begin{equation}
	\label{heat}
	\partial_tu = \Delta u = \sum_{i=1}^d \partial_i^2u,
\end{equation}
where $(t,x_1,\ldots,x_d)$ denotes a general point of the domain. It is typical to refer to $t$ as ``time'' \& $x_1,\ldots,x_d$ as ``spatial variables'', even in abstract contexts where these phrases fail to have their intuitive meaning. The collection of spatial variables is often referred to simply as $x$. For any given value of $t$, the RHS of equation is the Laplacian of function $u(t,\cdot):U\to\mathbb{R}$.

In physics \& engineering contexts, especially in the context of diffusion through a medium, it is more common to fix a \href{https://en.wikipedia.org/wiki/Cartesian_coordinate_system}{Cartesian coordinate system} \& then to consider the specific case of a function $u(t,x,y,z)$ of 3 spatial variables $(x,y,z)$ \& time variable $t$. One then says that $u$ is a solution of the heat equation if $\partial_tu = \alpha(\partial_x^2u + \partial_y^2u + \partial_z^2u)$ in which $\alpha$ is a positive coefficient called the \href{https://en.wikipedia.org/wiki/Thermal_diffusivity}{thermal diffusivity} of the medium. In addition to other physical phenomena, this equation describes the flow of heat in a homogeneous \& isotropic medium, with $u(t,x,y,z)$ being the temperature at the point $(x,y,z)$ \& time $t$. If the medium is not homogeneous \& isotropic, then $\alpha$ would not be a fixed coefficient, \& would instead depend on $(x,y,z)$; the equation would also have a slightly different form. In the physics \& engineering literature, it is common to use $\nabla^2$ to denote Laplacian, rather than $\Delta$.

In mathematics as well as in physics \& engineering, it is common to use \href{https://en.wikipedia.org/wiki/Newton%27s_notation}{Newton's notation} for time derivatives, so that $\dot{u}$ is used to denote $\partial_tu$, so the equation can be written $\dot{u} = \Delta u$. Note also that the ability to use either $\Delta$ or $\nabla^2$ to denote the Laplacian, without explicit reference to the spatial variables, is a reflection of the fact that the Laplacian is independent of the choice of coordinate system. In mathematical terms, one would say that the Laplacian is ``translationally \& rotationally invariant''. In fact, it is (loosely speaking) the simplest differential operator which has these symmetries. This can be taken as a significant (\& purely mathematical) justification of the use of Laplacian \& of heat equation in modeling any physical phenomena which are homogeneous \& isotropic, of which heat diffusion is a principal example.

The ``diffusivity constant'' $\alpha$ is often not present in mathematical studies of the heat equation, while its value can be very important in engineering. This is not a major difference, for the following reason. Let $u$ be a function with $\partial_tu = \alpha\Delta u$. Define a new function $v(t,x) = u(\frac{t}{\alpha},x)$. Then, according to the \href{https://en.wikipedia.org/wiki/Chain_rule}{chain rule}, one has $\partial_tv(t,x) = \cdots = \Delta u(\frac{t}{\alpha},x) = \Delta v(t,x)$. Thus, there is a straightforward way of translating between solutions of the heat equation with a general value of $\alpha$ \& solutions of the heat equation with $\alpha = 1$. As such, for sake of mathematical analysis, it is often sufficient to only consider the case $\alpha = 1$.

Since $\alpha > 0$ there is another option to define a $v$ satisfying $\partial_tv = \Delta v$ by setting $v(t,x) = u(t,\alpha^{\frac{1}{2}}x)$. Note that 2 possible means of defining the new function $v$ discussed here amount, in physical terms, to changing the unit of measure of time or the unit of measure of length.

\subsubsection{Interpretation}

\begin{enumerate}
	\item {\bf Physical interpretation of equation.} Informally, the Laplacian operator $\Delta$ gives the difference between the average value of a function in the neighborhood of a point, \& its value at that point. Thus, if $u$ is the temperature, $\Delta u$ tells (\& by how much) the material surrounding each point is hotter or colder, on the average, than the material at that point.
	
	By the \href{https://en.wikipedia.org/wiki/Second_law_of_thermodynamics}{2nd law of thermodynamics}, heat will flow from hotter bodies to adjacent colder bodies, in proportion to the difference of temperature \& of the \href{https://en.wikipedia.org/wiki/Thermal_conductivity}{thermal conductivity} of the material between them. When heat flows into (resp., out of) a material, its temperature increases (resp., decreases), in proportion to the amount of heat divided by the amount (\href{https://en.wikipedia.org/wiki/Mass}{mass}) of material, with a \href{https://en.wikipedia.org/wiki/Proportionality_(mathematics)}{proportionality factor} called the \href{https://en.wikipedia.org/wiki/Specific_heat_capacity}{specific heat capacity} of the material.
	
	By the combination of these observations, the heat equation says the rate $\dot{u}$ at which the material at a point will heat up (or cool down) is proportional to how much hotter (or cooler) the surrounding material is. The coefficient $\alpha$ in the equation takes into account the thermal conductivity, specific heat, \& \href{https://en.wikipedia.org/wiki/Density}{density} of the material.
	\item {\bf Interpretation of equation.} The 1st half of the above physical thinking can be put into a mathematical form. The key is that, for any fixed $x$, one has $u_{(x)}(0) = u(x)$, $u_{(x)}'(0) = 0$, $u_{(x)}''(0) = \frac{1}{n}\Delta u(x)$ where $u_{(x)}(r)$ is the single-variable function denoting the {\it average value} of $u$ over the surface of the sphere of radius $r$ centered at $x$; it can be defined by $u_{(x)}(r)\coloneqq\frac{1}{\omega_{d - 1}r^{d - 1}}\int_{\{y;|x - y| = r\}} u\,{\rm d}\mathcal{H}^{d - 1}$, in which $\omega_{d - 1}$ denotes the surface area of the unit ball in $d$-dimensional Euclidean space. This formalizes the above statement that the value of $\Delta u$ at a point $x$ measures the difference between the value of $u(x)$ \& the value of $u$ at point nearby to $x$, in the sense that the latter is encoded by the values of $u_{(x)}(r)$ for small positive values of $f$.
	
	Following this observation, one may interpret the heat equation as imposing an {\it infinitesimal averaging} of a function. Given a solution of the heat equation, the value of $u(t + \tau,x)$ for a small positive value of $\tau$ may be approximated as $\frac{1}{2n}$ times the average value of the function $u(t,\cdot)$ over a sphere of very small radius centered at $x$.
	\item {\bf Character of solutions.} {\sf Solution of a 1D heat PDE. The temperature $u$ is initially distributed over a 1D, 1-unit-long interval $x = [0,1]$ with insulated endpoints. The distribution approaches equilibrium over time. The behavior of temperature when the sides of a 1D rode are at fixed temperatures (in this case, $0.8$ \& 0 with initial Gaussian distribution). The temperature approaches a linear function because that is the stable solution of the equation: wherever temperature has a nonzero 2nd spatial derivative, the time derivative is nonzero as well.} The heat equation implies that peaks (\href{https://en.wikipedia.org/wiki/Local_maximum}{local maxima}) of $u$ will be gradually eroded down, with depressions (\href{https://en.wikipedia.org/wiki/Local_minimum}{local minima}) will be filled in. The value at some point will remain stable only as long as it is equal to the average value in its immediate surroundings. In particular, if the values in a neighborhood are very close to a linear function $Ax + By + Cz + D$, then the value at the center of that neighborhood will not be changing at that time (i.e., the derivative $\dot{u}$ will be 0).
	
	A more subtle consequence is the \href{https://en.wikipedia.org/wiki/Maximum_principle}{maximum principle}: the maximum value of $u$ in any region $R$ of the medium will not exceed the maximum value that previously occurred in $R$, unless it is on the boundary of $R$. I.e., the maximum temperature in a region $R$ can increase only if heat comes in from outside $R$. This is a property of \href{https://en.wikipedia.org/wiki/Parabolic_partial_differential_equation}{parabolic PDEs} \& is not difficult to prove mathematically.
	
	Another interesting property is that even if $u$ initially has a sharp jump (discontinuity) of value across some surface inside the medium, the jump is immediately smoothed out by a momentary, infinitesimally short but infinitely large rate of flow of heat through that surface. E.g., if 2 isolated bodies, initially at uniform but different temperatures $u_0,u_1$, are made to touch each other, the temperature at the point of contact will immediately assume some intermediate value, \& a zone will develop around that point where $u$ will gradually vary between $u_0,u_1$. If a certain amount of heat is suddenly applied to a point in the medium, it will spread out in all directions in the form of a diffusion wave. Unlike the \href{https://en.wikipedia.org/wiki/Mechanical_wave}{elastic} \& \href{https://en.wikipedia.org/wiki/Electromagnetic_wave}{electromagnetic waves}, the speed of a diffusion wave drops with time: as it spreads over a larger region, the temperature gradient decreases, \& therefore the heat flow decreases too.
\end{enumerate}

\subsubsection{Specific examples}

\begin{enumerate}
	\item {\bf Heat flow in a uniform rod.}For heat flow, the heat equation follows from the physical laws of \href{https://en.wikipedia.org/wiki/Conduction_(heat)}{conduction of heat} \& \href{https://en.wikipedia.org/wiki/Conservation_of_energy}{conservation of energy} (Cannon1984). By \href{https://en.wikipedia.org/wiki/Thermal_conduction#Fourier's_law}{Fourier's law} for an isotropic medium, the rate of flow of heat energy per unit area through a surface is proportional to the negative temperature gradient across it: ${\bf q} = k\nabla u$ where $k$ is the \href{https://en.wikipedia.org/wiki/Thermal_conductivity}{thermal conductivity} of the material, $u = u(t,{\bf x})$ is the temperature, \& ${\bf q} = {\bf q}(t,{\bf x})$ is a vector field representing the magnitude \& direction of the heat flow at the point ${\bf x}$ of space \& time $t$. [$\ldots$]
	\begin{itemize}
		\item {\bf Accounting for radiative loss.}
		\item {\bf Non-uniform isotropic medium.}
	\end{itemize}
	\item {\bf3D problem.}
	\item {\bf Internal heat generation.}
\end{enumerate}

\subsubsection{Solving heat equation using Fourier series}

\subsubsection{Heat conduction in nonhomogeneous anisotropic media}

\subsubsection{Fundamental solutions}

\subsubsection{Mean-value property for heat equation}

\subsubsection{Steady-state heat equation}
The steady-state heat equation is by definition not dependent on time. I.e., it is assumed condition exist s.t. $\partial_tu = 0$. This condition depends on the time constant \& the amount of time passed since boundary conditions have been imposed. Thus, the condition is fulfilled in situations in which the {\it time equilibrium constant is fast enough} that the more complex time-dependent heat equation can be approximated by the steady-state case. Equivalently, the steady-state condition exists for all cases in which {\it enough time has passed} that the thermal field ${\bf u}$ no longer evolves in time.

In the steady-state case, a spatial thermal gradient may (or may not) exist, but if it does, it does not change in time. This equation therefore describes the end result in all thermal problems in which a source is switched (e.g., an engine started in an automobile), \& enough time has passed for all permanent temperature gradients to establish themselves in space, after which these spatial gradients no longer change in time (as again, with an automobile in which the engine has been running for long enough). The other (trivial) solution is for all spatial temperature gradients to disappear as well, in which case the temperature become uniform in space, as well.

The equation is much simpler \& can help to understand better the physics of the materials without focusing on the dynamics of the heat transport process. It is widely used for simple engineering problems assuming there is equilibrium of the temperature fields \& heat transport, with time.

Steady-state condition $\partial_tu = 0$. The steady-state heat equation for a volume that contains a heat source (the inhomogeneous case), is the \href{https://en.wikipedia.org/wiki/Poisson%27s_equation}{Poisson's equation} $-k\Delta u = q$ where $u$: \href{https://en.wikipedia.org/wiki/Thermodynamic_temperature}{temperature}, $k$: \href{https://en.wikipedia.org/wiki/Thermal_conductivity}{thermal conductivity}, \& $q$: rate of heat generation per unit volume.

In \href{https://en.wikipedia.org/wiki/Electrostatics}{electrostatics}, this is equivalent to the case where the space under consideration contains an electrical charge. The steady-state heat equation without a heat source within the volume (the homogeneous case) is the equation in electrostatics for a volume of free space that does not contain a charge. It is described by \href{https://en.wikipedia.org/wiki/Laplace%27s_equation}{Laplace's equation} $\Delta u = 0$.

\subsubsection{Applications}
As the prototypical \href{https://en.wikipedia.org/wiki/Parabolic_partial_differential_equation}{parabolic PDE}, the heat equation is among the worst widely studied topics in pure mathematics, \& its analysis is regarded as fundamental to the broader field of PDEs. The heat equation can also be considered on \href{https://en.wikipedia.org/wiki/Riemannian_manifold}{Riemannian manifolds}, leading to many geometric applications. Following work of \href{https://en.wikipedia.org/wiki/Subbaramiah_Minakshisundaram}{\sc Subbaramiah Minakshisundaram} \& \href{https://en.wikipedia.org/wiki/%C3%85ke_Pleijel}{\sc Ake Pleijel}, the heat equation is closely related with \href{https://en.wikipedia.org/wiki/Spectral_geometry}{spectral geometry}. A seminal \href{https://en.wikipedia.org/wiki/Harmonic_map}{nonlinear variant of heat equation} was introduced to \href{https://en.wikipedia.org/wiki/Differential_geometry}{differential geometry} by \href{https://en.wikipedia.org/wiki/James_Eells}{\sc James Eells} \& \href{https://en.wikipedia.org/wiki/Joseph_H._Sampson}{\sc Joseph Sampson} in 1964, inspiring the introduction of the \href{https://en.wikipedia.org/wiki/Ricci_flow}{Ricci flow} by \href{https://en.wikipedia.org/wiki/Richard_S._Hamilton}{\sc Richard Hamilton} in 1982 \& culminating in the proof of the \href{https://en.wikipedia.org/wiki/Poincar%C3%A9_conjecture}{Poincar\'e conjecture} by \href{https://en.wikipedia.org/wiki/Grigori_Perelman}{\sc Grigori Perelman} in 2003. Certain solutions of the heat equation known as \href{https://en.wikipedia.org/wiki/Heat_kernel}{heat kernels} provide subtle information about the region on which they are defined, as exemplified through their application to the \href{https://en.wikipedia.org/wiki/Atiyah%E2%80%93Singer_index_theorem}{Atiyah--Singer index theorem}.

The heat equation, along with variants thereof, is also important in many fields of science \& applied mathematics. In \href{https://en.wikipedia.org/wiki/Probability_theory}{probability theory}, the heat equation is connected with the study of \href{https://en.wikipedia.org/wiki/Random_walk}{random walks} \& \href{https://en.wikipedia.org/wiki/Brownian_motion}{Brownian motion} via the \href{https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation}{Fokker--Planck equation}. The \href{https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_equation}{Black--Scholes equation} of \href{https://en.wikipedia.org/wiki/Financial_mathematics}{financial mathematics} is a smart variant of the heat equation, \& the \href{https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation}{Schr\"odinger equation} of \href{https://en.wikipedia.org/wiki/Quantum_mechanics}{quantum mechanics} can be regarded as a heat equation in \href{https://en.wikipedia.org/wiki/Imaginary_time}{imaginary time}. In \href{https://en.wikipedia.org/wiki/Image_analysis}{image analysis}, the heat equation is sometimes used to resole pixelation \& to \href{https://en.wikipedia.org/wiki/Edge_detection}{identify edges}. Following \href{https://en.wikipedia.org/wiki/Robert_D._Richtmyer}{\sc Robert Richtmyer} \& \href{https://en.wikipedia.org/wiki/John_von_Neumann}{\sc John von Neumann}'s introduction of ``artificial viscosity'' methods, solutions of heat equations have been useful in the mathematical formulation of \href{https://en.wikipedia.org/wiki/Shock_(fluid_dynamics)}{hydrodynamical shocks}. Solutions of the heat equation have also been given much attention in the numerical analysis literature, beginning in the 1950s with work of {\sc Jim Douglas, D.W. Peaceman, \& Henry Rachford Jr.}
\begin{enumerate}
	\item {\bf Particle diffusion.}
	\item {\bf Brownian motion.}
	\item {\bf Schrödinger equation for a free particle.}
	\item {\bf Thermal diffusivity in polymers.}
	\item {\bf Applications in different areas.} The heat equation arises in the modeling of a number of phenomena \& is often used in \href{https://en.wikipedia.org/wiki/Financial_mathematics}{financial mathematics} in the modeling of \href{https://en.wikipedia.org/wiki/Option_(finance)}{options}. The \href{https://en.wikipedia.org/wiki/Black%E2%80%93Scholes}{Black--Scholes} option pricing model's differential equation can be transformed into the heat equation allowing relatively easy solutions from a familiar body of mathematics. Many of the extensions to the simple option models do not have closed form solutions \& thus must be solved numerically to obtain a modeled option price. The equation describing pressure diffusion in a porous medium is identical in form with the heat equation. Diffusion problems dealing with \href{https://en.wikipedia.org/wiki/Dirichlet_boundary_conditions}{Dirichlet}, \href{https://en.wikipedia.org/wiki/Neumann_boundary_conditions}{Neumann}, \& \href{https://en.wikipedia.org/wiki/Robin_boundary_condition}{Robin boundary conditions} have closed form analytic solutions. The heat equation is also widely used in image analysis({\sc Perona \& Malik} 1990) \& in ML as the driving theory behind \href{https://en.wikipedia.org/wiki/Scale_space}{scale-space} or \href{https://en.wikipedia.org/wiki/Graph_Laplacian}{graph Laplacian} methods. The heat equation can be efficiently solved numerically using the implicit \href{https://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method}{Crank--Nicolson method} of ({\sc Crank \& Nicolson} 1947). This method can be extended to many of the models with no closed form solution.
	
	An abstract form of heat equation on \href{https://en.wikipedia.org/wiki/Manifold}{manifolds} provides a major approach to the \href{https://en.wikipedia.org/wiki/Atiyah%E2%80%93Singer_index_theorem}{Atiyah--Singer index theorem}, \& has led to much further work on heat equations in \href{https://en.wikipedia.org/wiki/Riemannian_geometry}{Riemannian geometry}.'' -- \href{https://en.wikipedia.org/wiki/Heat_equation}{Wikipedia{\tt/}heat equation}
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Helmholtz decomposition}
``In physics \& mathematics, the {\it Helmholtz decomposition theorem} or the {\it fundamental theorem of vector calculus} states that certain differentiable \href{https://en.wikipedia.org/wiki/Vector_field}{vector fields} can be resolved into the sum of an \href{https://en.wikipedia.org/wiki/Irrotational_vector_field}{irrotational} (\href{https://en.wikipedia.org/wiki/Curl_(mathematics)}{curl}-free) vector field \& a \href{https://en.wikipedia.org/wiki/Solenoidal}{solenoidal} (\href{https://en.wikipedia.org/wiki/Divergence}{divergence}-free) vector field. In physics, often only the decomposition of sufficiently smooth, rapidly decaying vector fields in 3D is discussed. It is named after \href{https://en.wikipedia.org/wiki/Hermann_von_Helmholtz}{\sc Hermann von Helmholtz}.

\begin{definition}
	For a vector field ${\bf F}\in C^1(V,\mathbb{R}^n)$ defined on a domain $V\subseteq\mathbb{R}^n$, a \emph{Helmholtz decomposition} is a pair of vector fields ${\bf G}\in C^1(V,\mathbb{R}^n),{\bf R}\in C^1(V,\mathbb{R}^n)$ s.t. ${\bf F}({\bf r}) = {\bf G}({\bf r}) + {\bf R}({\bf r})$, ${\bf G}({\bf r}) = -\nabla\Phi({\bf r})$, $\nabla\cdot{\bf R}({\bf r}) = 0$. Here, $\Phi\in C^2(V,\mathbb{R})$ is a \href{https://en.wikipedia.org/wiki/Scalar_potential}{scalar potential}, $\nabla\Phi$ is its gradient, \& $\nabla\cdot{\bf R}$ is the divergence of the vector field ${\bf R}$. The irrotational vector field ${\bf G}$ is called a \emph{gradient field} \& $\mathbb{R}$ is called a \emph{solenoidal field} or \emph{rotation field}. This decomposition does not exist for all vector fields \& is not unique.
\end{definition}

\subsubsection{History}
The Helmholtz decomposition in 3D was 1st described in 1849 by \href{https://en.wikipedia.org/wiki/George_Gabriel_Stokes}{\sc George Gabriel Stokes} for a theory of \href{https://en.wikipedia.org/wiki/Diffraction}{diffraction}. \href{https://en.wikipedia.org/wiki/Hermann_von_Helmholtz}{\sc Hermann von Helmholtz} published his paper on some \href{https://en.wikipedia.org/wiki/Hydrodynamics}{hydrodynamic} basic equations in 1858, which was part of his research on the \href{https://en.wikipedia.org/wiki/Helmholtz%27s_theorems}{Helmholtz's theorems} describing the motion of fluid in the vicinity of vortex lines. Their derivation required the vector fields to decay sufficiently fast at $\infty$. Later, this condition could be relaxed, \& the Helmholtz decomposition could be extended to higher dimensions. For \href{https://en.wikipedia.org/wiki/Riemannian_manifold}{Riemannian manifolds}, the Helmholtz-Hodge decomposition using \href{https://en.wikipedia.org/wiki/Differential_geometry}{differential geometry} \& \href{https://en.wikipedia.org/wiki/Tensor_calculus}{tensor calculus} was derived.

The decomposition has become an important tool for many problems in \href{https://en.wikipedia.org/wiki/Theoretical_physics}{theoretical physics}, but has also found applications in \href{https://en.wikipedia.org/wiki/Animation}{animation}, \href{https://en.wikipedia.org/wiki/Computer_vision}{computer vision} as well as \href{https://en.wikipedia.org/wiki/Robotics}{robotics}

\subsubsection{3D space}
Many physics textbooks restrict the Helmholtz decomposition to 3D space \& limit its application to vector fields that decay sufficiently fast at $\infty$ or to \href{https://en.wikipedia.org/wiki/Bump_function}{bump functions} that are defined on a \href{https://en.wikipedia.org/wiki/Bounded_domain}{bounded domain}. Then, a \href{https://en.wikipedia.org/wiki/Vector_potential}{vector potential} $A$ can be defined, s.t. the rotation field is given by ${\bf R} = \nabla\times{\bf A}$, using the curl of a vector field.

Let ${\bf F}$ be a vector field on a bounded domain $V\subseteq\mathbb{R}^3$, which is twice continuously differentiable inside $V$, \& let $S$ be the surface that encloses the domain $V$. Then ${\bf F}$ can be decomposed into a curl-free component \& a divergence-free component as \fbox{${\bf F} = -\nabla\Phi + \nabla\times{\bf A}$}. [$\ldots$]

\subsubsection{Generalization to higher dimensions}

\subsubsection{Differential forms}
The \href{https://en.wikipedia.org/wiki/Hodge_decomposition#Hodge_decomposition}{Hodge decomposition} is closely related to the Helmholtz decomposition, generalizing from vector fields on $\mathbb{R}^3$ to \href{https://en.wikipedia.org/wiki/Differential_forms}{differential forms} on a \href{https://en.wikipedia.org/wiki/Riemannian_manifold}{Riemannian manifold} $M$. Most formulations of the Hodge decomposition require $M$ to be \href{https://en.wikipedia.org/wiki/Compact_space}{compact}. Since this is not true of $\mathbb{R}^3$, the Hodge decomposition theorem is not strictly a generalization of the Helmholtz theorem. However, the compactness restriction in the usual formulation of the Hodge decomposition can be replaced by suitable decay assumptions at infinity on the differential forms involved, giving a proper generalization of the Helmholtz theorem.

\subsubsection{Extensions to fields not decaying at infinity}

\subsubsection{Uniqueness of the solution}

\subsubsection{Applications}

\begin{itemize}
	\item {\bf Electrodynamics.} The Helmholtz theorem is of particular interest in \href{https://en.wikipedia.org/wiki/Electrodynamics}{electrodynamics}, since it can be used to write \href{https://en.wikipedia.org/wiki/Maxwell%27s_equations}{Maxwell's equations} in the potential image \& solve them more easily. The Helmholtz decomposition can be used to prove that, given \href{https://en.wikipedia.org/wiki/Electric_current_density}{electric current density} \& \href{https://en.wikipedia.org/wiki/Charge_density}{charge density}, the \href{https://en.wikipedia.org/wiki/Electric_field}{electric field} \& the \href{https://en.wikipedia.org/wiki/Magnetic_flux_density}{magnetic flux density} can be determined. They are unique if the densities vanish at infinity \& one assumes the same for the potentials.
	\item {\bf Fluid dynamics.} In \href{https://en.wikipedia.org/wiki/Fluid_dynamics}{fluid dynamics}, the Helmholtz projection plays an important role, especially for the solvability theory of NSEs. If the Helmholtz projection is applied to the linearized incompressible NSEs, the \href{https://en.wikipedia.org/wiki/Stokes_flow}{Stokes equation} is obtained. This depends only on the velocity of the particles in the flow, but no longer on the static pressure, allowing the equation to be reduced to 1 unknown. However, both equations, the Stokes \& linearization equations, are equivalent. The operator $P\Delta$ is called the \href{https://en.wikipedia.org/wiki/Stokes_operator}{Stokes operator}.
	\item {\bf Dynamical systems theory.} In the theory of \href{https://en.wikipedia.org/wiki/Dynamical_system}{dynamical systems}, Helmholtz decomposition can be used to determine ``quasipotentials'' as well as to compute \href{https://en.wikipedia.org/wiki/Lyapunov_function}{Lyapunov functions} in some cases. 
	\item {\bf Medical Imaging.} In \href{https://en.wikipedia.org/wiki/Magnetic_resonance_elastography}{magnetic resonance elastography}, a variant of MR imaging where mechanical waves are used to probe the viscoelasticity of organs, the Helmholtz decomposition is sometimes used to separate the measured displacement fields into its shear component (divergence-free) \& its compression component (curl-free). In this way, the complex shear modulus can be calculated without contributions from compression waves.
	\item {\bf Computer animation \& robotics.} The Helmholtz decomposition is also used in the field of computer engineering. This includes robotics, image reconstruction but also computer animation, where the decomposition is used for realistic visualization of fluids or vector fields.'' -- \href{https://en.wikipedia.org/wiki/Helmholtz_decomposition}{Wikipedia{\tt/}Helmholtz decomposition}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}integral operator}
``An {\it integral operator} is an \href{https://en.wikipedia.org/wiki/Operator_(mathematics)}{operator} that involves \href{https://en.wikipedia.org/wiki/Integral}{integration}. Special instances are:
\begin{itemize}
	\item The operator of integration itself, denoted by the \href{https://en.wikipedia.org/wiki/Integral_symbol}{integral symbol}
	\item \href{https://en.wikipedia.org/wiki/Integral_linear_operator}{Integral linear operators}, which are \href{https://en.wikipedia.org/wiki/Linear_operator}{linear operators} induced by \href{https://en.wikipedia.org/wiki/Bilinear_form}{bilinear forms} involving integrals
	\item \href{https://en.wikipedia.org/wiki/Integral_transform}{Integral transforms}, which are maps between 2 \href{https://en.wikipedia.org/wiki/Function_space}{function spaces}, which involve integrals.'' -- \href{https://en.wikipedia.org/wiki/Integral_operator}{Wikipedia{\tt/}integral operator}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}integral transform}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item {\sc Đặng Đình Áng}. {\it Biến Đổi Tích Phân}.
\end{enumerate}
``In mathematics, an {\it integral transform} is a type of \href{https://en.wikipedia.org/wiki/Transform_(mathematics)}{transform} that maps a \href{https://en.wikipedia.org/wiki/Function_(mathematics)}{function} from its original \href{https://en.wikipedia.org/wiki/Function_space}{function space} into another function space via \href{https://en.wikipedia.org/wiki/Integral}{integration}, where some of the properties of the original function might be more easily characterized \& manipulated than in the original function space. The transformed function can generally be mapped back to the original function space using the {\it inverse transform}.

\subsubsection{General form}
An integral transform is any transform $T$ of the form $(Tf)(u) = \int_{t_1}^{t_2} f(t)K(t,u)\,{\rm d}t$. The input of this transform is a function $f$, \& the output is another function $Tf$. An integral transform is a particular kind of mathematical operator. There are numerous useful integral transforms. Each is specified by a choice of the function $K$ of 2 variables, called the {\it kernel} or {\it nucleus} (hạt nhân) of the transform.

Some kernels have an associated {\it inverse kernel} $K^{-1}(u,t)$ which (roughly speaking) yields an inverse transform: $f(t) = \int_{t_1}^{t_2} (Tf)(u)K^{-1}(u,t)\,{\rm d}u$. A {\it symmetric kernel} is one that is unchanged when the 2 variables are permuted; it is a kernel function $K$ s.t. $K(t,u) = K(u,t)$. In the theory of integral equations, symmetric kernels corresponds to \href{https://en.wikipedia.org/wiki/Self-adjoint_operators}{self-adjoint operators}.

\subsubsection{Motivation}
There are many classes of problems that are difficult to solve -- or at least quite unwieldy algebraically -- in their original representations. An integral transform ``maps'' an equation from its original ``domain'' into another domain, in which manipulating \& solving the equation may be much easier than in the original domain. The solution can then be mapped back to the original domain with the inverse of the integral transform.

There are many applications of probability that rely on integral transforms, such as ``pricing kernel'' or \href{https://en.wikipedia.org/wiki/Stochastic_discount_factor}{stochastic discount factor}, or the smoothing of data recovered from robust statistics, see \href{https://en.wikipedia.org/wiki/Kernel_(statistics)}{kernel (statistics)}.

\subsubsection{History}
The precursor of the transforms were the \href{https://en.wikipedia.org/wiki/Fourier_series}{Fourier series} to express functions in finite intervals. Later the \href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier transform} was developed to remove the requirement of finite intervals.

Using the Fourier series, just about any practical function of time (e.g., the \href{https://en.wikipedia.org/wiki/Voltage}{voltage} across the terminals of an \href{https://en.wikipedia.org/wiki/Electronic_device}{electronic device}) can be represented as a sum of sines \& cosines, each suitably scaled (multiplied by a constant factor), shifted (advanced or retarded in time) \& ``squeezed'' or ``stretched'' (increasing or decreasing the frequency). The sines \& cosines in the Fourier series are an example of an \href{https://en.wikipedia.org/wiki/Orthonormal_basis}{orthonormal basis}.

\subsubsection{Usage example}
As an example of an application of integral transforms, consider the \href{https://en.wikipedia.org/wiki/Laplace_transform}{Laplace transform}. This is a technique that maps \href{https://en.wikipedia.org/wiki/Differential_equation}{differential} or \href{https://en.wikipedia.org/wiki/Integro-differential_equation}{integro-differential equations} in the \href{https://en.wikipedia.org/wiki/Time_domain}{``time'' domain} into polynomial equations in what is termed the \href{https://en.wikipedia.org/wiki/Frequency_domain}{``complex frequency'' domain}. (Complex frequency is similar to actual, physical frequency but rather more general. Specifically, the imaginary component $\omega$ of the complex frequency $s = -\sigma + i\omega$ corresponds to the usual concept of frequency, viz., the rate at which a sinusoid cycles, whereas the real component $\sigma$ of the complex frequency corresponds to the degree of ``damping'', i.e., an exponential decrease of the amplitude.) The equation cast in terms of complex frequency is readily solved in the complex frequency domain (roots of the polynomial equations in the complex frequency domain correspond to \href{https://en.wikipedia.org/wiki/Eigenvalues}{eigenvalues} in the time domain), leading to a ``solution'' formulated in the frequency domain. Employing the \href{https://en.wikipedia.org/wiki/Inverse_Laplace_transform}{inverse transform}, i.e., the inverse procedure of the original Laplace transform, one obtains a time-domain solution. In this example, polynomials in the complex frequency domain (typically occurring in the denominator) correspond to \href{https://en.wikipedia.org/wiki/Power_series}{power series} in the time domain, while axial shifts in the complex frequency domain correspond to damping by decaying exponentials in the time doamin.

The Laplace transform finds wide application in physics \& particularly in electrical engineering, where the \href{https://en.wikipedia.org/wiki/Characteristic_equation_(calculus)}{characteristic equations} that describe the behavior of an electric circuit in the complex frequency domain correspond to linear combinations of exponentially scaled \& time-shifted \href{https://en.wikipedia.org/wiki/Damped_sinusoid}{damped sinusoids} in the time domain. Other integral transforms find special applicability within other scientific \& mathematical disciplines.

Another usage example is the kernel in the \href{https://en.wikipedia.org/wiki/Path_integral_formulation#Path_integral_in_quantum_mechanics}{path integral} $\psi(t,x)\coloneqq\int_\mathbb{R} \psi(t',x')K(t,x;t',x')\,{\rm d}x'$. This states that the total amplitude $\psi(t,x)$ to arrive at $(t,x)$ is the sum (the integral) over all possible values $x'$ of the total amplitude $\psi(t',x')$ to arrive at the point $(t',x')$ multiplied by the amplitude to go from $x'$ to $x$, i.e. $K(t,x;t',x')$. It is often referred to as the \href{https://en.wikipedia.org/wiki/Propagator}{propagator} for a given system. This (physics) kernel is the kernel of the integral transform. However, for each quantum system, there is a different kernel.

\subsubsection{Table of transforms}

\begin{enumerate}
	\item \href{https://en.wikipedia.org/wiki/Abel_transform}{Abel transform}
	\item Associated Legendre transform 
	\item \href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier transform}
	\item \href{https://en.wikipedia.org/wiki/Fourier_sine_transform}{Fourier sine transform}
	\item \href{https://en.wikipedia.org/wiki/Fourier_cosine_transform}{Fourier cosine transform}
	\item \href{https://en.wikipedia.org/wiki/Hankel_transform}{Hankel transform}
	\item \href{https://en.wikipedia.org/wiki/Hartley_transform}{Hartley transform}
	\item \href{https://en.wikipedia.org/wiki/Hermite_transform}{Hermite transform}
	\item \href{https://en.wikipedia.org/wiki/Hilbert_transform}{Hilbert transform}
	\item \href{https://en.wikipedia.org/wiki/Jacobi_transform}{Jacobi transform}
	\item \href{https://en.wikipedia.org/wiki/Laguerre_transform}{Laguerre transform}
	\item \href{https://en.wikipedia.org/wiki/Laplace_transform}{Laplace transform}
	\item \href{https://en.wikipedia.org/wiki/Legendre_transform_(integral_transform)}{Legendre transform}
	\item \href{https://en.wikipedia.org/wiki/Mellin_transform}{Mellin transform}
	\item \href{https://en.wikipedia.org/wiki/Two-sided_Laplace_transform}{2-sided Laplace transform}
	\item \href{https://en.wikipedia.org/wiki/Poisson_kernel}{Poisson kernel}
	\item \href{https://en.wikipedia.org/wiki/Radon_transform}{Radon transform}
	\item \href{https://en.wikipedia.org/wiki/Weierstrass_transform}{Weierstrass transform}
	\item \href{https://en.wikipedia.org/wiki/X-ray_transform}{X-ray transform}
\end{enumerate}
In the limits of integration for the inverse transform, $c$ is a constant which depends on the nature of the transform function. E.g., for the 1- \& 2-sided Laplace transform, $c$ must be greater than the largest real part of the zeros of the transform function. Note that there are alternative notations \& conventions for the Fourier transform.

\subsubsection{Different domains}
Here integral transforms are defined for functions on $\mathbb{R}$, but they can be defined more generally for functions on a group.
\begin{itemize}
	\item If instead one uses functions on the circle (periodic functions), integration kernels are then biperiodic functions; convolution by functions on the circle yields \href{https://en.wikipedia.org/wiki/Circular_convolution}{circular convolution}.
	\item If one uses functions on the \href{https://en.wikipedia.org/wiki/Cyclic_group}{cyclic group} of order $n$ ($C_n$ or $\mathbb{Z}/n\mathbb{Z}$), one obtains $n\times n$ matrices as integration kernels; convolution corresponds to \href{https://en.wikipedia.org/wiki/Circulant_matrices}{circulant matrices}.
\end{itemize}

\subsubsection{General theory}
Although the properties of integral transforms vary widely, they have some properties in common. E.g., every integral transform is a \href{https://en.wikipedia.org/wiki/Linear_operator}{linear operator}, since the integral is a linear operator, \& in fact if the kernel is allowed to be a \href{https://en.wikipedia.org/wiki/Generalized_function}{generalized function} then all linear operators are integral transforms (a properly formulated version of this statement is the \href{https://en.wikipedia.org/wiki/Schwartz_kernel_theorem}{Schwartz kernel theorem}).

The general theory of such \href{https://en.wikipedia.org/wiki/Integral_equation}{integral equations} is known as \href{https://en.wikipedia.org/wiki/Fredholm_theory}{Fredholm theory}. In this theory, the kernel is understood to be a \href{https://en.wikipedia.org/wiki/Compact_operator}{compact operator} acting on a Banach space of functions. Depending on the situation, the kernel is then variously referred to as the \href{https://en.wikipedia.org/wiki/Fredholm_operator}{Fredholm operator}, the \href{https://en.wikipedia.org/wiki/Nuclear_operator}{nuclear operator} or the \href{https://en.wikipedia.org/wiki/Fredholm_kernel}{Fredholm kernel}.'' -- \href{https://en.wikipedia.org/wiki/Integral_transform}{Wikipedia{\tt/}integral transform}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Korteweg--De Vries equation}
``{\sf\href{https://en.wikipedia.org/wiki/Cnoidal_wave}{Cnoidal wave} solution to the Korteweg-De Vries equation, in terms of the square of the \href{https://en.wikipedia.org/wiki/Jacobi_elliptic_function}{Jacobi elliptic function} cn (\& with value of the parameter $m = 0.9$). Numerical solution of the KdV equation $u_t + uu_x + \delta^2u_{xxx} = 0$, $\delta = 0.022$, with an initial condition $u(0,x) = \cos\pi x$. Time evolution was done by the Zabusky--Kruskal scheme. The initial coshine wave evoles into a train of solitary-type waves.} In mathematics, the {\it Korteweg-De Vries (KdV) equation} is a PDE which serves as a \href{https://en.wikipedia.org/wiki/Mathematical_model}{mathematical model} of waves on shallow water surfaces. It is particularly notable as the prototypical example of an \href{https://en.wikipedia.org/wiki/Integrable_system}{integrable PDE} \& exhibits many of the expected behaviors for an integrable PDE, e.g. a large number of explicit solutions, in particular \href{https://en.wikipedia.org/wiki/Soliton}{soliton} solutions, \& an infinite number of \href{https://en.wikipedia.org/wiki/Conserved_quantities}{conserved quantities}, despite the nonlinearity which typically renders PDEs intractable. The KdV can be solved by the \href{https://en.wikipedia.org/wiki/Inverse_scattering_transform}{inverse scattering method} (ISM). In fact, \href{https://en.wikipedia.org/wiki/Clifford_Gardner}{\sc Clifford Gardner}, \href{https://en.wikipedia.org/wiki/John_M._Greene}{\sc John M. Greene}, \href{https://en.wikipedia.org/wiki/Martin_Kruskal}{\sc Martin Kruskal}, \& \href{https://en.wikipedia.org/wiki/Robert_Miura}{\sc Robert Miura} developed the classical inverse scattering method to solve the KdV equation.

The KdV equation was 1st introduced by \href{https://en.wikipedia.org/wiki/Joseph_Valentin_Boussinesq}{\sc Joseph Valentin Boussinesq} (1877), \& rediscovered by \href{https://en.wikipedia.org/wiki/Diederik_Korteweg}{Diederik Korteweg} \& \href{https://en.wikipedia.org/wiki/Gustav_de_Vries}{Gustav de Vries} in 1895, who found the simplest solution, the 1-soliton solution. Understanding of the equation \& behavior of solutions was greatly advanced by the computer simulations of \href{https://en.wikipedia.org/wiki/Norman_Zabusky}{\sc Norman Zabusky} \& Kruskal in 1985 \& then the development of the inverse scattering transform in 1967.

\subsubsection{Definition}
The KdV equation is a PDE modeling (spatially) 1D \href{https://en.wikipedia.org/wiki/Nonlinear}{nonlinear} \href{https://en.wikipedia.org/wiki/Dispersion_relation}{dispersive} \href{https://en.wikipedia.org/wiki/Time_reversibility}{nondissipative} waves described by a function $\phi(t,x)$ adhering to:
\begin{equation}
	\partial_t\phi + \partial_x^3\phi - 6\phi\partial_x\phi = 0,\ t\ge0,x\in\mathbb{R},
\end{equation}
where $\partial_x^3\phi$ accounts for dispersion \& the nonlinear element $\phi\partial_x\phi$ is an \href{https://en.wikipedia.org/wiki/Advection}{advection} term. For modeling shallow water waves, $\phi$ is the height displacement of the water surface from its equilibrium height. The constant 6 in front of the last term is conventional but of no great significance: multiplying $t,x$, \& $\phi$ by constants can be used to make the coefficients of any of the 3 terms equal to any given nonzero constants. {\sf2-soliton solution to the KdV equation.}

\subsubsection{Soliton solutions}

\begin{enumerate}
	\item {\bf1-soliton solution.} Consider solutions in which a fixed wave form (given by $f(X)$) maintains its shape as it travels to the right at \href{https://en.wikipedia.org/wiki/Phase_speed}{phase speed} $c$. Such a solution is given by $\varphi(t,x) = f(x - ct - a) = f(X)$. Substituting it into the KdV equation gives the ODE $-c\frac{df}{dX} + \frac{d^3f}{dX^3} - 6f\frac{df}{dX} = 0$, or, integrating w.r.t. $X$, $-cf + \frac{d^2f}{dX^2} - 3f^2 = A$ where $A$ is a \href{https://en.wikipedia.org/wiki/Constant_of_integration}{constant of integration}. Interpreting the independent variable $X$ above as a virtual time variable, i.e., $f$ satisfies Newton's \href{https://en.wikipedia.org/wiki/Equation_of_motion}{equation of motion} of a particle of unit mass in a cubic potential $V(f) = -(f^3 + \frac{1}{2}cf^2 + Af)$. If $A = 0,c > 0$, then the potential function $V(f)$ has \href{https://en.wikipedia.org/wiki/Local_maximum}{local maximum} at $f = 0$; there is a solution in which $f(X)$ starts at this point at `virtual time' $-\infty$, eventually slides down to the \href{https://en.wikipedia.org/wiki/Local_minimum}{local minimum}, then back up the other side, reaching an equal height, \& then reverses direction, ending up at the \href{https://en.wikipedia.org/wiki/Local_maximum}{local maximum} again at time $\infty$. I.e., $f(X)$ approaches 0 as $X\to-\infty$. This is the characteristic shape of the \href{https://en.wikipedia.org/wiki/Soliton}{\it solitary wave} solution. More precisely, the solution is $\phi(t,x) = -\frac{1}{2}c{\rm sech}^2\left[\frac{\sqrt{c}}{2}(x - ct - a)\right]$ where sech stands for \href{https://en.wikipedia.org/wiki/Hyperbolic_secant}{hyperbolic secant} \& $a$ is an arbitrary constant. This describes a right-moving \href{https://en.wikipedia.org/wiki/Soliton}{soliton} with velocity $c$.
	\item {\bf$N$-soliton solution.} There is a known expression for a solution which is an $N$-soliton solution, which at late times revolves into $N$ separate single solitons. The solution depends on an decreasing positive set of parameters $\chi_1,\ldots,\chi_N > 0$ \& a nonzero set of parameters $\beta_1,\ldots,\beta_N$. The solution is given in the form $\phi(t,x) = -2\partial_x^2\log[\det A(t,x)]$ where the components of the matrix $A(t,x)$ are given by $A_{nm}(t,x)\coloneqq\delta_{nm} + \dfrac{\beta_ne^{8\chi_n^3t}e^{-(\chi_m + \chi_n)x}}{\chi_m + \chi_n}$. This is derived using the inverse scattering method.
\end{enumerate}

\subsubsection{Integrals of motion}
The KdV equation has infinitely many \href{https://en.wikipedia.org/wiki/Integral_of_motion}{integrals of motion}, which do not change with time. They can be given explicitly as $\int_\mathbb{R} P_{2n - 1}(\phi,\partial_x\phi,\partial_x^2\phi,\ldots)\,{\rm d}x$ where the polynomials $P_n$ are defined recursively by
\begin{equation*}
	P_1 = \phi,\ P_n = -\frac{dP_{n-1}}{dx} + \sum_{i=1}^{n-2} P_iP_{n - 1 - i},\ \forall n\ge2.
\end{equation*}
The 1st few integrals of motion are: the mass $\int \phi\,{\rm d}x$, the momentum $\int \phi^2\,{\rm d}x$, the energy $\int 2\phi^3 - (\partial_x\phi)^2\,{\rm d}x$. Only the odd-numbered terms $P_{2n+1}$ result in nontrivial (meaning nonzero) integrals of motion.

\subsubsection{Lax pairs}
The KdV equation $\partial_t\phi = 6\phi\partial_x\phi - \partial_x^3\phi$ can be reformulated as the \href{https://en.wikipedia.org/wiki/Lax_equation}{Lax equation} $L_t = [L,A]\coloneqq LA - AL$ with $L$ a \href{https://en.wikipedia.org/wiki/Sturm%E2%80%93Liouville_operator}{Sturm--Liouville operator} $L = -\partial_x^2 + \phi$, $A = 4\partial_x^3 - 6\phi\partial_x - 3[\partial_x,\phi]$ where $[\partial_x,\phi]$ is the \href{https://en.wikipedia.org/wiki/Commutator#Identities_(ring_theory)}{commutator} s.t. $[\partial_x,\phi]f = f\partial_x\phi$. The Lax pair accounts for the infinite number of \href{https://en.wikipedia.org/wiki/First_integrals}{1st integrals} of the KdV equation. $L$ is the time-independent \href{https://en.wikipedia.org/wiki/Schr%C3%B6dinger_operator}{Schr\"odinger operator} (disregarding constants) with potential $\phi(t,x)$. It can be shown that due to this Lax formulation that in fact the eigenvalues do not depend on $t$.

{\bf0-curvature representation.} Setting the components of the \href{https://en.wikipedia.org/wiki/Lax_pair#zero-curvature_representation}{Lax connection} to be
\begin{equation*}
	L_x = \begin{pmatrix}
		0&1\\\phi - \lambda & 0
	\end{pmatrix},\ L_t = \begin{pmatrix}
		-\phi_x & 2\phi + 4\lambda\\2\phi^2 - \phi_{xx} + 2\phi\lambda - 4\lambda^2 & \phi_x
	\end{pmatrix}
\end{equation*}
the KdV equation is equivalent to the zero-curvature equation for the Lax connection $\partial_tL_x - \partial_xL_t + [L_x,L_t] = 0$.

\subsubsection{Least action principle}
The Korteweg--De Vries equation $\partial_t\phi + 6\phi\partial_x\phi + \partial_x^3\phi = 0$, is the \href{https://en.wikipedia.org/wiki/Euler%E2%80%93Lagrange_equation}{Euler--Lagrange equation} of motion derived from the \href{https://en.wikipedia.org/wiki/Lagrangian_density}{Lagrangian density} $\mathcal{L}\coloneqq\frac{1}{2}\partial_x\psi\partial_t\psi + (\partial_x\psi)^3 - \frac{1}{2}(\partial_x^2\psi)^2$ with $\phi$ defined by $\phi\coloneqq\partial_x\psi$. [Derivation of Euler--Lagrange equations].

\subsubsection{Long-time asymptotics}
It can be shown that any sufficiently fast decaying smooth solution will eventually split into a finite superposition of solitons traveling to the right plus a decaying dispersive part traveling to the left. This was 1st observed by {\sf Zabusky \& Kruskal} (1965) \& can be rigorously proven using the nonlinear \href{https://en.wikipedia.org/wiki/Method_of_steepest_descent}{steepest descent} analysis for oscillatory \href{https://en.wikipedia.org/wiki/Riemann%E2%80%93Hilbert_problem}{Riemann--Hilbert problems}.

\subsubsection{History}
The history of the KdV equation started with experiments by \href{https://en.wikipedia.org/wiki/John_Scott_Russell}{\sc John Scott Russell} in 1834, followed by theoretical investigations by \href{https://en.wikipedia.org/wiki/Lord_Rayleigh}{\sc Lord Rayleigh} \& \href{https://en.wikipedia.org/wiki/Joseph_Boussinesq}{\sc Joseph Boussinesq} around 1870 \&, finally, {\sc Korteweg \& De Vries} in 1895.

The KdV equation was not studied much after this until {\sf Zabusky \& Kruskal} (1965) discovered numerically that its solutions seemed to decompose at large times into a collection of ``solitons'': well separated solitary waves. Moreover, the solitons seems to be almost unaffected in shape by passing through each other (though this could cause a change in their position). They also made the connection to earlier numerical experiments by \href{https://en.wikipedia.org/wiki/Fermi%E2%80%93Pasta%E2%80%93Ulam%E2%80%93Tsingou_problem}{\sc Fermi, Pasta, Ulam, \& Tsingou} by showing that the KdV equation was the \href{https://en.wikipedia.org/wiki/Continuum_limit}{continuum limit} of the \href{https://en.wikipedia.org/wiki/Fermi%E2%80%93Pasta%E2%80%93Ulam%E2%80%93Tsingou_problem}{FPUT} system. Development of the analytic solution by means of the \href{https://en.wikipedia.org/wiki/Inverse_scattering_transform}{inverse scattering transform} was done in 1967 by {\sc Gardner, Greene, Kruskal, \& Miura}. The KdV equation is now seen to be closely connected to \href{https://en.wikipedia.org/wiki/Huygens%27_principle}{Huygens' principle}.

\subsubsection{Applications \& connections}
The KdV equation has several connections to physical problems. In addition to being the governing equation of the string in the \href{https://en.wikipedia.org/wiki/Fermi%E2%80%93Pasta%E2%80%93Ulam%E2%80%93Tsingou_problem}{Fermi--Pasta--Ulam--Tsingou problem} in the continuum limit, it approximately describes the evolution of long, 1D waves in many physical settings, including:
\begin{itemize}
	\item shallow-water waves with weakly nonlinear restoring forces
	\item long \href{https://en.wikipedia.org/wiki/Internal_wave}{internal waves} in a density-stratified \href{https://en.wikipedia.org/wiki/Ocean}{ocean}
	\item \href{https://en.wikipedia.org/wiki/Ion_acoustic_wave}{ion acoustic waves} in a \href{https://en.wikipedia.org/wiki/Plasma_(physics)}{plasma}
	\item \href{https://en.wikipedia.org/wiki/Acoustics}{acoustic} waves on a \href{https://en.wikipedia.org/wiki/Crystal_lattice}{crystal lattice}.
\end{itemize}
The KdV equation can also be solved using the \href{https://en.wikipedia.org/wiki/Inverse_scattering_transform}{inverse scattering transform} e.g. those applied to the \href{https://en.wikipedia.org/wiki/Non-linear_Schr%C3%B6dinger_equation}{nonlinear Schr\"odinger equation}.

{\bf KdV equation \& Gross--Pitaevskii equation.} [$\ldots$] $\lambda = 1$ special case of the generalized stationary \href{https://en.wikipedia.org/wiki/Gross%E2%80%93Pitaevskii_equation}{Gross--Pitaevskii equation} (GPE) $-\partial_x^2\phi - 3\phi^\lambda\phi = \pm\phi$. Therefore, for the certain class of solutions of generalized GPE ($\lambda = 4$ for the true 1D condensate \& $\lambda = 2$ while using the 3D equation in 1D), 2 equations are one. Furthermore, taking the $\lambda = 3$ case with the minus sign \& the $\phi$ real, one obtains an attractive self-interaction that should yield a bright soliton.

\subsubsection{Variations}
Many different variations of the KdV equations have been studied:
\begin{enumerate}
	\item Korteweg–De Vries (KdV): $\partial_tu + \partial_x^3u + 6u\partial_xu = 0$.
	\item KdV (cylindrical) $\partial_tu + \partial_x^3u - 6u\partial_xu + \frac{u}{2t} = 0$.
	\item KdV (deformed)
	\item KdV (generalized) $\partial_tu + \partial_x^3u = \partial_x^5u$.
	\item \href{https://en.wikipedia.org/wiki/Generalized_Korteweg%E2%80%93De_Vries_equation}{KdV (generalized)} $\partial_tu + \partial_x^3u + \partial_xf(u) = 0$.
	\item \href{https://en.wikipedia.org/wiki/Modified_Korteweg-De_Vries_equation}{KdV (modified)} $\partial_tu + \partial_x^3u\pm6u^2\partial_xu = 0$.
	\item \href{https://en.wikipedia.org/wiki/Gardner_equation}{Gardner equation} $\partial_tu + \partial_x^3u - (6\varepsilon^2u^2 + 6u)\partial_xu = 0$.
	\item KdV (modified modified)
	\item KdV (spherical): $\partial_tu + \partial_x^3u - 6u\partial_xu + \frac{u}{t} = 0$.
	\item KdV (super)
	\item KdV (transitional): $\partial_tu + \partial_x^3u - 6f(t)u\partial_xu = 0$.
	\item KdV (variable coefficients): $\partial_tu + \beta t^n\partial_x^3u + \alpha t^nu\partial_xu = 0$.
	\item \href{https://en.wikipedia.org/wiki/Korteweg-de_Vries-Burgers%27_equation}{KdV--Burgers equation}: $\partial_tu + \mu\partial_x^3u + u\partial_xu - \nu\partial_x^2u = 0$.
	\item non-homogeneous KdV: $\partial_tu + \alpha u + \beta\partial_xu + \gamma\partial_x^2u = Ai(x)$, $u(0,x) = f(x)$.'' -- \href{https://en.wikipedia.org/wiki/Korteweg–De_Vries_equation}{Wikipedia{\tt/}Korteweg--De Vries equation}
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Korteweg--de Vries-Burgers' equation}
The {\it Korteweg-de Vries--Burgers equation} is a nonlinear PDE:
\begin{equation}
	\label{KdV Burgers}
	u_t + \alpha u_{xxx} + uu_x - \beta u_{xx} = 0.
\end{equation}
The equation gives a description for nonlinear waves in dispersive-dissipative media by combining the nonlinear \& \href{https://en.wikipedia.org/wiki/Dispersion_relation}{dispersive} elements from the \href{https://en.wikipedia.org/wiki/KdV_equation}{KdV equation} with the \href{https://en.wikipedia.org/wiki/Dissipative_system}{dissipative} element from \href{https://en.wikipedia.org/wiki/Burgers%27_equation}{Burger's equation}. The {\it modified KdV-Burgers equation} can be written as
\begin{equation}
	\label{modified KdV Burgers}
	u_t + \alpha u_{xxx} + u^2u_x - bu_{xx} = 0.
\end{equation}
'' -- \href{https://en.wikipedia.org/wiki/Korteweg-de_Vries-Burgers%27_equation}{Wikipedia{\tt/}Korteweg-de Vries-Burgers' equation}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}modified Korteweg-De Vries equation}
The {\it modified Korteweg–de Vries (KdV) equation} is an \href{https://en.wikipedia.org/wiki/Integrable_system}{integrable} nonlinear PDE:
\begin{equation}
	\label{modified KdV}
	u_t + u_{xxx} + \alpha u^2u_x = 0,
\end{equation}
where $\alpha$ is an arbitrary (nonzero) constant. This is a special case of the \href{https://en.wikipedia.org/wiki/Gardner_equation}{Gardner equation}.'' -- \href{https://en.wikipedia.org/wiki/Modified_Korteweg-De_Vries_equation}{Wikipedia{\tt/}modified Korteweg-De Vries equation}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Lax equivalence theorem}
``In numerical analysis, the {\it Lax equivalence theorem} is a fundamental theorem in the analysis of FDMs for the numerical solution of PDEs. It states that for a \href{https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations#Consistency_and_order}{consistent} FDM for a \href{https://en.wikipedia.org/wiki/Well-posed}{well-posed} linear \href{https://en.wikipedia.org/wiki/Initial_value_problem}{IVP}, the method is \href{https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations#Convergence}{convergent} iff it is \href{https://en.wikipedia.org/wiki/Numerical_stability#Stability_in_numerical_differential_equations}{stable}.

The importance of the theorem is that while the convergence of the solution of the FDM to the solution of the PDE is what is desired, it is ordinarily difficult to establish because the numerical method is defined by a \href{https://en.wikipedia.org/wiki/Recurrence_relation}{recurrence relation} while the differential equation involves a differentiable function. However, consistency -- the requirement that the FDM approximates the correct PDE -- is straightforward to verify, \& stability is typically much easier to show than convergence (\& would be needed in any event to show that \href{https://en.wikipedia.org/wiki/Round-off_error}{round-off error} will not destroy the computation). Hence convergence is usually shown via the Lax equivalence theorem.

Stability in this context means that a \href{https://en.wikipedia.org/wiki/Matrix_norm}{matrix norm} of the matrix used in the iteration is at most \href{https://en.wikipedia.org/wiki/Unity_(mathematics)}{unity}, called (practical) Lax--Richtmyer stability. Often a \href{https://en.wikipedia.org/wiki/Von_Neumann_stability_analysis}{von Neumann stability analysis} is substituted for convenience, although von Neumann stability only implies Lax--Richtmyer stability in certain cases.

This theorem is due to \href{https://en.wikipedia.org/wiki/Peter_Lax}{\sc Peter Lax}, sometimes called the {\it Lax--Richtmyer theorem}, after {\sc Peter Lax} \& \href{https://en.wikipedia.org/wiki/Robert_D._Richtmyer}{\sc Robert D. Richtmyer}.'' -- \href{https://en.wikipedia.org/wiki/Lax_equivalence_theorem}{Wikipedia{\tt/}Lax equivalence theorem}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}level set}
{\sf Points at constant slices of $x_2 = f(x_1)$. Lines at constant slices of $x_3 = f(x_1,x_2)$. Planes at constant slices of $x_4 = f(x_1,x_2,x_3)$. $(n - 1)$-dimensional level sets for functions of the form $f(x_1,\ldots,x_n) = \sum_{i=1}^n a_ix_i = a_1x_1 + \cdots + a_nx_n$ where $a_1,\ldots,a_n$ are constants, in $(n + 1)$-dimensional Euclidean space, for $n = 1,2,3$.} ``In mathematics, a {\it level set} of a \href{https://en.wikipedia.org/wiki/Real-valued_function}{real-valued function} $f$ of $n$ \href{https://en.wikipedia.org/wiki/Function_of_several_real_variables}{real variables} is a set where the function takes on a given constant value $c$, i.e., $L_c(f) = \{(x_1,\ldots,x_n)|f(x_1,\ldots,x_n) = c\}$. When the number of independent variables is 2, a level set is called a {\it level \href{https://en.wikipedia.org/wiki/Curve}{curve}}, also known as \href{https://en.wikipedia.org/wiki/Contour_line}{\it contour line} or {\it isoline}; so a level curve is the set of all real-valued solutions of an equation in 2 variables $x_1,x_2$. When $n = 3$, a level set is called a {\it level \href{https://en.wikipedia.org/wiki/Surface_(mathematics)}{surface}} (or \href{https://en.wikipedia.org/wiki/Isosurface}{\it isosurface}); so a level surface is the set of all real-valued roots of an equation in 3 variables $x_1,x_2,x_3$. For higher values of $n$, the level set is a {\it level \href{https://en.wikipedia.org/wiki/Hypersurface}{hypersurface}}, the set of all real-valued roots of an equation in $n > 3$ variables. A level set is a special case of a \href{https://en.wikipedia.org/wiki/Fiber_(mathematics)}{fiber}. {\sf Contour curves at constant slices of $x_3 = f(x_1,x_2)$. Curved surfaces at constant slices of $x_4 = f(x_1,x_2,x_3)$. $(n - 1)$-dimensional level sets of nonlinear functions $f(x_1,\ldots,x_n)$ in $(n + 1)$-dimensional Euclidean space, for $n = 1,2,3$.}

\subsubsection{Alternative names}
Level sets show up in many applications, often under different names. E.g., an \href{https://en.wikipedia.org/wiki/Implicit_curve}{implicit curve} is a level curve, which is considered independently of its neighbor curves, emphasizing that such a curve is defined by an \href{https://en.wikipedia.org/wiki/Implicit_equation}{implicit equation}. Analogously, a level surface is sometimes called an implicit surface or an \href{https://en.wikipedia.org/wiki/Isosurface}{isosurface}.

The name isocontour is also used, which means a contour of equal height. In various application areas, isocontours have received specific names, which indicate often the nature of the values of the considered function, e.g. \href{https://en.wikipedia.org/wiki/Isobar_(meteorology)}{isobar}, \href{https://en.wikipedia.org/wiki/Isotherm_(contour_line)}{isotherm}, \href{https://en.wikipedia.org/wiki/Contour_line#Types}{isogon}, \href{https://en.wikipedia.org/wiki/Isochrone_map}{isochrone}, \href{https://en.wikipedia.org/wiki/Isoquant}{isoquant} \& \href{https://en.wikipedia.org/wiki/Indifference_curve}{indifference curve}.

\begin{example}
	Consider the 2D Euclidean distance $d(x,y) = \sqrt{x^2 + y^2}$. A level set $L_r(d)$ of this function consists of those points that lie at a distance of $r$ from the origin, that make a circle. E.g., $(3,4)\in L_5(d)$, because $d(3,4) = 5$. Geometrically, this means that the point $(3,4)$ lies on the circle of radius 5 centered at the origin. More generally, a \href{https://en.wikipedia.org/wiki/Sphere}{sphere} in a \href{https://en.wikipedia.org/wiki/Metric_space}{metric space} $(M,m)$ with radius $r$ centered at $x\in M$ can be defined as the level set $L_r(y\mapsto m(x,y))$.
\end{example}

\begin{example}
	{\sf Intersections of a \href{https://en.wikipedia.org/wiki/Co-ordinate}{co-ordinate} function's level surfaces with a \href{https://en.wikipedia.org/wiki/Trefoil_knot}{trefoil knot}.} The plot of \href{https://en.wikipedia.org/wiki/Himmelblau%27s_function}{Himmelblau's function}. Each curve shown is a level curve of the function, \& they are spaced logarithmically: if a curve represents $L_x$, the curve directly ``within'' represents $L_{x/10}$, \& the curve directly ``outside'' represents $L_{10x}$. {\sf Log-spaced level curve plot of Himmelblau's function.}
\end{example}

\subsubsection{Level sets vs. gradient}

\begin{theorem}
	If the function $f$ is differentiable, the gradient of $f$ at a point is either zero, or perpendicular to the level set of $f$ at that point.
\end{theorem}
To understand what this means, imagine that 2 hikers are at the same location on a mountain. 1 of them is bold, \& decides to go in the direction where the slope is steepest. The other one is more cautious \& does not want to either climb or descend, choosing a path which stays at the same height. In our analogy, the above theorem asys that the 2 hikers will depart in directions perpendicular to each other.

A consequence of this theorem (\& its proof) is that $f$ is differentiable, a level set is a \href{https://en.wikipedia.org/wiki/Hypersurface}{hypersurface} \& a manifold outside the \href{https://en.wikipedia.org/wiki/Critical_point_(mathematics)}{critical points} of $f$. At a critical point, a level set may be reduced to a point (e.g., at a \href{https://en.wikipedia.org/wiki/Local_extremum}{local extremum} of $f$) or may have a \href{https://en.wikipedia.org/wiki/Singular_point_of_an_algebraic_variety}{singularity} such as a \href{https://en.wikipedia.org/wiki/Intersection_theory}{self-intersection point} or a \href{https://en.wikipedia.org/wiki/Cusp_(singularity)}{cusp}.

\subsubsection{Sublevel \& superlevel sets}
A set of the form $L_c^-(f)\coloneqq\{(x_1,\ldots,x_n)|f(x_1,\ldots,x_n)\le c\}$ is called a {\it sublevel set} of $f$ (or, alternatively, a {\it lower level set} or {\it trench} of $f$). A {\it strict sublevel} set of $f$ is $\{(x_1,\ldots,x_n)|f(x_1,\ldots,x_n) < c\}$. Similarly $L_c^+(f)\coloneqq\{(x_1,\ldots,x_n)|f(x_1,\ldots,x_n)\ge c\}$ is called a {\it superlevel set} of $f$ (or, alternatively, an {\it upper level set} of $f$). \& a {\it strict superlevel set} of $f$ is $\{(x_1,\ldots,x_n)|f(x_1,\ldots,x_n) > c\}$. Sublevel sets are important in \href{https://en.wikipedia.org/wiki/Mathematical_optimization}{minimization theory}. By \href{https://en.wikipedia.org/wiki/Extreme_value_theorem#Extension_to_semi-continuous_functions}{Weierstrass's theorem}, the \href{https://en.wikipedia.org/wiki/Totally_bounded_set}{boundness} of some nonempty sublevel set \& the lower-semicontinuity of the function implies that a function attains its minimum. The \href{https://en.wikipedia.org/wiki/Convex_set}{convexity} of all the sublevel sets characterizes \href{https://en.wikipedia.org/wiki/Quasiconvex_function}{quasiconvex functions}.'' -- \href{https://en.wikipedia.org/wiki/Level_set}{Wikipedia{\tt/}level set}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}level-set method}
``The {\it level-set method} (LSM) is a conceptual framework for using \href{https://en.wikipedia.org/wiki/Level_set}{level sets} as a tool for \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerical analysis} of \href{https://en.wikipedia.org/wiki/Surface_(topology)}{surfaces} \& \href{https://en.wikipedia.org/wiki/Shape}{shapes}. LSM can perform \href{https://en.wikipedia.org/wiki/Numerical_computation}{numerical computations} involving \href{https://en.wikipedia.org/wiki/Curve}{curves} \& surfaces on a fixed \href{https://en.wikipedia.org/wiki/Cartesian_grid}{Cartesian grid} without having to \href{https://en.wikipedia.org/wiki/Parametric_surface}{parameterize} these objects. LSM makes it easier to perform computations on shapes with sharp corners \& \href{https://en.wikipedia.org/wiki/Shape}{shapes} that change \href{https://en.wikipedia.org/wiki/Topology}{topology} (e.g. by splitting in 2 or developing holes). These characteristics make LSM effective for \href{https://en.wikipedia.org/wiki/Modeling}{modeling} objects that vary in time, such as an \href{https://en.wikipedia.org/wiki/Airbag}{airbag} inflating or a drop of oil floating in water.

\subsubsection{Overview}
A \href{https://en.wikipedia.org/wiki/Bounded_region}{bounded region} with a well-behaved boundary. Below it, the red surface is the graph of a level set function $\varphi$ determining this shape, \& the flat blue region represents the $X$-$Y$ plane. The boundary of the shape is then the zero-level set of $\varphi$, while the shape itself is the set of points in the plane for which $\varphi$ is positive (interior of the shape) or zero (at the boundary).

In the top row, the shape's topology changes as it is split in 2. It is challenging to describe this transformation numerically by \href{https://en.wikipedia.org/wiki/Parametrization_(geometry)}{parameterizing} the boundary of the shape \& following its evolution. An algorithm can be used to detect the moment the shape splits in 2 \& then construct parameterizations for the 2 newly obtained curves. On the bottom row, however, the plane at which the level set function is sampled is translated upwards, on which the shape's change in topology is described. It is less challenging to work with a shape's change in topology is described. It is less challenging to work with a shape through its level-set function rather than with itself directly, in which a method would need to consider all the possible deformations the shape might undergo.

Thus, in 2D, the level-set method amounts to representing a \href{https://en.wikipedia.org/wiki/Closed_curve}{closed curve} $\Gamma$ (e.g. the shape boundary) using an \href{https://en.wikipedia.org/wiki/Auxiliary_function}{auxiliary function} $\varphi$, called the {\it level-set function}. The curve $\Gamma$ is represented as the zero-level set of $\varphi$ by $\Gamma\coloneqq\{(x,y)|\varphi(x,y) = 0\}$, \& the level-set method manipulates $\Gamma$ {\it implicitly} through the function $\varphi$. This function $\varphi$ is assumed to take positive values inside the region delimited by the curve $\Gamma$ \& negative values outside.

\subsubsection{The level-set equation}
If the curve $\Gamma$ moves in the normal direction with a speed $v$, then by chain rule \& implicit differentiation, it can be determined that the level-set function $\varphi$ satisfies the {\it level-set equation} \fbox{$\partial_t\varphi = v|\nabla\varphi|$}. Here, $|\cdot|$ is the \href{https://en.wikipedia.org/wiki/Euclidean_norm}{Euclidean norm} (denoted customarily by single bars in PDEs), \& $t$ is time. This is a PDE, in particular a \href{https://en.wikipedia.org/wiki/Hamilton%E2%80%93Jacobi_equation}{Hamilton--Jacobi equation}, \& can be solved numerically, e.g., by using \href{https://en.wikipedia.org/wiki/Finite_difference}{finite differences} on a Cartesian grid.

However, the numerical solution of the level set equation may require advanced techniques. Simple FDMs fails quickly. \href{https://en.wikipedia.org/wiki/Upwind_scheme}{Upwinding} methods e.g. \href{https://en.wikipedia.org/wiki/Godunov_method}{Godunov method} are considered better; however, the level set method does not guarantee preservative of the volume \& shape of the set level in an advection field that maintains shape \& size, e.g., a uniform or \href{https://en.wikipedia.org/wiki/Rotational_velocity}{rotational velocity} field. Instead, the shape of the level set may become distorted, \& the level set may disappear over a few time steps. Therefore, high-order FDMs, e.g. high-order essentially non-oscillatory (ENO) schemes, are often required, \& even then, the feasibility of long-term simulations is questionable. More advanced methods have been developed ito overcome this; e.g., combinations of the leveling method with tracking marker particles suggested by the velocity field.

\subsubsection{Example}
Consider a unit circle in $\mathbb{R}^2$, shrinking it on itself at a constant rate, i.e., each point on the boundary of the circle moves along its inwards pointing normally at some fixed speed. The circle will shrink \& eventually collapse down to a point. If an initial distance field is constructed (i.e., a function whose value is the signed \href{https://en.wikipedia.org/wiki/Euclidean_distance}{Euclidean distance} to the boundary, positive interior, negative exterior) on the initial circle, the normalized gradient of this field will be the circle normal.

If the field has a constant value subtracted from it in time, the zero level (which was the initial boundary) of the new fields will also be circular \& will similarly collapse to a point. This is due to this being effectively the temporal integration of the \href{https://en.wikipedia.org/wiki/Eikonal_equation}{Eikonal equation} with a fixed front velocity.

\subsubsection{Applications}

\begin{itemize}
	\item In mathematical modeling of \href{https://en.wikipedia.org/wiki/Combustion}{combustion}, LSM is used to describe the instantaneous flame surface, known as \href{https://en.wikipedia.org/wiki/G_equation}{G equation}.
	\item \href{https://en.wikipedia.org/wiki/Level_set_(data_structures)}{Level-set data structures} have been developed to facilitate the use of the level-set method in computer applications.
	\item CFD
	\item \href{https://en.wikipedia.org/wiki/Trajectory}{Trajectory planning}
	\item Optimization
	\item \href{https://en.wikipedia.org/wiki/Image_processing}{Image processing}
	\item \href{https://en.wikipedia.org/wiki/Computational_biophysics}{Computational biophysics}
	\item Discrete \href{https://en.wikipedia.org/wiki/Complex_dynamics}{complex dynamics} (visualization of the \href{https://en.wikibooks.org/wiki/Fractals/Iterations_in_the_complex_plane/Mandelbrot_set}{parameter plane} \& the \href{https://en.wikibooks.org/wiki/Fractals/Iterations_in_the_complex_plane/Julia_set}{dynamic plane})
\end{itemize}

\subsubsection{History}
The level-set method was developed in 1979 by {\sc Alain Dervieux}, \& subsequently popularized by \href{https://en.wikipedia.org/wiki/Stanley_Osher}{\sc Stanley Osher} \& \href{https://en.wikipedia.org/wiki/James_Sethian}{\sc James Sethian}. It has since become popular in many disciplines, e.g., image processing, \href{https://en.wikipedia.org/wiki/Computer_graphics}{computer graphics}, \href{https://en.wikipedia.org/wiki/Computational_geometry}{computational geometry}, optimization, CFDs, \& \href{https://en.wikipedia.org/wiki/Computational_biology}{computational biology}.'' -- \href{https://en.wikipedia.org/wiki/Level-set_method}{Wikipedia{\tt/}level-set method}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}minimal surface}
{\sf A \href{https://en.wikipedia.org/wiki/Helicoid}{helicoid} minimal surface formed by a soap film on a helical frame.} ``In mathematics, a {\it minimal surface} is a surface that locally minimizes its area. This is equivalent to having zero \href{https://en.wikipedia.org/wiki/Mean_curvature}{mean curvature}.

The term ``minimal surface'' is used because these surfaces originally arose as surfaces that minimized total surface area subject to some constraint. Physical models of area-minimizing minimal surfaces can be made by dipping a wire frame into a soap solution, forming a \href{https://en.wikipedia.org/wiki/Soap_film}{soap film}, which is a minimal surface whose boundary is the wire frame. However, the term is used for more general surfaces that may \href{https://en.wikipedia.org/wiki/Immersed_submanifold#Immersed_submanifolds}{self-intersect} or do not have constraints. For a given constraint there may also exist several minimal surfaces with different areas (e.g., see \href{https://en.wikipedia.org/wiki/Minimal_surface_of_revolution}{minimal surface of revolution}): the standard definitions only relate to a \href{https://en.wikipedia.org/wiki/Local_optimum}{local optimum}, not a \href{https://en.wikipedia.org/wiki/Global_optimum}{global optimum}.

\subsubsection{Definitions}
{\sf\href{https://en.wikipedia.org/wiki/Saddle_tower}{Saddle tower} minimal surface. While any small change of the surface increases its area, there exist other surfaces with the same boundary with a smaller total area.} {\sf Minimal surface curvature planes. On a minimal surface, the curvature along the principal curvature planes are equal \& opposite at every point. This makes the mean curvature zero.} Minimal surfaces can be defined in several equivalent ways in $\mathbb{R}^3$. The fact that they are equivalent serves to demonstrate how minimal surface theory lies at the crossroads of several mathematical disciplines, especially \href{https://en.wikipedia.org/wiki/Differential_geometry}{differential geometry}, \href{https://en.wikipedia.org/wiki/Calculus_of_variations}{calculus of variations}, \href{https://en.wikipedia.org/wiki/Potential_theory}{potential theory}, \href{https://en.wikipedia.org/wiki/Complex_analysis}{complex analysis}, \& \href{https://en.wikipedia.org/wiki/Mathematical_physics}{mathematical physics}.

\begin{definition}[Local least area definition]
	A surface $M\subset\mathbb{R}^3$ is minimal iff every point $p\in M$ has a \href{https://en.wikipedia.org/wiki/Neighbourhood_(topology)}{neighborhood}, bounded by a simple closed curve, which has the least area among all surfaces having the same boundary.
\end{definition}
This property is local: there might exist regions in a minimal surface, together with other surfaces of smaller area which have the same boundary. This property establishes a connection with soap films; a soap film deformed to have a wire frame as boundary will minimize area.

\begin{definition}[Variational definition]
	A surface $M\subset\mathbb{R}^3$ is minimal iff it is a \href{https://en.wikipedia.org/wiki/Critical_point_(mathematics)}{critical point} of the area \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{functional} for all compactly supported \href{https://en.wikipedia.org/wiki/Calculus_of_variations}{variations}.
\end{definition}
This definition makes minimal surfaces a 2D analogue to \href{https://en.wikipedia.org/wiki/Geodesics}{geodesics}, which are analogously defined as critical points of the length functional.

\begin{definition}[Mean curvature definition]
	A surface $M\subset\mathbb{R}^3$ is minimal iff its \href{https://en.wikipedia.org/wiki/Mean_curvature}{mean curvature} is equal to zero at all points.
\end{definition}
A direct implication of this definition is that every point on the surface is a \href{https://en.wikipedia.org/wiki/Saddle_point}{saddle point} with equal \& opposite \href{https://en.wikipedia.org/wiki/Principal_curvatures}{principal curvatures}. By the \href{https://en.wikipedia.org/wiki/Young%E2%80%93Laplace_equation}{Young--Laplace equation}, the mean curvature of a soap film is proportional to the difference in pressure between the sides. If the soap film does not enclose a region, then this will make its mean curvature zero. By contrast, a spherical \href{https://en.wikipedia.org/wiki/Soap_bubble}{soap bubble} encloses a region which has a different pressure from the exterior region, \& as such does not have zero mean curvature.

\begin{definition}[Differential equation definition]
	A surface $M\subset\mathbb{R}^3$ is minimal iff it can be locally expressed as the graph of a solution of $(1 + u_x^2)u_{yy} - 2u_xu_yu_{xy} + (1 + u_y)^2u_{xx} = 0$.
\end{definition}
The PDE in this definition was originally found in 1762 by \href{https://en.wikipedia.org/wiki/Lagrange}{\sc Lagrange}, \& \href{https://en.wikipedia.org/wiki/Jean_Baptiste_Meusnier}{\sc Jean Baptiste Meusnier} discovered in 1776 that it implied a vanishing mean curvature.

\begin{definition}[Energy definition]
	A \href{https://en.wikipedia.org/wiki/Conformal_map}{conformal} immersion $X:M\to\mathbb{R}^3$ is minimal iff it is a critical point of the \href{https://en.wikipedia.org/wiki/Dirichlet_energy}{Dirichlet energy} for all compactly supported variations, or equivalently if any point $p\in M$ has a neighborhood with least energy relative to its boundary.
\end{definition}
This definition ties minimal surfaces to \href{https://en.wikipedia.org/wiki/Harmonic_functions}{harmonic functions} \& \href{https://en.wikipedia.org/wiki/Potential_theory}{potential theory}.

\begin{definition}[Harmonic definition]
	If $X = (x_1,x_2,x_3):M\to\mathbb{R}^3$ is an \href{https://en.wikipedia.org/wiki/Isometry}{isometric} \href{https://en.wikipedia.org/wiki/Immersion_(mathematics)}{immersion} of a \href{https://en.wikipedia.org/wiki/Riemann_surface}{Riemann surface} into 3-space, then $X$ is said to be \emph{minimal} whenever $x_i$ is a \href{https://en.wikipedia.org/wiki/Harmonic_function}{harmonic function} on $M$ for each $i$.
\end{definition}
A direct implication of this definition \& the \href{https://en.wikipedia.org/wiki/Harmonic_functions#Maximum_principle}{maximum principle for harmonic functions} is that there are no \href{https://en.wikipedia.org/wiki/Compact_space}{compact} \href{https://en.wikipedia.org/wiki/Complete_metric_space}{complete} minimal surfaces in $\mathbb{R}^3$.

\begin{definition}[Gauss map definition]
	A surface $M\to\mathbb{R}^3$ is minimal iff its \href{https://en.wikipedia.org/wiki/Stereographic_projection}{stereographically} projected \href{https://en.wikipedia.org/wiki/Gauss_map}{Gauss map} $g:M\to\mathbb{C}\cup\{\infty\}$ is \href{https://en.wikipedia.org/wiki/Meromorphic}{meromorphic} w.r.t. the underlying \href{https://en.wikipedia.org/wiki/Riemann_surface}{Riemann surface} structure, \& $M$ is not a piece of a sphere.
\end{definition}
This definition uses that the mean curvature is half of the \href{https://en.wikipedia.org/wiki/Trace_(linear_algebra)}{trace} of the \href{https://en.wikipedia.org/wiki/Shape_operator#Shape_operator}{shape operator}, which is linked to the derivative of the Gauss map. If the projected Gauss map obeys the \href{https://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations}{Cauchy--Riemann equations} then either the trace vanishes or every point of $M$ is \href{https://en.wikipedia.org/wiki/Umbilical_point}{umbilic}, in which case it is a piece of a sphere.

The local least area \& variational definitions allow extending minimal surfaces to other \href{https://en.wikipedia.org/wiki/Riemannian_manifolds}{Riemann manifolds} than $\mathbb{R}^3$.

\subsubsection{History}
Minimal surface theory originates with {\sc Lagrange} who in 1762 considered the variational problem of finding the surface $z = z(x,y)$ of least area stretched across a given closed contour. He derived the \href{https://en.wikipedia.org/wiki/Euler\%E2\%80\%93Lagrange\_equation}{Euler--Lagrange equation} for the solution
\begin{equation}
	\frac{{\rm d}}{{\rm d}x}\frac{z_x}{\sqrt{1 + z_x^2 + z_y^2}} + \frac{{\rm d}}{{\rm d}y}\frac{z_y}{\sqrt{1 + z_x^2 + z_y^2}} = 0.
\end{equation}
He did not succeed in finding any solution beyond the plane. In 1776 \href{https://en.wikipedia.org/wiki/Jean_Baptiste_Marie_Meusnier}{\sc Jean Baptiste Marie Meusnier} discovered that the \href{https://en.wikipedia.org/wiki/Helicoid}{helicoid} \& \href{https://en.wikipedia.org/wiki/Catenoid}{catenoid} satisfy the equation \& that the differential expression corresponds to twice the mean curvature of the surface, concluding that surfaces with zero mean curvature are area-minimizing.

By expanding Lagrange's equation to $(1 + z_x^2)z_{yy} - 2z_xz_yz_{xy} + (1 + z_y^2)z_{xx} = 0$, \href{https://en.wikipedia.org/wiki/Gaspard_Monge}{\sc Gaspard Monge} \& {\sc Legendre} in 1795 derived representation formulas for the solution surfaces. While these were successfully used by \href{https://en.wikipedia.org/wiki/Heinrich_Scherk}{\sc Heinrich Scherk} in 1830 to derive his \href{https://en.wikipedia.org/wiki/Scherk_surface}{surfaces}, they were generally regarded as practically unusable. \href{https://en.wikipedia.org/wiki/Eug%C3%A8ne_Charles_Catalan}{\sc Catalan} proved in 1842{\tt/}43 that the helicoid is the only \href{https://en.wikipedia.org/wiki/Ruled_surface}{ruled} minimal surface.

Progress had been fairly slow until the middle of the century when the \href{https://en.wikipedia.org/wiki/Bj%C3%B6rling_problem}{Bj\"orling problem} was solved using complex methods. The ``1st golden age'' of minimal surfaces began. \href{https://en.wikipedia.org/wiki/Hermann_Schwarz}{\sc Hermann Schwarz} found the solution of the \href{https://en.wikipedia.org/wiki/Plateau_problem}{Plateau problem} for a regular quadrilateral in 1865 \& for a general quadrilateral in 1867 (allowing the construction of his periodic \href{https://en.wikipedia.org/wiki/Schwarz_minimal_surface}{surface families}) using complex methods. \href{https://en.wikipedia.org/wiki/Weierstrass}{\sc Weierstrass} \& \href{https://en.wikipedia.org/wiki/Alfred_Enneper}{\sc Enneper} developed more useful \href{https://en.wikipedia.org/wiki/Weierstrass%E2%80%93Enneper_parameterization}{representation formulas}, firmly linking minimal surfaces to \href{https://en.wikipedia.org/wiki/Complex_analysis}{complex analysis} \& \href{https://en.wikipedia.org/wiki/Harmonic_functions}{harmonic functions}. Other important contributions came from {\sc Beltrami, Bonnet, Darboux, Lie, Riemann, Serret, \& Weingarten}.

Between 1925 \& 1950 minimal surface theory revived, now mainly aimed at nonparametric minimal surfaces. The complete solution of the Plateau problem by \href{https://en.wikipedia.org/wiki/Jesse_Douglas}{\sc Jesse Douglas} \& \href{https://en.wikipedia.org/wiki/Tibor_Rad%C3%B3}{\sc Tibor Rad\'o} was a major milestone. \href{https://en.wikipedia.org/wiki/Bernstein%27s_problem}{Bernstein's problem} \& \href{https://en.wikipedia.org/wiki/Robert_Osserman}{\sc Robert Osserman}'s work on complete minimal surfaces of finite total curvature were also important.

Another revival began in the 1980s. 1 cause was the discovery in 1982 by {\sc Celso Costa} of \href{https://en.wikipedia.org/wiki/Costa%27s_minimal_surface}{Costa's minimal surface} that disproved the conjecture that the plane, the catenoid, \& the helicoid are the only complete embedded minimal surfaces in $\mathbb{R}^3$ of finite topological type. This not only stimulated new work on using the old parametric methods, but also demonstrated the importance of computer graphics to visualize the studied surfaces \& numerical methods to solve the ``period problem'' (when using the \href{https://en.wikipedia.org/wiki/Associate_family}{conjugate surface method} to determine surface patches that can be assembled into a larger symmetric surface, certain parameters need to be numerically matched to produce an embedded surface). Another cause was the verification by {\sc H. Karcher} that the \href{https://en.wikipedia.org/wiki/Triply_periodic_minimal_surface}{triply periodic minimal surfaces} originally described empirically by {\sc Alan Schoen} in 1970 actually exist. This had led to a rich menagerie of surface families \& methods of deriving new surfaces from old, e.g. by adding handles or distorting them.

Currently the theory of minimal surfaces has diversified to minimal submanifolds in other ambient geometries, becoming relevant to mathematical physics (e.g., \href{https://en.wikipedia.org/wiki/Positive_mass_conjecture}{positive mass conjecture}, \href{https://en.wikipedia.org/wiki/Riemannian_Penrose_inequality}{Penrose conjecture}) \& 3-manifold geometry (e.g., \href{https://en.wikipedia.org/wiki/Smith_conjecture}{Smith conjecture}, \href{https://en.wikipedia.org/wiki/Poincar%C3%A9_conjecture}{Poincar\'e conjecture}, \href{https://en.wikipedia.org/wiki/Thurston_Geometrization_Conjecture}{Thurston Geometrization Conjecture}).

\subsubsection{Examples}
Classical examples of minimal surfaces include:
\begin{itemize}
	\item the \href{https://en.wikipedia.org/wiki/Plane_(geometry)}{plane}, which is a \href{https://en.wikipedia.org/wiki/Trivial_(mathematics)}{trivial} case
	\item \href{https://en.wikipedia.org/wiki/Catenoid}{catenoids}: minimal surfaces made by rotating a \href{https://en.wikipedia.org/wiki/Catenary}{catenary} once around its directrix
	\item \href{https://en.wikipedia.org/wiki/Helicoid}{helicoids}: A surface swept out by a line rotating with uniform velocity around an axis perpendicular to the line \& simultaneously moving along the axis with uniform velocity
\end{itemize}
Surfaces from the 19th century golden age include:
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Schwarz_minimal_surface}{Schwarz minimal surfaces}: \href{https://en.wikipedia.org/wiki/Triply_periodic_minimal_surface}{triply periodic surfaces} that fill $\mathbb{R}^3$
	\item \href{https://en.wikipedia.org/wiki/Riemann%27s_minimal_surface}{Riemann's minimal surface}: A posthumously described periodic surface
	\item \href{https://en.wikipedia.org/wiki/Enneper_surface}{Enneper surface}
	\item \href{https://en.wikipedia.org/wiki/Henneberg_surface}{Henneberg surface}: the 1st non-orientable minimal surface
	\item \href{https://en.wikipedia.org/wiki/Bour%27s_minimal_surface}{Bour's minimal surface}
	\item \href{https://en.wikipedia.org/wiki/Neovius_surface}{Neovius surface}: a triply periodic surface
\end{itemize}
Modern surfaces include:
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Gyroid}{Gyroid}: 1 of {\sc Schoen}'s surfaces from 1970, a triply periodic surface of particular interest for liquid crystal structure
	\item \href{https://en.wikipedia.org/wiki/Saddle_tower}{Saddle tower} family: generalizations of \href{https://en.wikipedia.org/wiki/Scherk_surface}{{\sc Scherk}'s 2nd surface}
	\item \href{https://en.wikipedia.org/wiki/Costa%27s_minimal_surface}{{\sc Costa}'s minimal surface}: Famous conjecture disproof. Described in 1982 by \href{https://en.wikipedia.org/wiki/Celso_Costa}{\sc Celso Costa} \& later visualized by \href{https://en.wikipedia.org/wiki/James_Hoffman}{\sc Jim Hoffman}. {\sc Jim Hoffman, David Hoffman, \& William Meeks III} then extended the definition to produce a family of surfaces with different rotational symmetries.
	\item \href{https://en.wikipedia.org/wiki/Chen%E2%80%93Gackstatter_surface}{Chen--Gackstatter surface} family, adding handles to the Enneper surface.
\end{itemize}

\subsubsection{Generalizations \& links to other fields}
Minimal surfaces can be defined in other \href{https://en.wikipedia.org/wiki/Manifolds}{manifolds} than $\mathbb{R}^3$, such as \href{https://en.wikipedia.org/wiki/Hyperbolic_space}{hyperbolic space}, higher-dimensional spaces or \href{https://en.wikipedia.org/wiki/Riemannian_manifolds}{Riemannian manifolds}.

The definition of minimal surfaces can be generalized{\tt/}extended to cover \href{https://en.wikipedia.org/wiki/Constant-mean-curvature_surface}{constant-mean-curvature surfaces}: surfaces with a constant mean curvature, which need not equal zero.

The curvature lines of an isothermal surface form an isothermal net.

In \href{https://en.wikipedia.org/wiki/Discrete_differential_geometry}{discrete differential geometry} discrete minimal surfaces are studied: \href{https://en.wikipedia.org/wiki/Simplicial_complex}{simplicial complexes} of triangles that minimize their area under small perturbations of their vertex positions. Such discretizations are often used to approximate minimal surfaces numerically, even if no closed form expressions are known.

\href{https://en.wikipedia.org/wiki/Wiener_process}{Brownian motion} on a minimal surface leads to probabilistic proofs of several theorems on minimal surfaces.

Minimal surfaces have become an area of intense scientific study, especially in the areas of \href{https://en.wikipedia.org/wiki/Molecular_engineering}{molecular engineering} \& \href{https://en.wikipedia.org/wiki/Materials_science}{materials science}, due to their anticipated applications in \href{https://en.wikipedia.org/wiki/Self-assembly}{self-assembly} of complex materials. The \href{https://en.wikipedia.org/wiki/Endoplasmic_reticulum}{endoplasmic reticulum}, an important structure in cell biology, is proposed to be under evolutionary pressure to conform a nontrivial minimal surface.

In the fields of \href{https://en.wikipedia.org/wiki/General_relativity}{general relativity} \& \href{https://en.wikipedia.org/wiki/Lorentzian_manifold}{Lorentzian geometry}, certain extensions \& modifications of the notion of minimal surface, known as \href{https://en.wikipedia.org/wiki/Apparent_horizon}{apparent horizons}, are significant. In contrast to the \href{https://en.wikipedia.org/wiki/Event_horizon}{event horizon}, they represent a \href{https://en.wikipedia.org/wiki/Curvature}{curvature}-based approach to understanding \href{https://en.wikipedia.org/wiki/Black_hole}{black hole} boundaries.

Structures with minimal surfaces can be used as tents. {\sf Circus tent approximates a minimal surface.}

Minimal surfaces are part of the \href{https://en.wikipedia.org/wiki/Generative_Design}{generative design} toolbox used by modern designers. In architecture there has been much interest in \href{https://en.wikipedia.org/wiki/Tensile_structure}{tensile structures}, which are closely related to minimal surfaces. Notable examples can be seen in the work of \href{https://en.wikipedia.org/wiki/Frei_Otto}{\sc Frei Otto}, \href{https://en.wikipedia.org/wiki/Shigeru_Ban}{\sc Shigeru Ban}, \& \href{https://en.wikipedia.org/wiki/Zaha_Hadid}{Zaha Hadid}. The design of the \href{https://en.wikipedia.org/wiki/Olympiastadion_(Munich)}{Munich Olympic Stadium} by {\sc Frei Otto} was inspired by soap surfaces. Another notable example, also by {\sc Frei Otto}, is the German Pavilion at \href{https://en.wikipedia.org/wiki/Expo_67_pavilions}{Expo 67} in Montreal, Canada.

In the art world, minimal surfaces have been extensively explored in the sculpture of \href{https://en.wikipedia.org/wiki/Robert_Engman}{\sc Robert Engman} (1927--2018), \href{https://en.wikipedia.org/wiki/Robert_Longhurst}{\sc Robert Longhurst} (1949--), \href{https://en.wikipedia.org/wiki/Charles_O._Perry}{\sc Charles O. Perry} (1929--2011), among others.'' -- \href{https://en.wikipedia.org/wiki/Minimal_surface}{Wikipedia{\tt/}minimal surface}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}nonlocal operator}
``In mathematics, a {\it nonlocal operator} is a mapping which maps functions on a topological space to functions, in such a way that the value of the output function at a given point cannot be determined solely from the values of the input function in any neighborhood of any point. An example of a nonlocal operator is the \href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier transform}.

\subsubsection{Formal definition}
Let $X$ be a \href{https://en.wikipedia.org/wiki/Topological_space}{topological space}, $Y$ a set, $F(X)$ a \href{https://en.wikipedia.org/wiki/Function_space}{function space} containing functions with domain $X$, \& $G(Y)$ a function space containing functions with domain $Y$. 2 functions $u,v\in F(X)$ are called equivalent at $x\in X$ if there exists a neighborhood $N$ of $x$ s.t. $u(x') = v(x')$, $\forall x'\in N$. An operator $A:F(X)\to G(Y)$ is said to be local if $\forall y\in Y$, there exists an $x\in X$ s.t. $Au(y) = Av(y)$, $\forall u,v\in F(x)$ which are equivalent at $x$. A nonlocal operator is an operator which is not local. For a local operator it is possible (in principle) to compute the value $Au(y)$ using only knowledge of the values of $u$ in an arbitrarily small neighborhood of a point $x$. For a nonlocal operator this is not possible.

\subsubsection{Examples}
\href{https://en.wikipedia.org/wiki/Differential_operator}{Differential operators} are examples of local operators. A large class of (linear) nonlocal operators is given by the \href{https://en.wikipedia.org/wiki/Integral_transform}{integral transforms}, such as the Fourier transform \& the Laplace transform. For an integral transform of the form $(Au)(y) = \int_X u(x)K(x,y)\,{\rm d}x$, where $K$ is some kernel function, it is necessary to know the values of $u$ a.e. on the support of $K(\cdot,y)$ in order to compute the value of $Au$ at $y$. An example of a \href{https://en.wikipedia.org/wiki/Singular_integral_operator}{singular integral operator} is the \href{https://en.wikipedia.org/wiki/Fractional_Laplacian}{fractional Laplacian} $(-\Delta)^sf(x) = c_{d,s}\int_{\mathbb{R}^d} \frac{f(x) - f(y)}{|x - y|^{d + 2s}}\,{\rm d}y$. The prefactor $c_{d,s}\coloneqq\frac{4^s\Gamma(\frac{d}{2} + s)}{\pi^{\frac{d}{2}}|\Gamma(-s)|}$ involves the \href{https://en.wikipedia.org/wiki/Gamma_function}{Gamma function} \& serves as a normalizing factor. The fractional Laplacian plays a role in, e.g., the study of nonlocal \href{https://en.wikipedia.org/wiki/Minimal_surfaces}{minimal surfaces}.

\subsubsection{Applications}
Some examples of applications of nonlocal operators are:
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Time_series}{Time series analysis using Fourier transformations}
	\item Analysis of \href{https://en.wikipedia.org/wiki/Dynamical_systems}{dynamical systems} using Laplace transformations
	\item \href{https://en.wikipedia.org/wiki/Image_denoising}{Image denoising} using \href{https://en.wikipedia.org/wiki/Non-local_means}{non-local means}
	\item Modeling \href{https://en.wikipedia.org/wiki/Gaussian_blur}{Gaussian blur} or \href{https://en.wikipedia.org/wiki/Motion_blur}{motion blur} in images using \href{https://en.wikipedia.org/wiki/Convolution}{convolution} with a \href{https://en.wikipedia.org/wiki/Kernel_(image_processing)}{blurring kernel} or \href{https://en.wikipedia.org/wiki/Point_spread_function}{point spread function}.'' -- \href{https://en.wikipedia.org/wiki/Nonlocal_operator}{Wikipedia{\tt/}nonlocal operator}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}numerical diffusion}
``{\it Numerical diffusion} is a difficulty with \href{https://en.wikipedia.org/wiki/Computer_simulation}{computer simulations} of continua (e.g., \href{https://en.wikipedia.org/wiki/Fluid}{fluids}) wherein the simulated medium exhibits a higher \href{https://en.wikipedia.org/wiki/Eddy_diffusion}{diffusivity} than the true medium. This phenomenon can be particularly egregious ($=$ extremely bad) when the system should not be diffusive at all, e.g. an ideal fluid acquiring some spurious viscosity in a numerical model.

\subsubsection{Explanation}
In \href{https://en.wikipedia.org/wiki/Eulerian_method}{Eulerian simulations}, time \& space are divided into a discrete grid \& the continuous differential equations of motion (e.g., \href{https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equation}{NSEs}) are \href{https://en.wikipedia.org/wiki/Discretization}{discretization} into \href{https://en.wikipedia.org/wiki/Finite-difference_equation}{finite-difference equations}. The discrete equations are in general more \href{https://en.wikipedia.org/wiki/Diffusion}{diffusive} than the original differential equations, so that the simulated system behaves differently than the intended physical system. The amount \& character of the difference depends on the system being simulated \& the type of discretization that is used. Most fluid dynamics or \href{https://en.wikipedia.org/wiki/Magnetohydrodynamics}{magnetohydrodynamic} simulations seek to reduce numerical diffusion to the minimum possible, to achieve high fidelity -- but under certain circumstances diffusion is added deliberately into the system to avoid \href{https://en.wikipedia.org/wiki/Mathematical_singularity}{singularities}. E.g., \href{https://en.wikipedia.org/wiki/Shock_wave}{shock waves} in fluids \& \href{https://en.wikipedia.org/wiki/Current_sheet}{current sheets} in \href{https://en.wikipedia.org/wiki/Plasma_(physics)}{plasmas} are infinitely thin in some approximations; this can cause difficulty for numerical codes. A simple way to avoid the difficulty is to add diffusion that smooths out the shock or current sheet. Higher order numerical methods (including spectral methods) tend to have less numerical diffusion than low order methods.

\subsubsection{Example}
As an example of numerical diffusion, consider an Eulerian simulation using an explicit time-advance of a drop of green dye diffusing through water. If the water is flowing diagonally through the simulation grid, then it is impossible to move the dye in the exact direction of the flow: at each time step the simulation can at best transfer some dye in each of the vertical \& horizontal directions. After a few time steps, the dye will have spread out through the grid due to this sideways transfer. This numerical effect takes the form of an extra high diffusion rate.

When numerical diffusion applies to the components of the \href{https://en.wikipedia.org/wiki/Momentum}{momentum} vector, it is called {\it numerical viscosity}, when it applies to a magnetic field, it is called \href{https://en.wikipedia.org/wiki/Numerical_resistivity}{numerical resistivity}.

{\sf Phasefield Simulation of an airbubble within a phase of water.} Consider a \href{https://en.wikipedia.org/wiki/Phase_field_models}{Phasefield-problem} with a high pressure loaded air bubble (blue) within a phase of water. Since there are no chemical or thermodynamical reactions during expansion of air in water there is no possibility to come up with another (i.e., non read or blue) phase during the simulation. These inaccuracies between single phrases are based on numerical diffusion \& can be decreased by \href{https://en.wikipedia.org/wiki/Polygon_mesh}{mesh} refining.'' -- \href{https://en.wikipedia.org/wiki/Numerical_diffusion}{Wikipedia{\tt/}numerical diffusion}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}numerical error}
{\sf Time series of the \href{https://en.wikipedia.org/wiki/Tent_map}{Tent map} for the parameter $m = 2$ which shows numerical error: ``the plot of time series (plot of $x$ variable w.r.t. number of iterations) stops fluctuating \& no values are observed after $n = 50$''. Parameter $m = 2$, initial point is random.} ``In \href{https://en.wikipedia.org/wiki/Software_engineering}{software engineering} \& mathematics, {\it numerical error} is the error in the \href{https://en.wikipedia.org/wiki/Numerical_computation}{numerical computations}.

\subsubsection{Types}
It can be the combined effect of 2 kinds of error in a calculation.
\begin{enumerate}
	\item the 1st is caused by the finite \href{https://en.wikipedia.org/wiki/Precision_(computer_science)}{precision} of computations involving \href{https://en.wikipedia.org/wiki/Floating-point}{floating-point} or integer values
	\item the 2nd usually called {\it truncation error} is the difference between the exact mathematical solution \& the approximate solution obtained when simplifications are made to the mathematical equations to make them more amenable to calculation. The term truncation comes from the fact that either these simplifications usually involve the truncation of an \href{https://en.wikipedia.org/wiki/Infinite_series}{infinite series} expansion so as to make the computation possible \& practical, or because the least significant bits of an arithmetic operation are thrown away.
\end{enumerate}

\subsubsection{Measure}
Floating-point numerical error is often measured in ULP (\href{https://en.wikipedia.org/wiki/Unit_in_the_last_place}{unit in the last place}).'' -- \href{https://en.wikipedia.org/wiki/Numerical_error}{Wikipedia{\tt/}numerical error}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}numerical stability}
``In the mathematical subfield of \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerical analysis}, {\it numerical stability} is a generally desirable property of \href{https://en.wikipedia.org/wiki/Numerical_algorithm}{numerical algorithms}. The precise definition of stability depends on the context. One is \href{https://en.wikipedia.org/wiki/Numerical_linear_algebra}{numerical linear algebra} \& the other is algorithms for solving ODEs \& PDEs by discrete approximation.

In numerical linear algebra, the principal concern is instabilities caused by proximity to singularities of various kinds, e.g. very small or nearly colliding \href{https://en.wikipedia.org/wiki/Eigenvalues}{eigenvalues}. On the other hand, in numerical algorithms for differential equations the concern is the growth of round-off errors \&{\tt/}or small fluctuations in initial data which might cause a large deviation of final answer from the exact solution.

Some numerical algorithms may damp out the small fluctuations (errors) in the input data; others might magnify such errors. Calculations that can be proven not to magnify approximation errors are called {\it numerically stable}. 1 of the common tasks of numerical analysis is to try to select algorithms which are {\it robust} -- i.e., do not produce a widely different result for very small change in the input data.

An \href{https://en.wikipedia.org/wiki/Opposite_(semantics)}{opposite} phenomenon is {\it instabillity}. Typically, an algorithm involves an approximative method, \& in some cases one could prove that the algorithm would approach the right solution in some limit (when using actual real numbers, not floating point numbers). Even in this case, there is no guarantee that it would converge to the correct solution, because the floating-point round-off or truncation errors can be magnified, instead of damped, causing the deviation from the exact solution to grow exponentially.

\subsubsection{Stability in numerical linear algebra}
{\sf Diagram showing the {\it forward error} $\Delta y$ \& the {\it backward error} $\Delta x$, \& their relation to the exact solution map $f$ \& the numerical solution $f^\star$.} There are different ways to formalize the concept of stability. The following definitions of forward, backward, \& mixed stability are often used in numerical linear algebra.

Consider the problem to be solved by the numerical algorithm as a function $f$ mapping the data $x$ to the solution $y$. The result of the algorithm, say $y^\star$, will usually deviate from the ``true'' solution $y$. The main causes of error are \href{https://en.wikipedia.org/wiki/Round-off_error}{round-off error} \& \href{https://en.wikipedia.org/wiki/Truncation_error}{truncation error}. The {\it forward error} of the algorithm is the difference between the result \& the solution; in this case, $\Delta y = y^\star - y$. The {\it backward error} is the smallest $\Delta x$ s.t. $f(x + \Delta x) = y^\star$, i.e., the backward error tells us what problem the algorithm actually solved. The forward \& backward error are related by the \href{https://en.wikipedia.org/wiki/Condition_number}{condition number}: the forward error is at most as big in magnitude as the condition number multiplied by the magnitude of the backward error.

In many cases, it is more natural to consider the \href{https://en.wikipedia.org/wiki/Relative_error}{relative error} $\frac{|\Delta x|}{|x|}$ instead of the absolute error $\Delta x$.

The algorithm is said to be {\it backward stable} if the backward error is small for all inputs $x$. Of course, ``small'' is a relative term \& its definition will depend on the context. Often, we want the error to be of the same order as, or perhaps only a few \href{https://en.wikipedia.org/wiki/Orders_of_magnitude}{orders of magnitude} bigger than the \href{https://en.wikipedia.org/wiki/Unit_round-off}{unit round-off}.

{\sf Mixed stability combines the concepts of forward error \& backward error.} The usual definition of numerical stability uses a more general concept, called {\it mixed stability}, which combines the forward error \& the backward error. An algorithm is stable in this sense if it solves a nearby problem approximately, i.e., if there exists a $\Delta x$ s.t. both $\Delta x$ is small \& $f(x + \Delta x) - y^\star$ is small. Hence, a backward stable algorithm is always stable.

An algorithm is {\it forward stable} if its forward error divided by the condition number of the problem is small, i.e., an algorithm is forward stable if it has a forward error of magnitude similar to some backward stable algorithm.

\subsubsection{Stability in numerical differential equations}
The above definitions are particularly relevant in situations where truncation errors are not important. In other contexts, e.g. when solving \href{https://en.wikipedia.org/wiki/Differential_equation}{differential equations}, a different definition of numerical stability is used.

In \href{https://en.wikipedia.org/wiki/Differential_equation}{numerical ODEs}, various concepts of numerical stability exist, e.g., \href{https://en.wikipedia.org/wiki/Stiff_equation#A-stability}{A-stability}. They are related to some concept of stability in the \href{https://en.wikipedia.org/wiki/Dynamical_system}{dynamatical systems} sense, often \href{https://en.wikipedia.org/wiki/Lyapunov_stability}{Lyapunov stability}. It is important to use a stable method when solving a \href{https://en.wikipedia.org/wiki/Stiff_equation}{stiff equation}.

Yet another definition is used in \href{https://en.wikipedia.org/wiki/Numerical_partial_differential_equations}{numerical PDEs}. An algorithm for solving a linear evolutionary PDE is stable if the \href{https://en.wikipedia.org/wiki/Total_variation}{total variation} of the numerical solution at a fixed time remains bounded as the step size goes to 0. The \href{https://en.wikipedia.org/wiki/Lax_equivalence_theorem}{Lax equivalence theorem} states that an algorithm \href{https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations#Convergence}{converges} if it is \href{https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations#Consistency_and_order}{consistent} \& \href{https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations#Stability_and_stiffness}{stable} (in this sense). Stability is sometimes achieved by including \href{https://en.wikipedia.org/wiki/Numerical_diffusion}{numerical diffusion}. Numerical diffusion is a mathematical term which ensures that roundoff \& other errors in the calculation get spread out \& do not add up to cause the calculation to ``blow up''. \href{https://en.wikipedia.org/wiki/Von_Neumann_stability_analysis}{Von Neumann stability analysis} is a commonly used procedure for the stability analysis of finite difference schemes as applied to linear PDEs. These results do not hold for nonlinear PDEs, where a general, consistent definition of stability is complicated by many properties absent in linear equations.

\subsubsection{Example}
Computing $\sqrt{2}$ is a \href{https://en.wikipedia.org/wiki/Well-posed_problem}{well-posed problem}. Many algorithms solve this problem by starting with an initial approximation $x_0$ to $\sqrt{2}$, e.g., $x_0 = 1.4$, \& then computing improved guesses $x_1,x_2$, etc. 1 such method is the famous \href{https://en.wikipedia.org/wiki/Babylonian_method}{Babylonian method}, given by $x_{n+1} = \frac{1}{2}\left(x_n + \frac{2}{x_n}\right)$. Another method, called ``method X'', is given by $x_{n+1} = (x_n^2 - 2)^2 + x_n$. Observe that the Babylonian method converges quickly regardless of the initial guess, whereas Method X converges extremely slowly with initial guess $x_0 = 1.4$ \& diverges for initial guess $x_0 = 1.42$. Hence, the Babylonian method is numerically stable, while Method X is numerically unstable.

Numerical stability is affected by the number of the significant digits the machine keeps. If a machine is used that keeps only the 4 most significant decimal digits, a good example on loss of significance can be given by the 2 equivalent functions $f(x)\coloneqq x(\sqrt{x + 1} - \sqrt{x}) = g(x)\coloneqq\frac{x}{\sqrt{x + 1} + \sqrt{x}}$. It is clear that \href{https://en.wikipedia.org/wiki/Loss_of_significance}{loss of significance} (caused here by \href{https://en.wikipedia.org/wiki/Catastrophic_cancellation}{catastrophic cancellation} from subtracting approximations to the nearby numbers $\sqrt{501},\sqrt{500}$, despite the subtraction being computed exactly) has a huge effect on the results, even though both functions are equivalent.'' -- \href{https://en.wikipedia.org/wiki/Numerical_stability}{Wikipedia{\tt/}numerical stability}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}operator (mathematics)}
``In mathematics, an {\it operator} is generally a \href{https://en.wikipedia.org/wiki/Map_(mathematics)}{mapping} or \href{https://en.wikipedia.org/wiki/Function_(mathematics)}{function} that acts on elements of a \href{https://en.wikipedia.org/wiki/Space_(mathematics)}{space} to produce elements of another space (possibly \& sometimes required to be the same space). There is no general definition of an {\it operator}, but the term is often used in place of {\it function} where the \href{https://en.wikipedia.org/wiki/Domain_of_a_function}{domain} is a set of functions or other structured objects. Also, the domain of an operator is often difficult to characterize explicitly (e.g. in the case of an \href{https://en.wikipedia.org/wiki/Integral_operator}{integral operator}), \& may be extended so as to act on related objects (an operator that acts on functions may act also on \href{https://en.wikipedia.org/wiki/Differential_equation}{differential equations} whose solutions are functions that satisfy the equation). See \href{https://en.wikipedia.org/wiki/Operator_(physics)}{Wikipedia{\tt/}operator (physics)}.

The most basic operators are \href{https://en.wikipedia.org/wiki/Linear_map}{linear maps}, which act on \href{https://en.wikipedia.org/wiki/Vector_space}{vector spaes}. Linear operators refer to linear maps whose domain \& range are the same space, e.g. from $\mathbb{R}^d\to\mathbb{R}^d$. Such operators often preserve properties, e.g. \href{https://en.wikipedia.org/wiki/Continuous_function}{continuity}. E.g., \href{https://en.wikipedia.org/wiki/Differentiation_(mathematics)}{differentiation} \& \href{https://en.wikipedia.org/wiki/Indefinite_integration}{indefinite integration} are linear operators; operators that are built from them are called \href{https://en.wikipedia.org/wiki/Differential_operator}{differential operators}, \href{https://en.wikipedia.org/wiki/Integral_operator}{integral operators} or integro-differential operators.

{\it Operator} is also used for denoting the symbol of a \href{https://en.wikipedia.org/wiki/Mathematical_operation}{mathematical operation}. This is related with the meaning of ``operator'' in \href{https://en.wikipedia.org/wiki/Computer_programming}{computer programming}, see \href{https://en.wikipedia.org/wiki/Operator_(computer_programming)}{Wikipedia{\tt/}operator (computer programming)}.

\subsubsection{Linear operators}
Main article: \href{https://en.wikipedia.org/wiki/Linear_operator}{Wikipedia{\tt/}linear operator}. The most common kind of operators encountered are {\it linear operators}. Let $U,V$ be \href{https://en.wikipedia.org/wiki/Vector_space}{vector spaces} over some \href{https://en.wikipedia.org/wiki/Field_(mathematics)}{field} $K$. A \href{https://en.wikipedia.org/wiki/Map_(mathematics)}{mapping} $A:U\to V$ is \href{https://en.wikipedia.org/wiki/Linear_(mathematics)}{linear} if $A(\alpha{\bf x} + \beta{\bf y}) = \alpha A{\bf x} + \beta A{\bf y}$, $\forall{\bf x},{\bf y}\in U$, $\forall\alpha,\beta\in K$, i.e., a linear operator preserves vector space operations, in the sense that it does not matter whether you apply the linear operator before or after the operations of addition \& scalar multiplication. In more technical words, linear operators are \href{https://en.wikipedia.org/wiki/Morphism}{morphisms} between vector spaces. In the finite-dimensional case linear operators can be represented by matrices in the following way. Let $K$ be a field, $U,V$ be finite-dimensional vector spaces over $K$. Select a basis ${\bf u}_1,\ldots,{\bf u}_n$ in $U$ \& ${\bf v}_1,\ldots,{\bf v}_m$ in $V$. Then let ${\bf x} = x^i{\bf u}_i$ be an arbitrary vector in $U$ (assuming \href{https://en.wikipedia.org/wiki/Einstein_convention}{Einstein convention}), \& $A:U\to V$ be a linear operator. Then $A{\bf x} = x^iA{\bf u}_i = x^i(A{\bf u}_i)^j{\bf v}_j$. Then $a_i^j\equiv(A{\bf u}_i)^j$, with all $a_i^j\in K$, is the matrix form of the operator $A$ in the fixed basis $\{{\bf u}_i\}_{i=1}^n$. The tensor $a_i^j$ does not depend on the choice of ${\bf x}$, \& $A{\bf x} = {\bf y}$ if $a_i^jx^i = y^j$. Thus in fixed bases $n$-by-$m$ matrices are in \href{https://en.wikipedia.org/wiki/Bijective}{bijective} correspondence to linear operators from $U\to V$.

The important concepts directly related to operators between finite-dimensional vector spaces are the ones of \href{https://en.wikipedia.org/wiki/Matrix_rank}{rank}, \href{https://en.wikipedia.org/wiki/Determinant}{determinant}, \href{https://en.wikipedia.org/wiki/Inverse_operator}{inverse operator}, \& \href{https://en.wikipedia.org/wiki/Eigenspace}{eigenspace}.

Linear operators also play a great role in the infinite-dimensional case. The concepts of rank \& determinant cannot be extended to infinite-dimensional matrices. This is why very different techniques are employed when studying linear operators (\& operators in general) in the infinite-dimensional case. The study of linear operators in the infinite-dimensional case is known as \href{https://en.wikipedia.org/wiki/Functional_analysis}{functional analysis} (so-called because various classes of functions form interesting examples of infinite-dimensional vector spaces).

The space of \href{https://en.wikipedia.org/wiki/Sequence}{sequences} of real numbers, or more generally sequences of vectors in any vector space, themselves form an infinite-dimensional vector space. The most important cases are sequences of real or complex numbers, \& these spaces, together with linear subspaces, are known as \href{https://en.wikipedia.org/wiki/Sequence_space}{sequence spaces}. Operators on these spaces are known as \href{https://en.wikipedia.org/wiki/Sequence_transformation}{sequence transformations}.

Bounded linear operators over a \href{https://en.wikipedia.org/wiki/Banach_space}{Banach space} form a \href{https://en.wikipedia.org/wiki/Banach_algebra}{Banach algebra} in respect to the standard operator norm. The theory of Banach algebras develops a very general concept of \href{https://en.wikipedia.org/wiki/Spectrum_(functional_analysis)}{spectra} that elegantly generalizes the theory of eigenspaces.

\subsubsection{Bounded operators}
Main articles: \href{https://en.wikipedia.org/wiki/Bounded_operator}{Wikipedia{\tt/}bounded operator}, \href{https://en.wikipedia.org/wiki/Operator_norm}{Wikipedia{\tt/}operator norm}, \& \href{https://en.wikipedia.org/wiki/Banach_algebra}{Wikipedia{\tt/}Banach algebra}. Let $U,V$ be 2 vector spaces over the same \href{https://en.wikipedia.org/wiki/Ordered_field}{ordered field}, e.g., $\mathbb{R}$, \& they are equipped with \href{https://en.wikipedia.org/wiki/Norm_(mathematics)}{norms}. Then a linear operator from $U\to V$ is called {\it bounded} if there exists $c > 0$ s.t. $\|A{\bf x}\|_V\le c\|{\bf x}\|_U$, $\forall{\bf x}\in U$. Bounded operators form a vector space. On this vector space we can introduce a norm that is compatible with the norms of $U,V$: $\|A\|\coloneqq\inf\{c:\|A{\bf x}\|_V\le c\|{\bf x}\|_U\}$. In case of operators from $U$ to itself it can be shown that $\|AB\|\le \|A\|\|B\|$. Any unital \href{https://en.wikipedia.org/wiki/Normed_algebra}{normed algebra} with this property is called a \href{https://en.wikipedia.org/wiki/Banach_algebra}{Banach algebra}. It is possible to generalize \href{https://en.wikipedia.org/wiki/Spectral_theory}{spectral theory} to such algebra. \href{https://en.wikipedia.org/wiki/C*-algebra}{$C^\star$-algebras}, which are \href{https://en.wikipedia.org/wiki/Banach_algebras}{Banach algebras} with some additional structure, play an important role in \href{https://en.wikipedia.org/wiki/Quantum_mechanics}{quantum mechanics}.

\subsubsection{Examples}

\begin{enumerate}
	\item {\sf Analysis (calculus).} Main articles: \href{https://en.wikipedia.org/wiki/Differential_operator}{Wikipedia{\tt/}differential operator} \& \href{https://en.wikipedia.org/wiki/Integral_operator}{Wikipedia{\tt/}integral operator}. From the point of view of \href{https://en.wikipedia.org/wiki/Functional_analysis}{functional analysis}, \href{https://en.wikipedia.org/wiki/Calculus}{calculus} is the study of 2 linear operators: the \href{https://en.wikipedia.org/wiki/Differential_operator}{differential operator} $\frac{{\rm d}}{{\rm d}t}$, \& the \href{https://en.wikipedia.org/wiki/Volterra_operator}{Volterra operator} $\int_0^t$.
	\item {\sf Fundamental analysis operators on scalar \& vector fields.} Main articles: \href{https://en.wikipedia.org/wiki/Vector_calculus}{Wikipedia{\tt/}vector calculus}, \href{https://en.wikipedia.org/wiki/Vector_field}{Wikipedia{\tt/}vector field}, \href{https://en.wikipedia.org/wiki/Scalar_field}{Wikipedia{\tt/}scalar field}, \href{https://en.wikipedia.org/wiki/Gradient}{Wikipedia{\tt/}gradient}, \href{https://en.wikipedia.org/wiki/Divergence}{Wikipedia{\tt/}divergence}, \href{https://en.wikipedia.org/wiki/Curl_(mathematics)}{Wikipedia{\tt/}curl}. 3 operators are key to \href{https://en.wikipedia.org/wiki/Vector_calculus}{vector calculus}:
	\begin{itemize}
		\item Grad \href{https://en.wikipedia.org/wiki/Gradient}{gradient} (with operator symbol $\nabla$) assigns a vector at every point in a scalar field that points in the direction of greatest rate of change of that field \& whose norm measures the absolute value of that greatest rate of change.
		\item Div \href{https://en.wikipedia.org/wiki/Divergence}{divergence} (with operator symbol $\nabla\cdot$) is a vector operator that measures a vector field's divergence from or convergence towards a given point.
		\item \href{https://en.wikipedia.org/wiki/Curl_(mathematics)}{Curl} (with operator symbol $\nabla\times$) is a vector operator that measures a vector field's curling (winding around, rotating around) trend about a given point.
	\end{itemize}
	As an extension of vector calculus operators in physics, engineering \& tensor spaces, grad, div, \& curl operators also are often associated with \href{https://en.wikipedia.org/wiki/Tensor_calculus}{tensor calculus} as well as vector calculus.
	\item {\sf Geometry.} Main articles: \href{https://en.wikipedia.org/wiki/General_linear_group}{Wikipedia{\tt/}general linear group}, \href{https://en.wikipedia.org/wiki/Isometry}{Wikipedia{\tt/}isometry}. In \href{https://en.wikipedia.org/wiki/Geometry}{geometry}, additional structures on \href{https://en.wikipedia.org/wiki/Vector_space}{vector spaces} are sometimes studied. Operators that map such vector spaces to themselves bijectively are very useful in these studies, they naturally form \href{https://en.wikipedia.org/wiki/Group_(mathematics)}{groups} by composition. E.g., bijective operators preserving the structure of a vector space are precisely the \href{https://en.wikipedia.org/wiki/Invertible_function}{invertible} \href{https://en.wikipedia.org/wiki/Linear_operator}{linear operators}. They form the \href{https://en.wikipedia.org/wiki/General_linear_group}{general linear group} under composition. However, they {\it do not} form a vector space under operator addition; since, e.g., both the identity \& -identity are invertible (bijective), but their sum $0$ is not. Operators preserving the \href{https://en.wikipedia.org/wiki/Euclidean_metric}{Eucliean metric} on such a space form the \href{https://en.wikipedia.org/wiki/Isometry_group}{isometry group}, \& those that fix the origin form a subgroup known as the \href{https://en.wikipedia.org/wiki/Orthogonal_group}{orthogonal group}. Operators in the orthogonal group that also preserve the orientation of vector tuples form the \href{https://en.wikipedia.org/wiki/Special_orthogonal_group}{special orthogonal group}, or the group of rotations.
	\item {\sf Probability theory.} Main article: \href{https://en.wikipedia.org/wiki/Probability_theory}{Wikipedia{\tt/}probability theory}. Operators are also involved in probability theory, e.g. \href{https://en.wikipedia.org/wiki/Expected_value}{expectation}, \href{https://en.wikipedia.org/wiki/Variance}{variance}, \& \href{https://en.wikipedia.org/wiki/Covariance}{covariance}, which are used to name both number statistics \& the operators which produce them. Indeed, every covariance is basically a \href{https://en.wikipedia.org/wiki/Dot_product}{dot product}: Every variance is a dot product of a vector with itself, \& thus is a \href{https://en.wikipedia.org/wiki/Quadratic_norm}{quadratic norm}; every standard deviation is a norm (square root of the quadratic norm); the corresponding cosine to this dot product is the \href{https://en.wikipedia.org/wiki/Pearson_correlation_coefficient}{Pearson correlation coefficient}; expected value is basically an integral operator (used to measure weighted shapes in the space).
	\item {\sf Fourier series \& Fourier transform.} Main articles: \href{https://en.wikipedia.org/wiki/Fourier_series}{Wikipedia{\tt/}Fourier series}, \href{https://en.wikipedia.org/wiki/Fourier_transform}{Wikipedia{\tt/}Fourier transform}. The Fourier transform is useful in applied mathematics, particularly physics \& signal processing. It is another integral operator; it is useful mainly because it converts a function on 1 (temporal) domain to a function on another (frequency) domain, in a way effectively invertible. No information is lost, as there is an inverse transform operator. In the simple case of \href{https://en.wikipedia.org/wiki/Periodic_function}{periodic functions}, this result is based on the theorem that any continuous periodic function can be represented as the sum of a series of \href{https://en.wikipedia.org/wiki/Sine_wave}{sine waves} \& cosine waves: $f(t) = \frac{a_0}{2} + \sum_{n=1}^\infty a_n\cos\omega nt + b_n\sin\omega nt$. The tuple $(a_0,a_1,b_1,a_2,b_2,\ldots)$ is in fact an element of an infinite-dimensional vector space \href{https://en.wikipedia.org/wiki/Sequence_space}{$l^2$}, \& thus Fourier series is a linear operator. When dealing with general function $\mathbb{R}\to\mathcal{C}$, the transform takes on an \href{https://en.wikipedia.org/wiki/Integral}{integral} form $f(t) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty} g(\omega)e^{i\omega t}\,{\rm d}\omega$.s
	\item {\sf Laplace transform.} Main article: \href{https://en.wikipedia.org/wiki/Laplace_transform}{Wikipedia{\tt/}Laplace transform}. The {\it Laplace transform} is another integral operator \& is involved in simplifying the process of solving differential equations. Given $f = f(s)$, it is defined by $F(s) = \mathcal{L}\{f\}(s)\coloneqq\int_0^\infty e^{-st}f(t)\,{\rm d}t$.'' -- \href{https://en.wikipedia.org/wiki/Operator_(mathematics)}{Wikipedia{\tt/}operator (mathematics)}
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}operator algebra}
``In \href{https://en.wikipedia.org/wiki/Functional_analysis}{functional analysis}, a branch of mathematics, an {\it operator algebra} is an \href{https://en.wikipedia.org/wiki/Algebra_over_a_field}{algebra} of continuous \href{https://en.wikipedia.org/wiki/Linear_operator}{linear operators} on a \href{https://en.wikipedia.org/wiki/Topological_vector_space}{topological vector space}, with the multiplication given by the \href{https://en.wikipedia.org/wiki/Function_composition}{composition of mappings}.

The results obtained in the study of operator algebras are often phrased in \href{https://en.wikipedia.org/wiki/Algebra}{algebraic} terms, while the techniques used are often highly \href{https://en.wikipedia.org/wiki/Mathematical_analysis}{analytic}. Although the study of operators algebras is usually classified as a branch of functional analysis, it has direct applications to \href{https://en.wikipedia.org/wiki/Representation_theory}{representation theory}, \href{https://en.wikipedia.org/wiki/Differential_geometry}{differential geometry}, \href{https://en.wikipedia.org/wiki/Quantum_statistical_mechanics}{quantum statistical mechanics}, \href{https://en.wikipedia.org/wiki/Quantum_information}{quantum information}, \& \href{https://en.wikipedia.org/wiki/Quantum_field_theory}{quantum field theory}.

\subsubsection{Overview}
Operator algebras can be used to study arbitrary sets of operators with little algebraic relation {\it simultaneously}. From this point of view, operator algebras can be regarded as a generalization of \href{https://en.wikipedia.org/wiki/Spectral_theory}{spectral theory} of a single operator. In general, operator algebras are \href{https://en.wikipedia.org/wiki/Noncommutative_ring}{non-commutative} \href{https://en.wikipedia.org/wiki/Ring_(mathematics)}{rings}.

An operator algebra is typically required to be \href{https://en.wikipedia.org/wiki/Closure_(mathematics)}{closed} in a specified operator \href{https://en.wikipedia.org/wiki/Topology}{topology} inside the whole algebra of continuous linear operators. In particular, it is a set of operators with both algebraic \& topological closure properties. In some disciplines such properties are \href{https://en.wikipedia.org/wiki/Axiom}{axiomatized} \& algebras with certain topological structure become the subject of the research.

Though algebras of operators are studied in various contexts (e.g., algebras of \href{https://en.wikipedia.org/wiki/Pseudo-differential_operator}{pseudo-differential operators} acting on spaces of \href{https://en.wikipedia.org/wiki/Distribution_(mathematics)}{distributions}), the term {\it operator algebra} is usually used in reference to algebras of \href{https://en.wikipedia.org/wiki/Bounded_operator}{bounded operators} on a \href{https://en.wikipedia.org/wiki/Banach_space}{Banach space} or, even more specially in reference to algebras of operators on a \href{https://en.wikipedia.org/wiki/Separable_space}{separable} \href{https://en.wikipedia.org/wiki/Hilbert_space}{Hilbert space}, endowed with the \href{https://en.wikipedia.org/wiki/Operator_norm}{operator norm} topology.

In the case of operators on a Hilbert space, the \href{https://en.wikipedia.org/wiki/Hermitian_adjoint}{Hermitian adjoint} map on operators gives a natural \href{https://en.wikipedia.org/wiki/Involution_(mathematics)}{involution}, which provides an additional algebraic structure that can be imposed on the algebra. In this context, the best studied examples are \href{https://en.wikipedia.org/wiki/Self-adjoint}{self-adjoint} operator algebras, meaning that they are closed under taking adjoints. These include \href{https://en.wikipedia.org/wiki/C*-algebra}{$C^\star$ algebras}, \href{https://en.wikipedia.org/wiki/Von_Neumann_algebra}{von Neumann algebras}, \& \href{https://en.wikipedia.org/wiki/AW*-algebra}{$\rm AM^\star$-algebras}. $C^\star$-algebras can be easily characterize abstractly by a condition relating the norm, involution, \& multiplication. Such abstractly defined $C^\star$-algebra can be identified to a certain closed \href{https://en.wikipedia.org/wiki/Subalgebra#Subalgebras_for_algebras_over_a_ring_or_field}{subalgebra} of the algebra of the continuous linear operators on a suitable Hilbert space. A similar result holds for von Neumann algebras.

\href{https://en.wikipedia.org/wiki/Commutative_algebra}{Commutative} self-adjoint operator algebras can be regarded as the algebra of complex-valued continuous functions on a \href{https://en.wikipedia.org/wiki/Locally_compact_space}{locally compact space}, or that of \href{https://en.wikipedia.org/wiki/Measurable_function}{measurable functions} on a \href{https://en.wikipedia.org/wiki/Measurable_space}{standard measurable space}. Thus, general operator algebras are often regarded as a noncommutative generalizations of these algebras, or the structure of the {\it base space} on which the functions are defined. This point of view is elaborated as the philosophy of \href{https://en.wikipedia.org/wiki/Noncommutative_geometry}{noncommutative geometry}, which tries to study various non-classical \&{\tt/}or pathological objects by noncommutative operator algebras.

Examples of operator algebras that are not self-adjoint include:
\begin{itemize}
	\item \href{https://en.wikipedia.org/wiki/Nest_algebra}{nest algebras}.
	\item many commutative subspace lattice algebras,
	\item many limit algebras.'' -- \href{https://en.wikipedia.org/wiki/Operator_algebra}{Wikipedia{\tt/}operator algebra}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}physics-informed neural networks PINNs}
``{\it Physics-informed neural networks} (PINNs), also referred as as {\it Theory-Trained Neural Networks} (TTNs), are a type of universal function approximators that can be embed the knowledge of any physical laws that govern a given data-set in the learning process, \& can be described by PDEs. They overcome the low data availability of some biological \& engineering systems that makes most state-of-the-art machine learning techniques lack robustness, rendering them ineffective in these scenarios. The prior knowledge of general physical laws acts in the training of \href{https://en.wikipedia.org/wiki/Neural_network}{neural networks} (NNs) as a \href{https://en.wikipedia.org/wiki/Regularization_(mathematics)}{regularization} agent that limits the space of admissible solutions, increasing the correctness of the function approximation. This way, embedding this prior information into a neural network results in enhancing the information content of the available data, facilitating the learning algorithm to capture the right solution \& to generalize well even with a low amount of training examples. {\sf Physics-informed neural networks for solving NSEs.}

\subsubsection{Function approximation}
Most of the physical laws that govern the dynamics of a system can be described by PDEs. E.g., the NSEs are a set of PDEs derived from the \href{https://en.wikipedia.org/wiki/Conservation_law}{conservation laws} (i.e., conservation of mass, momentum, \& energy) that govern \href{https://en.wikipedia.org/wiki/Fluid_mechanics}{fluid mechanics}. The solution of the NSEs with appropriate initial \& boundary conditions allows the quantification of flow dynamics in a precisely defined geometry. However, these equations cannot be solved exactly \& therefore numerical methods must be used (e.g. FDs, FEs, \& FVs). In this setting, these governing equations must be solved while accounting for prior assumptions, linearization, \& adequate time \& space discretization.

Recently, solving the governing PDEs of physical phenomena using \href{https://en.wikipedia.org/wiki/Deep_learning}{deep learning} has emerged as a new field of scientific machine learning (SciML), leveraging the \href{https://en.wikipedia.org/wiki/Universal_approximation_theorem}{universal approximation theorem} \& high expressivity of neural networks. In general, deep neural networks could approximate any high-dimensional function given that sufficient training data are supplied. However, such networks do not consider the physical characteristics underlying the problem, \& the level of approximation accuracy provided by them is still heavily dependent on careful specifications of the problem geometry as well as the initial \& boundary conditions. Without this preliminary information, the solution is not unique \& may lose physical correctness. On the other hand, physics-informed neural networks (PINNs) leverage governing physical equations in neural network training. Namely, PINNs are designed to be trained to satisfy the given training data as well as the imposed governing equations. In this fashion, a neural network can be guided with training data that do not necessarily need to be large \& complete. Potentially, an accurate solution of PDEs can be found without knowing the boundary conditions. Therefore, with some knowledge about the physical characteristics of the problem \& some form of training data (even sparse \& incomplete), PINN may be used for finding an optimal solution with high fidelity.

PINNs allow for addressing a wide range of problems in computational science \& represent a pioneering technology leading to the development of new classes of numerical solvers for PDEs. PINNs can be thought of as a meshfree alternative to traditional approaches (e.g., \href{https://en.wikipedia.org/wiki/Computational_Fluid_Dynamics}{CFD} for fluid dynamics), \& new data-driven approaches for model inversion \& system identification. Notably, the trained PINN network can be used for predicting the values on simulation grids of different resolutions without the need to be retrained. In addition, they allow for exploiting \href{https://en.wikipedia.org/wiki/Automatic_differentiation}{automatic differentiation} (AD) to compute the required derivatives in the PDEs, a new class of differentiation techniques widely used to derive neural networks assessed to be superior to \href{https://en.wikipedia.org/wiki/Numerical_differentiation}{numerical differentiation} or \href{https://en.wikipedia.org/wiki/Symbolic_differentiation}{symbolic differentiation}.

\subsubsection{Modeling \& computation}
A general nonlinear PDE can be:
\begin{equation*}
	u_t + N[u;\lambda] = 0,\ {\bf x}\in\Omega,\ t\in[0,T],
\end{equation*}
where $u(t,{\bf x})$ denotes the solution, $N[\cdot;\lambda]$: a nonlinear operator parametrized by $\lambda$, \& $\Omega\subset\mathbb{R}^d$. This general form of governing equations summarizes a wide range of problems in mathematical physics, e.g. conservative laws, diffusion process, advection-diffusion systems, \& kinetic equations. Given noisy measurements of a generic dynamic system described by the equation above, PINNs can be designed to solve 2 classes of problems:
\begin{itemize}
	\item data-driven solution
	\item data-driven discovery of PDEs.
\end{itemize}

\paragraph{Data-driven solution of PDEs.} The {\it data-driven solution of PDE} computes the hidden state $u(t,{\bf x})$ of the system given boundary data \&{\tt/}or measurements $z$, \& fixed model parameters $\lambda$. Solve:
\begin{equation*}
	u_t + N[u] = 0,\ {\bf x}\in\Omega,\ t\in[0,T].
\end{equation*}
By defining the residual $f(t,{\bf x})$ as $f\coloneqq u_t + N[u] = 0$, \& approximating $u(t,{\bf x})$ by a deep neural network. This network can be differentiated using automatic differentiation. The parameters of $u(t,{\bf x})$ \& $f(t,{\bf x})$ can be then learned by minimizing the following loss function $L_{\rm tot}\coloneqq L_u + L_f$ where $L_u\coloneqq\|u - z\|_\Gamma$ is the error between the PINN $u(t,{\bf x})$ \& the set of boundary conditions \& measured data on the set of points $\Gamma$ where the boundary conditions \& data are defined, \& $L_f\coloneqq\|f\|_\Gamma$ is the mean-squared error of the residual function. This 2nd term encourages the PINN to learn the structural information expressed by the PDE during the training process.

This approach has been used to yield computationally efficient physics-informed surrogate models with applications in the forecasting of physical processes, model predictive control, multi-physics \& multi-scale modeling, \& simulation. It has been shown to converge to the solution of the PDE.

\paragraph{Data-driven discovery of PDEs.} Given noisy \& incomplete measurements $z$ of the state of the system, the {\it data-driven discovery of PDE} results in computing the unknown state $u(t,{\bf x})$ \& learning model parameters $\lambda$ that best describe the observed data \& it reads as follows:
\begin{equation}
	u_t + N[u;\lambda] = 0,\ {\bf x}\in\Omega,\ t\in[0,T].
\end{equation}
By defining $f(t,{\bf x})\coloneqq u_t + N[u;\lambda] = 0$, \& approximating $u(t,{\bf x})$ by a deep neural network, $f(t,{\bf x})$ results in a PINN. This network can be derived using automatic differentiation. The parameters of $u(t,{\bf x}),f(t,{\bf x})$, together with the parameter $\lambda$ of the differential operator can be then learned by minimizing the following loss function $L_{\rm tot}\coloneqq L_u + L_f$ where $L_u\coloneqq\|u - z\|_\Gamma$, with $u,z$: state solutions \& measurements at sparse location $\Gamma$, respectively \& $L_f\coloneqq\|f\|_\Gamma$ residual function. This 2nd term requires the structured information represented by the PDEs to be satisfied in the training process.

This strategy allows for discovering dynamic models described by nonlinear PDEs assembling computationally efficient \& fully differentiable surrogate models that may find application in predictive forecasting, control, \& \href{https://en.wikipedia.org/wiki/Data_assimilation}{data assimilation}.

\subsubsection{Physics-informed neural networks for piecewise function approximation}
PINN is unable to approximate PDEs that have strong nonlinearity or sharp gradients that commonly occur in practical fluid flow problems. Piecewise approximation has been an old practice in the field of numerical approximation. With the capability of approximating strong nonlinearity extremely light weight PINNs are used to solve PDEs in much larger discrete subdomains that increases accuracy substantially \& decreases computational load as well. DPINN (Distributed physics-informed neural networks) \& DPIELM (Distributed physics-informed extreme learning machines) are generalizable space-time domain discretization for better approximation. DPIELM is an extremely fast \& lightweight approximator with competitive accuracy. Domain scaling on the top has a special effect. Another school of thought is discretization for parallel computation to leverage usage of available computational resources.

XPINNs is a generalized space-time domain decomposition approach for the physics-informed neural networks (PINNs) to solve nonlinear PDEs on arbitrary complex-geometry domains. The XPINNs further pushes the boundaries of both PINNs as well as Conservative PINNs (cPINNs), which is a spatial domain decomposition approach in the PINN framework tailored to conservation laws. Compared to PINN, the XPINN method has large representation \& parallelization capacity due to the inherent property of deployment of multiple neural networks in the smaller subdomains. Unlike cPINN, XPINN can be extended to any type of PDEs. Moreover, the domain can be decomposed in any arbitrary way (in space \& time), which is not possible in cPINN. Thus, XPINN offers both space \& time parallelization, thereby reducing the training cost more effectively. The XPINN is particularly effective for the large-scale problems (involving large data set) as well as for the high-dimensional problems where single network based PINN is not adequate. The rigorous bounds on the errors resulting from the approximation of the nonlinear PDEs (incompressible NSEs) with PINNS \& XPINNs are proved. However, DPINN debunks the use of residual (flux) matching at the domain interfaces as they hardly seem to improve the optimization.

\subsubsection{Physics-informed neural networks \& functional interpolation}
{\sf X-TFC framework scheme for PDE solution learning.} In the PINN framework, initial \& boundary conditions are not analytically satisfied, thus they need to be included in the loss function of the network to be simultaneously learned with the differential equation (DE) unknown functions. Having competing objectives during the network's training can lead to unbalanced gradients while using gradient-based techniques, which causes PINNs to often struggle to accurately learn the underlying DE solution. This drawback is overcome by using functional interpolation techniques such as the Theory of Functional Connections (TFC)'s constrained expression, in the Deep-TFC framework, which reduces the solution search space of constrained problems to the subspace of neural network that analytically satisfies the constraints. A further improvement of PINN \& functional interpolation approach is given by the Extreme Theory of Functional Connections (X-TFC) framework, where a single-layer Neural Network \& the \href{https://en.wikipedia.org/wiki/Extreme_learning_machine}{extreme learning machine} training algorithm are employed. X-TFC allows to improve the accuracy \& performance of regular PINNs, \& its robustness \& reliability are proved for stiff problems, optimal control, aerospace, \& rarefied gas dynamics applications.

\subsubsection{Physics-informed PointNet (PIPN) for multiple sets of irregular geometries}
Regular PINNs are only able to obtain the solution of a forward or inverse problem on a single geometry. It means that for any new geometry (computational domain), one must retrain a PINN. This limitation of regular PINNs imposes high computational costs, specifically for a comprehensive investigation of geometric parameters in industrial designs. Physics-informed PointNet (PIPN) is fundamentally the result of a combination of PINN's loss function with PointNet. In fact, instead of using a simple fully connected neural network, PIPN uses Pointnet as the core of its neural network. PointNet has been primarily designed for \href{https://en.wikipedia.org/wiki/Deep_learning}{deep learning} of 3D object classification \& segmentation by the research group of \href{https://en.wikipedia.org/wiki/Leonidas_J._Guibas}{Leonidas J. Guibas}. PointNet extracts geometric features of input computational domains in PIPN. Thus, PIPN is able to solve governing equations on multiple computational domains (rather than only a single domain) with irregular geometries, simultaneously. The effectiveness of PIPN has been shown for \href{https://en.wikipedia.org/wiki/Incompressible_flow}{incompressible flow}, \href{https://en.wikipedia.org/wiki/Heat_transfer}{heat transfer}, \& \href{https://en.wikipedia.org/wiki/Linear_elasticity}{linear elasticity}.

\subsubsection{Physics-informed neural networks (PINNs) for inverse computations}
Physics-informed neural networks (PINNs) have proven particularly effective in solving inverse problems within differential equations, demonstrating their applicability across science, engineering, \& economics. They have shown useful for solving inverse problems in a variety of fields, including nano-optics, topology optimization{\tt/}characterization, multiphase flow in porous media, \& high-speed fluid flow. PINNs have demonstrated flexibility when dealing with noisy \& uncertain observation datasets. They also demonstrated clear advantages in the inverse calculation of parameters for multi-fidelity datasets, meaning datasets with different quality, quantity, \& types of observations. Uncertainties in calculations can be evaluated using ensemble-based or Bayesian-based calculations.

\subsubsection{Physics-informed neural networks (PINNs) with backward stochastic differential equation}
\href{https://en.wikipedia.org/wiki/Deep_backward_stochastic_differential_equation_method}{Deep backward stochastic differential equation method} is a numerical method that combines deep learning with \href{https://en.wikipedia.org/wiki/Backward_stochastic_differential_equation}{Backward stochastic differential equation} (BSDE) to solve high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of \href{https://en.wikipedia.org/wiki/Deep_neural_networks}{deep neural networks}, deep BSDE addresses the computational challenges faced by traditional numerical methods like FDMs or Monte Carlo simulations, which struggle with the curse of dimensionality. Deep BSDE methods use neural networks to approximate solutions of high-dimensional PDEs, effectively reducing the computational burden. Additionally, integrating Physics-informed neural networks (PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws into the neural network architecture, ensuring solutions adhere to governing stochastic differential equations, resulting in more accurate \& reliable solutions.

\subsubsection{Physics-informed neural networks for biology}
An extension for adaptation of PINNs are Biologically-informed neural networks (BINNs). BINNs introduce 2 key adaptations to the typical PINN framework:
\begin{itemize}
	\item[(i)] the mechanistic terms of the governing PDE are replaced by neural networks, \&
	\item[(ii)] the loss function $L_{\rm tot}$ is modified to include $L_{\rm constr}$, a term used to incorporate domain-specific knowledge that helps enforce biological applicability.
\end{itemize}
For (i), this adaptation has the advantage of relaxing the need to specify the governing differential equation a priori, either explicitly or by using a library of candidate terms. Additionally, this approach circumvents the potential issue of misspecifying regularization terms in stricter theory-informed cases.

A natural example of BINNs can be found in cell dynamics, where the cell density $u(t,{\bf x})$ is governed by a reaction-diffusion equation with diffusion \& growth functions $D(u),G(u)$, respectively:
\begin{equation*}
	u_t = \nabla\cdot(D(u)\nabla u) + G(u)u,\ {\bf x}\in\Omega,\ t\in[0,T].
\end{equation*}
In this case, a component of $L_{\rm constr}$ could be $\|D\|_\Gamma$ for $D < D_{\min}$, $D > D_{\max}$, which penalizes values of $D$ that fall outside a biologically relevant diffusion range defined by $D_{\min}\le D\le D_{\max}$. Furthermore, the BINN architecture, when utilizing \href{https://en.wikipedia.org/wiki/Multilayer_perceptron}{multiplayer-perceptrons} (MLPs), would function as follows: an MLP is used to construct $u_{\rm MLP}(t,{\bf x})$ from model inputs $(t,{\bf x})$, serving as a surrogate model for the cell density $u(t,{\bf x})$. This surrogate is then fed into the 2 additional MLPs, $D_{\rm MLP}(u_{\rm MLP}),G_{\rm MLP}(u_{\rm MLP})$, which model the diffusion \& growth functions. Automatic differentiation can then be applied to compute the necessary derivatives of $u_{\rm MLP},D_{\rm MLP},G_{\rm MLP}$ to form the governing reaction-diffusion equation.

Note that since $u_{\rm MLP}$ is a surrogate for the cell density, it may contain errors, particularly in regions where the PDE is not fully satisfied. Therefore, the reaction-diffusion equation may be solved numerically, e.g. using a \href{https://en.wikipedia.org/wiki/Method_of_lines}{method-of-lines approach}.

\subsubsection{Limitations}
Translation \& discontinuous behavior are hard to approximate using PINNs. They fail when solving differential equations with slight advective dominance \& hence asymptotic behavior causes the method to fail. Such PDEs could be solved by scaling variables. This difficulty in training of PINNs in advection-dominated PDEs can be explained by the Kolmogorov $n$-width of the solution. They also fail to solve a system of dynamical systems \& hence have not been a success in solving chaotic equations. 1 of the reasons behind the failure of regular PINNs is soft-constraining of Dirichlet \& Neumann boundary conditions which pose a multi-objective optimization problem which requires manually weighing the loss terms to be able to optimize. More generally, posing the solution of a PDE as an optimization problem brings with it all the problems that are faced in the world of optimization, the major one being getting stuck in local optima.'' -- \href{https://en.wikipedia.org/wiki/Physics-informed_neural_networks}{Wikipedia{\tt/}physics-informed neural networks PINNs}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}rational function}
``In mathematics, a {\it rational functional} is any function that can be defined by a {\it rational fraction}, which is an \href{https://en.wikipedia.org/wiki/Algebraic_fraction}{algebraic fraction} s.t. both the \href{https://en.wikipedia.org/wiki/Numerator}{numerator} \& the \href{https://en.wikipedia.org/wiki/Denominator}{denominator} are polynomials. The \href{https://en.wikipedia.org/wiki/Coefficient}{coefficients} of the polynomials need not be rational numbers; they may be taken in any field $K$. In this case, one speaks of a rational function \& a rational fraction {\it over} $K$. The values of the \href{https://en.wikipedia.org/wiki/Variable_(mathematics)}{variables} may be taken in any field $L$ containing $K$. Then the domain of the function is the set of the values of the variables for which the denominator is not zero, \& the \href{https://en.wikipedia.org/wiki/Codomain}{codomain} is $L$. The set of rational functions over a field $K$ is a field, the \href{https://en.wikipedia.org/wiki/Field_of_fractions}{field of fractions} of the ring of the \href{https://en.wikipedia.org/wiki/Polynomial_function}{polynomial functions} over $K$.

\subsubsection{Definitions}
A function $f$ is called a {\it rational function} if it can be written in the form $f(x) = \frac{P(x)}{Q(x)}$ where $P,Q$ are \href{https://en.wikipedia.org/wiki/Polynomial_function}{polynomial functions} of $x$ \& $Q$ is not the \href{https://en.wikipedia.org/wiki/Zero_function}{ero function}. The domain of $f$ is the set of all values of $x$ for which the denominator $Q(x)$ is not zero. However, if $P,Q$ have a non-constant \href{https://en.wikipedia.org/wiki/Polynomial_greatest_common_divisor}{polynomial greatest common divisor} $R$, then setting $P = P_1R,Q = Q_1R$ produces a rational function $f_1(x) = \frac{P_1(x)}{Q_1(x)}$, which may have a larger domain than $f$, \& is equal to $f$ on the domain $f$. It is a common usage to identify $f$ \& $f_1$, i.e., to extend ``by continuity'' the domain of $f$ to that of $f_1$. Indeed, one can define a rational fraction as an \href{https://en.wikipedia.org/wiki/Equivalence_class}{equivalence class} of fractions of polynomials, where 2 fractions $\frac{A(x)}{B(x)},\frac{C(x)}{D(x)}$ are considered equivalent if $A(x)D(x) = B(x)C(x)$. In this case $\frac{P(x)}{Q(x)}$ is equivalent to $\frac{P_1(x)}{Q_1(x)}$. A {\it proper rational function} is a rational function in which the \href{https://en.wikipedia.org/wiki/Degree_of_a_polynomial}{degree} of $P(x)$ is less than the degree of $Q(x)$ \& both are \href{https://en.wikipedia.org/wiki/Real_polynomial}{real polynomials}, named by analogy to a \href{https://en.wikipedia.org/wiki/Fraction#Proper_and_improper_fractions}{proper fraction} in $\mathbb{Q}$.

\paragraph{Degree.} There are several non equivalent definitions of the degree of a rational function. Most commonly, the {\it degree} of a rational function is the maximum fo the degrees of its constituent polynomials $P,Q$, when the fraction is reduced to \href{https://en.wikipedia.org/wiki/Lowest_terms}{lowest terms}. If the degree of $f$ is $d$, then the equation $f(z) = w$ has $d$ distinct solutions in $z$ except for certain values of $w$, called {\it critical values}, where 2 or more solutions coincide or where some solution is rejected \href{https://en.wikipedia.org/wiki/Point_at_infinity}{at infinity} (i.e., when the degree of the equation decreases after having \href{https://en.wikipedia.org/wiki/Clearing_denominators}{cleared the denominator}).

In the case of \href{https://en.wikipedia.org/wiki/Complex_number}{complex} coefficients, a rational function with degree 1 is a \href{https://en.wikipedia.org/wiki/M%C3%B6bius_transformation}{\it M\"bius transformation}.

The \href{https://en.wikipedia.org/wiki/Degree_of_an_algebraic_variety}{degree} of the \href{https://en.wikipedia.org/wiki/Graph_of_a_function}{graph} of a rational function is not the degree as defined above: it is the maximum of the degree of the numerator \& one plus the degree of the denominator.

In some contexts, e.g. in \href{https://en.wikipedia.org/wiki/Asymptotic_analysis}{asymptotic analysis}, the {\it degree} of a rational function is the difference between the degrees of the numerator \& the denominator.

In \href{https://en.wikipedia.org/wiki/Network_synthesis}{network synthesis} \& \href{https://en.wikipedia.org/wiki/Network_analysis_(electrical_circuits)}{network analysis}, a rational function of degree 2 (i.e., the ratio of 2 polynomials of degree $\le2$) is often called a {\it biquadratic function}.

\subsubsection{Examples}
{\sf Rational function of degree $3$, with a graph of degree $3$: $y = \frac{x^3 - 2x}{2(x^2 - 5)}$. Rational function of degree $2$, with a graph of degree $3$: $y = \frac{x^2 - 3x - 2}{x^2 - 4}$.} The rational function $f(x) = \frac{x^3 - 2x}{2(x^2 - 5)}$ is not defined at $x^2 = 5\Leftrightarrow x = \pm\sqrt{5}$. It is asymptotic to $\frac{x}{2}$ as $x\to\infty$. The rational function $f(x) = \frac{x^2 + 2}{x^2 + 1}$ is defined for all real numbers, but not for all complex numbers, since if $x$ were a square root of $-1$ (i.e. the \href{https://en.wikipedia.org/wiki/Imaginary_unit}{imaginary unit} or its negative), then formal evaluation would lead to division by zero: $f(i) = \frac{i^2 + 2}{i^2 + 1} = \frac{-1 + 2}{-1 + 1} = \frac{1}{0}$, which is undefined.

A \href{https://en.wikipedia.org/wiki/Constant_function}{constant function} e.g. $f(x) = \pi$ is a rational function since constants are polynomials. The function itself is rational, even though the \href{https://en.wikipedia.org/wiki/Value_(mathematics)}{value} of $f(x)$ is irrational for all $x$.

Every \href{https://en.wikipedia.org/wiki/Polynomial_function}{polynomial function} $f(x) = P(x)$ is a rational function with $Q(x) = 1$. A functional that cannot be written in this form, e.g. $f(x) = \sin x$, is not a rational function. However, the adjective ``irrational'' is {\it not} generally used for functions.

Every \href{https://en.wikipedia.org/wiki/Laurent_polynomial}{Laurent polynomial} can be written as a rational function while the converse is not necessarily true, i.e., the ring of Laurent polynomials is a \href{https://en.wikipedia.org/wiki/Subring}{subring} of the rational functions.

The rational function $f(x) = \frac{x}{x}$ is equal to 1 for all $x$ except 0, where there is a \href{https://en.wikipedia.org/wiki/Removable_singularity}{removable singularity}. The sum, product, or quotient (excepting division by the zero polynomial) of 2 rational functions is itself a rational function. However, the process of reduction to standard form may inadvertently result in the removal of such singularities unless care is taken. Using the definition of rational functions as equivalence classes gets around this, since $\frac{x}{x}$ is equivalent to $\frac{1}{1}$.

\subsubsection{Taylor series}
The coefficients of a \href{https://en.wikipedia.org/wiki/Taylor_series}{Taylor series} of any rational function satisfy a \href{https://en.wikipedia.org/wiki/Recurrence_relation}{linear recurrence relation}, which can be found by equating the rational function to a Taylor series with indeterminate coefficients, \& collecting \href{https://en.wikipedia.org/wiki/Like_terms}{like terms} after clearing the denominator. E.g., $\frac{1}{x^2 - x + 2} = \sum_{k=0}^\infty a_kx^k$. Multiplying through by the denominator \& distributing, $1 = (x^2 - x + 2)\sum_{k=0}^\infty a_kx^k = \cdots = 2a_0 + (2a_1 - a_0)x + \sum_{k=2}^\infty (a_{k-2} - a_{k-1} + 2a_k)x^k$. Since this holds true for all $x$ in the \href{https://en.wikipedia.org/wiki/Radius_of_convergence}{radius of convergence} of the original Taylor series, we can compute as follows. $a_0 = \frac{1}{2},a_1 = \frac{1}{4},a_k = \frac{1}{2}(a_{k-1} - a_{k-2})$ for $k\ge2$. Conversely, any sequence that satisfies a linear recurrence determines a rational function when used as the coefficients of a Taylor series. This is useful in solving such recurrences, since by using \href{https://en.wikipedia.org/wiki/Partial_fraction}{partial fraction decomposition} we can write any proper rational function as a sum of factors of the form $\frac{1}{ax + b}$ \& expand these as \href{https://en.wikipedia.org/wiki/Geometric_series}{geometric series}, giving an explicit formula for the Taylor coefficients; this is the method of \href{https://en.wikipedia.org/wiki/Generating_functions}{generating functions} (phương pháp hàm sinh trong Tổ hợp).

\subsubsection{Abstract algebra \& geometric notion}
In \href{https://en.wikipedia.org/wiki/Abstract_algebra}{abstract algebra} the concept of a polynomial is extended to include formal expressions in which the coefficients of the polynomial can be taken from any field. In this setting, given a field $F$ \& some indeterminate $X$, a {\it rational expression} (also known as a {\it rational fraction} or, in \href{https://en.wikipedia.org/wiki/Algebraic_geometry}{algebraic geometry}, a {\it rational function}) is any element of the \href{https://en.wikipedia.org/wiki/Field_of_fractions}{field of fractions} of the \href{https://en.wikipedia.org/wiki/Polynomial_ring}{polynomial ring} $F[X]$. Any rational expression can be written as the quotient of 2 polynomials $\frac{P}{Q}$ with $Q\ne0$, although this representation isn't unique. $\frac{P}{Q}$ is equivalent to $\frac{R}{S}$, for polynomials $P,Q,R,S$, when $PS = QR$. However, since $F[X]$ is a \href{https://en.wikipedia.org/wiki/Unique_factorization_domain}{unique factorization domain}, there is a \href{https://en.wikipedia.org/wiki/Irreducible_fraction}{unique representation} for any rational expression $\frac{P}{Q}$ with $P,Q$ polynomials of lowest degree \& $Q$ chosen to be \href{https://en.wikipedia.org/wiki/Monic_polynomial}{monic}. This is similar to how a fraction of integers can always be written uniquely in lowest terms by canceling out common factors.

The field of rational expressions is denoted $F(X)$. This field is said to be generated (as a field) over $F$ by (a \href{https://en.wikipedia.org/wiki/Transcendental_element}{transcendental element}) $X$, because $F(X)$ does not contain any proper subfield containing both $F$ \& the element $X$.

\paragraph{Complex rational functions.} \href{https://en.wikipedia.org/wiki/Julia_set}{Julia sets} for rational maps. $\frac{1}{az^5 + z^3 + bz},\frac{1}{z^3 + z(-3 - 3i)},\frac{z^2 - 0.2 + 0.7i}{z^2 + 0.917},\frac{z^2}{z^9 - z + 0.025}$. In \href{https://en.wikipedia.org/wiki/Complex_analysis}{complex analysis}, a rational function $f(z) = \frac{P(z)}{Q(z)}$ is the ratio of 2 polynomials with complex coefficients, where $Q$ is not the zero polynomial \& $P,Q$ have no common factor (this avoids $f$ taking the indeterminate value $\frac{0}{0}$). The domain of $f$ is the set of complex numbers s.t. $Q(z)\ne0$. Every rational function can be naturally extended to a function whose domain \& range are the whole \href{https://en.wikipedia.org/wiki/Riemann_sphere}{Riemann sphere} (\href{https://en.wikipedia.org/wiki/Complex_projective_line}{complex projective line}). Rational functions are representative examples of \href{https://en.wikipedia.org/wiki/Meromorphic_function}{meromorphic functions}. Iteration of rational functions (maps) on the \href{https://en.wikipedia.org/wiki/Riemann_sphere}{Riemann sphere} creates \href{https://en.wikipedia.org/wiki/Discrete_dynamical_system}{discrete dynamical systems}.

\paragraph{Notion of rational function on an algebraic variety.} Main article: \href{https://en.wikipedia.org/wiki/Function_field_of_an_algebraic_variety}{Wikipedia{\tt/}function field of an algebraic variety}. Like polynomials, rational expressions can also be generalized to $n$ indeterminates $X_1,\ldots,X_n$, by taking the field of fractions of $F[X_1,\ldots,X_n]$, which is denoted by $F(X_1,\ldots,X_n)$.

An extended version of the abstract idea of rational function is used in algebraic geometry. There the \href{https://en.wikipedia.org/wiki/Function_field_of_an_algebraic_variety}{function field of an algebraic variety} $V$ is formed as the field of fractions of the \href{https://en.wikipedia.org/wiki/Coordinate_ring}{coordinate ring} of $V$ (more accurately said, of a \href{https://en.wikipedia.org/wiki/Zariski_topology}{Zariski}-\href{https://en.wikipedia.org/wiki/Dense_subset}{dense} affine open set in $V$). Its elements $f$ are considered as regular functions in the sense of algebraic geometry on non-empty open sets $U$, \& also may be seen as morphisms to the \href{https://en.wikipedia.org/wiki/Projective_line}{projective line}.

\subsubsection{Applications}
Rational functions are used in \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerical analysis} for \href{https://en.wikipedia.org/wiki/Interpolation}{interpolation} \& \href{https://en.wikipedia.org/wiki/Approximation}{approximation} of functions, e.g. the \href{https://en.wikipedia.org/wiki/Pad%C3%A9_approximation}{Pad\'e approximations} introduced by \href{https://en.wikipedia.org/wiki/Henri_Pad%C3%A9}{\sc Henri Pad\'e}. Approximations in terms of rational functions are well suited for \href{https://en.wikipedia.org/wiki/Computer_algebra_system}{computer algebra systems} \& other numerical \href{https://en.wikipedia.org/wiki/Software}{software}. Like polynomials, they can be evaluated straightforwardly, \& at the same time they express more diverse behavior than polynomials.

Rational functions are used to approximate or model more complex equations in science \& engineering including \href{https://en.wikipedia.org/wiki/Field_(physics)}{fields} \& \href{https://en.wikipedia.org/wiki/Force}{forces} in physics, \href{https://en.wikipedia.org/wiki/Spectroscopy}{spectroscopy} in analytical chemistry, enzyme kinetics in biochemistry, electronic circuitry, aerodynamics, medicine concentrations in vivo, \href{https://en.wikipedia.org/wiki/Wave_function}{wave functions} for atoms \& molecules, optics \& photography to improve image resolution, \& acoustics \& sound.

In \href{https://en.wikipedia.org/wiki/Signal_processing}{signal processing}, the \href{https://en.wikipedia.org/wiki/Laplace_transform}{Laplace transform} (for continuous systems) or the \href{https://en.wikipedia.org/wiki/Z-transform}{z-transform} (for discrete-time systems) of the \href{https://en.wikipedia.org/wiki/Impulse_response}{impulse response} of commonly-used \href{https://en.wikipedia.org/wiki/Linear_time-invariant_system}{linear time-invariant systems} (filters) with \href{https://en.wikipedia.org/wiki/Infinite_impulse_response}{infinite impulse response} are rational functions over complex numbers.'' -- \href{https://en.wikipedia.org/wiki/Rational_function}{Wikipedia{\tt/}rational function}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}relaxation (iterative method)}
``In \href{https://en.wikipedia.org/wiki/Numerical_mathematics}{numerical mathematics}, {\it relaxation methods} are \href{https://en.wikipedia.org/wiki/Iterative_method}{iterative methods} for solving \href{https://en.wikipedia.org/wiki/Simultaneous_equations}{systems of equations}, including nonlinear systems.

Relaxation methods were developed for solving large \href{https://en.wikipedia.org/wiki/Sparse_matrix}{sparse} \href{https://en.wikipedia.org/wiki/Linear_system}{linear systems}, which arose as \href{https://en.wikipedia.org/wiki/Finite_difference}{finite-difference} \href{https://en.wikipedia.org/wiki/Discretization}{discretizations} of differential equations. They are also used for the solution of linear equations for \href{https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)}{linear least-squares} problems \& also for system of linear inequalities, e.g. those arising in \href{https://en.wikipedia.org/wiki/Linear_programming}{linear programming}. They have also been developed for solving nonlinear systems of equations.

Relaxation methods are important especially in the solution of linear systems used to model \href{https://en.wikipedia.org/wiki/Elliptic_partial_differential_equation}{elliptic PDEs}, e.g., \href{https://en.wikipedia.org/wiki/Laplace%27s_equation}{Laplace's equation} \& its generalization, \href{https://en.wikipedia.org/wiki/Poisson%27s_equation}{Poisson's equation}. These equations describe \href{https://en.wikipedia.org/wiki/Boundary-value_problem}{BVPs}, in which the solution-function's values are specified on boundary of a domain; the problem is to compute a solution also on its interior. Relaxation methods are used to solve the linear equations resulting from a discretization of the differential equation, e.g. by finite differences.

Iterative relaxation of solutions is commonly dubbed \href{https://en.wikipedia.org/wiki/Smoothing}{smoothing} because with certain equations, e.g., Laplace's equation, it resembles repeated application of a local smoothing filter to the solution vector. These are not to be confused with \href{https://en.wikipedia.org/wiki/Relaxation_(approximation)}{relaxation} methods in mathematical optimization, which \href{https://en.wikipedia.org/wiki/Approximation_theory}{approximate} a difficult problem by a simpler problem whose ``relaxed'' solution provides information about the solution of the original problem.

\subsubsection{Model problem of potential theory}
Main article: \href{https://en.wikipedia.org/wiki/Discrete_Poisson_equation}{Wikipedia{\tt/}discrete Poisson equation}. When $\varphi$ is a smooth real-valued function on $\mathbb{R}$, its 2nd derivative can be approximated by
\begin{equation}
	\frac{d^2\varphi(x)}{dx^2} = \frac{\varphi(x - h) - 2\varphi(x) + \varphi(x + h)}{h^2} + O(h^2).
\end{equation}
Using this in both dimensions for a function $\varphi$ of 2 arguments at the point $(x,y)$, \& solving for $\varphi(x,y)$, results in:
\begin{equation}
	\varphi(x,y) = \frac{1}{4}\left(\varphi(x + h,y) + \varphi(x,y + h) + \varphi(x - h,y) + \varphi(x,y - h) - h^2\Delta\varphi(x,y)\right) + O(h^4).
\end{equation}
To approximate the solution of Poisson equation $\Delta\varphi = \nabla^2\varphi = f$ numerically on a 2D grid with grid spacing $h$, the relaxation method assigns the given values of function $\varphi$ to the grid points near the boundary \& arbitrary values to the interior grid points, \& then repeatedly performs the assignment $\varphi\coloneqq\varphi^\star$ on the interior points, where $\varphi^\star$ is defined by
\begin{equation}
	\varphi^\star(x,y) = \frac{1}{4}\left(\varphi(x + h,y) + \varphi(x,y + h) + \varphi(x - h,y) + \varphi(x,y - h) - h^2f(x,y)\right),
\end{equation}
until convergence. The method is easily generalized to other number of dimensions.

\subsubsection{Convergence \& acceleration}
While the method converges under general conditions, it typically makes slower progress than competing methods. Nonetheless, the study of relaxation methods remains a core part of linear algebra, because the transformations of relaxation theory provide excellent \href{https://en.wikipedia.org/wiki/Preconditioner}{preconditioners} for new methods. Indeed, the choice of preconditioners is often more important than the choice of iterative method.

\href{https://en.wikipedia.org/wiki/Multigrid_methods}{Multigrid methods} may be used to accelerate the methods. One can 1st compute an approximation on a coarser grid -- usually the double spacing $2h$ -- \& use that solution with \href{https://en.wikipedia.org/wiki/Interpolation}{interpolated} values for the other grid points as the initial assignment. This can then also be done recursively for the coarser computation.

In linear systems, the 2 main classes of relaxation methods are \href{https://en.wikipedia.org/wiki/Iterative_method#Stationary_iterative_methods}{stationary iterative methods}, \& the more general \href{https://en.wikipedia.org/wiki/Iterative_method#Krylov_subspace_methods}{Krylov subspace methods}. The \href{https://en.wikipedia.org/wiki/Jacobi_method}{Jacobi method} is a simple relaxation method. The \href{https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method}{Gauss--Seidel method} is an improvement upon the Jacobi method. \href{https://en.wikipedia.org/wiki/Successive_over-relaxation}{Successive over-relaxation} can be applied to either of the Jacobi \& Gauss--Seidel methods to speed convergence.'' -- \href{https://en.wikipedia.org/wiki/Relaxation_(iterative_method)}{Wikipedia{\tt/}relaxation (iterative method)}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Schrödinger equation}
``The {\sc Schrödinger equation} is a PDE that governs the \href{https://en.wikipedia.org/wiki/Wave_function}{wave function} of a non-relativistic quantum-mechanical system. Its discovery was a significant landmark in the development of \href{https://en.wikipedia.org/wiki/Quantum_mechanics}{quantum mechanics}. It is named after \href{https://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger}{\sc Erwin Schr\"odinger}, who postulated the equation in 1925 \& published it in 1926, forming the basis for the work that resulted in his \href{https://en.wikipedia.org/wiki/Nobel_Prize_in_Physics}{Nobel Prize in Physics} in 1933.

Conceptually, the Schrödinger equation is the quantum counterpart of \href{https://en.wikipedia.org/wiki/Newton%27s_second_law}{Newton's 2nd law} in \href{https://en.wikipedia.org/wiki/Classical_mechanics}{classical mechanics}. Given a set of known initial conditions, Newton's 2nd law makes a mathematical prediction as to what path a given physical system will take over time. The Schrödinger equation gives the evolution over time of the \href{https://en.wikipedia.org/wiki/Wave_function}{wave function}, the quantum-mechanical characterization of an isolated physical system. The equation was postulated by Schrödinger based on a postulate of \href{https://en.wikipedia.org/wiki/Louis_de_Broglie}{Louis de Broglie} that all matter has an associated \href{https://en.wikipedia.org/wiki/Matter_wave}{matter wave}. The equation predicted bound states of the atom in agreement with experimental observations.

The Schrödinger equation is not the only way to study quantum mechanical systems \& make predictions. Other formulations of quantum mechanics include \href{https://en.wikipedia.org/wiki/Matrix_mechanics}{matrix mechanics}, introduced by \href{https://en.wikipedia.org/wiki/Werner_Heisenberg}{\sc Werner Heisenberg}, \& the \href{https://en.wikipedia.org/wiki/Path_integral_formulation}{path integral formulation}, developed chiefly by \href{https://en.wikipedia.org/wiki/Richard_Feynman}{\sc Richard Feynman}. When these approaches are compared, the use of the Schrödinger equation is sometimes called ``wave mechanics''. The \href{https://en.wikipedia.org/wiki/Klein%E2%80%93Gordon_equation}{Klein--Gordon equation} is a \href{https://en.wikipedia.org/wiki/Wave_equation}{wave equation} which is the relativistic version of the Schrödinger equation. The Schrödinger equation is nonrelativistic because it contains a 1st derivative in time \& a 2nd derivative in space $\Rightarrow$ space \& time are not on equal footing.

\href{https://en.wikipedia.org/wiki/Paul_Dirac}{\sc Paul Dirac} incorporated \href{https://en.wikipedia.org/wiki/Special_relativity}{special relativity} \& quantum mechanics into a \href{https://en.wikipedia.org/wiki/Dirac_equation}{single formulation} that simplifies to the Schrödinger equation in the non-relativistic limit. This is the \href{https://en.wikipedia.org/wiki/Dirac_equation}{Diract equation}, which contains a single derivative in both space \& time. The 2nd-derivative PDE of the \href{https://en.wikipedia.org/wiki/Klein%E2%80%93Gordon_equation}{Klein--Gordon equation} led to a problem with probability density even though it was a \href{https://en.wikipedia.org/wiki/Relativistic_wave_equations}{relativistic wave equation}. The probability density could be negative, which is physically unviable\footnote{điều đó không thể tồn tại được về mặt vật lý.}. This was fixed by {\sc Dirac} by taking the so-called square-root of the Klein-Gordon operator \& in turn introducing \href{https://en.wikipedia.org/wiki/Gamma_matrices}{Dirac matrices}. In a modern context, the Klein--Gordon equation describes \href{https://en.wikipedia.org/wiki/Scalar_boson}{spin-less} particles, while the Dirac equation describes \href{https://en.wikipedia.org/wiki/Fermion}{spin-$\frac{1}{2}$} particles.

\subsubsection{Definition}

\begin{enumerate}
	\item {\bf Preliminaries.} Introductory courses on physics or chemistry typically introduce the Schrödinger equation in a way that can be appreciated knowing only the concepts \& notations of basic calculus, particularly derivatives w.r.t. space \& time. A special case of the Schrödinger equation that admits a statement in those terms is the position-space Schrödinger equation for a single nonrelativistic particle in 1D:
	\begin{equation}
		\label{Schrodinger}
		i\hslash\partial_t\Psi(t,x) = \left[-\frac{\hslash^2}{2m}\partial_x^2 + V(t,x)\right]\Psi(t,x).
	\end{equation}
	Here, $\Psi(t,x)$ is a wave function, a function that assigns a \href{https://en.wikipedia.org/wiki/Complex_number}{complex number} to each point $x$ at each time $t$. The parameter $m$ is the mass of the particle, \& $V(t,x)$ is the \href{https://en.wikipedia.org/wiki/Scalar_Potential}{\it potential} that represents the environment in which the particle exists. The constant $i$: \href{https://en.wikipedia.org/wiki/Imaginary_unit}{imaginary unit}, \& $\hslash$: reduced \href{https://en.wikipedia.org/wiki/Planck_constant}{Planck constant}, which has units of \href{https://en.wikipedia.org/wiki/Action_(physics)}{action} (\href{https://en.wikipedia.org/wiki/Energy}{energy} multiplied by time). [$\ldots$]
	\item {\bf Time-dependent equation.}
	\item {\bf Time-independent equation.}
\end{enumerate}

\subsubsection{Properties}

\subsubsection{Examples}

\subsubsection{Semiclassical limit}

\subsubsection{Density matrices}

\subsubsection{Relativistic quantum physics \& quantum field theory}

\subsubsection{History}

\subsubsection{Interpretation}

'' -- \href{https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation}{Wikipedia{\tt/}Schrödinger equation}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}spectral theory}
``In mathematics, {\it spectral theory} is an inclusive term for theories extending the \href{https://en.wikipedia.org/wiki/Eigenvector}{eigenvector} \& \href{https://en.wikipedia.org/wiki/Eigenvalue}{eigenvalue} theory of a single \href{https://en.wikipedia.org/wiki/Square_matrix}{square matrix} to a much broader theory of the structure of \href{https://en.wikipedia.org/wiki/Operator_(mathematics)}{operators} in a variety of \href{https://en.wikipedia.org/wiki/Mathematical_space}{mathematical spaces}. It is a result of studies of \href{https://en.wikipedia.org/wiki/Linear_algebra}{linear algebra} \& the solutions of \href{https://en.wikipedia.org/wiki/System_of_linear_equations}{systems of linear equations} \& their generalizations. The theory is connected to that of \href{https://en.wikipedia.org/wiki/Analytic_functions}{analytic functions} because the spectral properties of an operator are related to analytic functions of the spectral parameter.

\subsubsection{Mathematical backgrounds}
The name {\it spectral theory} was introduced by \href{https://en.wikipedia.org/wiki/David_Hilbert}{\sc David Hilbert} in his original formulation of \href{https://en.wikipedia.org/wiki/Hilbert_space}{Hilbert space} theory, which was cast in terms of \href{https://en.wikipedia.org/wiki/Quadratic_form}{quadratic forms} in infinitely many variables. The original \href{https://en.wikipedia.org/wiki/Spectral_theorem}{spectral theorem} was therefore conceived as a version of the theorem on \href{https://en.wikipedia.org/wiki/Principal_axis_theorem}{principal axes} of an \href{https://en.wikipedia.org/wiki/Ellipsoid}{ellipsoid}, in an infinite-dimensional setting. The later discovery in \href{https://en.wikipedia.org/wiki/Quantum_mechanics}{quantum mechanics} that spectral theory could explain features of \href{https://en.wikipedia.org/wiki/Emission_spectrum}{atomic spectra} was therefore fortuitous. {\sc Hilbert} himself was surprised by the unexpected application of this theory, noting that ``I developed my theory of infinitely many variables from purely mathematical interests, \& even called it `spectral analysis' without any presentiment that it would later find application to the actual spectrum of physics.''

There have been 3 main ways to formulate spectral theory, each of which find use in different domains. After {\sc Hilbert}'s initial formulation, the later development of abstract \href{https://en.wikipedia.org/wiki/Hilbert_space}{Hilbert spaces} \& the spectral theory of single \href{https://en.wikipedia.org/wiki/Normal_operator}{normal operators} on them were well suited to the requirements of physics, exemplified by the work of \href{https://en.wikipedia.org/wiki/John_von_Neumann}{\sc von Neumann}. The further theory built on this to address \href{https://en.wikipedia.org/wiki/Banach_algebra}{Banach algebras} in general. This development leads to the \href{https://en.wikipedia.org/wiki/Gelfand_representation}{Gelfand representation}, which covers the \href{https://en.wikipedia.org/wiki/Commutative_Banach_algebra}{commutative case}, \& further into \href{https://en.wikipedia.org/wiki/Non-commutative_harmonic_analysis}{non-commutative harmonic analysis}.

The difference can be seen in making the connection with \href{https://en.wikipedia.org/wiki/Fourier_analysis}{Fourier analysis}. The \href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier transform} on the \href{https://en.wikipedia.org/wiki/Real_line}{real line} is in 1 sense the spectral theory of \href{https://en.wikipedia.org/wiki/Derivative}{differentiation} as a \href{https://en.wikipedia.org/wiki/Differential_operator}{differential operator}. But for that to cover the phenomena one has already to deal with \href{https://en.wikipedia.org/wiki/Generalized_eigenfunction}{generalized eigenfunctions} (e.g., by means of a \href{https://en.wikipedia.org/wiki/Rigged_Hilbert_space}{rigged Hilbert space}). On the other hand, it is simple to construct a \href{https://en.wikipedia.org/wiki/Group_algebra_of_a_locally_compact_group}{group algebra}, the spectrum of which captures the Fourier transform's basic properties, \& this is carried out by means of \href{https://en.wikipedia.org/wiki/Pontryagin_duality}{Pontryagin duality}.

One can also study the spectral properties of operators on \href{https://en.wikipedia.org/wiki/Banach_spaces}{Banach spaces}. E.g., \href{https://en.wikipedia.org/wiki/Compact_operator}{compact operators} on Banach spaces have many spectral properties similar to that of \href{https://en.wikipedia.org/wiki/Matrix_(mathematics)}{matrices}.

\subsubsection{Physical background}
The background in the physics of \href{https://en.wikipedia.org/wiki/Vibration}{vibration} has been explained in this way:
\begin{quotation}
	Spectral theory is connected with the investigation of localized vibrations of a variety of different objects, from \href{https://en.wikipedia.org/wiki/Atom}{atoms} \& \href{https://en.wikipedia.org/wiki/Molecule}{molecules} in chemistry to obstacles in \href{https://en.wikipedia.org/wiki/Waveguide_(acoustics)}{acoustic waveguides}. These vibrations have \href{https://en.wikipedia.org/wiki/Frequency}{frequencies}, \& the issue is to decide when such localized vibrations occur, \& how to go about computing the frequencies. This is a very complicated problem since every object has not only a \href{https://en.wikipedia.org/wiki/Fundamental_tone}{fundamental tone} but also a complicated series of \href{https://en.wikipedia.org/wiki/Overtone}{overtones}, which vary radically from 1 body to another.
\end{quotation}
Such physical ideas have nothing to do with the mathematical theory on a technical level, but there are examples of indirect involvement (see e.g. \href{https://en.wikipedia.org/wiki/Mark_Kac}{\sc Mark Kac}'s question \href{https://en.wikipedia.org/wiki/Can_you_hear_the_shape_of_a_drum%3F}{\it Can you hear the shape of a drum?}). {\sc Hilbert}'s adoption of the term ``spectrum'' has been attributed to an 1897 paper of \href{https://en.wikipedia.org/wiki/Wilhelm_Wirtinger}{\sc Wilhelm Wirtinger} on \href{https://en.wikipedia.org/wiki/Hill_differential_equation}{Hill differential equation} (by \href{https://en.wikipedia.org/wiki/Jean_Dieudonn%C3%A9}{\sc Jean Dieudonn\'e}), \& it was taken up by his students during the 1st decade of the 20th century, among them \href{https://en.wikipedia.org/wiki/Erhard_Schmidt}{\sc Erhard Schmidt} \& \href{https://en.wikipedia.org/wiki/Frigyes_Riesz}{\sc Frigyes Riesz}. It was almost 20 years later, when \href{https://en.wikipedia.org/wiki/Quantum_mechanics}{quantum mechanics} was formulated in terms of the \href{https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation}{Schr\"odinger equation}, that the connection was made to \href{https://en.wikipedia.org/wiki/Atomic_spectra}{atomic spectra}; a connection with the mathematical physics of vibration had been suspected before, as remarked by \href{https://en.wikipedia.org/wiki/Henri_Poincar%C3%A9}{\sc Henry Poincar\'e}, but rejected for simple quantitative reasons, absent an explanation of the \href{https://en.wikipedia.org/wiki/Balmer_series}{Balmer series}. The later discovery in quantum mechanics that spectral theory could explain features of atomic spectra was therefore fortuitous, rather than being an object of {\sc Hilbert}'s spectral theory.

\subsubsection{A definition of spectrum}

\subsubsection{Spectral theory briefly}

\subsubsection{Resolution of the identity}

\subsubsection{Resolvent operator}

\subsubsection{Operator equations}

\subsubsection{Spectral theorem \& Rayleigh quotient}

'' -- \href{https://en.wikipedia.org/wiki/Spectral_theory}{Wikipedia{\tt/}spectral theory}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}transcendental function}
``In mathematics, a {\it transcendental function} is an \href{https://en.wikipedia.org/wiki/Analytic_function}{analytic function} that does not satisfy a \href{https://en.wikipedia.org/wiki/Polynomial}{polynomial} equation whose coefficients are functions of the independent variable that can be written using only the basic operations of addition, subtraction, multiplication, \& division (without the need of taking limits). This is in contrast to an \href{https://en.wikipedia.org/wiki/Algebraic_function}{algebraic function}.

Examples of transcendental functions include the \href{https://en.wikipedia.org/wiki/Exponential_function}{exponential function}, the \href{https://en.wikipedia.org/wiki/Logarithm}{logarithm} function, the \href{https://en.wikipedia.org/wiki/Hyperbolic_function}{hyperbolic functions}, \& the \href{https://en.wikipedia.org/wiki/Trigonometric_function}{trigonometric functions}. Equations over these expressions are called \href{https://en.wikipedia.org/wiki/Transcendental_equation}{transcendental equations}.

\subsubsection{Definition}
Formally, an \href{https://en.wikipedia.org/wiki/Analytic_function}{analytic function} $f$ of 1 real or complex variable is {\it transcendental} if it is \href{https://en.wikipedia.org/wiki/Algebraically_independent}{algebraically independent} of that variable. I.e., the function does not satisfy any polynomial equation. E.g., the function $f$ given by $f(x) = \frac{ax + b}{cx + d}$ for all $x\in\mathbb{R}\backslash\{-\frac{d}{c}\}$ is not transcendental, but algebraic, because it satisfies the polynomial equation $(ax + b) - (cx + d)f(x) = 0$. Similarly, the function $f$ satisfies the equation $f(x)^5 + f(x) = x$, $\forall x\in\mathbb{R}$, is not transcendental, but algebraic, even though it cannot be written as a finite expression involving the basic arithmetic operations. This definition can be extended to \href{https://en.wikipedia.org/wiki/Function_of_several_real_variables}{functions of several variables}.

\subsubsection{History}

\subsubsection{Examples}

\subsubsection{Algebraic \& transcendental functions}

\subsubsection{Transcendentally transcendental functions}

\subsubsection{Exceptional set}

\subsubsection{Dimensional analysis}

'' -- \href{https://en.wikipedia.org/wiki/Transcendental_function}{Wikipedia{\tt/}transcendental function}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}upwind scheme}
``In \href{https://en.wikipedia.org/wiki/Computational_physics}{computational physics}, the term advection scheme refers to a class of numerical \href{https://en.wikipedia.org/wiki/Discretization}{discretization} methods for solving \href{https://en.wikipedia.org/wiki/Hyperbolic_partial_differential_equation}{hyperbolic PDEs}. In the so-called upwind scheme {\it typically}, the so-called upstream variables are used to calculate the derivatives in a flow field. I.e., derivatives are estimated using a set of data points biased to be more ``upwind'' of the query point, w.r.t. the direction of the flow. Historically, the origin of upwind methods can be traced back to the work of \href{https://en.wikipedia.org/wiki/Richard_Courant}{\sc Courant}, {\sc Isaacson}, \& {\sc Rees} who proposed the CIR method.

\subsubsection{Model equation}
To illustrate the method, consider 1D linear \href{https://en.wikipedia.org/wiki/Advection_equation}{advection equation} $\partial_tu + a\partial_xu = 0$ which describes a wave propagating along the $x$-axis with a velocity $a$. This equation is also a mathematical mdoel for 1D linear \href{https://en.wikipedia.org/wiki/Advection}{advection}. Consider a typical grind point $i$ in the domain. In a 1D domain, there are only 2 directions associated with point $i$ -- left (towards negative infinity) \& right (towards positive infinity). If $a > 0$, the traveling wave solution of the 1D linear advection equation propagates towards the right, the left side is called the {\it upwind} side \& the right side is the {\it downwind} side. Similarly, if $a < 0$ the traveling wave solution propagates towards the left, the left side is called {\it downwind} side \& right side is the {\it upwind} side. If the finite difference scheme for the spatial derivative, $\partial_xu$ contains more points in the upwind side, the scheme is called an {\it upwind-biased} or simply an {\it upwind scheme}.

\subsubsection{1st-order upwind scheme}
{\sf A simulation of a 1st-order upwind scheme in which $a = \sin t$.} The simplest upwind scheme possible is the 1st-order upwind scheme. It is given by
\begin{equation}
	\label{1st-order upwind scheme}
	\left\{\begin{split}
		\frac{u_i^{n+1} - u_i^n}{\Delta t} + a\frac{u_i^n - u_{i-1}^n}{\Delta x} &= 0&&\mbox{if } a > 0,\\
		\frac{u_i^{n+1} - u_i^n}{\Delta t} + a\frac{u_{i+1}^n - u_i^n}{\Delta x} &= 0&&\mbox{if } a < 0,
	\end{split}\right.
\end{equation}
where $n$ refers to the $t$ dimension \& $i$ refers to the $x$ dimension. By comparison, a central difference scheme in this scenario would like like
\begin{equation}
	\frac{u_i^{n+1} - u_i^n}{\Delta t} + a\frac{u_{i+1}^n - u_{i-1}^n}{2\Delta x} = 0
\end{equation}
regardless of ${\rm sign}a$.
\begin{enumerate}
	\item {\bf Compact form.} Define $a^+\coloneqq\max\{a,0\}$, $a^-\coloneqq\min\{a,0\}$ \& $u_x^+\coloneqq\frac{u_i^n - u_{i-1}^n}{\Delta x}$, $u_x^-\coloneqq\frac{u_{i+1}^n - u_i^n}{\Delta x}$ the 2 conditional equations \eqref{1st-order upwind scheme} can be combined \& written in a compact form as
	\begin{equation}
		\label{1st-order upwind scheme: compact form}
		u_i^{n+1} = u_i^n - \Delta t[a^+u_x^- + a^-u_x^+],
	\end{equation}
	which is a general way of writing any upwind-type schemes.
	\item {\bf Stability.} The upwind scheme is \href{https://en.wikipedia.org/wiki/Numerical_stability}{stable} if the following \href{https://en.wikipedia.org/wiki/Courant%E2%80%93Friedrichs%E2%80%93Lewy_condition}{Courant--Friedrichs--Lewy condition} (CFL) is satisfied. $c\coloneqq\left|\frac{a\Delta t}{\Delta x}\right|\le1$ \& $0\le a$. A \href{https://en.wikipedia.org/wiki/Taylor_series}{Taylor series} analysis of the upwind scheme will show that it is 1st-order accurate in space \& time. Modified wavenumber analysis shows that the 1st-order upwind scheme introduces severe \href{https://en.wikipedia.org/wiki/Numerical_diffusion}{numerical diffusion}{\tt/}dissipation in the solution where large gradients exist due to necessity of high wavenumbers to represent sharp gradients. {\sf The effects of the Courant number $c$ on the stability of the 1st-order upward numerical scheme.}
\end{enumerate}

\subsubsection{2nd-order upwind scheme}
The spatial accuracy of the 1st-order upwind scheme can be improved by including 3 data points instead of just 2, which offers a more accurate finite difference stencil for the approximation of spatial derivative. For the 2nd-order upwind scheme, $u_x^-$ becomes the 3-point backward difference in \eqref{1st-order upwind scheme: compact form} \& is defined as $u_x^+\coloneqq\dfrac{3u_i^n - 4u_{i-1}^n + u_{i-2}^n}{2\Delta x}$ \& $u_x^+$ is the 3-point forward difference, defined as $u_x^-\coloneqq\dfrac{-u_{i+2}^n + 4u_{i+1}^n - 3u_i^n}{2\Delta x}$. This scheme is less diffusive compared to the 1st-order accurate scheme \& is called {\it linear upwind differencing (LUD) scheme}.'' -- \href{https://en.wikipedia.org/wiki/Upwind_scheme}{Wikipedia{\tt/}upwind scheme}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}