\documentclass{article}
\usepackage[backend=biber,natbib=true,style=alphabetic,maxbibnames=50]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[utf8]{vietnam}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,enumitem,float,graphicx,mathtools,tikz}
\usetikzlibrary{angles,calc,intersections,matrix,patterns,quotes,shadings}
\allowdisplaybreaks
\newtheorem{assumption}{Assumption}
\newtheorem{baitoan}{}
\newtheorem{cauhoi}{Câu hỏi}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{dangtoan}{Dạng toán}
\newtheorem{definition}{Definition}
\newtheorem{dinhly}{Định lý}
\newtheorem{dinhnghia}{Định nghĩa}
\newtheorem{example}{Example}
\newtheorem{ghichu}{Ghi chú}
\newtheorem{hequa}{Hệ quả}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{lemma}{Lemma}
\newtheorem{luuy}{Lưu ý}
\newtheorem{nhanxet}{Nhận xét}
\newtheorem{notation}{Notation}
\newtheorem{note}{Note}
\newtheorem{principle}{Principle}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{question}{Question}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{vidu}{Ví dụ}
\usepackage[left=1cm,right=1cm,top=5mm,bottom=5mm,footskip=4mm]{geometry}
\def\labelitemii{$\circ$}
\DeclareRobustCommand{\divby}{%
	\mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\title{Data Science -- Khoa Học Dữ Liệu}
\author{Nguyễn Quản Bá Hồng\footnote{A Scientist {\it\&} Creative Artist Wannabe. E-mail: {\tt nguyenquanbahong@gmail.com}. Bến Tre City, Việt Nam.}}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
	This text is a part of the series {\it Some Topics in Advanced STEM \& Beyond}:
	
	{\sc url}: \url{https://nqbh.github.io/advanced_STEM/}.
	
	Latest version:
	\begin{itemize}
		\item {\it Data Science -- Khoa Học Dữ Liệu}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/data_science/NQBH_data_science.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/data_science/NQBH_data_science.tex}.
	\end{itemize}
\end{abstract}
\tableofcontents

%------------------------------------------------------------------------------%

\section{Basic Data Science -- Khoa Học Dữ Liệu Cơ Bản}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{McKinney2022}. {\sc Wes McKinney}. {\it Python for Data Analysis: Data Wrangling with pandas, {\tt NumPy} \& Jupyter}. {\sf[356 Amazon ratings][25357 Goodreads ratings]}
	
	{\sf Amazon review.} Get definitive handbook for manipulating, processing, cleaning, \& crunching datasets in Python. Updated for Python 3.10 \& {\tt pandas} 1.4, 3e of this hand-on guide is packed with practical case studies that show you how to solve a broad set of data analysis problems effectively. Learn latest versions of pandas, NumPy, \& Jupyter in process.
	
	Written by {\sc Wes McKinney}, creator of Python {\tt pandas} project, this book is a practical, modern introduction to data science tools in Python. Ideal for analysts new to Python \& for Python programmers new to data science \& scientific computing. Data files \& related material are available on GitHub.
	\begin{itemize}
		\item use Jupyter notebook \& IPython shell for exploratory computing
		\item Learn basic \& advanced features in NumPy
		\item Get started with data analysis tools in {\tt pandas} library
		\item Use flexible tools to load, clean, transform, merge, \& reshape data
		\item Create informative visualizations with matplotlib
		\item Apply {\tt pandas} groupby facility to slice, dice, \& summarize datasets
		\item Analyze \& manipulative regular \& irregular time series data
		\item Learn how to solve real-world data analysis problems with thorough, detailed examples
	\end{itemize}
	{\sf About the Author.} {\sc Wes McKinney} is a Nashville-based software developer \& entrepreneur. After finishing his undergraduate degree in mathematics at MIT in 2007, he went on to do quantitative finance work at AQR Capital Management in Greenwich, CT. Frustrated by cumbersome data analysis tools, he learned Python \& started building what would later become {\tt pandas} project. He's now an active member of Python data community \& is an advocate for Python use in data analysis, finance, \& statistical computing applications.
	
	{\sc Wes} was later cofounder \& CEO of DataPad, whose technology assets \& team were acquired by Cloudera in 2014. He has since become involved in big data technology, joining Project Management Committees for Apache Arrow \& Apache Parquet projects in Apache Software Foundation. In 2018, he founded Ursa Labs, a not-for-profit organization focused Apache Arrow development, in partnership with RStudio \& 2 Sigma Investments. In 2021, he cofounded technology startup Voltron Data, where he currently works as Chief Technology Officer.
	
	``With this new edition, {\sc Wes} has updated his book to ensure it remains go-to resource for all things related to data analysis with Python \& pandas. I cannot recommend this book highly enough.'' -- {\sc Paul Barry}, Lecturer \& author of O'Reiley; {\it Head 1st Python}
	
	{\sc Wes McKinney}, cofounder \& chief technology officer of Voltron Data, is an active member of Python data community \& an advocate for Python use in data analysis, finance, \& statistical computing applications. A graduate of MIT, he's also a member of project management committees for Apache Software Foundation's Apache Arrow \& Apache Parquet projects.
	
	{\sf Preface.} 1e of this book was published in 2012, during a time when open source data analysis libraries for Python, especially pandas, were very new \& developing rapidly. When time came to write 2e in 2016--2017, needed to update book not only for Python 3.6 (1e used Python 2.7) but also for many changes in {\tt pandas} that had occurred over previous 5 years. 2022, there are fewer Python language changes (now at Python 3.10, with 3.11 coming out at end of 2022), but {\tt pandas} has continued to evolve.
	
	In 3e, goal: bring content up to date with current versions of Python, NumPy, pandas, \& other projects, while also remaining relatively conservative about discussing newer Python projects having appeared in last few years. Since this book has become an important resource for many university courses \& working professionals, try to avoid topics that are at risk of falling out of date within 1--2 year. That way paper copies won't be too difficult to follow in 2023 or 2024 or beyond.
	
	A new feature of 3e: open access online version hosted on website \url{https://wesmckinney.com/book}, to serve as a resource \& convenience for owners of print \& digital editions. Intend to keep content reasonably up to date there, so if you paper paper book \& run into sth that doesn't work properly, should check there for latest content changes.
	
	{\bf Using Code Examples.} Can find data files \& related material for each chap in this book's GitHub repository at \url{https://github.com/wesm/pydata-book}, which is mirrored to Gitee (for those who cannot access GitHub) at \url{https://gitee.com/wesmckinn/pydata-book}.
	
	This book is here to help get job done. In general, if example code is offered with this book, may use it in your programs \& documentation. Do not need to contact for permission unless you're reproducing a significant portion of code. E.g., writing a program that uses several chunks of code from this book does not require permission. Selling or distributing examples from O'Reilly books does not require permission. Answering a question by citing this book \& quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product's documentation does require permission.
	
	{\bf Acknowledgments for 3e (2022).} $> 1$ decade since started writing 1e of this book \& $> 15$ years since originally started journey as a Python programmer. A lot has changed since then! Python has evolved from a relatively niche (ngách) language for data analysis to most popular \& most widely used language powering plurality (if not majority!) of DS, ML, \& AI work.
	
	Have not been an active contributor to {\tt pandas} open source project since 2013, but its worldwide developer community has continued to thrive, serving as a model of community-centric open source software development. Many ``next-generation'' Python projects that deal with tabular data are modeling their user interfaces directly after pandas, so project has proved to have an enduring influence on future trajectory of Python DS ecosystem.
	
	{\bf Acknowledgments for 2e (2017).} 5 years almost to day since completed manuscript for this book's 1e in Jul 2012. A lot has changed. Python community has grown immensely, \& ecosystem of open source software around it has flourished.
	
	This new edition of book would not exist if for tireless efforts of {\tt pandas} core developers, who have grown project \& its user community into 1 of cornerstones of Python DS ecosystem.
	
	With open source software projects more thinly resourced than ever relative to size of user bases, it is becoming increasingly important for businesses to provide support for development of key open source projects. It's the right thing to do.
	\begin{itemize}
		\item {\sf1. Preliminaries.}
		\begin{itemize}
			\item {\sf1.1. What Is This Book About?} This book is concerned with nuts \& bolts of manipulating, processing, cleaning, \& crunching (nhai giòn tan) data in Python. Goal: offer a guide to parts of Python programming language \& its data-oriented library ecosystem \& tools that will equip you to become an effective data analyst. While ``data analysis'' is in title of book, focus is specifically on Python programming, libraries, \& tools as opposed to data analysis methodology. This is Python programming you need {\it for} data analysis.
			
			Sometime after {\sc Wes} originally published this book in 2012, people started using term {\it data science} as an umbrella description for everything from simple descriptive statistics to more advanced statistical analysis \& ML. Python open source ecosystem for doing data analysis (or DS) has also expanded significantly since then. There are now many other books which focus specifically on these more advanced methodologies. Hope: this book serves as adequate preparation to enable you to move on to a more domain-specific resource.			
			\begin{remark}
				Some might characterize much of content of book as ``data manipulation'' as opposed to ``data analysis.'' Also use terms \emph{wrangling} or \emph{munging} to refer to data manipulation.
			\end{remark}
			{\sf What Kinds of Data?} Primary focus is on {\it structured data}, a deliberately vague term that encompasses many different common forms of data, e.g.:
			\begin{itemize}
				\item Tabular or spreadsheet-like data in which each column may be a different type (string, numeric, date, or otherwise). This includes most kinds of data commonly stored in relational databases or tab- or comma-delimited text files.
				\item Multidimensional arrays (matrices).
				\item Multiple tables of data interrelated by key columns (what would be primary or foreign keys for a SQL user).
				\item Evenly or unevenly spaced time series.
			\end{itemize}
			This is by no means a complete list. Even though it may not always be obvious, a large percentage of datasets can be transformed into a structured form that is more suitable for analysis \& modeling. If not, it may be possible to extract features from a dataset into a structured form. E.g., a collection of news articles could be processed into a word frequency table, which could then be used to perform sentiment analysis.
			
			Most users of spreadsheet programs like Microsoft Excel, perhaps most widely used data analysis tool in the world, will not be strangers to these kinds of data.
			\item {\sf1.2. Why Python for Data Analysis?} For many people, Python programming language has strong appeal. Since its 1st appearance in 1991, Python has become 1 of most popular interpreted programming languages, along with Perl, Ruby, \& others. Python \& Ruby have become especially popular since 2005 or so for building websites using their numerous web frameworks, like Rails (Ruby) \& Django (Python). Such languages are often called {\it scripting} languages, as they can be used to quickly write small programs, or {\it scripts} to automate other tasks. I don't like term ``scripting languages,'' as it carries a connotation that they cannot be used for building serious software. Among interpreted languages, for various historical \& cultural reasons, Python has developed a large \& active scientific computing \& data analysis community. In last 20 years, Python has gone from a bleeding-edge or ``at your own risk'' scientific computing language to 1 of most important languages for DS, ML, \& general software development in academia \& industry.
			
			For data analysis \& interactive computing \& data visualization, Python will inevitably draw comparisons with other open source \& commercial programming languages \& tools in wide use, e.g. R, MATLAB, SAS, Stata, \& others. In recent years, Python's improved open source libraries (e.g. {\tt pandas} \& scikit-learn) have made it a popular choice for data analysis tasks. Combined with Python's overall strength for general-purpose software engineering, it is an excellent option as a primary language for building data applications.
			\begin{itemize}
				\item {\sf Python as Glue.} Part of Python's success in scientific computing: ease of integrating C, C++, \& FORTRAN code - -1 phần thành công của Python trong điện toán khoa học: dễ dàng tích hợp mã C, C++, \& FORTRAN. Most modern computing environments share a similar set of legacy FORTRAN \& C libraries for doing linear algebra, optimization, integration, fast Fourier transforms, \& other such algorithms. Same story has held true for many companies \& national labs that have used Python to glue together decades' worth of legacy software.
				
				Many programs consist of small portions of code where most of time is spent, with large amounts of ``glue code'' that doesn't run often. In many cases, execution time of glue code is significant; effort is most fruitfully invested in optimizing computational bottlenecks, sometimes by moving code to a lower-level language like C.
				\item {\sf Solving ``2-Language'' Problem.} In many organizations, common to research, prototype, \& test new ideas using a more specialized computing language like SAS or R \& then later port those ideas to be part of a larger production system written in, say, Java, C\#, or C++. What people are increasingly finding: Python is a suitable language not only for doing research \& prototyping but also for building production systems. {\it Why maintain 2 development environments when one will suffice?} Believe more \& more companies will go down this path, as there are often significant organizational benefits to having both researchers \& software engineers using same set of programming tools.
				
				Over last decade some new approaches to solving ``2-language'' problem have appeared, e.g. Julia programming language. Getting most out of Python in many cases {\it will} require programming in a low-level language like C or C++ \& creating Python bindings to that code. I.e., ``just-in-time'' (JIT) compiler technology provided by libraries like Numba have provided a way to achieve excellent performance in many computational algorithms without having to leave Python programming environment.
				\item {\bf Why Not Python?} While Python is an excellent environment for building many kinds of analytical applications \& general-purpose systems, there are a number of uses for which Python may be less suitable.
				
				As Python is an interpreted programming language, in general most Python code will run substantially slower than code written in a compiled language like Java or C++. As {\it programmer time} is often more valuable than {\it CPU time}, many are happy to make this trade-off. However, in an application with very low latency or demanding resource utilization requirements (e.g., a high-frequency trading systems), time spent programming in a lower-level (but also lower-productivity) language like C++ to achieve maximum possible performance might be time well spent.
				
				-- Vì Python là ngôn ngữ lập trình được thông dịch, nhìn chung hầu hết mã Python sẽ chạy chậm hơn đáng kể so với mã được viết bằng ngôn ngữ biên dịch như Java hoặc C++. Vì {\it thời gian lập trình} thường có giá trị hơn {\it thời gian CPU}, nhiều người vui vẻ chấp nhận sự đánh đổi này. Tuy nhiên, trong một ứng dụng có độ trễ rất thấp hoặc yêu cầu sử dụng tài nguyên khắt khe (ví dụ: hệ thống giao dịch tần suất cao), thời gian dành cho việc lập trình bằng ngôn ngữ cấp thấp hơn (nhưng cũng có năng suất thấp hơn) như C++ để đạt được hiệu suất tối đa có thể là thời gian được sử dụng hợp lý.
				
				Python can be a challenging language for building highly concurrent, multithreaded applications, particularly applications with many CPU-bound threads. Reason for this: it has what is known as {\it global interpreter lock} (GIL), a mechanism that prevents interpreter from executing $> 1$ Python instruction at a time. Technical reasons for why GIL exists are beyond scope of this book. While it is true that in many big data processing applications, a cluster of computers may be required to process a dataset in a reasonable amount of time, there are still situations where a single-process, multithreaded system is desirable.
				
				This is not to say: Python cannot execute truly multithreaded, parallel code. Python C extensions that use native mutithreading (in C or C++) can run code in parallel without being impacted by GIL, as long as they do not need to regularly interact with Python objects.
			\end{itemize}
			\item {\sf1.3. Essential Python Libraries.} For those who are less familiar with Python data ecosystem \& libraries used throughout book, a brief overview of some of them:
			\begin{itemize}
				\item {\sf NumPy.} \href{https://numpy.org}{NumPy}, short for Numerical Python, has long been a cornerstone of numerical computing in Python. It provides data structures, algorithms, \& library glue needed for most scientific applications involving numerical data in Python. {\tt NumPy} contains, among other things:
				\begin{itemize}
					\item A fast \& efficient multidimensional array object {\tt ndarray}
					\item Functions for performing element-wise computations with arrays or mathematical operations between arrays
					\item Tools for reading \& writing array-based datasets to disk
					\item Linear algebra operations, Fourier transform, \& random number generation
					\item A mature C API to enable Python extensions \& native C or C++ code to access NumPy's data structures \& computational facilities
				\end{itemize}
				Beyond fast array-processing capabilities that {\tt NumPy} adds to Python, 1 of its primary uses in data analysis is as a container for data to be passed between algorithms \& libraries. For numerical data, {\tt NumPy} arrays are more efficient for storing \& manipulating data than the other built-in Python data structures. Also, libraries written in a lower-level language, e.g. C or FORTRAN, can operate on data stored in a {\tt NumPy} array without copying data into some other memory representation. Thus, many numerical computing tools for Python either assume {\tt NumPy} arrays as a primary data structure or else target interoperability with NumPy.
				\item {\tt pandas.} \href{https://pandas.pydata.org}{pandas} provides high-level data structures \& functions designed to make working with structured or tabular data intuitive \& flexible. Since its emergence in 2010, it has helped enable Python to be a powerful \& productive data analysis environment. Primary objects in {\tt pandas} that will be used in this book are {\tt DataFrame}, a tabular, column-oriented data structure with both row \& column labels, \& {\tt Series}, a 1D labeled array object.
				
				{\tt pandas} blends array-computing ideas of {\tt NumPy} with kinds of data manipulation capabilities found in spreadsheets \& relationship databases (e.g. SQL). It provides convenient indexing functionality to enable you to reshape, slice \& dice, perform aggregations (thực hiện tổng hợp), \& select subsets of data. Since data manipulation, preparation, \& cleaning are such important skills in data analysis, {\tt pandas} is 1 of primary focuses of this book.
				
				As a bit of background, {\sc McKinney} started building {\tt pandas} in early 2008 during his tenure at AQR Capital Management, a quantitative investment management firm. At time, {\sc McKinney} had a distinct set of requirements that were not addressed by any single tool at his disposal:
				\begin{itemize}
					\item Data structures with labeled axes supporting automatic or explicit data alignment -- this prevents common errors resulting from misaligned data \& working with differently indexed data coming from different sources
					\item Integrated time series functionality
					\item Same data structures handle both time series data \& non-time series data
					\item Arithmetic operations \& reductions that preserve metadata
					\item Flexible handling of missing data
					\item Merge \& other relational operations found in popular databases (e.g., SQL-based)
				\end{itemize}
				Wanted to be able to do all of these things in 1 place, preferably in a language well suited to general-purpose software development. Python was a good candidate language for this, but at that time an integrated set of data structures \& tools providing this functionality did not exist. As a result of having been built initially to solve finance \& business analytics problems, {\tt pandas} features especially deep time series functionality \& tools well suited for working with time-indexed data generated by business processes.
				
				{\sc McKinney} spent a large part of 2011 \& 2012 expanding pandas's capabilities with some of former AQR colleagues, {\sc Adam Klein, Chang She}. In 2013, stopped being as involved in day-to-day project development, \& {\tt pandas} has since become a fully community-owned \& community-maintained project with well $> 2000$ unique contributors around world.
				
				For users of R language for statistical computing, {\tt DataFrame} name will be familiar, as object was named after similar R {\tt data.frame} object. Unlike Python, data frames are built into R programming language \& its standard library. As a result, many features found in {\tt pandas} are typically either part of R core implementation or provided by add-on packages.
				
				pandas name itself is derived from {\it panel data}, an econometrics term for multidimensional structured datasets, \& a play on phrase {\it Python data analysis}.
				\item {\sf matplotlib.} \href{https://matplotlib.org}{matplotlib} is most popular Python library for producing plots \& other 2D data visualizations. It was originally created by {\sc John D. Hunter} \& is now maintained by a large team of developers. It is designed for creating plots suitable for publication. While there are other visualization libraries available to Python programmers, matplotlib is still widely used \& integrates reasonably well with rest of ecosystem. Think it is a safe choice as a default visualization tool.
				\item {\tt IPython \& Jupyter.} \href{https://ipython.org}{IPython project} began in 2001 as {\sc Fernando P\'erez}'s side project to make a better interactive Python interpreter. Over subsequent 20 years it has become 1 of most important tools in modern Python data stack. While it does not provide any computational or data analytical tools by itself, IPython is designed for both interactive computing \& software development work. It encourages an {\it execute-explore} workflow instead of typical {\it edit-compile-run} workflow of many other programming languages. It also provides integrated access to OS's shell \& filesystem; this reduces need to switch between a terminal window \& a Python session in many cases. Since much of data analysis coding involves exploration, trial \& error, \& iteration, IPython can help you get job done faster.
				
				In 2014, {\sc Fernando} \& IPython team announced \href{https://jupyter.org}{Jupyter project}, a broader initiative to design language-agnostic interactive computing tools. IPython web notebook became Jupyter notebook, with support now for $> 40$ programming languages. IPython system can now be used as a {\it kernel} (a programming language mode) for using Python with Jupyter.
				
				IPython itself has become a component of much broader Jupyter open source project, which provides a productive environment for interactive \& exploratory computing. Its oldest \& simplest ``mode'' is as an enhanced Python shell designed to accelerate writing, testing, \& debugging of Python code. You can also use IPython system through Jupyter notebook.
				
				Jupyter notebook system also allows you to author content in Markdown \& HTML, providing you a means to create rich documents with code \& text.
				
				{\sc McKinney} personally uses IPython \& Jupyter regularly in Python work, whether running, debugging, or testing code.
				
				In \href{https://github.com/wesm/pydata-book}{accompanying book materials on GitHub}, you will find Jupyter notebooks containing all code examples from each chap. If cannot access GitHub where you are, can \href{https://gitee.com/wesmckinn/pydata-book}{try mirror on Gitee}.
				\item {\tt SciPy.} \href{https://scipy.org}{SciPy} is a collection of packages addressing a number of foundational problems in scientific computing. Some of tools it contains in its various modules:
				\begin{itemize}
					\item {\tt scipy.integrate}: Numerical integration routines \& differential equation solvers
					\item {\tt scipy.linalg}: Linear algebra routines \& matrix decompositions extending beyond those provided in {\tt numpy.linalg}
					\item {\tt scipy.optimize}: Function optimizers (minimizers) \& root finding algorithms
					\item {\tt scipy.signal}: Signal processing tools
					\item {\tt scipy.sparse}: Sparse matrices \& sparse linear system solvers
					\item {\tt scipy.special}: Wrapper around SPECFUN, a FORTRAN library implementing many common mathematical functions, e.g. {\tt gamma} function
					\item {\tt scipy.stats}: Standard continuous \& discrete probability distributions (density functions, samplers, continuous distribution functions), various statistical tests, \& more descriptive statistics
				\end{itemize}
				Together, {\tt NumPy} \& SciPy form a reasonably complete \& mature computational foundation for many traditional scientific computing applications.
				\item {\tt scikit-learn}: Since project's inception in 2007, \href{https://scikit-learn.org}{scikit-learn} has become premier general-purpose ML toolkit for Python programmers. As of this writing, $> 2000$ different individuals have contributed code to project. It includes submodels for such models as:
				\begin{itemize}
					\item Classification: SVM, nearest neighbors, random forest, logistic regression, etc.
					\item Regression: Lasso, ridge regression, etc.
					\item Clustering: $k$-means, spectral clustering, etc.
					\item Dimensionality reduction: PCA, feature selection, matrix factorization, etc.
					\item Model selection: Grid search, cross-validation, metrics
					\item Preprocessing: Feature extraction, normalization
				\end{itemize}
				Along with pandas, statsmodels, \& IPython, scikit-learn has been critical for enabling Python to be a productive DS programming language. While I won't be able to include a comprehensive guide to scikit-learn in this book, I will give a brief introduction to some of its models \& how to use them with other tools presented in book.
				\item \href{https://statsmodels.org}{\tt statsmodels} is a statistical analysis package that was seeded by work from Stanford University statistics professor {\sc Jonathan Taylor}, who implemented a number of regression analysis models popular in R programming language. {\sc Skipper Seabold \& Josef Perktold} formally created new statsmodels project in 2010 \& since then have grown project to a critical mass of engaged users \& contributors. {\sc Nathaniel Smith} developed Patsy project, which provides a formula or model specification framework for statsmodels inspired by R's formula system.
				
				Compared with scikit-learn, statsmodels contains algorithms for classical (primarily frequentist) statistics \& econometrics. This includes such submodules as:
				\begin{itemize}
					\item Regression models: linear regression, generalized linear models, robust linear models, linear mixed effect models, etc.
					\item Analysis of variance (ANOVA)
					\item Time series analysis: AR, ARMA, ARIMA, VAR, \& other models
					\item Nonparametric methods: Kernel density estimation, kernel regression
					\item Visualization of statistical model results
				\end{itemize}
				statsmodels is more focused on statistical inference, providing uncertainty estimates \& $p$-values for parameters. scikit-learn, by contrast, is more prediction focused.
				
				As with scikit-learn, give a brief introduction to statsmodels \& how to use it with {\tt NumPy} \& pandas.
				\item {\tt Other Packages.} In 2022, there are many other Python libraries which might be discussed in a book about DS. This includes some newer projects like TensorFlow or PyTorch, which have become popular for ML or AI work. Now that there are other books out there that focus more specifically on those projects, recommend using this book to build a foundation in general-purpose Python data wrangling. Then, you should be well prepared to move on to a more advanced resource that may assume a certain level of expertise.
			\end{itemize}
			\item {\sf1.4. Installation \& Setup.} Since everyone uses Python for different applications, there is no single solution for setting up Python \& obtaining necessary add-on packages. Many readers will not have a complete Python development environment suitable for following along with this book, so here give detailed instructions to get set up on each OS. Use Miniconda, a minimal installation of conda package manager, along with \href{https://conda-forge.org}{conda-forge}, a community-maintained software distribution based on conda. This book uses Python 3.10 throughout, but if read in future, welcome to install a newer version of Python.
			
			If for some reason these instructions become out-of-date by time you are reading this, can check \href{https://wesmckinney.com/book}{website for book} which I will endeavor to keep up to date with latest installation instructions.
			\begin{itemize}
				\item {\tt Miniconda on Windows.}
				\item {\tt GNU{\tt/}Linux.} Linux details will vary a bit depending on Linux distribution type, but here give details for such distributions as Debian, Ubuntu, CentOS, \& Fedora. Setup is similar to macOS with exception of how Miniconda is installed. Most readers will want to download default 64-bit installer file, which is for x86 architecture (but possible in future more users will have aarch64-based Linux machines). Installer is a shell script that must be executed in terminal. Then have a file named sth similar to \verb|Miniconda3-latest-Linux-x86_64.sh|. To install it, execute this script with {\tt bash}:
				\begin{verbatim}
					$ bash Miniconda3-latest-Linux-x86_64.sh
				\end{verbatim}
				
				\begin{remark}
					Some Linux distributions have all required Python packages (although outdated versions, in some cases) in their package managers \& can be installed using a tool like {\tt apt}. Setup described here uses Miniconda, as it's both easily reproducible across distributions \& simpler to upgrade packages to their latest versions.
				\end{remark}
				Will have a choice of where to put Miniconda files. Recommend installing files in default location in home directory; e.g., \verb|/home/$USER/miniconda| (with your username, naturally).
				
				Installer will ask if wish to modify shell scripts to automatically activate Miniconda. Recommend doing this (select ``yes'') as a matter of convenience.
				
				After completing installation, start a new terminal process \& verify that you are picking up new Miniconda installation:
				\begin{verbatim}
					(base) nqbh@nqbh-dell:~/advanced_STEM_beyond/data_science$ python
					Python 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:27:36) [GCC 11.2.0] on linux
					Type "help", "copyright", "credits" or "license" for more information.
					>>>
				\end{verbatim}
				To exit Python shell, type {\tt exit()} \& press Enter or press Ctrl-D.
				\item {\sf Miniconda on macOS.}
				\item {\sf Installing Necessary Packages.} Have set up Miniconda on system, time to install main packages will be using in this book. 1st step: configure {\tt conda-forge} as default package channel by running commands in a shell:
				\begin{verbatim}
					(base) $ conda config --add channels conda-forge
					(base) $ conda config --set channel_priority strict
				\end{verbatim}
				Now create a new conda ``environment'' with {\tt conda create} command using Python 3.10:
				\begin{verbatim}
					(base) $ conda create -y -n pydata-book python=3.10
					
					(base) nqbh@nqbh-dell:~$ conda create -y -n pydata-book python=3.12.7
					Retrieving notices: done
					Channels:
					- conda-forge
					- defaults
					Platform: linux-64
					Collecting package metadata (repodata.json): done
					Solving environment: done
					
					## Package Plan ##
					
					environment location: /home/nqbh/anaconda3/envs/pydata-book
					
					added / updated specs:
					- python=3.12.7
					
					
					The following packages will be downloaded:
					
					package                    |            build
					---------------------------|-----------------
					_libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge
					_openmp_mutex-4.5          |            2_gnu          23 KB  conda-forge
					bzip2-1.0.8                |       h4bc722e_7         247 KB  conda-forge
					ca-certificates-2024.12.14 |       hbcca054_0         153 KB  conda-forge
					ld_impl_linux-64-2.43      |       h712a8e2_2         654 KB  conda-forge
					libexpat-2.6.4             |       h5888daf_0          72 KB  conda-forge
					libffi-3.4.2               |       h7f98852_5          57 KB  conda-forge
					libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge
					libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge
					libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge
					liblzma-5.6.3              |       hb9d3cd8_1         109 KB  conda-forge
					liblzma-devel-5.6.3        |       hb9d3cd8_1         368 KB  conda-forge
					libnsl-2.0.1               |       hd590300_0          33 KB  conda-forge
					libsqlite-3.47.2           |       hee588c1_0         853 KB  conda-forge
					libuuid-2.38.1             |       h0b41bf4_0          33 KB  conda-forge
					libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge
					libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge
					ncurses-6.5                |       he02047a_1         868 KB  conda-forge
					openssl-3.4.0              |       h7b32b05_1         2.8 MB  conda-forge
					pip-24.3.1                 |     pyh8b19718_2         1.2 MB  conda-forge
					python-3.12.7              |hc5c86c4_0_cpython        30.1 MB  conda-forge
					readline-8.2               |       h8228510_1         275 KB  conda-forge
					setuptools-75.7.0          |     pyhff2d567_0         756 KB  conda-forge
					tk-8.6.13                  |noxft_h4845f30_101         3.2 MB  conda-forge
					tzdata-2024b               |       hc8b5060_0         119 KB  conda-forge
					wheel-0.45.1               |     pyhd8ed1ab_1          61 KB  conda-forge
					xz-5.6.3                   |       hbcc6ac9_1          23 KB  conda-forge
					xz-gpl-tools-5.6.3         |       hbcc6ac9_1          33 KB  conda-forge
					xz-tools-5.6.3             |       hb9d3cd8_1          88 KB  conda-forge
					------------------------------------------------------------
					Total:        43.4 MB
					
					The following NEW packages will be INSTALLED:
					
					_libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge 
					_openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu 
					bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 
					ca-certificates    conda-forge/linux-64::ca-certificates-2024.12.14-hbcca054_0 
					ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_2 
					libexpat           conda-forge/linux-64::libexpat-2.6.4-h5888daf_0 
					libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 
					libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 
					libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_1 
					libgomp            conda-forge/linux-64::libgomp-14.2.0-h77fa898_1 
					liblzma            conda-forge/linux-64::liblzma-5.6.3-hb9d3cd8_1 
					liblzma-devel      conda-forge/linux-64::liblzma-devel-5.6.3-hb9d3cd8_1 
					libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 
					libsqlite          conda-forge/linux-64::libsqlite-3.47.2-hee588c1_0 
					libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 
					libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 
					libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 
					ncurses            conda-forge/linux-64::ncurses-6.5-he02047a_1 
					openssl            conda-forge/linux-64::openssl-3.4.0-h7b32b05_1 
					pip                conda-forge/noarch::pip-24.3.1-pyh8b19718_2 
					python             conda-forge/linux-64::python-3.12.7-hc5c86c4_0_cpython 
					readline           conda-forge/linux-64::readline-8.2-h8228510_1 
					setuptools         conda-forge/noarch::setuptools-75.7.0-pyhff2d567_0 
					tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 
					tzdata             conda-forge/noarch::tzdata-2024b-hc8b5060_0 
					wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 
					xz                 conda-forge/linux-64::xz-5.6.3-hbcc6ac9_1 
					xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.6.3-hbcc6ac9_1 
					xz-tools           conda-forge/linux-64::xz-tools-5.6.3-hb9d3cd8_1 
					
					
					
					Downloading and Extracting Packages:
					
					Preparing transaction: done                                                     
					Verifying transaction: done                                                     
					Executing transaction: done                                                     
					#                                                                               
					# To activate this environment, use                                             
					#                                                                               
					#     $ conda activate pydata-book                                              
					#                                                                               
					# To deactivate an active environment, use                                      
					#                                                                               
					#     $ conda deactivate
				\end{verbatim}
				After installation completes, activate environment with {\tt conda activate}:
				\begin{verbatim}
					(base) nqbh@nqbh-dell:~$ conda activate pydata-book                             
					(pydata-book) nqbh@nqbh-dell:~$
				\end{verbatim}
				
				\begin{remark}
					Necessary to use {\tt conda activate} to activate your environment each time you open a new terminal. Can see information about active conda environment at any time from terminal by running {\tt conda info}.
				\end{remark}
				Now, install essential packages used throughout book (along with their dependencies) with {\tt conda install}:
				\begin{verbatim}
					(pydata-book) $ conda install -y {\tt pandas} jupyter matplotlib
					
					(pydata-book) nqbh@nqbh-dell:~$ conda install -y {\tt pandas} jupyter matplotlib      
					Channels:                                                                       
					- conda-forge                                                                  
					- defaults                                                                     
					Platform: linux-64                                                              
					Collecting package metadata (repodata.json): done                               
					Solving environment: done                                                       
					
					## Package Plan ##                                                              
					
					environment location: /home/nqbh/anaconda3/envs/pydata-book
					
					added / updated specs:
					- jupyter
					- matplotlib
					- pandas
					
					
					The following packages will be downloaded:
					
					package                    |            build
					---------------------------|-----------------
					alsa-lib-1.2.13            |       hb9d3cd8_0         547 KB  conda-forge
					anyio-4.8.0                |     pyhd8ed1ab_0         113 KB  conda-forge
					argon2-cffi-23.1.0         |     pyhd8ed1ab_1          18 KB  conda-forge
					argon2-cffi-bindings-21.2.0|  py312h66e93f0_5          34 KB  conda-forge
					arrow-1.3.0                |     pyhd8ed1ab_1          98 KB  conda-forge
					asttokens-3.0.0            |     pyhd8ed1ab_1          28 KB  conda-forge
					async-lru-2.0.4            |     pyhd8ed1ab_1          15 KB  conda-forge
					attrs-24.3.0               |     pyh71513ae_0          55 KB  conda-forge
					babel-2.16.0               |     pyhd8ed1ab_1         6.2 MB  conda-forge
					beautifulsoup4-4.12.3      |     pyha770c72_1         115 KB  conda-forge
					bleach-6.2.0               |     pyhd8ed1ab_3         129 KB  conda-forge
					bleach-with-css-6.2.0      |       hd8ed1ab_3           6 KB  conda-forge
					brotli-1.1.0               |       hb9d3cd8_2          19 KB  conda-forge
					brotli-bin-1.1.0           |       hb9d3cd8_2          18 KB  conda-forge
					brotli-python-1.1.0        |  py312h2ec8cdc_2         342 KB  conda-forge
					cached-property-1.5.2      |       hd8ed1ab_1           4 KB  conda-forge
					cached_property-1.5.2      |     pyha770c72_1          11 KB  conda-forge
					cairo-1.18.2               |       h3394656_1         956 KB  conda-forge
					certifi-2024.12.14         |     pyhd8ed1ab_0         158 KB  conda-forge
					cffi-1.17.1                |  py312h06ac9bb_0         288 KB  conda-forge
					charset-normalizer-3.4.1   |     pyhd8ed1ab_0          46 KB  conda-forge
					comm-0.2.2                 |     pyhd8ed1ab_1          12 KB  conda-forge
					contourpy-1.3.1            |  py312h68727a3_0         270 KB  conda-forge
					cycler-0.12.1              |     pyhd8ed1ab_1          13 KB  conda-forge
					cyrus-sasl-2.1.27          |       h54b06d7_7         214 KB  conda-forge
					dbus-1.13.6                |       h5008d03_3         604 KB  conda-forge
					debugpy-1.8.11             |  py312h2ec8cdc_0         2.5 MB  conda-forge
					decorator-5.1.1            |     pyhd8ed1ab_1          14 KB  conda-forge
					defusedxml-0.7.1           |     pyhd8ed1ab_0          23 KB  conda-forge
					double-conversion-3.3.0    |       h59595ed_0          77 KB  conda-forge
					entrypoints-0.4            |     pyhd8ed1ab_1          11 KB  conda-forge
					exceptiongroup-1.2.2       |     pyhd8ed1ab_1          20 KB  conda-forge
					executing-2.1.0            |     pyhd8ed1ab_1          28 KB  conda-forge
					expat-2.6.4                |       h5888daf_0         135 KB  conda-forge
					font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge
					font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge
					font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge
					font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge
					fontconfig-2.15.0          |       h7e30c49_1         259 KB  conda-forge
					fonts-conda-ecosystem-1    |                0           4 KB  conda-forge
					fonts-conda-forge-1        |                0           4 KB  conda-forge
					fonttools-4.55.3           |  py312h178313f_1         2.7 MB  conda-forge
					fqdn-1.5.1                 |     pyhd8ed1ab_1          16 KB  conda-forge
					freetype-2.12.1            |       h267a509_2         620 KB  conda-forge
					graphite2-1.3.13           |    h59595ed_1003          95 KB  conda-forge
					h11-0.14.0                 |     pyhd8ed1ab_1          51 KB  conda-forge
					h2-4.1.0                   |     pyhd8ed1ab_1          51 KB  conda-forge
					harfbuzz-10.1.0            |       h0b3b770_0         1.5 MB  conda-forge
					hpack-4.0.0                |     pyhd8ed1ab_1          29 KB  conda-forge
					httpcore-1.0.7             |     pyh29332c3_1          48 KB  conda-forge
					httpx-0.28.1               |     pyhd8ed1ab_0          62 KB  conda-forge
					hyperframe-6.0.1           |     pyhd8ed1ab_1          17 KB  conda-forge
					icu-75.1                   |       he02047a_0        11.6 MB  conda-forge
					idna-3.10                  |     pyhd8ed1ab_1          49 KB  conda-forge
					importlib-metadata-8.5.0   |     pyha770c72_1          28 KB  conda-forge
					importlib_resources-6.5.2  |     pyhd8ed1ab_0          33 KB  conda-forge
					ipykernel-6.29.5           |     pyh3099207_0         116 KB  conda-forge
					ipython-8.31.0             |     pyh707e725_0         587 KB  conda-forge
					ipywidgets-8.1.5           |     pyhd8ed1ab_1         111 KB  conda-forge
					isoduration-20.11.0        |     pyhd8ed1ab_1          19 KB  conda-forge
					jedi-0.19.2                |     pyhd8ed1ab_1         824 KB  conda-forge
					jinja2-3.1.5               |     pyhd8ed1ab_0         110 KB  conda-forge
					json5-0.10.0               |     pyhd8ed1ab_1          31 KB  conda-forge
					jsonpointer-3.0.0          |  py312h7900ff3_1          17 KB  conda-forge
					jsonschema-4.23.0          |     pyhd8ed1ab_1          73 KB  conda-forge
					jsonschema-specifications-2024.10.1|     pyhd8ed1ab_1          16 KB  conda-forge
					jsonschema-with-format-nongpl-4.23.0|       hd8ed1ab_1           7 KB  conda-forge
					jupyter-1.1.1              |     pyhd8ed1ab_1           9 KB  conda-forge
					jupyter-lsp-2.2.5          |     pyhd8ed1ab_1          54 KB  conda-forge
					jupyter_client-8.6.3       |     pyhd8ed1ab_1         104 KB  conda-forge
					jupyter_console-6.6.3      |     pyhd8ed1ab_1          26 KB  conda-forge
					jupyter_core-5.7.2         |     pyh31011fe_1          56 KB  conda-forge
					jupyter_events-0.11.0      |     pyhd8ed1ab_0          22 KB  conda-forge
					jupyter_server-2.15.0      |     pyhd8ed1ab_0         320 KB  conda-forge
					jupyter_server_terminals-0.5.3|     pyhd8ed1ab_1          19 KB  conda-forge
					jupyterlab-4.3.4           |     pyhd8ed1ab_0         6.9 MB  conda-forge
					jupyterlab_pygments-0.3.0  |     pyhd8ed1ab_2          18 KB  conda-forge
					jupyterlab_server-2.27.3   |     pyhd8ed1ab_1          48 KB  conda-forge
					jupyterlab_widgets-3.0.13  |     pyhd8ed1ab_1         182 KB  conda-forge
					keyutils-1.6.1             |       h166bdaf_0         115 KB  conda-forge
					kiwisolver-1.4.7           |  py312h68727a3_0          69 KB  conda-forge
					krb5-1.21.3                |       h659f571_0         1.3 MB  conda-forge
					lcms2-2.16                 |       hb7c19ff_0         239 KB  conda-forge
					lerc-4.0.0                 |       h27087fc_0         275 KB  conda-forge
					libblas-3.9.0              |26_linux64_openblas          16 KB  conda-forge
					libbrotlicommon-1.1.0      |       hb9d3cd8_2          67 KB  conda-forge
					libbrotlidec-1.1.0         |       hb9d3cd8_2          32 KB  conda-forge
					libbrotlienc-1.1.0         |       hb9d3cd8_2         275 KB  conda-forge
					libcblas-3.9.0             |26_linux64_openblas          16 KB  conda-forge
					libclang-cpp19.1-19.1.6    |default_hb5137d0_0        19.6 MB  conda-forge
					libclang13-19.1.6          |default_h9c6a7e4_0        11.3 MB  conda-forge
					libcups-2.3.3              |       h4637d8d_4         4.3 MB  conda-forge
					libdeflate-1.23            |       h4ddbbb0_0          71 KB  conda-forge
					libdrm-2.4.124             |       hb9d3cd8_0         237 KB  conda-forge
					libedit-3.1.20240808       | pl5321h7949ede_0         132 KB  conda-forge
					libegl-1.7.0               |       ha4b6fd6_2          44 KB  conda-forge
					libgfortran-14.2.0         |       h69a702a_1          53 KB  conda-forge
					libgfortran5-14.2.0        |       hd5240d6_1         1.4 MB  conda-forge
					libgl-1.7.0                |       ha4b6fd6_2         132 KB  conda-forge
					libglib-2.82.2             |       h2ff4ddf_0         3.7 MB  conda-forge
					libglvnd-1.7.0             |       ha4b6fd6_2         129 KB  conda-forge
					libglx-1.7.0               |       ha4b6fd6_2          74 KB  conda-forge
					libiconv-1.17              |       hd590300_2         689 KB  conda-forge
					libjpeg-turbo-3.0.0        |       hd590300_1         604 KB  conda-forge
					liblapack-3.9.0            |26_linux64_openblas          16 KB  conda-forge
					libllvm19-19.1.6           |       ha7bfdaf_0        38.3 MB  conda-forge
					libntlm-1.8                |       hb9d3cd8_0          33 KB  conda-forge
					libopenblas-0.3.28         |pthreads_h94d23a6_1         5.3 MB  conda-forge
					libopengl-1.7.0            |       ha4b6fd6_2          50 KB  conda-forge
					libpciaccess-0.18          |       hd590300_0          28 KB  conda-forge
					libpng-1.6.45              |       h943b412_0         283 KB  conda-forge
					libpq-17.2                 |       h3b95a9b_1         2.5 MB  conda-forge
					libsodium-1.0.20           |       h4ab18f5_0         201 KB  conda-forge
					libstdcxx-14.2.0           |       hc0a3c3a_1         3.7 MB  conda-forge
					libstdcxx-ng-14.2.0        |       h4852527_1          53 KB  conda-forge
					libtiff-4.7.0              |       hd9ff511_3         418 KB  conda-forge
					libwebp-base-1.5.0         |       h851e524_0         420 KB  conda-forge
					libxcb-1.17.0              |       h8a09558_0         387 KB  conda-forge
					libxkbcommon-1.7.0         |       h2c5496b_1         579 KB  conda-forge
					libxml2-2.13.5             |       h8d12d68_1         674 KB  conda-forge
					libxslt-1.1.39             |       h76b75d6_0         248 KB  conda-forge
					markupsafe-3.0.2           |  py312h178313f_1          24 KB  conda-forge
					matplotlib-3.10.0          |  py312h7900ff3_0          16 KB  conda-forge
					matplotlib-base-3.10.0     |  py312hd3ec401_0         7.8 MB  conda-forge
					matplotlib-inline-0.1.7    |     pyhd8ed1ab_1          14 KB  conda-forge
					mistune-3.1.0              |     pyhd8ed1ab_0          67 KB  conda-forge
					munkres-1.1.4              |     pyh9f0ad1d_0          12 KB  conda-forge
					mysql-common-9.0.1         |       h266115a_4         605 KB  conda-forge
					mysql-libs-9.0.1           |       he0572af_4         1.3 MB  conda-forge
					nbclient-0.10.2            |     pyhd8ed1ab_0          27 KB  conda-forge
					nbconvert-core-7.16.5      |     pyhd8ed1ab_1         185 KB  conda-forge
					nbformat-5.10.4            |     pyhd8ed1ab_1          99 KB  conda-forge
					nest-asyncio-1.6.0         |     pyhd8ed1ab_1          11 KB  conda-forge
					notebook-7.3.2             |     pyhd8ed1ab_0         8.6 MB  conda-forge
					notebook-shim-0.2.4        |     pyhd8ed1ab_1          16 KB  conda-forge
					numpy-2.2.1                |  py312h7e784f5_0         8.1 MB  conda-forge
					openjpeg-2.5.3             |       h5fbd93e_0         335 KB  conda-forge
					openldap-2.6.9             |       he970967_0         766 KB  conda-forge
					overrides-7.7.0            |     pyhd8ed1ab_1          29 KB  conda-forge
					packaging-24.2             |     pyhd8ed1ab_2          59 KB  conda-forge
					pandas-2.2.3               |  py312hf9745cd_1        14.7 MB  conda-forge
					pandocfilters-1.5.0        |     pyhd8ed1ab_0          11 KB  conda-forge
					parso-0.8.4                |     pyhd8ed1ab_1          74 KB  conda-forge
					pcre2-10.44                |       hba22ea6_2         930 KB  conda-forge
					pexpect-4.9.0              |     pyhd8ed1ab_1          52 KB  conda-forge
					pickleshare-0.7.5          |  pyhd8ed1ab_1004          11 KB  conda-forge
					pillow-11.1.0              |  py312h80c1187_0        40.8 MB  conda-forge
					pixman-0.44.2              |       h29eaf8c_0         372 KB  conda-forge
					pkgutil-resolve-name-1.3.10|     pyhd8ed1ab_2          10 KB  conda-forge
					platformdirs-4.3.6         |     pyhd8ed1ab_1          20 KB  conda-forge
					prometheus_client-0.21.1   |     pyhd8ed1ab_0          48 KB  conda-forge
					prompt-toolkit-3.0.48      |     pyha770c72_1         264 KB  conda-forge
					prompt_toolkit-3.0.48      |       hd8ed1ab_1           6 KB  conda-forge
					psutil-6.1.1               |  py312h66e93f0_0         476 KB  conda-forge
					pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge
					ptyprocess-0.7.0           |     pyhd8ed1ab_1          19 KB  conda-forge
					pure_eval-0.2.3            |     pyhd8ed1ab_1          16 KB  conda-forge
					pycparser-2.22             |     pyh29332c3_1         108 KB  conda-forge
					pygments-2.19.1            |     pyhd8ed1ab_0         868 KB  conda-forge
					pyparsing-3.2.1            |     pyhd8ed1ab_0          91 KB  conda-forge
					pyside6-6.8.1              |  py312h91f0f75_0        10.4 MB  conda-forge
					pysocks-1.7.1              |     pyha55dd90_7          21 KB  conda-forge
					python-dateutil-2.9.0.post0|     pyhff2d567_1         217 KB  conda-forge
					python-fastjsonschema-2.21.1|     pyhd8ed1ab_0         221 KB  conda-forge
					python-json-logger-2.0.7   |     pyhd8ed1ab_0          13 KB  conda-forge
					python-tzdata-2024.2       |     pyhd8ed1ab_1         139 KB  conda-forge
					python_abi-3.12            |          5_cp312           6 KB  conda-forge
					pytz-2024.1                |     pyhd8ed1ab_0         184 KB  conda-forge
					pyyaml-6.0.2               |  py312h66e93f0_1         202 KB  conda-forge
					pyzmq-26.2.0               |  py312hbf22597_3         369 KB  conda-forge
					qhull-2020.2               |       h434a139_5         540 KB  conda-forge
					qt6-main-6.8.1             |       h588cce1_2        49.2 MB  conda-forge
					referencing-0.35.1         |     pyhd8ed1ab_1          41 KB  conda-forge
					requests-2.32.3            |     pyhd8ed1ab_1          57 KB  conda-forge
					rfc3339-validator-0.1.4    |     pyhd8ed1ab_1          10 KB  conda-forge
					rfc3986-validator-0.1.1    |     pyh9f0ad1d_0           8 KB  conda-forge
					rpds-py-0.22.3             |  py312h12e396e_0         346 KB  conda-forge
					send2trash-1.8.3           |     pyh0d859eb_1          22 KB  conda-forge
					six-1.17.0                 |     pyhd8ed1ab_0          16 KB  conda-forge
					sniffio-1.3.1              |     pyhd8ed1ab_1          15 KB  conda-forge
					soupsieve-2.5              |     pyhd8ed1ab_1          36 KB  conda-forge
					stack_data-0.6.3           |     pyhd8ed1ab_1          26 KB  conda-forge
					terminado-0.18.1           |     pyh0d859eb_0          22 KB  conda-forge
					tinycss2-1.4.0             |     pyhd8ed1ab_0          28 KB  conda-forge
					tomli-2.2.1                |     pyhd8ed1ab_1          19 KB  conda-forge
					tornado-6.4.2              |  py312h66e93f0_0         821 KB  conda-forge
					traitlets-5.14.3           |     pyhd8ed1ab_1         107 KB  conda-forge
					types-python-dateutil-2.9.0.20241206|     pyhd8ed1ab_0          22 KB  conda-forge
					typing-extensions-4.12.2   |       hd8ed1ab_1          10 KB  conda-forge
					typing_extensions-4.12.2   |     pyha770c72_1          39 KB  conda-forge
					typing_utils-0.1.0         |     pyhd8ed1ab_1          15 KB  conda-forge
					unicodedata2-15.1.0        |  py312h66e93f0_1         360 KB  conda-forge
					uri-template-1.3.0         |     pyhd8ed1ab_1          23 KB  conda-forge
					urllib3-2.3.0              |     pyhd8ed1ab_0          98 KB  conda-forge
					wayland-1.23.1             |       h3e06ad9_0         314 KB  conda-forge
					wcwidth-0.2.13             |     pyhd8ed1ab_1          32 KB  conda-forge
					webcolors-24.11.1          |     pyhd8ed1ab_0          18 KB  conda-forge
					webencodings-0.5.1         |     pyhd8ed1ab_3          15 KB  conda-forge
					websocket-client-1.8.0     |     pyhd8ed1ab_1          46 KB  conda-forge
					widgetsnbextension-4.0.13  |     pyhd8ed1ab_1         877 KB  conda-forge
					xcb-util-0.4.1             |       hb711507_2          19 KB  conda-forge
					xcb-util-cursor-0.1.5      |       hb9d3cd8_0          20 KB  conda-forge
					xcb-util-image-0.4.0       |       hb711507_2          24 KB  conda-forge
					xcb-util-keysyms-0.4.1     |       hb711507_0          14 KB  conda-forge
					xcb-util-renderutil-0.3.10 |       hb711507_0          17 KB  conda-forge
					xcb-util-wm-0.4.2          |       hb711507_0          50 KB  conda-forge
					xkeyboard-config-2.43      |       hb9d3cd8_0         380 KB  conda-forge
					xorg-libice-1.1.2          |       hb9d3cd8_0          57 KB  conda-forge
					xorg-libsm-1.2.5           |       he73a12e_0          27 KB  conda-forge
					xorg-libx11-1.8.10         |       h4f16b4b_1         818 KB  conda-forge
					xorg-libxau-1.0.12         |       hb9d3cd8_0          14 KB  conda-forge
					xorg-libxcomposite-0.4.6   |       hb9d3cd8_2          13 KB  conda-forge
					xorg-libxcursor-1.2.3      |       hb9d3cd8_0          32 KB  conda-forge
					xorg-libxdamage-1.1.6      |       hb9d3cd8_0          13 KB  conda-forge
					xorg-libxdmcp-1.1.5        |       hb9d3cd8_0          19 KB  conda-forge
					xorg-libxext-1.3.6         |       hb9d3cd8_0          49 KB  conda-forge
					xorg-libxfixes-6.0.1       |       hb9d3cd8_0          19 KB  conda-forge
					xorg-libxi-1.8.2           |       hb9d3cd8_0          46 KB  conda-forge
					xorg-libxrandr-1.5.4       |       hb9d3cd8_0          29 KB  conda-forge
					xorg-libxrender-0.9.12     |       hb9d3cd8_0          32 KB  conda-forge
					xorg-libxtst-1.2.5         |       hb9d3cd8_3          32 KB  conda-forge
					xorg-libxxf86vm-1.1.6      |       hb9d3cd8_0          17 KB  conda-forge
					yaml-0.2.5                 |       h7f98852_2          87 KB  conda-forge
					zeromq-4.3.5               |       h3b0a872_7         328 KB  conda-forge
					zipp-3.21.0                |     pyhd8ed1ab_1          21 KB  conda-forge
					zstandard-0.23.0           |  py312hef9b889_1         410 KB  conda-forge
					zstd-1.5.6                 |       ha6fb4c9_0         542 KB  conda-forge
					------------------------------------------------------------
					Total:       295.3 MB
					
					The following NEW packages will be INSTALLED:
					
					alsa-lib           conda-forge/linux-64::alsa-lib-1.2.13-hb9d3cd8_0 
					anyio              conda-forge/noarch::anyio-4.8.0-pyhd8ed1ab_0 
					argon2-cffi        conda-forge/noarch::argon2-cffi-23.1.0-pyhd8ed1ab_1 
					argon2-cffi-bindi~ conda-forge/linux-64::argon2-cffi-bindings-21.2.0-py312h66e93f0_5 
					arrow              conda-forge/noarch::arrow-1.3.0-pyhd8ed1ab_1 
					asttokens          conda-forge/noarch::asttokens-3.0.0-pyhd8ed1ab_1 
					async-lru          conda-forge/noarch::async-lru-2.0.4-pyhd8ed1ab_1 
					attrs              conda-forge/noarch::attrs-24.3.0-pyh71513ae_0 
					babel              conda-forge/noarch::babel-2.16.0-pyhd8ed1ab_1 
					beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.12.3-pyha770c72_1 
					bleach             conda-forge/noarch::bleach-6.2.0-pyhd8ed1ab_3 
					bleach-with-css    conda-forge/noarch::bleach-with-css-6.2.0-hd8ed1ab_3 
					brotli             conda-forge/linux-64::brotli-1.1.0-hb9d3cd8_2 
					brotli-bin         conda-forge/linux-64::brotli-bin-1.1.0-hb9d3cd8_2 
					brotli-python      conda-forge/linux-64::brotli-python-1.1.0-py312h2ec8cdc_2 
					cached-property    conda-forge/noarch::cached-property-1.5.2-hd8ed1ab_1 
					cached_property    conda-forge/noarch::cached_property-1.5.2-pyha770c72_1 
					cairo              conda-forge/linux-64::cairo-1.18.2-h3394656_1 
					certifi            conda-forge/noarch::certifi-2024.12.14-pyhd8ed1ab_0 
					cffi               conda-forge/linux-64::cffi-1.17.1-py312h06ac9bb_0 
					charset-normalizer conda-forge/noarch::charset-normalizer-3.4.1-pyhd8ed1ab_0 
					comm               conda-forge/noarch::comm-0.2.2-pyhd8ed1ab_1 
					contourpy          conda-forge/linux-64::contourpy-1.3.1-py312h68727a3_0 
					cycler             conda-forge/noarch::cycler-0.12.1-pyhd8ed1ab_1 
					cyrus-sasl         conda-forge/linux-64::cyrus-sasl-2.1.27-h54b06d7_7 
					dbus               conda-forge/linux-64::dbus-1.13.6-h5008d03_3 
					debugpy            conda-forge/linux-64::debugpy-1.8.11-py312h2ec8cdc_0 
					decorator          conda-forge/noarch::decorator-5.1.1-pyhd8ed1ab_1 
					defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0 
					double-conversion  conda-forge/linux-64::double-conversion-3.3.0-h59595ed_0 
					entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_1 
					exceptiongroup     conda-forge/noarch::exceptiongroup-1.2.2-pyhd8ed1ab_1 
					executing          conda-forge/noarch::executing-2.1.0-pyhd8ed1ab_1 
					expat              conda-forge/linux-64::expat-2.6.4-h5888daf_0 
					font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 
					font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 
					font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 
					font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 
					fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 
					fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 
					fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 
					fonttools          conda-forge/linux-64::fonttools-4.55.3-py312h178313f_1 
					fqdn               conda-forge/noarch::fqdn-1.5.1-pyhd8ed1ab_1 
					freetype           conda-forge/linux-64::freetype-2.12.1-h267a509_2 
					graphite2          conda-forge/linux-64::graphite2-1.3.13-h59595ed_1003 
					h11                conda-forge/noarch::h11-0.14.0-pyhd8ed1ab_1 
					h2                 conda-forge/noarch::h2-4.1.0-pyhd8ed1ab_1 
					harfbuzz           conda-forge/linux-64::harfbuzz-10.1.0-h0b3b770_0 
					hpack              conda-forge/noarch::hpack-4.0.0-pyhd8ed1ab_1 
					httpcore           conda-forge/noarch::httpcore-1.0.7-pyh29332c3_1 
					httpx              conda-forge/noarch::httpx-0.28.1-pyhd8ed1ab_0 
					hyperframe         conda-forge/noarch::hyperframe-6.0.1-pyhd8ed1ab_1 
					icu                conda-forge/linux-64::icu-75.1-he02047a_0 
					idna               conda-forge/noarch::idna-3.10-pyhd8ed1ab_1 
					importlib-metadata conda-forge/noarch::importlib-metadata-8.5.0-pyha770c72_1 
					importlib_resourc~ conda-forge/noarch::importlib_resources-6.5.2-pyhd8ed1ab_0 
					ipykernel          conda-forge/noarch::ipykernel-6.29.5-pyh3099207_0 
					ipython            conda-forge/noarch::ipython-8.31.0-pyh707e725_0 
					ipywidgets         conda-forge/noarch::ipywidgets-8.1.5-pyhd8ed1ab_1 
					isoduration        conda-forge/noarch::isoduration-20.11.0-pyhd8ed1ab_1 
					jedi               conda-forge/noarch::jedi-0.19.2-pyhd8ed1ab_1 
					jinja2             conda-forge/noarch::jinja2-3.1.5-pyhd8ed1ab_0 
					json5              conda-forge/noarch::json5-0.10.0-pyhd8ed1ab_1 
					jsonpointer        conda-forge/linux-64::jsonpointer-3.0.0-py312h7900ff3_1 
					jsonschema         conda-forge/noarch::jsonschema-4.23.0-pyhd8ed1ab_1 
					jsonschema-specif~ conda-forge/noarch::jsonschema-specifications-2024.10.1-pyhd8ed1ab_1 
					jsonschema-with-f~ conda-forge/noarch::jsonschema-with-format-nongpl-4.23.0-hd8ed1ab_1 
					jupyter            conda-forge/noarch::jupyter-1.1.1-pyhd8ed1ab_1 
					jupyter-lsp        conda-forge/noarch::jupyter-lsp-2.2.5-pyhd8ed1ab_1 
					jupyter_client     conda-forge/noarch::jupyter_client-8.6.3-pyhd8ed1ab_1 
					jupyter_console    conda-forge/noarch::jupyter_console-6.6.3-pyhd8ed1ab_1 
					jupyter_core       conda-forge/noarch::jupyter_core-5.7.2-pyh31011fe_1 
					jupyter_events     conda-forge/noarch::jupyter_events-0.11.0-pyhd8ed1ab_0 
					jupyter_server     conda-forge/noarch::jupyter_server-2.15.0-pyhd8ed1ab_0 
					jupyter_server_te~ conda-forge/noarch::jupyter_server_terminals-0.5.3-pyhd8ed1ab_1 
					jupyterlab         conda-forge/noarch::jupyterlab-4.3.4-pyhd8ed1ab_0 
					jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.3.0-pyhd8ed1ab_2 
					jupyterlab_server  conda-forge/noarch::jupyterlab_server-2.27.3-pyhd8ed1ab_1 
					jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-3.0.13-pyhd8ed1ab_1 
					keyutils           conda-forge/linux-64::keyutils-1.6.1-h166bdaf_0 
					kiwisolver         conda-forge/linux-64::kiwisolver-1.4.7-py312h68727a3_0 
					krb5               conda-forge/linux-64::krb5-1.21.3-h659f571_0 
					lcms2              conda-forge/linux-64::lcms2-2.16-hb7c19ff_0 
					lerc               conda-forge/linux-64::lerc-4.0.0-h27087fc_0 
					libblas            conda-forge/linux-64::libblas-3.9.0-26_linux64_openblas 
					libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.1.0-hb9d3cd8_2 
					libbrotlidec       conda-forge/linux-64::libbrotlidec-1.1.0-hb9d3cd8_2 
					libbrotlienc       conda-forge/linux-64::libbrotlienc-1.1.0-hb9d3cd8_2 
					libcblas           conda-forge/linux-64::libcblas-3.9.0-26_linux64_openblas 
					libclang-cpp19.1   conda-forge/linux-64::libclang-cpp19.1-19.1.6-default_hb5137d0_0 
					libclang13         conda-forge/linux-64::libclang13-19.1.6-default_h9c6a7e4_0 
					libcups            conda-forge/linux-64::libcups-2.3.3-h4637d8d_4 
					libdeflate         conda-forge/linux-64::libdeflate-1.23-h4ddbbb0_0 
					libdrm             conda-forge/linux-64::libdrm-2.4.124-hb9d3cd8_0 
					libedit            conda-forge/linux-64::libedit-3.1.20240808-pl5321h7949ede_0 
					libegl             conda-forge/linux-64::libegl-1.7.0-ha4b6fd6_2 
					libgfortran        conda-forge/linux-64::libgfortran-14.2.0-h69a702a_1 
					libgfortran5       conda-forge/linux-64::libgfortran5-14.2.0-hd5240d6_1 
					libgl              conda-forge/linux-64::libgl-1.7.0-ha4b6fd6_2 
					libglib            conda-forge/linux-64::libglib-2.82.2-h2ff4ddf_0 
					libglvnd           conda-forge/linux-64::libglvnd-1.7.0-ha4b6fd6_2 
					libglx             conda-forge/linux-64::libglx-1.7.0-ha4b6fd6_2 
					libiconv           conda-forge/linux-64::libiconv-1.17-hd590300_2 
					libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.0.0-hd590300_1 
					liblapack          conda-forge/linux-64::liblapack-3.9.0-26_linux64_openblas 
					libllvm19          conda-forge/linux-64::libllvm19-19.1.6-ha7bfdaf_0 
					libntlm            conda-forge/linux-64::libntlm-1.8-hb9d3cd8_0 
					libopenblas        conda-forge/linux-64::libopenblas-0.3.28-pthreads_h94d23a6_1 
					libopengl          conda-forge/linux-64::libopengl-1.7.0-ha4b6fd6_2 
					libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hd590300_0 
					libpng             conda-forge/linux-64::libpng-1.6.45-h943b412_0 
					libpq              conda-forge/linux-64::libpq-17.2-h3b95a9b_1 
					libsodium          conda-forge/linux-64::libsodium-1.0.20-h4ab18f5_0 
					libstdcxx          conda-forge/linux-64::libstdcxx-14.2.0-hc0a3c3a_1 
					libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-14.2.0-h4852527_1 
					libtiff            conda-forge/linux-64::libtiff-4.7.0-hd9ff511_3 
					libwebp-base       conda-forge/linux-64::libwebp-base-1.5.0-h851e524_0 
					libxcb             conda-forge/linux-64::libxcb-1.17.0-h8a09558_0 
					libxkbcommon       conda-forge/linux-64::libxkbcommon-1.7.0-h2c5496b_1 
					libxml2            conda-forge/linux-64::libxml2-2.13.5-h8d12d68_1 
					libxslt            conda-forge/linux-64::libxslt-1.1.39-h76b75d6_0 
					markupsafe         conda-forge/linux-64::markupsafe-3.0.2-py312h178313f_1 
					matplotlib         conda-forge/linux-64::matplotlib-3.10.0-py312h7900ff3_0 
					matplotlib-base    conda-forge/linux-64::matplotlib-base-3.10.0-py312hd3ec401_0 
					matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.1.7-pyhd8ed1ab_1 
					mistune            conda-forge/noarch::mistune-3.1.0-pyhd8ed1ab_0 
					munkres            conda-forge/noarch::munkres-1.1.4-pyh9f0ad1d_0 
					mysql-common       conda-forge/linux-64::mysql-common-9.0.1-h266115a_4 
					mysql-libs         conda-forge/linux-64::mysql-libs-9.0.1-he0572af_4 
					nbclient           conda-forge/noarch::nbclient-0.10.2-pyhd8ed1ab_0 
					nbconvert-core     conda-forge/noarch::nbconvert-core-7.16.5-pyhd8ed1ab_1 
					nbformat           conda-forge/noarch::nbformat-5.10.4-pyhd8ed1ab_1 
					nest-asyncio       conda-forge/noarch::nest-asyncio-1.6.0-pyhd8ed1ab_1 
					notebook           conda-forge/noarch::notebook-7.3.2-pyhd8ed1ab_0 
					notebook-shim      conda-forge/noarch::notebook-shim-0.2.4-pyhd8ed1ab_1 
					numpy              conda-forge/linux-64::numpy-2.2.1-py312h7e784f5_0 
					openjpeg           conda-forge/linux-64::openjpeg-2.5.3-h5fbd93e_0 
					openldap           conda-forge/linux-64::openldap-2.6.9-he970967_0 
					overrides          conda-forge/noarch::overrides-7.7.0-pyhd8ed1ab_1 
					packaging          conda-forge/noarch::packaging-24.2-pyhd8ed1ab_2 
					pandas             conda-forge/linux-64::pandas-2.2.3-py312hf9745cd_1 
					pandocfilters      conda-forge/noarch::pandocfilters-1.5.0-pyhd8ed1ab_0 
					parso              conda-forge/noarch::parso-0.8.4-pyhd8ed1ab_1 
					pcre2              conda-forge/linux-64::pcre2-10.44-hba22ea6_2 
					pexpect            conda-forge/noarch::pexpect-4.9.0-pyhd8ed1ab_1 
					pickleshare        conda-forge/noarch::pickleshare-0.7.5-pyhd8ed1ab_1004 
					pillow             conda-forge/linux-64::pillow-11.1.0-py312h80c1187_0 
					pixman             conda-forge/linux-64::pixman-0.44.2-h29eaf8c_0 
					pkgutil-resolve-n~ conda-forge/noarch::pkgutil-resolve-name-1.3.10-pyhd8ed1ab_2 
					platformdirs       conda-forge/noarch::platformdirs-4.3.6-pyhd8ed1ab_1 
					prometheus_client  conda-forge/noarch::prometheus_client-0.21.1-pyhd8ed1ab_0 
					prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.48-pyha770c72_1 
					prompt_toolkit     conda-forge/noarch::prompt_toolkit-3.0.48-hd8ed1ab_1 
					psutil             conda-forge/linux-64::psutil-6.1.1-py312h66e93f0_0 
					pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 
					ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd8ed1ab_1 
					pure_eval          conda-forge/noarch::pure_eval-0.2.3-pyhd8ed1ab_1 
					pycparser          conda-forge/noarch::pycparser-2.22-pyh29332c3_1 
					pygments           conda-forge/noarch::pygments-2.19.1-pyhd8ed1ab_0 
					pyparsing          conda-forge/noarch::pyparsing-3.2.1-pyhd8ed1ab_0 
					pyside6            conda-forge/linux-64::pyside6-6.8.1-py312h91f0f75_0 
					pysocks            conda-forge/noarch::pysocks-1.7.1-pyha55dd90_7 
					python-dateutil    conda-forge/noarch::python-dateutil-2.9.0.post0-pyhff2d567_1 
					python-fastjsonsc~ conda-forge/noarch::python-fastjsonschema-2.21.1-pyhd8ed1ab_0 
					python-json-logger conda-forge/noarch::python-json-logger-2.0.7-pyhd8ed1ab_0 
					python-tzdata      conda-forge/noarch::python-tzdata-2024.2-pyhd8ed1ab_1 
					python_abi         conda-forge/linux-64::python_abi-3.12-5_cp312 
					pytz               conda-forge/noarch::pytz-2024.1-pyhd8ed1ab_0 
					pyyaml             conda-forge/linux-64::pyyaml-6.0.2-py312h66e93f0_1 
					pyzmq              conda-forge/linux-64::pyzmq-26.2.0-py312hbf22597_3 
					qhull              conda-forge/linux-64::qhull-2020.2-h434a139_5 
					qt6-main           conda-forge/linux-64::qt6-main-6.8.1-h588cce1_2 
					referencing        conda-forge/noarch::referencing-0.35.1-pyhd8ed1ab_1 
					requests           conda-forge/noarch::requests-2.32.3-pyhd8ed1ab_1 
					rfc3339-validator  conda-forge/noarch::rfc3339-validator-0.1.4-pyhd8ed1ab_1 
					rfc3986-validator  conda-forge/noarch::rfc3986-validator-0.1.1-pyh9f0ad1d_0 
					rpds-py            conda-forge/linux-64::rpds-py-0.22.3-py312h12e396e_0 
					send2trash         conda-forge/noarch::send2trash-1.8.3-pyh0d859eb_1 
					six                conda-forge/noarch::six-1.17.0-pyhd8ed1ab_0 
					sniffio            conda-forge/noarch::sniffio-1.3.1-pyhd8ed1ab_1 
					soupsieve          conda-forge/noarch::soupsieve-2.5-pyhd8ed1ab_1 
					stack_data         conda-forge/noarch::stack_data-0.6.3-pyhd8ed1ab_1 
					terminado          conda-forge/noarch::terminado-0.18.1-pyh0d859eb_0 
					tinycss2           conda-forge/noarch::tinycss2-1.4.0-pyhd8ed1ab_0 
					tomli              conda-forge/noarch::tomli-2.2.1-pyhd8ed1ab_1 
					tornado            conda-forge/linux-64::tornado-6.4.2-py312h66e93f0_0 
					traitlets          conda-forge/noarch::traitlets-5.14.3-pyhd8ed1ab_1 
					types-python-date~ conda-forge/noarch::types-python-dateutil-2.9.0.20241206-pyhd8ed1ab_0 
					typing-extensions  conda-forge/noarch::typing-extensions-4.12.2-hd8ed1ab_1 
					typing_extensions  conda-forge/noarch::typing_extensions-4.12.2-pyha770c72_1 
					typing_utils       conda-forge/noarch::typing_utils-0.1.0-pyhd8ed1ab_1 
					unicodedata2       conda-forge/linux-64::unicodedata2-15.1.0-py312h66e93f0_1 
					uri-template       conda-forge/noarch::uri-template-1.3.0-pyhd8ed1ab_1 
					urllib3            conda-forge/noarch::urllib3-2.3.0-pyhd8ed1ab_0 
					wayland            conda-forge/linux-64::wayland-1.23.1-h3e06ad9_0 
					wcwidth            conda-forge/noarch::wcwidth-0.2.13-pyhd8ed1ab_1 
					webcolors          conda-forge/noarch::webcolors-24.11.1-pyhd8ed1ab_0 
					webencodings       conda-forge/noarch::webencodings-0.5.1-pyhd8ed1ab_3 
					websocket-client   conda-forge/noarch::websocket-client-1.8.0-pyhd8ed1ab_1 
					widgetsnbextension conda-forge/noarch::widgetsnbextension-4.0.13-pyhd8ed1ab_1 
					xcb-util           conda-forge/linux-64::xcb-util-0.4.1-hb711507_2 
					xcb-util-cursor    conda-forge/linux-64::xcb-util-cursor-0.1.5-hb9d3cd8_0 
					xcb-util-image     conda-forge/linux-64::xcb-util-image-0.4.0-hb711507_2 
					xcb-util-keysyms   conda-forge/linux-64::xcb-util-keysyms-0.4.1-hb711507_0 
					xcb-util-renderut~ conda-forge/linux-64::xcb-util-renderutil-0.3.10-hb711507_0 
					xcb-util-wm        conda-forge/linux-64::xcb-util-wm-0.4.2-hb711507_0 
					xkeyboard-config   conda-forge/linux-64::xkeyboard-config-2.43-hb9d3cd8_0 
					xorg-libice        conda-forge/linux-64::xorg-libice-1.1.2-hb9d3cd8_0 
					xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.5-he73a12e_0 
					xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.10-h4f16b4b_1 
					xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb9d3cd8_0 
					xorg-libxcomposite conda-forge/linux-64::xorg-libxcomposite-0.4.6-hb9d3cd8_2 
					xorg-libxcursor    conda-forge/linux-64::xorg-libxcursor-1.2.3-hb9d3cd8_0 
					xorg-libxdamage    conda-forge/linux-64::xorg-libxdamage-1.1.6-hb9d3cd8_0 
					xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 
					xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.6-hb9d3cd8_0 
					xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-6.0.1-hb9d3cd8_0 
					xorg-libxi         conda-forge/linux-64::xorg-libxi-1.8.2-hb9d3cd8_0 
					xorg-libxrandr     conda-forge/linux-64::xorg-libxrandr-1.5.4-hb9d3cd8_0 
					xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.12-hb9d3cd8_0 
					xorg-libxtst       conda-forge/linux-64::xorg-libxtst-1.2.5-hb9d3cd8_3 
					xorg-libxxf86vm    conda-forge/linux-64::xorg-libxxf86vm-1.1.6-hb9d3cd8_0 
					yaml               conda-forge/linux-64::yaml-0.2.5-h7f98852_2 
					zeromq             conda-forge/linux-64::zeromq-4.3.5-h3b0a872_7 
					zipp               conda-forge/noarch::zipp-3.21.0-pyhd8ed1ab_1 
					zstandard          conda-forge/linux-64::zstandard-0.23.0-py312hef9b889_1 
					zstd               conda-forge/linux-64::zstd-1.5.6-ha6fb4c9_0 
					
					
					
					Downloading and Extracting Packages:
					
					Preparing transaction: done                                                     
					Verifying transaction: done                                                     
					Executing transaction: done
				\end{verbatim}
				Will be using some other packages, too, but these can be installed later once they are needed. There are 2 ways to install packages: with {\tt conda install} \& with {\tt pip install}. {\tt conda install} should always be preferred when using Miniconda, but some packages are not available through conda, so if \verb|conda install $package_name| fails, try \verb|pip install $package_name|.				
				\begin{remark}
					If want to install all of packages used in rest of book, can do that now by running:
					\begin{verbatim}
						(pydata-book) nqbh@nqbh-dell:~$ conda install lxml beautifulsoup4 html5lib openpyxl \
						requests sqlalchemy seaborn scipy statsmodels \
						patsy scikit-learn pyarrow pytables numba
						Channels:                                                                       
						- conda-forge                                                                  
						- defaults                                                                     
						Platform: linux-64                                                              
						Collecting package metadata (repodata.json): done                               
						Solving environment: done                                                       
						
						## Package Plan ##                                                              
						
						environment location: /home/nqbh/anaconda3/envs/pydata-book                   
						
						added / updated specs:                                                        
						- beautifulsoup4                                                            
						- html5lib                                                                  
						- lxml                                                                      
						- numba           
						- openpyxl
						- patsy
						- pyarrow
						- pytables
						- requests
						- scikit-learn
						- scipy
						- seaborn
						- sqlalchemy
						- statsmodels
						
						
						The following packages will be downloaded:
						
						package                    |            build
						---------------------------|-----------------
						aws-c-auth-0.8.0           |      hb921021_15         105 KB  conda-forge
						aws-c-cal-0.8.1            |       h1a47875_3          46 KB  conda-forge
						aws-c-common-0.10.6        |       hb9d3cd8_0         231 KB  conda-forge
						aws-c-compression-0.3.0    |       h4e1184b_5          19 KB  conda-forge
						aws-c-event-stream-0.5.0   |      h7959bf6_11          53 KB  conda-forge
						aws-c-http-0.9.2           |       hefd7a92_4         193 KB  conda-forge
						aws-c-io-0.15.3            |       h831e299_5         154 KB  conda-forge
						aws-c-mqtt-0.11.0          |      h11f4f37_12         190 KB  conda-forge
						aws-c-s3-0.7.7             |       hf454442_0         111 KB  conda-forge
						aws-c-sdkutils-0.2.1       |       h4e1184b_4          55 KB  conda-forge
						aws-checksums-0.2.2        |       h4e1184b_4          71 KB  conda-forge
						aws-crt-cpp-0.29.7         |       hd92328a_7         346 KB  conda-forge
						aws-sdk-cpp-1.11.458       |       hc430e4a_4         2.9 MB  conda-forge
						azure-core-cpp-1.14.0      |       h5cfcd09_0         337 KB  conda-forge
						azure-identity-cpp-1.10.0  |       h113e628_0         227 KB  conda-forge
						azure-storage-blobs-cpp-12.13.0|       h3cf044e_1         536 KB  conda-forge
						azure-storage-common-cpp-12.8.0|       h736e048_1         146 KB  conda-forge
						azure-storage-files-datalake-cpp-12.12.0|       ha633028_1         281 KB  conda-forge
						blosc-1.21.6               |       he440d0b_1          47 KB  conda-forge
						c-ares-1.34.4              |       hb9d3cd8_0         201 KB  conda-forge
						c-blosc2-2.15.2            |       h3122c55_1         334 KB  conda-forge
						et_xmlfile-2.0.0           |     pyhd8ed1ab_1          21 KB  conda-forge
						gflags-2.2.2               |    h5888daf_1005         117 KB  conda-forge
						glog-0.7.1                 |       hbabe93e_0         140 KB  conda-forge
						greenlet-3.1.1             |  py312h2ec8cdc_1         232 KB  conda-forge
						hdf5-1.14.4                |nompi_h2d575fe_105         3.8 MB  conda-forge
						html5lib-1.1               |     pyhd8ed1ab_2          93 KB  conda-forge
						joblib-1.4.2               |     pyhd8ed1ab_1         215 KB  conda-forge
						libabseil-20240722.0       | cxx17_hbbce691_4         1.3 MB  conda-forge
						libaec-1.1.3               |       h59595ed_0          35 KB  conda-forge
						libarrow-18.1.0            |   hd595efa_7_cpu         8.4 MB  conda-forge
						libarrow-acero-18.1.0      |   hcb10f89_7_cpu         598 KB  conda-forge
						libarrow-dataset-18.1.0    |   hcb10f89_7_cpu         574 KB  conda-forge
						libarrow-substrait-18.1.0  |   h08228c5_7_cpu         510 KB  conda-forge
						libcrc32c-1.1.2            |       h9c3ff4c_0          20 KB  conda-forge
						libcurl-8.11.1             |       h332b0f4_0         413 KB  conda-forge
						libev-4.33                 |       hd590300_2         110 KB  conda-forge
						libevent-2.1.12            |       hf998b51_1         417 KB  conda-forge
						libgoogle-cloud-2.33.0     |       h2b5623c_1         1.2 MB  conda-forge
						libgoogle-cloud-storage-2.33.0|       h0121fbd_1         766 KB  conda-forge
						libgrpc-1.67.1             |       h25350d4_1         7.4 MB  conda-forge
						libllvm14-14.0.6           |       hcd5def8_4        30.0 MB  conda-forge
						libnghttp2-1.64.0          |       h161d5f1_0         632 KB  conda-forge
						libparquet-18.1.0          |   h081d1f1_7_cpu         1.1 MB  conda-forge
						libprotobuf-5.28.3         |       h6128344_1         2.8 MB  conda-forge
						libre2-11-2024.07.02       |       hbbce691_2         205 KB  conda-forge
						libssh2-1.11.1             |       hf672d98_0         297 KB  conda-forge
						libthrift-0.21.0           |       h0e7cc3e_0         416 KB  conda-forge
						libutf8proc-2.9.0          |       hb9d3cd8_1          80 KB  conda-forge
						llvmlite-0.43.0            |  py312h374181b_1         3.3 MB  conda-forge
						lxml-5.3.0                 |  py312he28fd5a_2         1.3 MB  conda-forge
						lz4-c-1.10.0               |       h5888daf_1         163 KB  conda-forge
						nomkl-1.0                  |       h5ca1d4c_0           4 KB  conda-forge
						numba-0.60.0               |  py312h83e6fd3_0         5.4 MB  conda-forge
						numexpr-2.10.2             |py312h6a710ac_100         191 KB  conda-forge
						numpy-2.0.2                |  py312h58c1407_1         8.1 MB  conda-forge
						openpyxl-3.1.5             |  py312h710cb58_1         680 KB  conda-forge
						orc-2.0.3                  |       h12ee42a_2         1.1 MB  conda-forge
						patsy-1.0.1                |     pyhd8ed1ab_1         182 KB  conda-forge
						py-cpuinfo-9.0.0           |     pyhd8ed1ab_1          25 KB  conda-forge
						pyarrow-18.1.0             |  py312h7900ff3_0          25 KB  conda-forge
						pyarrow-core-18.1.0        |py312h01725c0_0_cpu         4.4 MB  conda-forge
						pytables-3.10.2            |  py312hf8651a9_0         1.6 MB  conda-forge
						re2-2024.07.02             |       h9925aae_2          26 KB  conda-forge
						s2n-1.5.10                 |       hb5b8611_0         347 KB  conda-forge
						scikit-learn-1.6.0         |  py312h7a48858_0        10.0 MB  conda-forge
						scipy-1.15.0               |  py312h180e4f1_1        18.2 MB  conda-forge
						seaborn-0.13.2             |       hd8ed1ab_3           7 KB  conda-forge
						seaborn-base-0.13.2        |     pyhd8ed1ab_3         223 KB  conda-forge
						snappy-1.2.1               |       h8bd8927_1          42 KB  conda-forge
						sqlalchemy-2.0.36          |  py312h66e93f0_0         3.3 MB  conda-forge
						statsmodels-0.14.4         |  py312hc0a28a1_0        11.5 MB  conda-forge
						threadpoolctl-3.5.0        |     pyhc1e730c_0          23 KB  conda-forge
						zlib-ng-2.2.3              |       h7955e40_0         106 KB  conda-forge
						------------------------------------------------------------
						Total:       138.7 MB
						
						The following NEW packages will be INSTALLED:
						
						aws-c-auth         conda-forge/linux-64::aws-c-auth-0.8.0-hb921021_15 
						aws-c-cal          conda-forge/linux-64::aws-c-cal-0.8.1-h1a47875_3 
						aws-c-common       conda-forge/linux-64::aws-c-common-0.10.6-hb9d3cd8_0 
						aws-c-compression  conda-forge/linux-64::aws-c-compression-0.3.0-h4e1184b_5 
						aws-c-event-stream conda-forge/linux-64::aws-c-event-stream-0.5.0-h7959bf6_11 
						aws-c-http         conda-forge/linux-64::aws-c-http-0.9.2-hefd7a92_4 
						aws-c-io           conda-forge/linux-64::aws-c-io-0.15.3-h831e299_5 
						aws-c-mqtt         conda-forge/linux-64::aws-c-mqtt-0.11.0-h11f4f37_12 
						aws-c-s3           conda-forge/linux-64::aws-c-s3-0.7.7-hf454442_0 
						aws-c-sdkutils     conda-forge/linux-64::aws-c-sdkutils-0.2.1-h4e1184b_4 
						aws-checksums      conda-forge/linux-64::aws-checksums-0.2.2-h4e1184b_4 
						aws-crt-cpp        conda-forge/linux-64::aws-crt-cpp-0.29.7-hd92328a_7 
						aws-sdk-cpp        conda-forge/linux-64::aws-sdk-cpp-1.11.458-hc430e4a_4 
						azure-core-cpp     conda-forge/linux-64::azure-core-cpp-1.14.0-h5cfcd09_0 
						azure-identity-cpp conda-forge/linux-64::azure-identity-cpp-1.10.0-h113e628_0 
						azure-storage-blo~ conda-forge/linux-64::azure-storage-blobs-cpp-12.13.0-h3cf044e_1 
						azure-storage-com~ conda-forge/linux-64::azure-storage-common-cpp-12.8.0-h736e048_1 
						azure-storage-fil~ conda-forge/linux-64::azure-storage-files-datalake-cpp-12.12.0-ha633028_1 
						blosc              conda-forge/linux-64::blosc-1.21.6-he440d0b_1 
						c-ares             conda-forge/linux-64::c-ares-1.34.4-hb9d3cd8_0 
						c-blosc2           conda-forge/linux-64::c-blosc2-2.15.2-h3122c55_1 
						et_xmlfile         conda-forge/noarch::et_xmlfile-2.0.0-pyhd8ed1ab_1 
						gflags             conda-forge/linux-64::gflags-2.2.2-h5888daf_1005 
						glog               conda-forge/linux-64::glog-0.7.1-hbabe93e_0 
						greenlet           conda-forge/linux-64::greenlet-3.1.1-py312h2ec8cdc_1 
						hdf5               conda-forge/linux-64::hdf5-1.14.4-nompi_h2d575fe_105 
						html5lib           conda-forge/noarch::html5lib-1.1-pyhd8ed1ab_2 
						joblib             conda-forge/noarch::joblib-1.4.2-pyhd8ed1ab_1 
						libabseil          conda-forge/linux-64::libabseil-20240722.0-cxx17_hbbce691_4 
						libaec             conda-forge/linux-64::libaec-1.1.3-h59595ed_0 
						libarrow           conda-forge/linux-64::libarrow-18.1.0-hd595efa_7_cpu 
						libarrow-acero     conda-forge/linux-64::libarrow-acero-18.1.0-hcb10f89_7_cpu 
						libarrow-dataset   conda-forge/linux-64::libarrow-dataset-18.1.0-hcb10f89_7_cpu 
						libarrow-substrait conda-forge/linux-64::libarrow-substrait-18.1.0-h08228c5_7_cpu 
						libcrc32c          conda-forge/linux-64::libcrc32c-1.1.2-h9c3ff4c_0 
						libcurl            conda-forge/linux-64::libcurl-8.11.1-h332b0f4_0 
						libev              conda-forge/linux-64::libev-4.33-hd590300_2 
						libevent           conda-forge/linux-64::libevent-2.1.12-hf998b51_1 
						libgoogle-cloud    conda-forge/linux-64::libgoogle-cloud-2.33.0-h2b5623c_1 
						libgoogle-cloud-s~ conda-forge/linux-64::libgoogle-cloud-storage-2.33.0-h0121fbd_1 
						libgrpc            conda-forge/linux-64::libgrpc-1.67.1-h25350d4_1 
						libllvm14          conda-forge/linux-64::libllvm14-14.0.6-hcd5def8_4 
						libnghttp2         conda-forge/linux-64::libnghttp2-1.64.0-h161d5f1_0 
						libparquet         conda-forge/linux-64::libparquet-18.1.0-h081d1f1_7_cpu 
						libprotobuf        conda-forge/linux-64::libprotobuf-5.28.3-h6128344_1 
						libre2-11          conda-forge/linux-64::libre2-11-2024.07.02-hbbce691_2 
						libssh2            conda-forge/linux-64::libssh2-1.11.1-hf672d98_0 
						libthrift          conda-forge/linux-64::libthrift-0.21.0-h0e7cc3e_0 
						libutf8proc        conda-forge/linux-64::libutf8proc-2.9.0-hb9d3cd8_1 
						llvmlite           conda-forge/linux-64::llvmlite-0.43.0-py312h374181b_1 
						lxml               conda-forge/linux-64::lxml-5.3.0-py312he28fd5a_2 
						lz4-c              conda-forge/linux-64::lz4-c-1.10.0-h5888daf_1 
						nomkl              conda-forge/noarch::nomkl-1.0-h5ca1d4c_0 
						numba              conda-forge/linux-64::numba-0.60.0-py312h83e6fd3_0 
						numexpr            conda-forge/linux-64::numexpr-2.10.2-py312h6a710ac_100 
						openpyxl           conda-forge/linux-64::openpyxl-3.1.5-py312h710cb58_1 
						orc                conda-forge/linux-64::orc-2.0.3-h12ee42a_2 
						patsy              conda-forge/noarch::patsy-1.0.1-pyhd8ed1ab_1 
						py-cpuinfo         conda-forge/noarch::py-cpuinfo-9.0.0-pyhd8ed1ab_1 
						pyarrow            conda-forge/linux-64::pyarrow-18.1.0-py312h7900ff3_0 
						pyarrow-core       conda-forge/linux-64::pyarrow-core-18.1.0-py312h01725c0_0_cpu 
						pytables           conda-forge/linux-64::pytables-3.10.2-py312hf8651a9_0 
						re2                conda-forge/linux-64::re2-2024.07.02-h9925aae_2 
						s2n                conda-forge/linux-64::s2n-1.5.10-hb5b8611_0 
						scikit-learn       conda-forge/linux-64::scikit-learn-1.6.0-py312h7a48858_0 
						scipy              conda-forge/linux-64::scipy-1.15.0-py312h180e4f1_1 
						seaborn            conda-forge/noarch::seaborn-0.13.2-hd8ed1ab_3 
						seaborn-base       conda-forge/noarch::seaborn-base-0.13.2-pyhd8ed1ab_3 
						snappy             conda-forge/linux-64::snappy-1.2.1-h8bd8927_1 
						sqlalchemy         conda-forge/linux-64::sqlalchemy-2.0.36-py312h66e93f0_0 
						statsmodels        conda-forge/linux-64::statsmodels-0.14.4-py312hc0a28a1_0 
						threadpoolctl      conda-forge/noarch::threadpoolctl-3.5.0-pyhc1e730c_0 
						zlib-ng            conda-forge/linux-64::zlib-ng-2.2.3-h7955e40_0 
						
						The following packages will be DOWNGRADED:
						
						numpy                               2.2.1-py312h7e784f5_0 --> 2.0.2-py312h58c1407_1 
						
						
						Proceed ([y]/n)? y
						
						
						Downloading and Extracting Packages:
						
						Preparing transaction: done                                                                                                                                                                                                            
						Verifying transaction: done                                                                                                                                                                                                            
						Executing transaction: done
					\end{verbatim}
					
					\begin{question}[Downgrade NumPy]
						Why downgrade {\tt NumPy} version?
					\end{question}
					On Windows, substitute a carat \verb|^| for line continuation \verb|\| used on Linux \& macOS.
				\end{remark}	
				Can update packages by using {\tt conda update} command:
				\begin{verbatim}
					conda update package_name
				\end{verbatim}
				{\tt pip} also supports upgrades using {\tt--upgrade} flag:
				\begin{verbatim}
					pip install --upgrade package_name
				\end{verbatim}
				Have several opportunities to try out these commands throughout book.
				\begin{remark}
					While can use both {\tt conda} \& {\tt pip} to install packages, should avoid updating packages originally installed with conda using pip (\& vice versa), as doing so can lead to environment problems. Recommend sticking to conda if can \& falling back on pip only for packages that are unavailable with {\tt conda install}.
				\end{remark}
				\item {\sf Integrated Development Environments \& Text Editors.} When asked about standard development environment, almost always says ``IPython plus a text editor.'' Typically write a program \& iteratively test \& debug each piece of it in IPython or Jupyter notebooks. Also useful to be able to play around with data interactively \& visually verify that a particular set of data manipulations is doing right thing. Libraries like {\tt pandas} \& {\tt NumPy} are designed to be productive to use in shell.
				
				When building software, however, some users may prefer to use a more richly featured integrated development environment (IDE) \& rather than an editor like Emacs or Vim which provide a more minimal environment out of box. Some that you can explore:
				\begin{itemize}
					\item PyDev (free), an IDE built on Eclipse platform
					\item PyCharm from JetBrains (subscription-based for commercial users, free for open source developers)
					\item Python Tools for Visual Studio (for Windows users)
					\item Spyder (free), an IDE currently shipped with Anaconda
					\item Komodo IDE (commercial)
				\end{itemize}
				Due to popularity of Python, most text editors, like VS Code \& Sublime Text 2, have excellent Python support.
			\end{itemize}
			\item {\sf1.5. Community \& Conferences.} Outside of an internet search, various scientific \& data-related Python mailing lists are generally helpful \& responsive to questions. Some to take a look at include:
			\begin{itemize}
				\item pydata: A Google Group list for questions related to Python for data analysis \& pandas
				\item pystatsmodels: For statsmodels or pandas-related questions
				\item Mailing list for scikit-learn \verb|scikit-learn@python.org| \& ML in Python, generally
				\item numpy-discussion: For NumPy-related questions
				\item scipy-user: For general SciPy or scientific Python questions
			\end{itemize}
			Deliberately did not post URLs for these in case they change. They can be easily located via an internet search.
			
			Each year many conferences are held all over world for Python programmers. If would like to connect with other Python programmers who share interests, encourage to explore attending one, if possible. Many conferences have financial support available for those who cannot afford admission or travel to conference. Some to consider:
			\begin{itemize}
				\item PyCon \& EuroPython: 2 main general Python conferences in North America \& Europe, resp.
				\item SciPy \& EuroSciPy: Scientific-computing-oriented conferences in North America \& Europe, resp.
				\item SciPy \& EuroSciPy: Scientific-computing-oriented conferences in North America \& Europe, resp.
				\item PyData: A worldwide series of regional conferences a targeted at DS \& data analysis use cases
				\item International \& regional PyCon conferences (see \url{https://pycon.org} for a complete listing)
			\end{itemize}
			\item {\sf1.6. Navigating This Book.} If have never programmed in Python before, will want to spend some time in Chaps. 2--3, where have placed a condensed tutorial on Python language features \& IPython shell \& Jupyter notebooks. These things are prerequisite knowledge for remainder of book. If have Python experience already, may instead choose to skim or skip these chaps.
			
			Next, give a short introduction to key features of NumPy, leaving more advanced {\tt NumPy} use for Appendix A. Then, introduce {\tt pandas} \& devote rest of book to data analysis topics applying {\tt pandas, NumPy, matplotlib} (for visualization). Have structured material in an incremental fashion, though there is occasionally some minor crossover between chaps, with a few cases where concepts are used that haven't been introduced yet.
			
			While readers may have many different end goals for their work, tasks required generally fall into a number of different broad groups:
			\begin{itemize}
				\item {\it Interacting with outside world}: Reading \& writing with a variety of file formats \& data stores
				\item {\it Preparation}: Cleaning, munging, combining, normalizing, reshaping, slicing \& dicing, \& transforming data for analysis
				\item {\it Transformation}: Applying mathematical \& statistical operations to groups of datasets to derive new datasets (e.g., aggregating a large table by group variables)
				\item {\it Modeling \& computation}: Connecting your data to statistical models, ML algorithms, or other computational tools
				\item {\it Presentation}: Creating interactive or static graphical visualizations or textual summaries
			\end{itemize}
			
			\begin{itemize}
				\item {\sf Code Examples.} Most of code examples in book are shown with input \& output as it should appear executed in IPython shell or in Jupyter notebooks:
				\begin{verbatim}
					In [5]: CODE EXAMPLE
					Out[5]: OUTPUT
				\end{verbatim}
				When see a code example like this, intent is for you to type example code in {\tt In} block in your coding environment \& execute it by pressing {\tt Enter} key (or {\tt Shift-Enter} in Jupyter). Should see output similar to what is shown in {\tt Out} block.
				
				Changed default console output settings in {\tt NumPy} \& {\tt pandas} to improve readability \& brevity throughout book. E.g., may see more digits of precision printed in numeric data. To exactly match output shown in book, can execute following Python code before running code examples:
				\begin{verbatim}
					import numpy as np
					import {\tt pandas} as pd
					pd.options.display.max_columns = 20
					pd.options.display.max_rows = 20
					pd.options.display.max_colwidth = 80
					np.set_printoptions(precision=4, suppress=True)
				\end{verbatim}
				\item {\sf Data Examples.} Datasets for examples in each chap are hosted in \url{https://github.com/wesm/pydata-book} (or in \url{https://gitee.com/wesmckinn/pydata-book} if cannot access GitHub). Can download this data either by using Git version control system on command line or by downloading a zip file of repository from website. If you run into problems, navigate to book website \url{https://wesmckinney.com/book} for up-to-date instructions about obtaining book materials.
				
				If download a zip file containing example datasets, must then fully extract contents of zip file to a directory \& navigate to that directory from terminal before proceeding with running book's code examples:
				\begin{verbatim}
					$ pwd
					/home/wesm/book-materials
					$ ls
					appa.ipynb ch05.ipynb ch09.ipynb ch13.ipynb  README.md
					ch02.ipynb ch06.ipynb ch10.ipynb COPYING     requirements.txt
					ch03.ipynb ch07.ipynb ch11.ipynb datasets
					ch04.ipynb ch08.ipynb ch12.ipynb examples
				\end{verbatim}
				Have made every effort to ensure: GitHub repository contains everything necessary to reproduce examples, but may have made some mistakes or omissions.
				\item {\sf Import Conventions.} Python community has adopted a number of naming conventions for commonly used modules:
				\begin{verbatim}
					import numpy as np
					import matplotlib.pyplot as plt
					import {\tt pandas} as pd
					import seaborn as sns
					import statsmodels as sm
				\end{verbatim}
				I.e., when see {\tt np.arrange}, this is a reference to {\tt arrange} function in NumPy. This is done because it's considered bad practice in Python software development to import everything {\tt from numpy import *} from a large package like NumPy.
			\end{itemize}
		\end{itemize}
		\item {\sf2. Python Language Basics, IPython, \& Jupyter Notebooks.} When wrote 1e of this book in 2011--2012, there were fewer resources available for learning about doing data analysis in Python. This was partially a chicken-\&-egg problem; many libraries that we know take for granted, like {\tt pandas, scikit-learn, statsmodels}, were comparatively immature back then. Now in 2022, there is now a growing literature on DS, data analysis, \& ML, supplementing prior works on general-purpose scientific computing geared toward computational scientists, physicists, \& professionals in other research fields. There are also excellent books about learning Python programming language itself \& becoming an effective software engineer.
		
		As this book is intended as an introductory text in working with data in Python, feel valuable to have a self-contained overview of some of most important features of Python's built-in data structures \& libraries from perspective of data manipulation. So, will only present roughly enough information in Chaps. 2--3 to enable you to follow along with rest of book.
		
		Much of this book focuses on table-based analytics \& data preparation tools for working with datasets that are small enough to fit on your personal computer. to use these tools you must sometimes do some wrangling to arrange messy data into a more nicely tabular (or {\it structured}) form. Fortunately, Python is an ideal language for doing this. Greater your facility with Python language \& its built-in data types, easier it will be for you to prepare new datasets for analysis.
		
		Some of tools in this book are best explored from a live IPython or Jupyter session. Once learn how to start up IPython \& Jupyter session. Once learn how to start up IPython \& Jupyter, recommend: follow along with examples so can experiment \& try different things. As with any keyboard-driven console-like environment, developing familiarity with common commands is also part of learning curve.		
		\begin{remark}
			There are introductory Python concepts that this chap does not cover, like classes \& object-oriented programming, which may find useful in your foray ()cuộc đột kích, cướp phá, xâm lược) into data analysis in Python.
			
			To deepen Python language knowledge, recommend: supplement this chap with \href{http://docs.python.org}{official Python tutorial} \& potentially 1 of many excellent books on general-purpose Python programming. Some recommendations to get you started include:
			\begin{itemize}
				\item {\it Python Cookbook}, 3e, by {\sc David Beazley, Brian K. Jones}
				\item {\it Fluent Python} by {\sc Luciano Ramalho}
				\item {\it Effective Python}, 2e, by {\sc Brett Slatkin}
			\end{itemize}
		\end{remark}
		
		\begin{itemize}
			\item {\sf2.1. Python Interpreter.} Python is an {\it interpreted} language. Python interpreter runs a program by executing 1 statement at a time. Standard interactive Python interpreter can be invoked on command line with {\tt python} command:
			\begin{verbatim}
				(pydata-book) nqbh@nqbh-dell:~$ python
				Python 3.12.7 | packaged by conda-forge | (main, Oct  4 2024, 16:05:46) [GCC 13.3.0] on linux                                                        
				Type "help", "copyright", "credits" or "license" for more information.            
				>>>
			\end{verbatim}
			{\tt>>>} is {\it prompt} after which you'll type code expressions. To exit Python interpreter, can either type {\tt exit()} or press Ctrl-D (works on Linux \& macOS only).
			
			Running Python programs is as simple as calling {\tt python} with a {\tt.py} file as its 1st argument.
			
			While some Python programmers execute all of their Python code in this way, those doing data analysis or scientific computing make use of IPython, an enhanced Python interpreter, or Jupyter notebooks, web-based code notebooks originally created within IPython project. Give an introduction to using IPython \& Jupyter in this chap \& have included a deeper look at IPython functionality in Appendix A. When use \verb|%run| command, IPython executes code in specified file in same process, enabling to explore results interactively when it's done:
			\begin{verbatim}
				(pydata-book) nqbh@nqbh-dell:~$ ipython                            
				Python 3.12.7 | packaged by conda-forge | (main, Oct  4 2024, 16:05:46) [GCC 13.3.0]                                                                                Type 'copyright', 'credits' or 'license' for more information      
				IPython 8.31.0 -- An enhanced Interactive Python. Type '?' for help.                                                                                                In [1]: %run hello_world.py
				Hello world
				
				In [2]:
			\end{verbatim}
			Default IPython prompt adopts numbered {\tt In [2]:} style, cf. standard {\tt>>>} prompt.
			\item {\sf2.2. IPython Basics.} Run with IPython shell \& Jupyter notebook, \& introduce to some of essential concepts.
			\begin{itemize}
				\item {\sf Running IPython Shell.} Can launch IPython shell on command line just like launching regular Python interpreter except with {\tt ipython} command {\tt ipython}. You can execute arbitrary Python statements by typing them \& pressing Return (or Enter). When type just a variable into IPython, it renders a string representation of object:
				\begin{verbatim}
					In [5]: import numpy as np
					
					In [6]: data = [np.random.standard_normal() for i in range(7)]
					
					In [7]: data
					Out[7]: 
					[-0.960515015233981,
					0.29199995965351516,
					0.656773965407049,
					1.0319443387105414,
					-0.15623460611892206,
					-0.17214640580390445,
					0.5260760636382895]
				\end{verbatim}
				1st 2 lines are Python code statements; 2nd statement creates a variable named {\tt data} that refers to a newly created Python dictionary. Last line prints value of {\tt data} in console.
				
				Many kinds of Python objects are formatted to be more readable, or {\it pretty-printed}, which is distinct from normal printing with {\tt print}. If printed above {\tt data} variable in standard Python interpreter, it would be much less readable:
				\begin{verbatim}
					>>> import numpy as np
					>>> data = [np.random.standard_normal() for i in range(7)]
					>>> print(data)
					>>> data
					[-0.5767699931966723, -0.1010317773535111, -1.7841005313329152,
					-1.524392126408841, 0.22191374220117385, -1.9835710588082562,
					-1.6081963964963528]
				\end{verbatim}
				IPython also provides facilities to execute arbitrary blocks of code (via a somewhat glorified copy-\&-paste approach) \& whole Python scripts. Can also use Jupyter notebook to work with larger blocks of code.
				\item {\sf Running Jupyter Notebook.} 1 of major components of Jupyter project is {\it notebook}, a type of interactive document for code, text (including Markdown), data visualizations, \& other output. Jupyter notebook interacts with {\it kernels}, which are implementations of Jupyter interactive computing protocol specific to different programming languages. Python Jupyter kernel uses IPython system for its underlying behavior.
				
				To start up Jupyter, run command {\tt jupyter notebook} in a terminal:
				\begin{verbatim}
					$ jupyter notebook
					[I 15:20:52.739 NotebookApp] Serving notebooks from local directory:
					/home/wesm/code/pydata-book
					[I 15:20:52.739 NotebookApp] 0 active kernels
					[I 15:20:52.739 NotebookApp] The Jupyter Notebook is running at:
					http://localhost:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4bb443a63f2d...
					[I 15:20:52.740 NotebookApp] Use Control-C to stop this server and shut down
					all kernels (twice to skip confirmation).
					Created new window in existing browser session.
					To access the notebook, open this file in a browser:
					file:///home/wesm/.local/share/jupyter/runtime/nbserver-185259-open.html
					Or copy and paste one of these URLs:
					http://localhost:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4...
					or http://127.0.0.1:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4...
				\end{verbatim}
				NQBH's:
				\begin{verbatim}
					(base) nqbh@nqbh-dell:~$ conda activate pydata-book
					(pydata-book) nqbh@nqbh-dell:~$ jupyter notebook
					[I 2025-01-10 15:13:58.486 ServerApp] jupyter_lsp | extension was successfully linked.
					[I 2025-01-10 15:13:58.488 ServerApp] jupyter_server_terminals | extension was successfully linked.
					[I 2025-01-10 15:13:58.491 ServerApp] jupyterlab | extension was successfully linked.
					[I 2025-01-10 15:13:58.493 ServerApp] notebook | extension was successfully linked.
					[I 2025-01-10 15:13:58.610 ServerApp] notebook_shim | extension was successfully linked.
					[I 2025-01-10 15:13:58.622 ServerApp] notebook_shim | extension was successfully loaded.
					[I 2025-01-10 15:13:58.623 ServerApp] jupyter_lsp | extension was successfully loaded.
					[I 2025-01-10 15:13:58.624 ServerApp] jupyter_server_terminals | extension was successfully loaded.
					[I 2025-01-10 15:13:58.624 LabApp] JupyterLab extension loaded from /home/nqbh/anaconda3/envs/pydata-book/lib/python3.12/site-packages/jupyterlab
					[I 2025-01-10 15:13:58.624 LabApp] JupyterLab application directory is /home/nqbh/anaconda3/envs/pydata-book/share/jupyter/lab
					[I 2025-01-10 15:13:58.624 LabApp] Extension Manager is 'pypi'.
					[I 2025-01-10 15:13:58.661 ServerApp] jupyterlab | extension was successfully loaded.
					[I 2025-01-10 15:13:58.663 ServerApp] notebook | extension was successfully loaded.
					[I 2025-01-10 15:13:58.663 ServerApp] Serving notebooks from local directory: /home/nqbh
					[I 2025-01-10 15:13:58.663 ServerApp] Jupyter Server 2.15.0 is running at:
					[I 2025-01-10 15:13:58.663 ServerApp] http://localhost:8888/tree?token=6f7ecdf66d339bf97d3a73aa22ceff2f9eb3957d2aa3d4a6
					[I 2025-01-10 15:13:58.663 ServerApp]     http://127.0.0.1:8888/tree?token=6f7ecdf66d339bf97d3a73aa22ceff2f9eb3957d2aa3d4a6
					[I 2025-01-10 15:13:58.663 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
					[C 2025-01-10 15:13:58.684 ServerApp] 
					
					To access the server, open this file in a browser:
					file:///home/nqbh/.local/share/jupyter/runtime/jpserver-73029-open.html
					Or copy and paste one of these URLs:
					http://localhost:8888/tree?token=6f7ecdf66d339bf97d3a73aa22ceff2f9eb3957d2aa3d4a6
					http://127.0.0.1:8888/tree?token=6f7ecdf66d339bf97d3a73aa22ceff2f9eb3957d2aa3d4a6
					[I 2025-01-10 15:13:58.695 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
					Gtk-Message: 15:13:58.798: Not loading module "atk-bridge": The functionality is provided by GTK natively. Please try to not load it.
					[73110, Main Thread] WARNING: GTK+ module /snap/firefox/5561/gnome-platform/usr/lib/gtk-2.0/modules/libcanberra-gtk-module.so cannot be loaded.
					GTK+ 2.x symbols detected. Using GTK+ 2.x and GTK+ 3 in the same process is not supported.: 'glib warning', file /build/firefox/parts/firefox/build/toolkit/xre/nsSigHandlers.cpp:201
					
					(firefox:73110): Gtk-WARNING **: 15:13:58.845: GTK+ module /snap/firefox/5561/gnome-platform/usr/lib/gtk-2.0/modules/libcanberra-gtk-module.so cannot be loaded.
					GTK+ 2.x symbols detected. Using GTK+ 2.x and GTK+ 3 in the same process is not supported.
					Gtk-Message: 15:13:58.845: Failed to load module "canberra-gtk-module"
					[73110, Main Thread] WARNING: GTK+ module /snap/firefox/5561/gnome-platform/usr/lib/gtk-2.0/modules/libcanberra-gtk-module.so cannot be loaded.
					GTK+ 2.x symbols detected. Using GTK+ 2.x and GTK+ 3 in the same process is not supported.: 'glib warning', file /build/firefox/parts/firefox/build/toolkit/xre/nsSigHandlers.cpp:201
					
					(firefox:73110): Gtk-WARNING **: 15:13:58.846: GTK+ module /snap/firefox/5561/gnome-platform/usr/lib/gtk-2.0/modules/libcanberra-gtk-module.so cannot be loaded.
					GTK+ 2.x symbols detected. Using GTK+ 2.x and GTK+ 3 in the same process is not supported.
					Gtk-Message: 15:13:58.846: Failed to load module "canberra-gtk-module"
				\end{verbatim}
				On many platforms, Jupyter will automatically open in default web browser (unless start it with {\tt--no-browser}). Otherwise, can navigate to HTTP address printed when started notebook, here \url{http://localhost:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4bb443a63f2d3055}. See {\sf Fig. 2.1: Jupyter notebook landing page} for what this looks like in Google Chrome.				
				\begin{remark}
					Many people use Jupyter as a local computing environment, but it can also be deployed on servers \& accessed remotely. Won't cover those details here, but encourage to explore this topic on internet if it's relevant to your needs.
				\end{remark}
				To create a new notebook, click {\tt New} button \& select {\tt Python 3} option. Should see sth like {\sf Fig. 2.2: Jupyter new notebook view}. If this is 1st time, try clicking on empty code ``cell'' \& entering a line of Python code. Then press Shift-Enter to execute it.
				
				When save notebook (see {\tt Save \& Checkpoint} under notebook {\tt File} menu), it creates a file with extension {\tt.ipynb}: a self-contained file format containing all of content (including any evaluated code output) currently in notebook. These can be loaded \& edited by other Jupyter users.
				
				To rename an open notebook, click on notebook title at top of page \& type new title, pressing {\tt Enter} when finished.
				
				To load an existing notebook, put file in same directory where started notebook process (or in a subfolder within it), then click name from landing page. Can try it out with notebooks from {\tt wesm/pydata-book} repository on GitHub {\sf Fig. 2.3: Jupyter example view for an existing notebook}.
				
				When want to close a notebook, click File menu \& select {\tt Close \& Halt}. If simply close browser tab, Python process associated with notebook will keep running in background.
				
				While Jupyter notebook may feel like a distinct experience from IPython shell, nearly all of commands \& tools in this chap can be used in either environment.
				\item {\sf Tab Completion.} On surface, IPython shell looks like a cosmetically different version (phiên bản khác biệt về mặt thẩm mỹ) of standard terminal Python interpreter (invoked with {\tt python}). 1 of major improvements over standard Python shell is {\it tab completion}, found in many IDEs or other interactive computing analysis environments. While entering expressions in shell, pressing {\tt Tab} key will search namespace for any variables (objects, functions, etc.) matching characters you have typed so far \& show results in a convenient drop-down menu:
				\begin{verbatim}
					In [1]: an_apple = 27
					In [2]: an_example = 42
					In [3]: an<Tab>
					an_apple an_example  any
				\end{verbatim}
				Note: IPython displayed both of 2 variables I defined, as well as built-in function {\tt any}. Also, you can also complete methods \& attributes on any object after typing a period:
				\begin{verbatim}
					In [3]: b = [1, 2, 3]
					
					In [4]:  b.<Tab>
					append()  count()   insert()  reverse()
					clear()   extend()  pop()     sort()   
					copy()    index()   remove()           
				\end{verbatim}
				Same is true for modules:
				\begin{verbatim}
					In [1]:  import datetime
					
					In [2]: datetime.
					date          MAXYEAR       timedelta     UTC          
					datetime      MINYEAR       timezone                   
					datetime_CAPI time          tzinfo                     
				\end{verbatim}
				
				\begin{remark}
					IPython by default hides methods \& attributes starting with underscores, e.g. magic methods \& internal ``private'' methods \& attributes, in order to avoid cluttering display (\& confusing novice users -- gây bối rối cho người dùng mới!). These, too, can be tab-completed, but must 1st type an underscore to see them. If prefer to always see such methods in tab completion, can change this setting in IPython configuration. See \href{https://ipython.readthedocs.io}{IPython documentation} to find out how to do this.
				\end{remark}
				Tab completion works in many contexts outside of searching interactive namespace \& completng object or module attributes. When typing anything that looks like a file path (even in a Python string), pressing Tab key will complete anything on your computer's filesystem matching what you've typed.
				
				Combined with \verb|%run| command, this functionality can save you many keystrokes.
				
				Another area where tab completion saves time is in completion of function keyword arguments (including $=$ sign!) {\sf Fig. 2.4: Autocomplete function keywords in a Jupyter notebook}.
				
				Have a closer look at functions in a little bit:
				\item {\sf Introspection.} Using a question mark {\tt?} before or after a variable will display some general information about object:
				\begin{verbatim}
					In [12]: b?
					Type:        list
					String form: [1, 2, 3]
					Length:      3
					Docstring:  
					Built-in mutable sequence.
					
					If no argument is given, the constructor creates a new empty list.
					The argument must be an iterable if specified.
					
					In [13]: ?b
					Type:        list
					String form: [1, 2, 3]
					Length:      3
					Docstring:  
					Built-in mutable sequence.
					
					If no argument is given, the constructor creates a new empty list.
					The argument must be an iterable if specified.
					
					In [14]: print?
					Signature: print(*args, sep=' ', end='\n', file=None, flush=False)
					Docstring:
					Prints the values to a stream, or to sys.stdout by default.
					
					sep
					string inserted between values, default a space.
					end
					string appended after the last value, default a newline.
					file
					a file-like object (stream); defaults to the current sys.stdout.
					flush
					whether to forcibly flush the stream.
					Type:      builtin_function_or_method
				\end{verbatim}
				This is referred to as {\it object introspection}. If object is a function or instance method, docstring, if defined, will also be shown. Suppose we'd written following function (which you can reproduce in IPython or Jupyter):
				\begin{verbatim}
					def add_numbers(a, b):
					    """
					    Add two numbers together
					    Returns
					    -------
					    the_sum : type of arguments
					    """
					return a + b
				\end{verbatim}
				Then using {\tt?} shows us docstring:
				\begin{verbatim}
					In [6]: add_numbers?
					Signature: add_numbers(a, b)
					Docstring:
					Add two numbers together
					Returns
					-------
					the_sum : type of arguments
					File:    <ipython-input-9-6a548a216e27>
					Type:    function
				\end{verbatim}
				{\tt?} has a final usage, which is for searching IPython namespace in a manner similar to standard Unix or Windows command line. A number of characters combined with wildcard {\tt*} will show all names matching wildcard expression. E.g., could get a list of all functions in top-level NumPy namespace containing {\tt load}: [Missing line: {\tt np.loads} cf. book]
				\begin{verbatim}
					In [1]: import numpy as np
					
					In [2]: np.*load*?
					np.__loader__
					np.load
					np.loadtxt
				\end{verbatim}
			\end{itemize}
			\item {\sf2.3. Python Language Basics.} Give an overview of essential Python programming concepts \& language mechanics. In Chap. 3, go into more detail about Python data structures, functions, \& other built-in tools.
			\begin{itemize}
				\item {\sf Language Semantics.} Python language design is distinguished by its emphasis on readability, simplicity, \& explicitness. Some people go so far as to liken it to ``executable pseudocode.''
				\begin{itemize}
					\item {\tt Indentation, not braces.} Python uses whitespace (tabs or spaces) to structure code instead of using braces as in many other languages like R, C++, Java, \& Perl. Consider a {\tt for} loop from a sorting algorithm:
					\begin{verbatim}
						for x in array:
						    if x < pivot:
						        less.append(x)
						    else:
						        greater.append(x)
					\end{verbatim}
					A colon denotes start of an indented code block after which all of code must be indented by same amount until end of block.
					
					Love it or hate it, significant whitespace is a fact of life for Python programmers. While it may seem foreign at 1st, will hopefully grow accustomed to it in time.
					\begin{remark}
						Strong recommend using \emph{4 spaces} as your default indentation \& replacing tabs with 4 spaces. Many text editors have a setting that will replace tab stops with spaces automatically insert 4 spaces on new lines following a colon \& replace tabs by 4 spaces.
					\end{remark}
					As you can see by now, Python statements also do not need to be terminated by semicolons. Semicolons can be used, however, to separate multiple statements on a single line:
					\begin{verbatim}
						a = 5; b = 6; c = 7
					\end{verbatim}
					Putting multiple statements on 1 line is generally discouraged in Python as it can make code less readable.
					\item {\sf Everything is an object.} An important characteristic of Python language is consistency of its {\it object model}. Every number, string, data structure, function, class, module, \& so on exists in Python interpreter in its own ``box,'' which is referred to as a {\it Python object}. Each object has an associated {\it type} (e.g., {\it integer, string}, or {\it function}) \& internal data. In practice this makes language very flexible, as even functions can be treated like any other object.
					\item {\sf Comments.} Any text preceded by hash mark (pound sign) \verb|#| is ignored by Python interpreter. Often used to add comments to code. At times may also want to exclude certain blocks of code without deleting them. 1 solution: {\it comment out} code:
					\begin{verbatim}
						results = []
						for line in file_handle:
						    # keep the empty lines for now
						    # if len(line) == 0:
						    #   continue
						    results.append(line.replace("foo", "bar"))
					\end{verbatim}
					Comments can also occur after a line of executed code. While some programmers prefer comments to be placed in line preceding a particular line of code, this can be useful at times:
					\begin{verbatim}
						print("Reached this line") # Simple status report
					\end{verbatim}
					\item {\sf Function \& object method calls.} Call functions using parentheses \& passing 0 or more arguments, optionally assigning returned value to a variable:
					\begin{verbatim}
						result = f(x, y, z)
						g()
					\end{verbatim}
					Almost every object in Python has attached functions, known as {\it methods}, that have access to object's internal contents. Can call them using following syntax:
					\begin{verbatim}
						obj.some_method(x, y, z)
					\end{verbatim}
					Functions can take both {\it positional \& keyword} arguments:
					\begin{verbatim}
						result = f(a, b, c, d=5, e="foo")
					\end{verbatim}
					\item {\sf Variables \& argument passing.} When assigning a variable (or {\it name}) in Python, you are creating a {\it reference} to object shown on RHS of equals sign. In practical terms, consider a list of integers:
					\begin{verbatim}
						In [8]: a = [1, 2, 3]
					\end{verbatim}
					Suppose: assign {\tt a} to a new variable {\tt b}:
					\begin{verbatim}
						In [9]: b = a
						
						In [10]: b
						Out[10]: [1, 2, 3]
					\end{verbatim}
					In some languages, assignment if {\tt b} will cause data {\tt[1, 2, 3]} to be copied. In Python, {\tt a} \& {\tt b} actually now refer to same object, original list {\tt[1, 2, 3]} (see {\sf Fig. 2.5: 2 references for same object} for a mock-up). Can prove this by appending an element to {\tt a} \& then examining {\tt b}:
					\begin{verbatim}
						In [11]: a.append(4)
						
						In [12]: b
						Out[12]: [1, 2, 3, 4]
					\end{verbatim}
					Understanding semantics of references in Python, \& when, how, \& why data is copied, is especially critical when you are working with larger datasets in Python.
					
					-- Hiểu được ngữ nghĩa của các tham chiếu trong Python, \& khi nào, như thế nào, \& lý do tại sao dữ liệu được sao chép, đặc biệt quan trọng khi bạn làm việc với các tập dữ liệu lớn hơn trong Python.					
					\begin{remark}
						Assignment is also referred to as {\rm binding}, as we are binding a name to an object. Variable names that have been assigned may occasionally be referred to as bound variables.
					\end{remark}
					When pass objects as arguments to a function, new local variables are created referencing original objects without any copying. If bind a new object to a variable inside a function, that will not overwrite a variable of same name in ``scope'' outside of function (``parent scope''). Therefore possible to alter internals of a mutable argument. Suppose had following function:
					\begin{verbatim}
						In [13]: def append_element(some_list, element):
						   ....:     some_list.append(element)
					\end{verbatim}
					Then have:
					\begin{verbatim}
						In [14]: data = [1, 2, 3]
						
						In [15]: append_element(data, 4)
						
						In [16]: data
						Out[16]: [1, 2, 3, 4]
					\end{verbatim}
					\item {\sf Dynamic references, strong types.} Variables in Python have no inherent type associated with them; a variable can refer to a different type of object simply by doing an assignment. There is no problem with following:
					\begin{verbatim}
						In [17]: a = 5
						
						In [18]: type(a)
						Out[18]: int
						
						In [19]: a = "foo"
						
						In [20]: type(a)
						Out[20]: str
					\end{verbatim}
					Variables are names for objects within a particular namespace; type information is stored in object itself. Some observers might hastily conclude: Python is not a ``typed language.'' Wrong: consider:
					\begin{verbatim}
						In [21]: "5" + 5
						---------------------------------------------------------------------------
						TypeError
						Traceback (most recent call last)
						<ipython-input-21-7fe5aa79f268> in <module>
						----> 1 "5" + 5
						TypeError: can only concatenate str (not "int") to str
					\end{verbatim}
					In some languages, string {\tt'5'} might get implicitly converted (or {\it cast}) to an integer, thus yielding 10. In other languages integer {\tt5} might be cast to a string, yielding concatenated string {\tt'55'}. In Python, such implicit casts are not allowed. In this regard, say: Python is a {\it strongly typed} language, i.e., every object has a specific type (or {\it class}), \& implicit conversions will occur only in certain permitted circumstances, e.g.:
					\begin{verbatim}
						In [22]: a = 4.5
						
						In [23]: b = 2
						
						# String formatting, to be visited later
						In [24]: print(f"a is {type(a)}, b is {type(b)}")
						a is <class 'float'>, b is <class 'int'>
						
						In [25]: a / b
						Out[25]: 2.25
					\end{verbatim}
					Here, even though {\tt b} is an integer, it is implicitly converted to a float for division operation.
					
					Knowing type of an object is important, \& useful to be able to write functions that can handle many different kinds of input. Can check: an object is an instance of a particular type using {\tt isinstance} function:
					\begin{verbatim}
						In [26]: a = 5
						
						In [27]: isinstance(a, int)
						Out[27]: True
					\end{verbatim}
					{\tt isinstance} can accept a type of types if want to check: an object's type is among those present in tuple:
					\begin{verbatim}
						In [28]: a = 5; b = 4.5
						
						In [29]: isinstance(a, (int, float))
						Out[29]: True
						
						In [30]: isinstance(b, (int, float))
						Out[30]: True
					\end{verbatim}
					\item {\sf Attributes \& methods.} Objects n Python typically have both attributes (other Python objects stored ``inside'' object) \& methods (functions associated with an object that can have access to object's internal data). Both of them are accessed via syntax \verb|obj.attribute_name|:
					\begin{verbatim}
In [1]: a = "foo"

In [2]: a.<Press Tab>
capitalize()   encode()       format()       isalpha()      isidentifier() isspace()      ljust()        partition()    rfind()        rsplit()       startswith()   translate()   
casefold()     endswith()     format_map()   isascii()      islower()      istitle()      lower()        removeprefix() rindex()       rstrip()       strip()        upper()       
center()       expandtabs()   index()        isdecimal()    isnumeric()    isupper()      lstrip()       removesuffix() rjust()        split()        swapcase()     zfill()       
count()        find()         isalnum()      isdigit()      isprintable()  join()         maketrans()    replace()      rpartition()   splitlines()   title()                      
					\end{verbatim}
					Attributes \& methods can also be accessed by name via {\tt getattr} function:
					\begin{verbatim}
						In [32]: getattr(a, "split")
						Out[32]: <function str.split(sep=None, maxsplit=-1)>
					\end{verbatim}
					While will not extensively use functions {\tt getattr} \& related functions {\tt hasattr} \& {\tt setattr} in this book, they can be used very effectively to write generic, reusable code.
					\item {\sf Duck typing.} Often may not care about type of an object but rather only whether it has certain methods or behavior. This is sometimes called {\it duck typing}, after saying ``If it walks like a duck \& quacks like a duck, then it's a duck.'' E.g., you can verify: an object is iterable if it implements {\it iterator protocol}. For many objects, this means it has an \verb|__iter__| ``magic method,'' though an alternative \& better way to check is to try using {\tt iter} function:
					\begin{verbatim}
						In [33]: def isiterable(obj):
						   ....:     try:
						   ....:         iter(obj)
						   ....:         return True
						   ....:     except TypeError: # not iterable
						   ....:         return False
					\end{verbatim}
					This function would return {\tt True} for strings as well as most Python collection types:
					\begin{verbatim}
						In [34]: isiterable("a string")
						Out[34]: True
						
						In [35]: isiterable([1, 2, 3])
						Out[35]: True
						
						In [36]: isiterable(5)
						Out[36]: False
					\end{verbatim}
					\item {\sf Imports.} In Python, a {\it module} is simply a file with {\tt.py} extension containing Python code. Suppose had following module:
					\begin{verbatim}
						# some_module.py
						PI = 3.14159
						
						def f(x):
						    return x + 2
						    
						def g(a, b):
						    return a + b
					\end{verbatim}
					If wanted to access variables \& functions defined in \verb|some_module.py|, from another file in same directory, could do:
					\begin{verbatim}
						import some_module
						result = some_module.f(5)
						pi = some_module.PI
					\end{verbatim}
					Or alternately:
					\begin{verbatim}
						from some_module import g, PI
						result = g(5, PI)
					\end{verbatim}
					By using {\tt as} keyword, can give imports different variable names:
					\begin{verbatim}
						import some_module as sm
						from some_module import PI as pi, g as gf
						
						r1 = sm.f(pi)
						r2 = gf(6, pi)
					\end{verbatim}
					\item {\sf Binary operators \& comparisons.} Most of binary math operations \& comparisons use familiar mathematical syntax used in other programming languages:
					\begin{verbatim}
						In [37]: 5 - 7
						Out[37]: -2
						
						In [38]: 12 + 21.5
						Out[38]: 33.5
						
						In [39]: 5 <= 2
						Out[39]: False
					\end{verbatim}
					See {\sf Table 2.1: Binary operators} for all of available binary operators.
					
					To check if 2 variables refer to same object, use {\tt is} keyword. Use {\tt is not} to check that 2 objects are not the same:
					\begin{verbatim}
						In [40]: a = [1, 2, 3]
						
						In [41]: b = a
						
						In [42]: c = list(a)
						
						In [43]: a is b
						Out[43]: True
						
						In [44]: a is not c
						Out[44]: True
					\end{verbatim}
					Since {\tt list} function always creates a new Python list (i.e., a copy), can be sure: {\tt c} is distinct from {\tt a}. Comparing with {\tt is} is not same as {\tt==} operator, because in this case have:
					\begin{verbatim}
						In [45]: a == c
						Out[45]: True
					\end{verbatim}
					A common use of {\tt is} \& {\tt is not} is to check if a variable is {\tt None}, since there is only 1 instance of {\tt None}:
					\begin{verbatim}
						In [46]: a = None
						
						In [47]: a is None
						Out[47]: True
					\end{verbatim}
					\item {\sf Mutable \& immutable objects.} Many objects in Python, e.g. lists, dictionaries, NumPy arrays, \& most user-defined types (classes), are {\it mutable} (có thể thay đổi). I.e., object or values that they contain can be modified:
					\begin{verbatim}
						In [48]: a_list = ["foo", 2, [4, 5]]
						
						In [49]: a_list[2] = (3, 4)
						
						In [50]: a_list
						Out[50]: ['foo', 2, (3, 4)]
					\end{verbatim}
					Others, like strings \& tuples, are immutable, which means their internal data cannot be changed:
					\begin{verbatim}
						In [51]: a_tuple = (3, 5, (4, 5))
						In [52]: a_tuple[1] = "four"
						---------------------------------------------------------------------------
						TypeError
						Traceback (most recent call last)
						<ipython-input-52-cd2a018a7529> in <module>
						----> 1 a_tuple[1] = "four"
						TypeError: 'tuple' object does not support item assignment
					\end{verbatim}
					Remember: just because you {\it can} mutate an object does not mean that you always {\it should}. Such actions are known as {\it side effects}. E.g., when writing a function, any side effects should be explicitly communicated to user in function's documentation or comments. If possible, recommend trying to avoid side effects \& {\it favor immutability}, even though there may be mutable objects involved.
				\end{itemize}
				\item {\sc Scalar Types.} Python has a small set of built-in types for handling numerical data, strings, Boolean ({\tt True} or {\tt False}) values, \& dates \& time. These ``single value'' types are sometimes called {\it scalar types}, \& refer to them in this book as {\it scalars}. See {\sf Table 2.2: Standard Python scalar types}
				\begin{itemize}
					\item {\tt None}: Python ``null'' value (only 1 instance of {\tt None} object exists)
					\item {\tt str}: String type; holds Unicode strings
					\item {\tt bytes}: Raw binary data
					\item {\tt float}: Double-precision floating-point number (note there is no separate {\tt double} type)
					\item {\tt bool}: A Boolean {\tt True} or {\tt False} value
					\item {\tt int}: Arbitrary precision integer
				\end{itemize}
				for a list of main scalar types. Date \& time handling will be discussed separately, as these are provided by {\tt datetime} module in standard library.
				\begin{itemize}
					\item {\sf Numeric types.} Primary Python types for numbers are {\tt int} \& {\tt float}. An {\tt int} can store arbitrarily large numbers:
					\begin{verbatim}
						In [53]: ival = 17239871
						
						In [54]: ival ** 6
						Out[54]: 26254519291092456596965462913230729701102721
					\end{verbatim}
					Floating-point numbers are represented with Python {\tt float} type. Under hood, each one is a double-precision value. They can also be expressed with scientific notation:
					\begin{verbatim}
						In [55]: fval = 7.243
						
						In [56]: fval2 = 6.78e-5
					\end{verbatim}
					Integer division not resulting in a whole number will always yield a floating-point number:
					\begin{verbatim}
						In [57]: 3 / 2
						Out[57]: 1.5
					\end{verbatim}
					To get C-style integer division (which drops fractional part if result is not a whole number), use floor division operator {\tt//}:
					\begin{verbatim}
						In [58]: 3 // 2
						Out[58]: 1
					\end{verbatim}
					\item {\sf Strings.} Many people use Python for its built-in string handling capabilities. Can write {\it string literals} using either single quotes {\tt'} or double quotes {\tt"} (double quotes are generally favored):
					\begin{verbatim}
						a = 'one way of writing a string'
						b = "another way"
					\end{verbatim}
					Python string type is {\tt str}.
					
					For multiline strings with line breaks, can use triple quotes, either {\tt'''} or {\tt"""}:
					\begin{verbatim}
						c = """
						This is a longer string that
						spans multiple lines
						"""
					\end{verbatim}
					It may surprise: this string {\tt c} actually contains 4 lines of text; line breaks after {\tt"""} \& after {\tt lines} are included in string. Can count new line characters with {\tt count} method on {\tt c}:
					\begin{verbatim}
						In [60]: c.count("\n")
						Out[60]: 3
					\end{verbatim}
					Python strings are immutable; you cannot modify a string:
					\begin{verbatim}
						In [61]: a = "this is a string"
						
						In [62]: a[10] = "f"
						---------------------------------------------------------------------------
						TypeError
						Traceback (most recent call last)
						<ipython-input-62-3b2d95f10db4> in <module>
						----> 1 a[10] = "f"
						TypeError: 'str' object does not support item assignment
					\end{verbatim}
					To interpret this error message, read from bottom up. Tried to replace character (``item'') at position 10 with letter {\tt"f"}, but this is not allowed for string objects. If need to modify a string, have to use a function or method that creates a new string, e.g. string {\tt replace} method:
					\begin{verbatim}
						In [63]: b = a.replace("string", "longer string")
						
						In [64]: b
						Out[64]: 'this is a longer string'
					\end{verbatim}
					After this operation, variable {\tt a} is unmodified:
					\begin{verbatim}
						In [65]: a
						Out[65]: 'this is a string'
					\end{verbatim}
					Many Python objects can be converted to a string using {\tt str} function:
					\begin{verbatim}
						In [66]: a = 5.6
						In [67]: s = str(a)
						In [68]: print(s)
						5.6
					\end{verbatim}
					Strings are a sequence of Unicode characters \& therefore can be treated like other sequences, e.g. lists \& tuples:
					\begin{verbatim}
						In [69]: s = "python"
						
						In [70]: list(s)
						Out[70]: ['p', 'y', 't', 'h', 'o', 'n']
						
						In [71]: s[:3]
						Out[71]: 'pyt'
					\end{verbatim}
					Syntax {\tt s[:3]} is called {\it slicing} \& is implemented for many kinds of Python sequences. This will be explained in more detail later on, as it is used extensively in this book.
					
					Backslash character \verb|\| is an {\it escape character}, i.e., it is used to specify special characters like newline \verb|\n| or Unicode characters. To write a string literal with backslashes, need to escape them:
					\begin{verbatim}
						In [72]: s = "12\\34"
						
						In [73]: print(s)
						12\34
					\end{verbatim}
					If have a string with a lot of backslashes \& no special characters, might find this a bit annoying. Fortunately, can preface leading quote of string with {\tt r}, i.e.,  characters should be interpreted as is:
					\begin{verbatim}
						In [74]: s = r"this\has\no\special\characters"
						
						In [75]: s
						Out[75]: 'this\\has\\no\\special\\characters'
					\end{verbatim}
					{\tt r} stands for {\it raw}.
					
					Adding 2 strings together concatenates them \& produces a new string:
					\begin{verbatim}
						In [76]: a = "this is the first half "
						
						In [77]: b = "and this is the second half"
						
						In [78]: a + b
						Out[78]: 'this is the first half and this is the second half'
					\end{verbatim}
					String templating or formatting is another important topic. Number of ways to do so has expanded with advent of Python 3, \& here briefly describe mechanics of 1 of main interfaces. String objects have a {\tt format} method that can be used to substitute formatted arguments into string, producing a new string:
					\begin{verbatim}
						In [79]: template = "{0:.2f} {1:s} are worth US${2:d}"
					\end{verbatim}
					In this string: \verb|{0:.2f}| means to format 1st argument as a floating-point number with no decimal places. \verb|{1:s}| means to format 2nd argument as a string. \verb|{2:d}| means to format 3rd argument as an exact integer.
					
					To substitute arguments for these format parameters, pass a sequence of arguments to {\tt format} method:
					\begin{verbatim}
						In [80]: template.format(88.46, "Argentine Pesos", 1)
						Out[80]: '88.46 Argentine Pesos are worth US$1'
					\end{verbatim}
					Python 3.6 introduced a new feature called {\it f-strings} (short for {\it formatted string literals}) which can make creating formatted strings even more convenient. To create an f-string, write character {\tt f} immediately preceding a string literal. Within string, enclose Python expressions in curly braces to substitute value of expression into formatted string:
					\begin{verbatim}
						In [81]: amount = 10
						
						In [82]: rate = 88.46
						
						In [83]: currency = "Pesos"
						
						In [84]: result = f"{amount} {currency} is worth US${amount / rate}"
					\end{verbatim}
					Format specifiers can be added after each expression using same syntax as with string templates above:
					\begin{verbatim}
						In [85]: f"{amount} {currency} is worth US${amount / rate:.2f}"
						Out[85]: '10 Pesos is worth US$0.11'
					\end{verbatim}
					String formatting is a deep topic; there are multiple methods \& numerous options \& tweaks available to control how values are formatted in resulting string. To learn more, consult \url{https://docs.python.org/3/library/string.html}.
					\item {\sf Bytes \& Unicode.} In modern Python (i.e., Python 3.0 \& up), Unicode has become 1st-class string type to enable more consistent handling of ASCII \& non-ASCII text. In older versions of Python, strings were all bytes without any explicit Unicode encoding. Could convert to Unicode assuming knew character encoding. An example Unicode string with non-ASCII characters:
					\begin{verbatim}
						In [86]: val = "español"
						
						In [87]: val
						Out[87]: 'español'
					\end{verbatim}
					Can convert this Unicode string to its UTF-8 bytes representation using {\tt encode} method:
					\begin{verbatim}
						In [88]: val_utf8 = val.encode("utf-8")
						
						In [89]: val_utf8
						Out[89]: b'espa\xc3\xb1ol'
						
						In [90]: type(val_utf8)
						Out[90]: bytes
					\end{verbatim}
					Assuming know Unicode encoding of a {\tt bytes} object, can go back using {\tt decode} method:
					\begin{verbatim}
						In [91]: val_utf8.decode("utf-8")
						Out[91]: 'español'
					\end{verbatim}
					While now preferable to use UTF-8 for any encoding, for historical reasons, may encounter data in any number of different encodings:
					\begin{verbatim}
						In [92]: val.encode("latin1")
						Out[92]: b'espa\xf1ol'
						
						In [93]: val.encode("utf-16")
						Out[93]: b'\xff\xfee\x00s\x00p\x00a\x00\xf1\x00o\x00l\x00'
						
						In [94]: val.encode("utf-16le")
						Out[94]: b'e\x00s\x00p\x00a\x00\xf1\x00o\x00l\x00'
					\end{verbatim}
					Most common to encounter {\tt bytes} object in context of working with files, where implicitly decoding all data to Unicode strings may not be desired.
					\item {\sf Booleans.} 2 Boolean values in Python are written as {\tt True, False}. Comparisons \& other conditional expressions evaluate to either {\tt True} or {\tt False}. Boolean values are combined with {\tt and} \& {\tt or} keywords:
					\begin{verbatim}
						In [95]: True and True
						Out[95]: True
						
						In [96]: False or True
						Out[96]: True
					\end{verbatim}
					When converted to numbers, {\tt False} becomes {\tt0} \& {\tt True} becomes {\tt1}:
					\begin{verbatim}
						In [97]: int(False)
						Out[97]: 0
						
						In [98]: int(True)
						Out[98]: 1
					\end{verbatim}
					Keyword {\tt not} flips a Boolean value from {\tt True} to {\tt False} or vice versa:
					\begin{verbatim}
						In [99]: a = True
						
						In [100]: b = False
						
						In [101]: not a
						Out[101]: False
						
						In [102]: not b
						Out[102]: True
					\end{verbatim}
					\item {\sf Type casting.} {\tt str, bool, int, float} types are also functions that can be used to cast values to those types:
					\begin{verbatim}
						In [103]: s = "3.14159"
						
						In [104]: fval = float(s)
						
						In [105]: type(fval)
						Out[105]: float
						
						In [106]: int(fval)
						Out[106]: 3
						
						In [107]: bool(fval)
						Out[107]: True
						
						In [108]: bool(0)
						Out[108]: False
					\end{verbatim}
					Note: most nonzero values when cast to {\tt bool} become {\tt True}.
					\item {\sf None.} {\tt None} is Python null value type:
					\begin{verbatim}
						In [109]: a = None
						
						In [110]: a is None
						Out[110]: True
						
						In [111]: b = 5
						
						In [112]: b is not None
						Out[112]: True
					\end{verbatim}
					{\tt None} is also a common default value for function arguments:
					\begin{verbatim}
						def add_and_maybe_multiply(a, b, c = None):
						    result = a + b
						    
						    if c is not None:
						        result = result * c
						    
						    return result
					\end{verbatim}
					\item {\sf Dates \& times.} Built-in Python {\tt datetime} module provides {\tt datetime, date, time} types. {\tt datetime} type combines information stored in {\tt date} \& {\tt time} \& is most commonly used:
					\begin{verbatim}
						In [113]: from datetime import datetime, date, time
						
						In [114]: dt = datetime(2011, 10, 29, 20, 30, 21)
						
						In [115]: dt.day
						Out[115]: 29
						
						In [116]: dt.minute
						Out[116]: 30
					\end{verbatim}
					Given a {\tt datetime} instance, can extract equivalent {\tt date} \& {\tt time} objects by calling methods on {\tt datetime} of same name:
					\begin{verbatim}
						In [117]: dt.date()
						Out[117]: datetime.date(2011, 10, 29)
						
						In [118]: dt.time()
						Out[118]: datetime.time(20, 30, 21)
					\end{verbatim}
					{\tt strftime} method formats a {\tt datetime} as a string:
					\begin{verbatim}
						In [119]: dt.strftime("%Y-%m-%d %H:%M")
						Out[119]: '2011-10-29 20:30'
					\end{verbatim}
					Strings can be converted (parsed) into {\tt datetime} objects with {\tt strptime} function:
					\begin{verbatim}
						In [120]: datetime.strptime("20091031", "%Y%m%d")
						Out[120]: datetime.datetime(2009, 10, 31, 0, 0)
					\end{verbatim}
					See {\sf Table 11.2: {\tt datetime} format specification (ISO C89 compatible)} for a full list of format specifications.
					
					When aggregating or otherwise group time series data, it will occasionally be useful to replace time fields of a series of {\tt datetimes} -- e.g., replacing {\tt minute, second} fields with 0:
					\begin{verbatim}
						In [121]: dt_hour = dt.replace(minute=0, second=0)
						
						In [122]: dt_hour
						Out[122]: datetime.datetime(2011, 10, 29, 20, 0)
					\end{verbatim}
					Since {\tt datetime.datetime} is an immutable type, methods like these always produce new objects. So in previous example, {\tt dt} is not modified by {\tt replace}:
					\begin{verbatim}
						In [123]: dt
						Out[123]: datetime.datetime(2011, 10, 29, 20, 30, 21)
					\end{verbatim}
					Difference of 2 {\tt datetime} objects produces a {\tt datetime.timedelta} type:
					\begin{verbatim}
						In [124]: dt2 = datetime(2011, 11, 15, 22, 30)
						
						In [125]: delta = dt2 - dt
						
						In [126]: delta
						Out[126]: datetime.timedelta(days=17, seconds=7179)
						
						In [127]: type(delta)
						Out[127]: datetime.timedelta
					\end{verbatim}
					Output {\tt timedelta(17, 7179)} indicates: {\tt timedelta} encodes an offset of 17 days \& 7178 seconds.
					
					Adding a {\tt timedelta} to a {\tt datetime} produces a new shifted {\tt datetime}:
					\begin{verbatim}
						In [128]: dt
						Out[128]: datetime.datetime(2011, 10, 29, 20, 30, 21)
						
						In [129]: dt + delta
						Out[129]: datetime.datetime(2011, 11, 15, 22, 30)
					\end{verbatim}
				\end{itemize}
				\item {\sf Control Flow.} Python has several built-in keywords for conditional logic, loops, \& other standard {\it control flow} concepts found in other programming languages.
				\begin{itemize}
					\item {\sf if, elif, \& else.} {\tt if} statement is 1 of most well-known control flow statement types. It checks a condition that, if {\tt True}, evaluates code in block that follows:
					\begin{verbatim}
						x = -5
						if x < 0:
						    print("It's negative")
					\end{verbatim}
					\& {\tt if} statement can be optionally followed by 1 or more {\tt elif} blocks \& a catchall {\tt else} block if all of conditions are {\tt False}:
					\begin{verbatim}
						if x < 0:
						    print("It's negative")
						elif x == 0:
						    print("Equal to zero")
						elif 0 < x < 5:
						    print("Positive but smaller than 5")
						else:
						    print("Positive and larger than or equal to 5")
					\end{verbatim}
					If any of conditions are {\tt True}, no further {\tt elif} or {\tt else} blocks will be reached. With a compound condition using {\tt and} or {\tt or}, conditions are evaluated left to right \& will short-circuit:
					\begin{verbatim}
						In [130]: a = 5; b = 7
						
						In [131]: c = 8; d = 4
						
						In [132]: if a < b or c > d:
						   .....:
						print("Made it")
						Made it
					\end{verbatim}
					In this example, comparison {\tt c > d} never gets evaluated because 1st comparison was {\tt True}.
					
					Also possible to chain comparisons:
					\begin{verbatim}
						In [133]: 4 > 3 > 2 > 1
						Out[133]: True
					\end{verbatim}
					\item {\sf for loops.} {\tt for} loops are for iterating over a collection (like a list or tuple) or an iterater. Standard syntax for a {\tt for} loop is:
					\begin{verbatim}
						for value in collection:
						    # do something with value
					\end{verbatim}
					Can advance a {\tt for} loop to next iteration, skipping remainder of block, using {\tt continue} keyword. Consider this code, which sums up integers in a list \& skips {\tt None} values:
					\begin{verbatim}
						sequence = [1, 2, None, 4, None, 5]
						total = 0
						for value in sequence:
						    if value is None:
						        continue
						    total += value
					\end{verbatim}
					A {\tt for} loop can be exited altogether with {\tt break} keyword. This code sums elements of list until a 5 is reached:
					\begin{verbatim}
						sequence = [1, 2, 0, 4, 6, 5, 2, 1]
						total_until_5 = 0
						for value in sequence:
						    if value == 5:
						         break
						    total_until_5 += value
					\end{verbatim}
					{\tt break} keyword only terminates innermost {\tt for} loop; any outer {\tt for} loops will continue to run:
					\begin{verbatim}
						In [134]: for i in range(4):
						   .....:     for j in range(4):
						   .....:         if j > i:
						   .....:             break
						   .....:         print((i, j))
						   .....:
						(0, 0)
						(1, 0)
						(1, 1)
						(2, 0)
						(2, 1)
						(2, 2)
						(3, 0)
						(3, 1)
						(3, 2)
						(3, 3)
					\end{verbatim}
					If elements in collection or iterator are sequences (tuples or lists, say), they can be conveniently {\it unpacked} into variables in {\tt for} loop statement:
					\begin{verbatim}
						for a, b, c in iterator:
						    # do something
					\end{verbatim}
					\item {\sf while loops.} A {\tt while} loop specifies a condition \& a block of code that is to be executed until condition evaluates to {\tt False} or loop is explicitly ended with {\tt break}:
					\begin{verbatim}
						x = 256
						total = 0
						while x > 0:
						    if total > 500:
						        break
						    total += x
						    x = x // 2
					\end{verbatim}
					\item {\sf pass.} {\tt pass} is ``no-op'' (or ``do nothing'') statement in Python. It can be used in blocks where no action is to be taken (or as a placeholder for code not yet implemented); it is required only because Python uses whitespace to delimit blocks:
					\begin{verbatim}
						if x < 0:
						    print("negative!")
						elif x == 0:
						    # TODO: put something smart here
						    pass
						else:
						    print("positive!")
					\end{verbatim}
					\item {\sf range.} {\tt range} function generates a sequence of evenly spaced integers:
					\begin{verbatim}
						In [135]: range(10)
						Out[135]: range(0, 10)
						
						In [136]: list(range(10))
						Out[136]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
					\end{verbatim}
					A start, end, \& step (which may be negative) can be given:
					\begin{verbatim}
						In [137]: list(range(0, 20, 2))
						Out[137]: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
						
						In [138]: list(range(5, 0, -1))
						Out[138]: [5, 4, 3, 2, 1]
					\end{verbatim}
					{\tt range} produces integers up to but not including endpoint. A common use of {\tt range} is for iterating through sequences by index:
					\begin{verbatim}
						In [139]: seq = [1, 2, 3, 4]
						
						In [140]: for i in range(len(seq)):
						   .....:     print(f"element {i}: {seq[i]}")
						element 0: 1
						element 1: 2
						element 2: 3
						element 3: 4
					\end{verbatim}
					While can use functions like {\tt list} to store all integers generated by {\tt range} in some other data structure, often default iterator form will be what you want. This snippet sums all numbers from 0 to 99999 that are multiples of 3 or 5:
					\begin{verbatim}
						In [141]: total = 0
						In [142]: for i in range(100_000):
						   .....:     # % is the modulo operator
						   .....:     if i % 3 == 0 or i % 5 == 0:
						   .....:         total += i
						   
						In [143]: print(total)
						2333316668
					\end{verbatim}
					While range generated can be arbitrarily large, memory use at any given time may be very small.
				\end{itemize}
			\end{itemize}
			\item {\sf2.4. Conclusion.} This chap provided a brief introduction to some basic Python language concepts \& IPython \& Jupyter programming environments. In Chap. 3, discuss many built-in data types, functions, \& input-output utilities that will be used continuously throughout rest of book.
		\end{itemize}
		\item {\sf3. Built-In Data Structures, Functions, \& Files.} This chap discusses capabilities built into Python language that will be used ubiquitously throughout book. While add-on libraries like {\tt pandas} \& NumPy add advanced computational functionality for larger datasets, they are designed to be used together with Python's built-in data manipulation tools.
		
		Start with PYthon's workhorse data structures: tuples, lists, dictionaries, \& sets. Discuss creating your own reusable Python functions. Look at mechanics of Python file objects \& interacting with local hard drive.
		\begin{itemize}
			\item {\sf3.1. Data Structures \& Sequences.} Python's data structures are simple but powerful. Mastering their use is a critical part of becoming a proficient Python programmer. Start with tuple, list, \& dictionary, which are some of most frequently used {\it sequence} types.
			\begin{itemize}
				\item {\sf Tuple.} A {\it tuple} is a fixed-length, immutable sequence of Python objects which, once assigned, cannot be changed. Easiest way to create one is with a comma-separated sequence of values wrapped in parentheses:
				\begin{verbatim}
					In [2]: tup = (4, 5, 6)
					
					In [3]: tup
					Out[3]: (4, 5, 6)
				\end{verbatim}
				In many contexts, parentheses can be omitted, so here could also have written:
				\begin{verbatim}
					In [4]: tup = 4, 5, 6
					
					In [5]: tup
					Out[5]: (4, 5, 6)
				\end{verbatim}
				Can convert any sequence or iterator to a tuple by invoking {\tt tuple}:
				\begin{verbatim}
					In [6]: tuple([4, 0, 2])
					Out[6]: (4, 0, 2)
					
					In [7]: tup = tuple('string')
					
					In [8]: tup
					Out[8]: ('s', 't', 'r', 'i', 'n', 'g')
				\end{verbatim}
				Elements can be accessed with square brackets {\tt[]} as with most other sequence types. As in C, C++, Java, \& many other languages, sequences are 0-indexed in Python:
				\begin{verbatim}
					In [9]: tup[0]
					Out[9]: 's'
				\end{verbatim}
				When defining tuples within more complicated expressions, often necessary to enclose values in parentheses, as in this example of creating a tuple of tuples:
				\begin{verbatim}
					In [10]: nested_tup = (4, 5, 6), (7, 8)
					
					In [11]: nested_tup
					Out[11]: ((4, 5, 6), (7, 8))
					
					In [12]: nested_tup[0]
					Out[12]: (4, 5, 6)
					
					In [13]: nested_tup[1]
					Out[13]: (7, 8)
				\end{verbatim}
				While objects stored in a tuple may be mutable themselves, once tuple is created, impossible to modify which object is stored in each slot:
				\begin{verbatim}
					In [14]: tup = tuple(['foo', [1, 2], True])
					In [15]: tup[2] = False
					---------------------------------------------------------------------------
					TypeError
					Traceback (most recent call last)
					<ipython-input-15-b89d0c4ae599> in <module>
					----> 1 tup[2] = False
					TypeError: 'tuple' object does not support item assignment
				\end{verbatim}
				If an object inside a tuple is mutable, e.g. a list, can modify it in place:
				\begin{verbatim}
					In [16]: tup[1].append(3)
					
					In [17]: tup
					Out[17]: ('foo', [1, 2, 3], True)
				\end{verbatim}
				Can concatenate tuples using {\tt+} operator to produce longer tuples:
				\begin{verbatim}
					In [18]: (4, None, 'foo') + (6, 0) + ('bar',)
					Out[18]: (4, None, 'foo', 6, 0, 'bar')
				\end{verbatim}
				Multiplying a tuple by an integer, as with lists, has effect of concatenating that many copies of tuple:
				\begin{verbatim}
					In [19]: ('foo', 'bar') * 4
					Out[19]: ('foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'bar')
				\end{verbatim}
				Note: objects themselves are not copied, only references to them.
				\begin{itemize}
					\item {\sf Unpacking tuples.} If try to {\it assign} to a tuple-like expression of variables, Python will attempt to {\it unpack} value on RHS of equals sign:
					\begin{verbatim}
						In [20]: tup = (4, 5, 6)
						
						In [21]: a, b, c = tup
						
						In [22]: b
						Out[22]: 5
					\end{verbatim}
					Even sequences with nested tuples can be unpacked:
					\begin{verbatim}
						In [23]: tup = 4, 5, (6, 7)
						
						In [24]: a, b, (c, d) = tup
						
						In [25]: d
						Out[25]: 7
					\end{verbatim}
					Using this functionality you can easily swap variable names, a task that in many languages might look like:
					\begin{verbatim}
						tmp = a
						a = b
						b = tmp
					\end{verbatim}
					But, in Python, swap can be done like this:
					\begin{verbatim}
						In [26]: a, b = 1, 2
						In [27]: a
						Out[27]: 1
						In [28]: b
						Out[28]: 2
						In [29]: b, a = a, b
						In [30]: a
						Out[30]: 2
						In [31]: b
						Out[31]: 1
					\end{verbatim}
					A common use of variable unpacking is iterating over sequences of tuples or lists:
					\begin{verbatim}
						In [32]: seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
						In [33]: for a, b, c in seq:
						....:     print(f'a={a}, b={b}, c={c}')
						a=1, b=2, c=3
						a=4, b=5, c=6
						a=7, b=8, c=9
					\end{verbatim}
					Another common use is returning multiple values from a function.
					
					There are some situations where may want to ``pluck'' (nhổ) a few elements from beginning of a tuple. There is a special syntax that can do this, {\tt*rest}, which is also used in function signatures to capture an arbitrarily long list of positional arguments:
					\begin{verbatim}
						In [34]: values = 1, 2, 3, 4, 5
						In [35]: a, b, *rest = values
						In [36]: a
						Out[36]: 1
						In [37]: b
						Out[37]: 2
						In [38]: rest
						Out[38]: [3, 4, 5]
					\end{verbatim}
					This {\tt reset} bit is sometimes something you want to discard; there is nothing special about {\tt rest} name. As a matter of convention, many Python programmers will use underscore \verb|_| for unwanted variables:
					\begin{verbatim}
						In [39]: a, b, *_ = values
					\end{verbatim}
					\item {\sf Tuple methods.}  Since size \& contents of a tuple cannot be modified, very light on instance methods. A particularly useful one (also available on lists) is {\tt count}, which counts number of occurrences of a value:
					\begin{verbatim}
						In [40]: a = (1, 2, 2, 2, 3, 4, 2)
						In [41]: a.count(2)
						Out[41]: 4
					\end{verbatim}
				\end{itemize}
				\item {\sf List.} In contrast with tuples, lists are variable length \& their contents can be modified in place. Lists are mutable. Can define them using square brackets {\tt[]} or using {\tt list} type function:
				\begin{verbatim}
					In [42]: a_list = [2, 3, 7, None]
					In [43]: tup = ("foo", "bar", "baz")
					In [44]: b_list = list(tup)
					In [45]: b_list
					Out[45]: ['foo', 'bar', 'baz']
					In [46]: b_list[1] = "peekaboo"
					In [47]: b_list
					Out[47]: ['foo', 'peekaboo', 'baz']
				\end{verbatim}
				Lists \& tuples are semantically similar (though tuples cannot be modified) \& can be used interchangeably in many functions.
				
				{\tt list} built-in function is frequently used in data processing as a way to materialize an iterator or generator expression:
				\begin{verbatim}
					In [48]: gen = range(10)
					In [49]: gen
					Out[49]: range(0, 10)
					In [50]: list(gen)
					Out[50]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
				\end{verbatim}
				\begin{itemize}
					\item {\sf Adding \& removing elements.} Elements can be appended to end of list with {\tt append} method:
					\begin{verbatim}
						In [51]: b_list.append("dwarf")
						In [52]: b_list
						Out[52]: ['foo', 'peekaboo', 'baz', 'dwarf']
					\end{verbatim}
					Using {\tt insert}, can insert an element at a specific location in list:
					\begin{verbatim}
						In [53]: b_list.insert(1, "red")
						In [54]: b_list
						Out[54]: ['foo', 'red', 'peekaboo', 'baz', 'dwarf']
					\end{verbatim}
					Insertion index must be between 0 \& length of list, inclusive.					
					\begin{remark}
						{\tt insert} is computationally expensive compared with {\tt append}, because references to subsequent elements have to be shifted internally to make room for new element. If need to insert elements at both beginning \& end of a sequence, may wish to explore {\tt collections.deque}, a double-ended queue, which is optimized for this purpose \& found in Python Standard Library.
					\end{remark}
					Inverse operation to {\tt insert} is {\tt pop}, which removes \& returns an element at a particular index:
					\begin{verbatim}
						In [55]: b_list.pop(2)
						Out[55]: 'peekaboo'
						In [56]: b_list
						Out[56]: ['foo', 'red', 'baz', 'dwarf']
					\end{verbatim}
					Elements can be removed by value with {\tt remove}, which locates 1st such value \& removes it from list:
					\begin{verbatim}
						In [57]: b_list.append("foo")
						In [58]: b_list
						Out[58]: ['foo', 'red', 'baz', 'dwarf', 'foo']
						In [59]: b_list.remove("foo")
						In [60]: b_list
						Out[60]: ['red', 'baz', 'dwarf', 'foo']
					\end{verbatim}
					If performance is not a concern, by using {\tt append} \& {\tt remove}, can use a Python list as a set-like data structure (although Python has actual set objects).
					
					Check if a list contains a value using {\tt in} keyword:
					\begin{verbatim}
						In [61]: "dwarf" in b_list
						Out[61]: True
					\end{verbatim}
					Keyword {\tt not} can be used to negate {\tt in}:
					\begin{verbatim}
						In [62]: "dwarf" not in b_list
						Out[62]: False
					\end{verbatim}
					Checking whether a list contains a value is a lot slower than doing so with dictionaries \& sets, as Python makes a linear scan across values of list, whereas it can check others (based on hash tables) in constant time.
					\item {\sf Concatenating \& combining lists.} Similar to tuples, adding 2 lists together with {\tt+} concatenates them:
					\begin{verbatim}
						In [63]: [4, None, "foo"] + [7, 8, (2, 3)]
						Out[63]: [4, None, 'foo', 7, 8, (2, 3)]
					\end{verbatim}
					If have a list already defined, can append multiple elements to it using {\tt extend} method:
					\begin{verbatim}
						In [64]: x = [4, None, "foo"]
						In [65]: x.extend([7, 8, (2, 3)])
						In [66]: x
						Out[66]: [4, None, 'foo', 7, 8, (2, 3)]
					\end{verbatim}
					Note: list concatenation by addition is a comparatively expensive operation since a new list must be created \& objects copied over. using {\tt extend} to append elements to an existing list, especially if building up a large list, is usually preferable. Thus
					\begin{verbatim}
						everything = []
						for chunk in list_of_lists:
						    everything.extend(chunk)
					\end{verbatim}
					is faster than concatenative alternative:
					\begin{verbatim}
						everything = []
						for chunk in list_of_lists:
						    everything = everything + chunk
					\end{verbatim}
					\item {\sf Sorting.} Can sort a list in place (without creating a new object) by calling its {\tt sort} function:
					\begin{verbatim}
						In [67]: a = [7, 2, 5, 1, 3]
						In [68]: a.sort()
						In [69]: a
						Out[69]: [1, 2, 3, 5, 7]
					\end{verbatim}
					{\tt sort} has a few options that will occasionally come in handy. One is ability to pass a secondary {\it sort key} -- i.e., a function that produces a value to use to sort objects. E.g., could sort a collection of strings by their lengths:
					\begin{verbatim}
						In [70]: b = ["saw", "small", "He", "foxes", "six"]
						In [71]: b.sort(key=len)
						In [72]: b
						Out[72]: ['He', 'saw', 'six', 'small', 'foxes']
					\end{verbatim}
					{\tt sorted} function can produce a sorted copy of a general sequence.
					\item {\sf Slicing.} Can select sections of most sequence types by using slice notation, which in its basic form consists of {\tt start:stop} passed to indexing operator {\tt[]}:
					\begin{verbatim}
						In [73]: seq = [7, 2, 3, 7, 5, 6, 0, 1]
						In [74]: seq[1:5]
						Out[74]: [2, 3, 7, 5]
					\end{verbatim}
					Slices can also be assigned with a sequence:
					\begin{verbatim}
						In [75]: seq[3:5] = [6, 3]
						In [76]: seq
						Out[76]: [7, 2, 3, 6, 3, 6, 0, 1]
					\end{verbatim}
					While element at {\tt start} index is included, {\tt stop} index is {\it not included}, so that number of elements in result is {\tt stop - start}.
					
					Either {\tt start} or {\tt stop} can be omitted, in which case they default to start of sequence \& end of sequence, resp.:
					\begin{verbatim}
						In [77]: seq[:5]
						Out[77]: [7, 2, 3, 6, 3]
						In [78]: seq[3:]
						Out[78]: [6, 3, 6, 0, 1]
					\end{verbatim}
					Negative indices slide sequence relative to end:
					\begin{verbatim}
						In [79]: seq[-4:]
						Out[79]: [3, 6, 0, 1]
						In [80]: seq[-6:-2]
						Out[80]: [3, 6, 3, 6]
					\end{verbatim}
					Slicing semantics takes a bit of getting used to, especially if you're coming from R or MATLAB. See {\sf Fig. 3.1: Illustration of Python slicing conventions} for a helpful illustration of slicing with positive \& negative integers. In figure, indices are shown at ``bin edges'' to help show where slice selections start \& stop using positive or negative indices.
					
					A {\tt step} can also be used after a 2nd colon to, say, take every other element:
					\begin{verbatim}
						In [81]: seq[::2]
						Out[81]: [7, 3, 3, 0]
					\end{verbatim}
					A clever use of this is to pass {\tt-1}, which has useful effect of reversing a list or tuple:
					\begin{verbatim}
						In [82]: seq[::-1]
						Out[82]: [1, 0, 6, 3, 6, 3, 2, 7]
					\end{verbatim}
				\end{itemize}
				\item {\sf Dictionary.} Dictionary or {\tt dict} may be most important built-in Python data structure. In other programming languages, dictionaries are sometimes called {\it hash maps} or {\it associative arrays}. A dictionary stores a collection of {\it key-value} pairs, where {\it key \& value} are Python objects. Each key is associated with a value so that a value can be conveniently retrieved, inserted, modified, or deleted given a particular key. 1 approach for creating a dictionary is to use curly braces \verb|{}| \& colons to separate keys \& values:
				\begin{verbatim}
					In [83]: empty_dict = {}
					In [84]: d1 = {"a": "some value", "b": [1, 2, 3, 4]}
					In [85]: d1
					Out[85]: {'a': 'some value', 'b': [1, 2, 3, 4]}
				\end{verbatim}
				Can access, insert, or set elements using same syntax as for accessing elements of a list or tuple:
				\begin{verbatim}
					In [86]: d1[7] = "an integer"
					In [87]: d1
					Out[87]: {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
					In [88]: d1["b"]
					Out[88]: [1, 2, 3, 4]
				\end{verbatim}
				Can check if a dictionary contains a key using same syntax used for checking whether a list or tuple contains a value:
				\begin{verbatim}
					In [89]: "b" in d1
					Out[89]: True
				\end{verbatim}
				Can delete values using either {\tt del} keyword or {\tt pop} method (which simultaneously returns value \& deletes key):
				\begin{verbatim}
					In [90]: d1[5] = "some value"
					In [91]: d1
					Out[91]:
					{'a': 'some value',
						'b': [1, 2, 3, 4],
						7: 'an integer',
						5: 'some value'}
					In [92]: d1["dummy"] = "another value"
					In [93]: d1
					Out[93]:
					{'a': 'some value',
						'b': [1, 2, 3, 4],
						7: 'an integer',
						5: 'some value',
						'dummy': 'another value'}
					In [94]: del d1[5]
					In [95]: d1
					Out[95]:
					{'a': 'some value',
						'b': [1, 2, 3, 4],
						7: 'an integer',
						'dummy': 'another value'}
					In [96]: ret = d1.pop("dummy")
					In [97]: ret
					Out[97]: 'another value'
					In [98]: d1
					Out[98]: {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}
				\end{verbatim}
				{\tt keys \& values} method gives you iterators of dictionary's keys \& values, resp. Order of keys depends on order of their insertion, \& these functions output keys \& values in same respective order:
				\begin{verbatim}
					In [99]: list(d1.keys())
					Out[99]: ['a', 'b', 7]
					In [100]: list(d1.values())
					Out[100]: ['some value', [1, 2, 3, 4], 'an integer']
				\end{verbatim}
				If need to iterate over both keys \& values, can use {\tt items} method to iterate over keys \& values as 2-tuples:
				\begin{verbatim}
					In [101]: list(d1.items())
					Out[101]: [('a', 'some value'), ('b', [1, 2, 3, 4]), (7, 'an integer')]
				\end{verbatim}
				Can merge 1 dictionary into another using {\tt update} method:
				\begin{verbatim}
					In [102]: d1.update({"b": "foo", "c": 12})
					In [103]: d1
					Out[103]: {'a': 'some value', 'b': 'foo', 7: 'an integer', 'c': 12}
				\end{verbatim}
				{\tt update} method changes dictionaries in place, so any existing keys in data passed to {\tt update} will have their old values discarded.
				\begin{itemize}
					\item {\sf Creating dictionaries from sequences.} Common to occasionally end up with 2 sequences that you want to pair up element-wise in a dictionary. As a 1st cut, might write code like this:
					\begin{verbatim}
						mapping = {}
						for key, value in zip(key_list, value_list):
						    mapping[key] = value
					\end{verbatim}
					Since a dictionary is essentially a collection of 2-tuples, {\tt dict} function accepts a list of 2-tuples:
					\begin{verbatim}
						In [104]: tuples = zip(range(5), reversed(range(5)))
						In [105]: tuples
						Out[105]: <zip at 0x7fefe4553a00>
						In [106]: mapping = dict(tuples)
						In [107]: mapping
						Out[107]: {0: 4, 1: 3, 2: 2, 3: 1, 4: 0}
					\end{verbatim}
					Talk about {\it dictionary comprehensions}, which are another way to construct dictionaries.
					\item {\sf Default values.} Common to have logic like:
					\begin{verbatim}
						if key in some_dict:
						    value = some_dict[key]
						else:
						    value = default_value
					\end{verbatim}
					Thus, dictionary methods {\tt get} \& {\tt pop} can take a default value to be returned, so that above {\tt if-else} block can be written simply as:
					\begin{verbatim}
						value = some_dict.get(key, default_value)
					\end{verbatim}
					{\tt get} by default will return {\tt None} if key is not present, while {\tt pop} will raise an exception. With {\it setting} values, it may be that values in a dictionary are another kind of collection, like a list. E.g., could imagine categorizing a list of words by their 1st letters as a dictionary of lists:
					\begin{verbatim}
						In [108]: words = ["apple", "bat", "bar", "atom", "book"]
						In [109]: by_letter = {}
						In [110]: for word in words:
						   .....:     letter = word[0]
						   .....:     if letter not in by_letter:
						   .....:         by_letter[letter] = [word]
						   .....:    else:
						   .....:        by_letter[letter].append(word)
						   .....:
						In [111]: by_letter
						Out[111]: {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}
					\end{verbatim}
					{\tt setdefault} dictionary method can be used to simplify this workflow. Preceding {\tt for} loop can be rewritten as:
					\begin{verbatim}
						In [112]: by_letter = {}
						In [113]: for word in words:
						   .....:     letter = word[0]
						   .....:     by_letter.setdefault(letter, []).append(word)
						   .....:
						In [114]: by_letter
						Out[114]: {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}
					\end{verbatim}
					Built-in {\tt collections} module has a useful class, {\tt defaultdict}, which makes this even easier. To create one, pass a type or function for generating default value for each slot in dictionary:
					\begin{verbatim}
						In [115]: from collections import defaultdict
						In [116]: by_letter = defaultdict(list)
						In [117]: for word in words:
						   .....:     by_letter[word[0]].append(word)
					\end{verbatim}
					\item {\sf Valid dictionary key types.} While values of a dictionary can be any Python object, keys generally have to be immutable objects like scalar types (int, float, string) or tuples (all objects in tuple need to be immutable, too). Technical term here is {\it hashability}. Can check whether an object is hashable (can be used as a key in a dictionary) with {\tt hash} function:
					\begin{verbatim}
						In [118]: hash("string")
						Out[118]: 3634226001988967898
						In [119]: hash((1, 2, (2, 3)))
						Out[119]: -9209053662355515447
						In [120]: hash((1, 2, [2, 3])) # fails because lists are mutable
						---------------------------------------------------------------------------
						TypeError
						Traceback (most recent call last)
						<ipython-input-120-473c35a62c0b> in <module>
						----> 1 hash((1, 2, [2, 3])) # fails because lists are mutable
						TypeError: unhashable type: 'list'
					\end{verbatim}
					Hash values you see when using {\tt hash} function in general will depend on Python version you are using.
					
					To use a list as a key, 1 option: convert it to a tuple, which can be hashed as long as its elements also can be:
					\begin{verbatim}
						In [121]: d = {}
						In [122]: d[tuple([1, 2, 3])] = 5
						In [123]: d
						Out[123]: {(1, 2, 3): 5}
					\end{verbatim}
				\end{itemize}
				\item {\sf Set.} A {\it set} is an unordered collection of unique elements. A set can be created in 2 ways: via {\tt set} function or via a {\it set literal} with curly braces:
				\begin{verbatim}
					In [124]: set([2, 2, 2, 1, 3, 3])
					Out[124]: {1, 2, 3}
					In [125]: {2, 2, 2, 1, 3, 3}
					Out[125]: {1, 2, 3}
				\end{verbatim}
				Sets support mathematical set {\it operations} like union, intersection, difference, \& symmetric difference. Consider these 2 example sets:
				\begin{verbatim}
					In [126]: a = {1, 2, 3, 4, 5}
					In [127]: b = {3, 4, 5, 6, 7, 8}
				\end{verbatim}
				Union of these 2 sets is set of distinct elements occurring in either set. This can be computed with either {\tt union} method or {\tt|} binary operator:
				\begin{verbatim}
					In [128]: a.union(b)
					Out[128]: {1, 2, 3, 4, 5, 6, 7, 8}
					In [129]: a | b
					Out[129]: {1, 2, 3, 4, 5, 6, 7, 8}
				\end{verbatim}
				Intersection contains elements occurring in both sets. {\tt\&} operator or {\tt intersection} method can be used:
				\begin{verbatim}
					In [130]: a.intersection(b)
					Out[130]: {3, 4, 5}
					In [131]: a & b
					Out[131]: {3, 4, 5}
				\end{verbatim}
				See {\sf Table 3.1: Python set operations} for a list of commonly used set methods.				
				\begin{remark}
					If you pass an input that is not a set to methods like {\tt union} \& {\tt intersection}, Python will convert input to a set before executing operation. When using binary operators, both objects must already be sets.
				\end{remark}
				All of logical set operations have in-place counterparts, which enable you to replace contents of set on left side of operation with result. For very large sets, this may be more efficient:
				\begin{verbatim}
					In [132]: c = a.copy()
					In [133]: c |= b
					In [134]: c
					Out[134]: {1, 2, 3, 4, 5, 6, 7, 8}
					In [135]: d = a.copy()
					In [136]: d &= b
					In [137]: d
					Out[137]: {3, 4, 5}
				\end{verbatim}
				Like dictionary keys, set elements generally must be immutable, \& they must be {\it hashable} (i.e., calling {\tt hash} on a value does not raise an exception). In order to store list-like elements (or other mutable sequences) in a set, can convert them to tuples:
				\begin{verbatim}
					In [138]: my_data = [1, 2, 3, 4]
					In [139]: my_set = {tuple(my_data)}
					In [140]: my_set
					Out[140]: {(1, 2, 3, 4)}
				\end{verbatim}
				Can also check if a set is a subset of (is contained in) or a superset of (contains all elements of) another set:
				\begin{verbatim}
					In [141]: a_set = {1, 2, 3, 4, 5}
					In [142]: {1, 2, 3}.issubset(a_set)
					Out[142]: True
					In [143]: a_set.issuperset({1, 2, 3})
					Out[143]: True
				\end{verbatim}
				Sets are equal iff their contents are equal:
				\begin{verbatim}
					In [144]: {1, 2, 3} == {3, 2, 1}
					Out[144]: True
				\end{verbatim}
				\item {\sf Built-In Sequence Functions.} Python has a handful of useful sequence functions that you should familiarize yourself with \& use at any opportunity.
				\begin{itemize}
					\item {\sf enumerate.} Common when iterating over a sequence to want to keep track of index of current item. A do-it-yourself approach would look like:
					\begin{verbatim}
						index = 0
						for value in collection:
						    # do something with value
						    index += 1
					\end{verbatim}
					Since this is so common, Python has a built-in function, {\tt enumerate}, which returns a sequence of {\tt(i, value)} tuples:
					\begin{verbatim}
						for index, value in enumerate(collection):
						    # do something with value
					\end{verbatim}
					\item {\sf sorted.} {\tt sorted} function returns a new sorted list from elements of any sequence:
					\begin{verbatim}
						In [145]: sorted([7, 1, 2, 6, 0, 3, 2])
						Out[145]: [0, 1, 2, 2, 3, 6, 7]
						In [146]: sorted("horse race")
						Out[146]: [' ', 'a', 'c', 'e', 'e', 'h', 'o', 'r', 'r', 's']
					\end{verbatim}
					{\tt sorted} function accepts same arguments as {\tt sort} method on lists.
					\item {\sf zip}. {\tt zip} ``pairs'' up elements of a number of lists, tuples, or other sequences to create a list of tuples:
					\begin{verbatim}
						In [147]: seq1 = ["foo", "bar", "baz"]
						In [148]: seq2 = ["one", "two", "three"]
						In [149]: zipped = zip(seq1, seq2)
						In [150]: list(zipped)
						Out[150]: [('foo', 'one'), ('bar', 'two'), ('baz', 'three')]
					\end{verbatim}
					{\tt zip} can take an arbitrary number of sequences, \& number of elements it produces is determined by {\it shortest} sequence:
					\begin{verbatim}
						In [151]: seq3 = [False, True]
						In [152]: list(zip(seq1, seq2, seq3))
						Out[152]: [('foo', 'one', False), ('bar', 'two', True)]
					\end{verbatim}
					A common use of {\tt zip} is simultaneously iterating over multiple sequences, possibly also combined with {\tt enumerate}:
					\begin{verbatim}
						In [153]: for index, (a, b) in enumerate(zip(seq1, seq2)):
						   .....:     printf(f"{index}: {a}, {b}")
						   .....:
						0: foo, one
						1: bar, two
						2: baz, three
					\end{verbatim}
					\item {\sf reversed.} {\tt reversed} iterates over elements of a sequence in reverse order:
					\begin{verbatim}
						In [154]: list(reversed(range(10)))
						Out[154]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
					\end{verbatim}
					Keep in mind: {\tt reversed} is a generator, so it does not create reversed sequence until materialized (e.g., with {\tt list} or a {\tt for} loop).
				\end{itemize}
				\item {\sf List, Set, \& Dictionary Comprehensions.} {\it List comprehensions} are a convenient \& widely used Python language feature. They allow you to concisely form a new list by filtering elements of a collection, transforming elements passing filter into 1 concise expression. They take basic form:
				\begin{verbatim}
					[expr for value in collection if condition]
				\end{verbatim}
				$\Leftrightarrow$ following {\tt for} loop:
				\begin{verbatim}
					result = []
					for value in collection:
					    if condition:
					        result.append(expr)
				\end{verbatim}
				Filter condition can be omitted, leaving only expression. E.g., given a list of strings, could filter out strings with length {\tt 2} or less \& convert them to uppercase like this:
				\begin{verbatim}
					In [155]: strings = ["a", "as", "bat", "car", "dove", "python"]
					In [156]: [x.upper() for x in strings if len(x) > 2]
					Out[156]: ['BAT', 'CAR', 'DOVE', 'PYTHON']
				\end{verbatim}
				Set \& dictionary comprehensions are a natural extension, producing sets \& dictionaries in an idiomatically similar way instead of lists.
				
				A dictionary comprehension looks like this:
				\begin{verbatim}
					dict_comp = {key-expr: value-expr for value in collection if condition}
				\end{verbatim}
				A set comprehension looks like equivalent list comprehension except with curly braces instead of square brackets:
				\begin{verbatim}
					set_comp = {expr for value in collection if condition}
				\end{verbatim}
				Like list comprehensions, set \& dictionary comprehensions are mostly conveniences, but they similarly can make code both easier to write \& read. Consider list of strings from before. Suppose wanted a set containing just lengths of strings contained in collection; could easily compute this using a set comprehension:
				\begin{verbatim}
					In [157]: unique_lengths = {len(x) for x in strings}
					In [158]: unique_lengths
					Out[158]: {1, 2, 3, 4, 6}
				\end{verbatim}
				Could also express this more functionally using {\tt map} function, introduced shortly:
				\begin{verbatim}
					In [159]: set(map(len, strings))
					Out[159]: {1, 2, 3, 4, 6}
				\end{verbatim}
				As a simple dictionary comprehension example, could create a lookup map of these strings for their locations in list:
				\begin{verbatim}
					In [160]: loc_mapping = {value: index for index, value in enumerate(strings)}
					In [161]: loc_mapping
					Out[161]: {'a': 0, 'as': 1, 'bat': 2, 'car': 3, 'dove': 4, 'python': 5}
				\end{verbatim}
				\item {\sf Nested list comprehensions.} Suppose have a list of lists containing some English \& Spanish names:
				\begin{verbatim}
					In [162]: all_data = [["John", "Emily", "Michael", "Mary", "Steven"],
					   .....:             ["Maria", "Juan", "Javier", "Natalia", "Pilar"]]
				\end{verbatim}
				Suppose wanted to get a single list containing all names with 2 or more {\tt a}'s in them. Could certainly do this with a simple {\tt for} loop:
				\begin{verbatim}
					In [163]: names_of_interest = []
					In [164]: for names in all_data:
					   .....:     enough_as = [name for name in names if name.count("a") >= 2]
					   .....:     names_of_interest.extend(enough_as)
					   .....:
					In [165]: names_of_interest
					Out[165]: ['Maria', 'Natalia']
				\end{verbatim}
				Can actually wrap this whole operation up in a single {\it nested list comprehension}, which will look like:
				\begin{verbatim}
					In [166]: result = [name for names in all_data for name in names
					   .....:           if name.count("a") >= 2]
				    In [167]: result
				    Out[167]: ['Maria', 'Natalia']
				\end{verbatim}
				At 1st, nested list comprehensions are a bit hard to wrap your head around. {\tt for} parts of list comprehension are arranged according to order of nesting, \& any filter condition is put at end as before. Another example where ``flatten'' a list of tuples of integers into a simple list of integers:
				\begin{verbatim}
					In [168]: some_tuples = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
					In [169]: flattened = [x for tup in some_tuples for x in tup]
					In [170]: flattened
					Out[170]: [1, 2, 3, 4, 5, 6, 7, 8, 9]
				\end{verbatim}
				Keep in mind: order of {\tt for} expressions would be same if wrote a nested {\tt for} loop instead of a list comprehension:
				\begin{verbatim}
					flattened = []
					for tup in some_tuples:
					    for x in tup:
					        flattened.append(x)
				\end{verbatim}
				Can have arbitrarily many levels of nesting, though if have $>$ 2 or 3 levels of nesting, should probably start to question whether this makes sense from a code readability standpoint. Important to distinguish syntax just shown from a list comprehension inside a list comprehension, which is also perfectly valid:
				\begin{verbatim}
					In [172]: [[x for x in tup] for tup in some_tuples]
					Out[172]: [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
				\end{verbatim}
				This produces a list of lists, rather than a flattened list of all of inner elements.
			\end{itemize}
			\item {\sf3.2. Functions.} {\it Functions} are primary \& most important method of code organization \& reuse in Python. As a rule of thumb, if anticipate needing to repeat same or very similar code more than once, it may be worth writing a reusable function. Functions can also help make your code more readable by giving a name to a group of Python statements.
			
			Functions are declared with {\tt def} keyword. A function contains a block of code with an optional use of {\tt return} keyword:
			\begin{verbatim}
				In [173]: def my_function(x, y):
				   .....:      return x + y
			\end{verbatim}
			When a line with {\tt return} is reached, value or expression after {\tt return} is sent to context where function was called, e.g.:
			\begin{verbatim}
				In [174]: my_function(1, 2)
				Out[174]: 3
				In [175]: result = my_function(1, 2)
				In [176]: result
				Out[176]: 3
			\end{verbatim}
			There is no issue with having multiple {\tt return} statements. If Python reaches end of a function without encountering a {\tt return} statement, {\tt None} is returned automatically. E.g.:
			\begin{verbatim}
				In [177]: def function_without_return(x):
				   .....:     print(x)
				In [178]: result = function_without_return("hello!")
				hello!
				In [179]: print(result)
				None
			\end{verbatim}
			Each function can have {\it positional} arguments \& {\it keyword} arguments. Keyword arguments are most commonly used to specify default values or optional arguments. Here define a function with an optional {\tt z} argument with default value {\tt1.5}:
			\begin{verbatim}
				def my_function2(x, y, z=1.5):
				    if z > 1:
				        return z * (x + y)
				    else:
				        return z / (x + y)
			\end{verbatim}
			While keyword arguments are optional, all positional arguments must be specified when calling a function.
			
			Can pass values to {\tt z} argument with or without keyword provided, though using keyword is encouraged:
			\begin{verbatim}
				In [181]: my_function2(5, 6, z=0.7)
				Out[181]: 0.06363636363636363
				In [182]: my_function2(3.14, 7, 3.5)
				Out[182]: 35.49
				In [183]: my_function2(10, 20)
				Out[183]: 45.0
			\end{verbatim}
			Main restriction on function arguments: keyword arguments {\it must} follow positional arguments (if any). Can specify keyword arguments in any order. This frees you from having to remember order in which function arguments were specified. Need to remember only what their names are.
			\begin{itemize}
				\item {\sf Namespaces, Scope, \& Local Functions.} Functions can access variables created inside function as well as those outside function in higher (or even {\it global}) scopes. An alternative \& more descriptive name describing a variable scope in Python is a {\it namespace}. Any variables that are assigned within a function by default are assigned to local namespace. Local namespace is created when function is called \& is immediately populated by function's arguments. After function is finished, local namespace is destroyed (with some exceptions that are outside purview (phạm vi) of this chap). Consider following function:
				\begin{verbatim}
					def func():
					    a = []
					    for i in range(5):
					        a.append(i)
				\end{verbatim}
				When {\tt func()} is called, empty list {\tt a} is created, 5 elements are appended, \& then {\tt a} is destroyed when function exists. Suppose instead had declared {\tt a} as follows:
				\begin{verbatim}
					In [184]: a = []
					In [185]: def func():
					   .....:     for i in range(5):
					   .....:         a.append(i)
				\end{verbatim}
				Each call to {\tt func} will modify list {\tt a}:
				\begin{verbatim}
					In [186]: func()
					In [187]: a
					Out[187]: [0, 1, 2, 3, 4]
					In [188]: func()
					In [189]: a
					Out[189]: [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]
				\end{verbatim}
				Assigning variables outside of function's scope is possible, but those variables must be declared explicitly using either {\tt global} or {\tt nonlocal} keywords:
				\begin{verbatim}
					In [190]: a = None
					In [191]: def bind_a_variable():
					   .....:     global a
					   .....:     a = []
					   .....: bind_a_variable(a)
					   .....:
					In [192]: print(a)
					[]
				\end{verbatim}
				{\tt nonlocal} allows a function to modify variables defined in a higher-level scope that is not global. Since its use is somewhat esoteric (bí truyền, bí mật) (I never use it in this book), refer to Python documentation to learn more about it.
				\begin{remark}
					Generally discourage use of {\tt global} keyword. Typically, global variables are used to store some kind of state in a system. If fiond yourself using a lot of them, it may indicate a need for object-oriented programming (using classes).
				\end{remark}
				\item {\sf Returning Multiple Values.} When 1st programmed in Python after having programmed in Java \& C++, 1 of favorite features was ability to return multiple values from a function with simple syntax. E.g.:
				\begin{verbatim}
					def f():
					    a = 5
					    b = 6
					    c = 7
					    return a, b, c
					    
					a, b, c = f()
				\end{verbatim}
				In data analysis \& other scientific applications, may find yourself doing this often. What's happening here: function is actually just returning {\it1} object, a tuple, which is then being unpacked into result variables. In preceding example, could have done this instead:
				\begin{verbatim}
					return_value = f()
				\end{verbatim}
				In this case, \verb|return_value| would be a 3-tuple with 3 returned variables. A potentially attractive alternative to returning multiple values like before might be to return a dictionary instead:
				\begin{verbatim}
					def f():
					    a = 5
					    b = 6
					    c = 7
					    return {"a" : a, "b" : b, "c" : c}
				\end{verbatim}
				This alternative technique can be useful depending on what you are trying to do.
				\item {\sf Functions Are Objects.} Since Python functions are objects, many constructs can be easily expressed that are difficult to do in other languages. Suppose were doing some data cleaning \& needed to apply a bunch of transformations to following list of strings:
				\begin{verbatim}
					In [193]: states = ["Alabama ", "Georgia!", "Georgia", "georgia", "FlOrIda",
					                    "south carolina##", "West virginia?"]
				\end{verbatim}
				Anyone who has ever worked with user-submitted survey data has seen messy results like these. Lots of things need to happen to make this list of strings uniform \& ready for analysis: stripping whitespace, removing punctuation symbols, \& standardizing proper capitalization. 1 way to do this: use built-in string methods along with {\tt re} standard library module for regular expressions:
				\begin{verbatim}
					import re
					
					def clean_strings(strings):
					    result = []
					    for value in strings:
					        value = value.strip()
					        value = re.sub("[!#?]", "", value)
					        value = value.title()
					        result.append(value)
					    return result
				\end{verbatim}
				Result looks like this:
				\begin{verbatim}
					In [195]: clean_strings(states)
					Out[195]:
					['Alabama',
					 'Georgia',
					 'Georgia',
					 'Georgia',
					 'Florida',
					 'South    Carolina',
					 'West Virginia']
				\end{verbatim}
				An alternative approach that you may find useful: make a list of operations you want to apply to a particular set of strings:
				\begin{verbatim}
					def remove_punctuation(value):
					    return re.sub("[!#?]", "", value)
					    
					clean_ops = [str.strip, remove_punctuation, str.title]
					
					def clean_strings(strings, ops):
					    result = []
					    for value in strings:
					        for func in ops:
					            value = func(value)
					        result.append(value)
					    return result
				\end{verbatim}
				Then have following:
				\begin{verbatim}
					In [197]: clean_strings(states, clean_ops)
					Out[197]:
					['Alabama',
					 'Georgia',
					 'Georgia',
					 'Georgia',
					 'Florida',
					 'South   Carolina',
					 'West Virginia']
				\end{verbatim}
				A more {\it functional} pattern like this enables you to easily modify how strings are transformed at a very high level. \verb|clean_strings| function is also now more reusable \& generic.
				
				Can use functions as arguments to other functions like built-in {\tt map} function, which applies a function to a sequence of some kind:
				\begin{verbatim}
					In [198]: for x in map(remove_punctuation, states):
					   .....:     print(x)
					Alabama
					Georgia
					Georgia
					georgia
					FlOrIda
					south   carolina
					West virginia
				\end{verbatim}
				{\tt map} can be used as an alternative to list comprehensions without any filter.
				\item {\sf Anonymous (Lambda) Functions.} Python has support for {\it anonymous} or{\it lambda} functions, which are a way of writing functions consisting of a single statement, result of which is return of writing functions consisting of a single statement, result of which is return value. They are defined with {\tt lambda} keyword, which has no meaning other than ``we are declaring an anonymous function'':
				\begin{verbatim}
					In [199]: def short_function(x):
					   .....:     return x * 2
					In [200]: equiv_anon = lambda x: x * 2
				\end{verbatim}
				Usually refer to these as lambda functions in rest of book. They are especially convenient in data analysis because there are many cases where data transformation functions will take functions as arguments. Often less typing (\& clearer) to pass a lambda function as opposed to writing a full-out function declaration or even assigning lambda function to a local variable. E.g.:
				\begin{verbatim}
					In [201]: def apply_to_list(some_list, f):
					   .....:     return [f(x) for x in some_list]
					In [202]: ints = [4, 0, 1, 5, 6]
					In [203]: apply_to_list(ints, lambda x: x * 2)
					Out[203]: [8, 0, 2, 10, 12]
				\end{verbatim}
				Could also have written {\tt [x * 2 for x in ints]}, but here were able to succinctly pass a custom operator to \verb|apply_to_list| function.
				
				As another example, suppose wanted to sort a collection of strings by number of distinct letters in each string:
				\begin{verbatim}
					In [204]: strings = ["foo", "card", "bar", "aaaa", "abab"]
				\end{verbatim}
				Here could pass a lambda function to list's {\tt sort} method:
				\begin{verbatim}
					In [205]: strings.sort(key=lambda x: len(set(x)))
					In [206]: strings
					Out[206]: ['aaaa', 'foo', 'abab', 'bar', 'card']
				\end{verbatim}
				\item {\sf Generators.} Many objects in Python support iteration, e.g. over objects in a list or lines in a file. This is accomplished by means of {\it iterator protocol}, a generic way to make objects iterable. E.g., iterating over a dictionary yields dictionary keys:
				\begin{verbatim}
					In [207]: some_dict = {"a": 1, "b": 2, "c": 3}
					In [208]: for key in some_dict:
					   .....:     print(key)
					a
					b
					c
				\end{verbatim}
				When write \verb|for key in some_dict|, Python interpreter 1st attempts to create an iterator out of \verb|some_dict|:
				\begin{verbatim}
					In [209]: dict_iterator = iter(some_dict)
					In [210]: dict_iterator
					Out[210]: <dict_keyiterator at 0x7fefe45465c0>
				\end{verbatim}
				An iterator is any object that will yield objects to Python interpreter when used in a context like a {\tt for loop}. Most methods expecting a list or list-like object will also accept any iterable object. This includes built-in methods e.g. {\tt min, max, sum} \& type constructors like {\tt list, tuple}:
				\begin{verbatim}
					In [211]: list(dict_iterator)
					Out[211]: ['a', 'b', 'c']
				\end{verbatim}
				A {\it generator} is a convenient way, similar to writing a normal function, to construct a new iterable object. Whereas normal functions execute \& return a single result at a time, generators can return a sequence of multiple values by pausing \& resuming execution each time generator is used. To create a generator, use {\tt yield} keyword instead of {\tt return} in a function:
				\begin{verbatim}
					def squares(n=10):
					    print(f"Generating squares from 1 to {n ** 2}")
					    for i in range(1, n + 1):
					        yield i ** 2
				\end{verbatim}
				When actually call generator, no code is immediately executed:
				\begin{verbatim}
					In [213]: gen = squares()
					In [214]: gen
					Out[214]: <generator object squares at 0x7fefe437d620>
				\end{verbatim}
				Not until you request elements from generator that it begins executing its code:
				\begin{verbatim}
					In [215]: for x in gen:
					   .....:     print(x, end=" ")
					Generating squares from 1 to 100
					1 4 9 16 25 36 49 64 81 100
				\end{verbatim}
				
				\begin{remark}
					Since generators produce output 1 element at a time vs. an entire list all at once, it can help your program use less memory.
				\end{remark}
				\begin{itemize}
					\item {\sf Generator expressions.} Another way to make a generator is by using a {\it generator expression}. This is a generator analogue to list, dictionary, \& set comprehensions. To create one, enclose what would otherwise be a list comprehension within parentheses instead of brackets:
					\begin{verbatim}
						In [216]: gen = (x ** 2 for x in range(100))
						In [217]: gen
						Out[217]: <generator object <genexpr> at 0x7fefe437d000>
					\end{verbatim}
					$\Leftrightarrow$ following verbose generator:
					\begin{verbatim}
						def _make_gen():
						    for x in range(100):
						        yield  ** 2
						gen = _make_gen()
					\end{verbatim}
					Generator expressions can be used instead of list comprehensions as function arguments in some cases:
					\begin{verbatim}
						In [218]: sum(x ** 2 for x in range(100))
						Out[218]: 328350
						In [219]: dict((i, i ** 2) for i in range(5))
						Out[219]: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}
					\end{verbatim}
					Depending on number of elements produced by comprehension expression, generator version can sometimes by meaningfully faster.
					\item {\sf itertools module.} Standard library {\tt itertools} module has a collection of generators for many common data algorithms. E.g., {\tt groupby} takes any sequence \& a function, grouping consecutive elements in sequence by return value of function. E.g.:
					\begin{verbatim}
						In [220]: import itertools
						In [221]: def first_letter(x):
						   .....:     return x[0]
						In [222]: names = ["Alan", "Adam", "Wes", "Will", "Albert", "Steven"]
						In [223]: for letter, names in itertools.groupby(names, first_letter):
						   .....:     print(letter, list(names)) # names is a generator
						A ['Alan', 'Adam']
						W ['Wes', 'Will']
						A ['Albert']
						S ['Steven']
					\end{verbatim}
					See {\sf Table 3.2: Some useful {\tt itertools} functions} for a list of a few other {\tt itertools} functions frequently found helpful. Check out \url{https://docs.python.org/3/library/itertools.html} for more on this useful built-in utility module. {\sf Function: Description}
					\begin{enumerate}
						\item {\tt chain(*iterables)}: Generates a sequence by chaining iterators together. Once elements from 1st iterator are exhausted, elements from next iterator are returned, \& so on.
						\item {\tt combinations(iterable, k)}: Generates a sequence of all possible $k$-tuples of elements in iterable, ignoring order \& without replacement (see also companion function \verb|combinations_with_replacement|).
						\item {\tt permutations(iterate, k)}: Generates a sequence of all possible $k$-tuples of elements in iterable, respecting order.
						\item {\tt groupby(iterable[, keyfunc])}: Generates {\tt(key, sub-iterator)} for each unique key.
						\item {\tt product(*iterables, repeat=1)}: Generates Cartesian product of input iterables as tuples, similar to a nested {\tt for} loop.
					\end{enumerate}
				\end{itemize}
				\item {\sf Errors \& Exception Handling.} Handling Python errors or {\it exceptions} gracefully is an important part of building robust programs. In data analysis applications, many functions work only on certain kinds of input. E.g., Python's {\tt float} function is capable of casting a string to a floating-point number, but it fails with {\tt ValueError} on improper inputs:
				\begin{verbatim}
					In [224]: float("1.2345")
					Out[224]: 1.2345
					In [225]: float("something")
					---------------------------------------------------------------------------
					ValueError
					Traceback (most recent call last)
					<ipython-input-225-5ccfe07933f4> in <module>
					----> 1 float("something")
					ValueError: could not convert string to float: 'something'
				\end{verbatim}
				Suppose wanted a version of {\tt float} that fails gracefully, returning input argument. Can do this by writing a function that encloses call to {\tt float} in a {\tt try/except} block (execute this code in IPython):
				\begin{verbatim}
					def attempt_float(x):
					    try:
					        return float(x)
					    except:
					        return x
				\end{verbatim}
				Code in {\tt except} part of block will only be executed if {\tt float(x)} raises an exception:
				\begin{verbatim}
					In [227]: attempt_float("1.2345")
					Out[227]: 1.2345
					In [228]: attempt_float("something")
					Out[228]: 'something'
				\end{verbatim}
				Might notice: {\tt float} can raise exceptions other than {\tt ValueError}:
				\begin{verbatim}
					In [229]: float((1, 2))
					---------------------------------------------------------------------------
					TypeError
					Traceback (most recent call last)
					<ipython-input-229-82f777b0e564> in <module>
					----> 1 float((1, 2))
					TypeError: float() argument must be a string or a real number, not 'tuple'
				\end{verbatim}
				Might want to suppress only {\tt ValueError}, since a {\tt TypeError} (input was not a string or numeric value) might indicate a legitimate bug in your program. To do that, write exception type after {\tt except}:
				\begin{verbatim}
					def attempt_float(x):
					    try:
					        return float(x)
					    except ValueError:
					        return x
				\end{verbatim}
				Have then:
				\begin{verbatim}
					In [231]: attempt_float((1, 2))
					---------------------------------------------------------------------------
					TypeError
					Traceback (most recent call last)
					<ipython-input-231-8b0026e9e6b7> in <module>
					----> 1 attempt_float((1, 2))
					<ipython-input-230-6209ddecd2b5> in attempt_float(x)
					1 def attempt_float(x):
					2
					try:
					----> 3
					return float(x)
					4
					except ValueError:
					5
					return x
					TypeError: float() argument must be a string or a real number, not 'tuple'
				\end{verbatim}
				Can catch multiple exception types by writing a tuple of exception types instead (parentheses are required):
				\begin{verbatim}
					def attempt_float(x):
					    try:
					        return float(x)
					    except (TypeError, ValueError):
					        return x
				\end{verbatim}
				In some cases, may not want to suppress an exception, but want some code to be executed regardless of whether or not code in {\tt try} block succeeds. To do this, use {\tt finally}:
				\begin{verbatim}
					f = open(path, mode="w")
					
					try:
					    write_to_file(f)
					finally:
					    f.close()
				\end{verbatim}
				Here, file object {\tt f} will {\it always} get closed. Similarly, can have code that executes only if {\tt try:} block succeeds using {\tt else}:
				\begin{verbatim}
					f = open(path, mode="w")
					
					try:
					    write_to_file(f)
					except:
					    print("Failed")
					else:
					    print("Succeeded")
					finally:
					    f.close()
				\end{verbatim}
				\begin{itemize}
					\item {\sf Exceptions in IPython.} If an exception is raised while you are \verb|%run|-ing a script or executing any statement, IPython will by default print a full call stack trace (traceback) with a few lines of context around position at each point in stack:
					\begin{verbatim}
						In [10]: %run examples/ipython_bug.py
						---------------------------------------------------------------------------
						AssertionError
						Traceback (most recent call last)
						/home/wesm/code/pydata-book/examples/ipython_bug.py in <module>()
						13
						throws_an_exception()
						14
						---> 15 calling_things()
						/home/wesm/code/pydata-book/examples/ipython_bug.py in calling_things()
						11 def calling_things():
						12
						works_fine()
						---> 13
						throws_an_exception()
						14
						15 calling_things()
						/home/wesm/code/pydata-book/examples/ipython_bug.py in throws_an_exception()
						7
						a = 5
						8
						b = 6
						----> 9
						assert(a + b == 10)
						10
						11 def calling_things():
						AssertionError:
					\end{verbatim}
					Having additional context by itself is a big advantage over standard Python interpreter (which does not provide any additional context). Can control amount of context shown using \verb|%xmode| magic command, from {\tt Plain} (same as standard Python interpreter) to {\tt Verbose} (which inlines function argument values \& more). See in Appendix B, can step {\it into stack} (using \verb|% debug| (``địt em béo ú gay'' or ``dái em béo ú ghê'' or ``đi ẻ bị u gan'') or \verb|%pdb| (``phở{\tt/}phân đầu{\tt/}đuôi bò{\tt/}buồi'' or ``phở{\tt/}phân đặc biệt'') magics) after an error has occurred for interactive postmortem debugging.
				\end{itemize}
			\end{itemize}
			\item {\sf3.3. Files \& OS.} Most of this book uses high-level tools like \verb|pandas.read_csv| to read data files from disk into Python data structures. However, important to understand basics of how to work with files in Python. Fortunately, relatively straightforward, which is 1 reason Python is so popular for text \& file munging.
			
			To open a file for reading or writing, use built-in {\tt open} function with either a relative or absolute file path \& an optional file encoding:
			\begin{verbatim}
				In [233]: path = "examples/segismundo.txt"
				In [234]: f = open(path, encoding="utf-8")
			\end{verbatim}
			Here, pass {\tt encoding="utf-8"} as a best practice because default Unicode encoding for reading files varies from platform to platform.
			
			By default, file is opened in read-only model {\tt"r"}. Can then treat file object {\tt f} like a list \& iterate over lines like so:
			\begin{verbatim}
				for line in f:
				    print(line)
			\end{verbatim}
			Lines come out of file with end-of-line (EOL) markers intact, often see code to get an EOL-free list of lines in a file like:
			\begin{verbatim}
				In [235]: lines = [x.rstrip() for x in open(path, encoding="utf-8")]
				In [236]: lines
				Out[236]:
				['Sueña el rico en su riqueza,',
				'que más cuidados le ofrece;',
				'',
				'sueña el pobre que padece',
				'su miseria y su pobreza;',
				'',
				'sueña el que a medrar empieza,',
				'sueña el que afana y pretende,',
				'sueña el que agravia y ofende,',
				'',
				'y en el mundo, en conclusión,',
				'todos sueñan lo que son,',
				'aunque ninguno lo entiende.',
				'']
			\end{verbatim}
			When use {\tt open} to create file objects, recommended to close file when finished with it. Closing file releases its resources back to OS:
			\begin{verbatim}
				In [237]: f.close()
			\end{verbatim}
			1 of ways to make it easier to clean up open files: use {\tt with} statement:
			\begin{verbatim}
				In [238]: with open(path, encoding="utf-8") as f:
				   .....:     lines = [x.rstrip() for x in f]
			\end{verbatim}
			This will automatically close file {\tt f} when exiting {\tt with} block. Failing to ensure that files are closed will not cause problems in many small programs or scripts, but it can be an issue in programs that need to interact with a large number of files.
			
			If had typed {\tt f = open(path, "w")}, a {\it new file} at {\tt examples/segismundo.txt} would have been created (be careful!), overwriting any file in its place. There is also {\tt"x"} file mode, which creates a writable file but fails if file path already exists. See {\sf Table 3.3: Python file modes} for a list of all valid file read{\tt/}write modes.
			
			For readable files, some of most commonly used methods are {\tt read, seek, tell}. {\tt read} returns a certain number of characters from file. What constitutes a ``character'' is determined by file encoding or simply raw bytes if file is opened in binary mode:
			\begin{verbatim}
				In [239]: f1 = open(path)
				In [240]: f1.read(10)
				Out[240]: 'Sueña el r'
				In [241]: f2 = open(path, mode="rb") # Binary mode
				In [242]: f2.read(10)
				Out[242]: b'Sue\xc3\xb1a el '
			\end{verbatim}
			{\tt read} method advances file object position by number of bytes read. {\tt tell} gives current position:
			\begin{verbatim}
				In [243]: f1.tell()
				Out[243]: 11
				In [244]: f2.tell()
				Out[244]: 10
			\end{verbatim}
			Even though read 10 characters from file {\tt f1} opened in text mode, position is 11 because it took that many bytes to decode 10 characters using default encoding. Can check default encoding in {\tt sys} module:
			\begin{verbatim}
				In [245]: import sys
				In [246]: sys.getdefaultencoding()
				Out[246]: 'utf-8'
			\end{verbatim}
			To get consistent behavior across platforms, best to pass an encoding (e.g. {\tt encoding="utf-8"}, which is widely used) when opening files.
			
			{\tt seek} changes file position to indicated byte in file:
			\begin{verbatim}
				In [247]: f1.seek(3)
				Out[247]: 3
				In [248]: f1.read(1)
				Out[248]: 'ñ'
				In [249]: f1.tell()
				Out[249]: 5
			\end{verbatim}
			Lastly, remember to close files:
			\begin{verbatim}
				In [250]: f1.close()
				In [251]: f2.close()
			\end{verbatim}
			To write text to a file, can use file's {\tt write} or {\tt writelines} methods. E.g., could create a version of {\tt examples/segismundo.txt} with no blank lines like so:
			\begin{verbatim}
				In [252]: path
				Out[252]: 'examples/segismundo.txt'
				In [253]: with open("tmp.txt", mode="w") as handle:
				   .....:     handle.writelines(x for x in open(path) if len(x) > 1)
				In [254]: with open("tmp.txt") as f:
				   .....:     lines = f.readlines()
				In [255]: lines
				Out[255]:
				['Sueña el rico en su riqueza,\n',
				 'que más cuidados le ofrece;\n',
				 'sueña el pobre que padece\n',
				 'su miseria y su pobreza;\n',
				 'sueña el que a medrar empieza,\n',
				 'sueña el que afana y pretende,\n',
				 'sueña el que agravia y ofende,\n',
				 'y en el mundo, en conclusión,\n',
				 'todos sueñan lo que son,\n',
				 'aunque ninguno lo entiende.\n']
			\end{verbatim}
			See {\sf Table 3.4: Important Python file methods or attributes} for many of most commonly used file methods.
			\begin{itemize}
				\item {\sf Bytes \& Unicode with Files.} Default behavior for Python files (whether readable or writable) is {\it text mode}, i.e., intend to work with Python strings (i.e., Unicode). This contrasts with {\it binary mode}, which can obtain by appending {\tt b} to file mode. Revisiting file (which contains non-ASCII characters with UTF-8 encoding) from previous sect, have:
				\begin{verbatim}
					In [258]: with open(path) as f:
					   .....:     chars = f.read(10)
					In [259]: chars
					Out[259]: 'Sueña el r'
					In [260]: len(chars)
					Out[260]: 10
				\end{verbatim}
				UTF-8 is a variable-length Unicode encoding, so when request some number of characters from file, Python reads enough bytes (which could be as few as 10 or as many as 40 bytes) from file to decode that many characters. If open file in {\tt"rb"} mode instead, {\tt read} requests that exact number of bytes:
				\begin{verbatim}
					In [261]: with open(path, mode="rb") as f:
					   .....:      data = f.read(10)
				    In [262]: data
				    Out[262]: b'Sue\xc3\xb1a el '
				\end{verbatim}
				Depending on text encoding, may be able to decode bytes to a {\tt str} object yourself, but only if each of encoded Unicode characters is fully formed:
				\begin{verbatim}
					In [263]: data.decode("utf-8")
					Out[263]: 'Sueña el '
					In [264]: data[:4].decode("utf-8")
					---------------------------------------------------------------------------
					UnicodeDecodeError
					Traceback (most recent call last)
					<ipython-input-264-846a5c2fed34> in <module>
					----> 1 data[:4].decode("utf-8")
					UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 3: unexpecte
					d end of data
				\end{verbatim}
				Text mode, combined with {\tt encoding} option of {\tt open}, provides a convenient way to convert from 1 Unicode encoding to another:
				\begin{verbatim}
					In [265]: sink_path = "sink.txt"
					In [266]: with open(path) as source:
					   .....:    with open(sink_path, "x", encoding="iso-8859-1") as sink:
					   .....:        sink.write(source.read())
			        In [267]: with open(sink_path, encoding="iso-8859-1") as f:
			           .....:     print(f.read(10))
			        Sueña el r
				\end{verbatim}
				Beware using {\tt seek} when opening files in any mode other than binary. If file position falls in middle of bytes defining a Unicode character, then subsequent reads will result in an error:
				\begin{verbatim}
					In [269]: f = open(path, encoding='utf-8')
					In [270]: f.read(5)
					Out[270]: 'Sueña'
					In [271]: f.seek(4)
					Out[271]: 4
					In [272]: f.read(1)
					---------------------------------------------------------------------------
					UnicodeDecodeError
					Traceback (most recent call last)
					<ipython-input-272-5a354f952aa4> in <module>
					----> 1 f.read(1)
					/miniconda/envs/book-env/lib/python3.10/codecs.py in decode(self, input, final)
					320
					# decode input (taking the buffer into account)
					321
					data = self.buffer + input
					--> 322
					(result, consumed) = self._buffer_decode(data, self.errors, final
					)
					323
					# keep undecoded input until the next call
					324
					self.buffer = data[consumed:]
					UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb1 in position 0: invalid s
					tart byte
					In [273]: f.close()
				\end{verbatim}
				If find yourself regularly doing data analysis on non-ASCII text data, mastering Python's Unicode functionality will prove valuable. See \url{https://docs.python.org} for much more.
			\end{itemize}
			\item {\sf3.4. Conclusion.} With some of basics of Python environment \& language now under your belt, time to move on \& learn about NumPy \& array-oriented computing in Python.
		\end{itemize}
		\item {\sf4. {\tt NumPy} Basics: Arrays \& Vectorized Computation.} NumPy, short for Numerical Python, is 1 of most important foundational packages for numerical computing in Python. Many computational packages providing scientific functionality use NumPy's array objects as 1 of standard interface {\it lingua francas} for data exchange. Much of knowledge about NumPy covered is transferable to {\tt pandas} as well.
		
		Some of things you'll find in Numpy:
		\begin{itemize}
			\item {\tt ndarray}, an efficient multidimensional array providing fast array-oriented arithmetic operations \& flexible {\it broadcasting} capabilities
			\item Mathematical functions for fast operations on entire arrays of data without having to write loops
			\item Tools for reading{\tt/}writing array data to disk \& working with memory-mapped files
			\item Linear algebra, random number generation, \& Fourier transform capabilities
			\item A C API for connecting NumPy with libraries written in C, C++, or FORTRAN
		\end{itemize}
		Because NumPy provides a comprehensive \& well-documented C API, straightforward to pass data to external libraries written in a low-level language, \& for external libraries to return data to Python as NumPy arrays. This feature has made Python a language of choice for wrapping legacy C, C++, or FORTRAN codebases \& giving them a dynamic \& accessible interface.
		
		While NumPy by itself does not provide modeling or scientific functionality, having an understanding of NumPy arrays \& array-oriented computing will help you use tools with array computing semantics, like {\tt pandas}, much more effectively. Since NumPy is a large topic, will cover many advanced NumPy features like broadcasting in more depth later (see Appendix A). Many of these advanced features are not needed to follow rest of book, but they may help you as you go deeper into scientific computing in Python.
		
		For most data analysis applications, main areas of functionality focused on are:
		\begin{itemize}
			\item Fast array-based operations for data munging \& cleaning, subsetting \& filtering, transformation, \& any other kind of computation
			\item Common array algorithms like sorting, unique, \& set operations
			\item Efficient descriptive statistics \& aggregating{\tt/}summarizing data
			\item Data alignment \& relational data manipulations for merging \& joining heterogeneous datasets
			\item Expressing conditional logic as array expressions instead of loops with {\tt if-elif-else} branches
			\item Group-wise data manipulations (aggregation, transformation, \& function application)
		\end{itemize}
		While NumPy provides a computational foundation for general numerical data processing, many readers will want to use {\tt pandas} as basis for most kinds of statistics or analytics, especially on tabular data. Also, {\tt pandas} provides some more domain-specific functionality like time series manipulation, which is not present in NumPy.
		\begin{remark}
			Array-oriented computing in Python traces its roots back to 1995, when {\sc Jim Hugunin} created Numeric library. Over next 10 years, many scientific programming communities began doing array programming in Python, but library ecosystem had became fragmented in early 2000s. In 2005, {\sc Travis Oliphant} was able to forge NumPy project from then Numeric \& Numarray projects to bring community together around a single array computing framework.
		\end{remark}
		1 of reasons NumPy is so important for numerical computations in Python is because it is designed for efficiency on large arrays of data. There are a number of reasons for this:
		\begin{itemize}
			\item NumPy internally stores data in a contiguous block of memory, independent of other built-in Python objects. NumPy's library of algorithms written in C language can operate on this memory without any type checking or other overhead. NumPy arrays also use much less memory than built-in Python sequences.
			
			-- NumPy lưu trữ dữ liệu nội bộ trong một khối bộ nhớ liền kề, độc lập với các đối tượng Python tích hợp khác. Thư viện thuật toán của NumPy được viết bằng ngôn ngữ C có thể hoạt động trên bộ nhớ này mà không cần kiểm tra kiểu hoặc bất kỳ chi phí nào khác. Mảng NumPy cũng sử dụng ít bộ nhớ hơn nhiều so với chuỗi Python tích hợp.
			\item NumPy operations perform complex computations on entire arrays without need for Python {\tt for} loops, which can be slow for large sequences. NumPy is faster than regular Python code because its C-based algorithms avoid overhead present with regular interpreted Python code.
			
			-- Các hoạt động NumPy thực hiện các phép tính phức tạp trên toàn bộ mảng mà không cần vòng lặp Python {\tt for}, có thể chậm đối với các chuỗi lớn. NumPy nhanh hơn mã Python thông thường vì các thuật toán dựa trên C của nó tránh được chi phí phát sinh trong mã Python được biên dịch thông thường.
		\end{itemize}
		To give an idea of performance difference, consider a NumPy array of 1 million integers, \& equivalent Python list:
		\begin{verbatim}
			In [7]: import numpy as np
			In [8]: my_arr = np.arange(1_000_000)
			In [9]: my_list = list(range(1_000_000))
		\end{verbatim}
		Multiply each sequence by 2:
		\begin{verbatim}
			In [10]: %timeit my_arr2 = my_arr * 2
			715 us +- 13.2 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)
			In [11]: %timeit my_list2 = [x * 2 for x in my_list]
			48.8 ms +- 298 us per loop (mean +- std. dev. of 7 runs, 10 loops each)
		\end{verbatim}
		NumPy-based algorithms are generally 10--100 times faster (or more) than their pure Python counterparts \& use significantly less memory.
		\begin{itemize}
			\item {\sf4.1. NumPy ndarray: A Multidimensional Array Object.} 1 of key features of NumPy is its $N$-dimensional array object, or {\tt ndarray}, which is a fast, flexible container for large datasets in Python. Arrays enable you to perform mathematical operations on whole blocks of data using similar syntax to equivalent operations between scalar elements.
			
			To give a flavor of how NumPy enables batch computations with similar syntax to scalar values on built-in Python objects, 1st import NumPy \& create a small array:
			\begin{verbatim}
				In [12]: import numpy as np
				In [13]: data = np.array([[1.5, -0.1, 3], [0, -3, 6.5]])
				In [14]: data
				Out[14]:
				array([[ 1.5, -0.1, 3.],
				       [  0., -3. , 6.5]])
			\end{verbatim}
			Then write mathematical operations with {\tt data}:
			\begin{verbatim}
				In [15]: data * 10
				Out[15]:
				array([[ 15., -1., 30.],
				       [ 0., -30., 65.]])
				In [16]: data + data
				Out[16]:
				array([[ 3. , -0.2, 6. ],
				       [ 0. , -6. , 13. ]])
			\end{verbatim}
			In 1st example, all of elements have been multiplied by 10. In 2nd, corresponding values in each ``cell'' in array have been added to each other.
			\begin{remark}
				In this chap \& throughout book, use standard NumPy convention of always using {\tt import numpy as np}. Possible to put {\tt from numpy import *} in your code to avoid having to write {\tt np.}, but advise against making a habit of this. {\tt numpy} namespace is large \& contains a number of functions whose names conflict with built-in Python functions (like {\tt min, max}). Following standard conventions like these is almost always a good idea.
			\end{remark}
			An {\tt ndarray} is a generic multidimensional container for homogeneous data, i.e., all of elements must be same type. Every array has a {\tt shape}, a tuple indicating size of each dimension, \& a {\tt dtype}, an object describing {\it data type} of array:
			\begin{verbatim}
				In [17]: data.shape
				Out[17]: (2, 3)
				In [18]: data.dtype
				Out[18]: dtype('float64')
			\end{verbatim}
			This chap will introduce to basics of using NumPy arrays, \& should be sufficient for following along with rest of book. While unnecessary to have a deep understanding of NumPy for many data analytical applications, becoming proficient in array-oriented programming \& thinking is a key step along way to becoming a scientific Python guru.
			\begin{remark}
				Whenever see ``array,'' ``NumPy array,'' or ``ndarray'' in book text, in most cases they all refer to {\tt ndarray} object.
			\end{remark}
			
			\begin{itemize}
				\item {\sf Creating {\tt ndarrays}.} Easiest way to create an array is to use {\tt array} function. This accepts any sequence-like object (including other arrays) \& produces a new NumPy array containing passed data. E.g., a list is a good candidate for conversion:
				\begin{verbatim}
					In [19]: data1 = [6, 7.5, 8, 0, 1]
					In [20]: arr1 = np.array(data1)
					In [21]: arr1
					Out[21]: array([6. , 7.5, 8. , 0. , 1. ])
				\end{verbatim}
				Nested sequences, like a list of equal-length lists, will be converted into a multidimensional array:
				\begin{verbatim}
					In [22]: data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]
					In [23]: arr2 = np.array(data2)
					In [24]: arr2
					Out[24]:
					array([[1, 2, 3, 4],
					       [5, 6, 7, 8]])
				\end{verbatim}
				Since {\tt data2} was a list of lists, NumPy array {\tt arr2} has 2D, with shape inferred from data. Can confirm this by inspecting {\tt ndim} \& {\tt shape} attributes:
				\begin{verbatim}
					In [25]: arr2.ndim
					Out[25]: 2
					In [26]: arr2.shape
					Out[26]: (2, 4)
				\end{verbatim}
				Unless explicitly specified, {\tt numpy.array} tries to infer a good data type for array that it creates. Data type is stored in a special {\tt dtype} metadata object; e.g., in previous 2 examples have:
				\begin{verbatim}
					In [27]: arr1.dtype
					Out[27]: dtype('float64')
					In [28]: arr2.dtype
					Out[28]: dtype('int64')
				\end{verbatim}
				In addition to {\tt numpy.array}, there are a number of other functions for creating new arrays. As examples, {\tt numpy.zeros} \& {\tt numpy.ones} create arrays of 0s or 1s, resp., with a given length or shape. {\tt numpy.empty} creates an array without initializing its values to any particular value. To create a higher dimensional array with these methods, pass a tuple for shape:
				\begin{verbatim}
					In [29]: np.zeros(10)
					Out[29]: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
					In [30]: np.zeros((3, 6))
					Out[30]:
					array([[0., 0., 0., 0., 0., 0.],
					      [0., 0., 0., 0., 0., 0.],
					     [0., 0., 0., 0., 0., 0.]])
					In [31]: np.empty((2, 3, 2))
					Out[31]:
					array([[[0., 0.],
					        [0., 0.],
					        [0., 0.]],
					       [[0., 0.],
					        [0., 0.],
					        [0., 0.]]])
				\end{verbatim}
				
				\begin{remark}
					Not safe to assume {\tt numpy.empty} will return an array of all 0s. This function returns uninitialized memory \& thus may contain nonzero ``garbage'' values. Should use this function only if intend to populate new array with data.
				\end{remark}
				{\tt numpy.arrange} is an array-valued version of built-in Python {\tt range} function:
				\begin{verbatim}
					In [32]: np.arange(15)
					Out[32]: array([ 0, 1,
					2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])
				\end{verbatim}
				See {\sf Table 4.1: Some important NumPy array creation functions} for a short list of standard array creation functions. Since NumPy is focused on numerical computing, data type, if not specified, will in many cases be {\tt float64} (floating point). {\tt Function: Description}
				\begin{itemize}
					\item {\tt array}: Convert input data (list, tuple, array, or other sequence type) to an ndarray either by inferring a data type or explicitly specifying a data type; copies input data by default
					\item {\tt asarray}: Convert input to ndarray, but do not copy if input is already an ndarray
					\item {\tt arrange}: Like built-in {\tt range} but returns an ndarray instead of a list
					\item \verb|ones, ones_like|: Produce an array of all 1s with given shape \& data type; \verb|ones_like| takes another array \& produces a {\tt ones} array of same shape \& data type
					\item \verb|zeros, zeros_like|: Like \verb|ones, ones_like| but producing arrays of 0s instead
					\item \verb|empty, empty_like|: Create new arrays by allocating new memory, but do not populate with any values like {\tt ones, zeros}
					\item \verb|full, full_like|: Produce an array of given shape \& data type with all values set to indicated ``fill value''; \verb|full_like| takes another array \& produces a filled array of same shape \& data type
					\item {\tt eye, identity}: Create a square $N\times N$ identity matrix (1s on diagonal \& 0s elsewhere)
				\end{itemize}
				\item {\sf Data Types for {\tt ndarrays}.} {\it Data type} or {\tt dtype} is a special object containing information (or {\it metadata}, data about data) ndarray needs to interpret a chunk of memory as a particular type of data:
				\begin{verbatim}
					In [33]: arr1 = np.array([1, 2, 3], dtype=np.float64)
					In [34]: arr2 = np.array([1, 2, 3], dtype=np.int32)
					In [35]: arr1.dtype
					Out[35]: dtype('float64')
					In [36]: arr2.dtype
					Out[36]: dtype('int32')
				\end{verbatim}
				Data types are a source of NumPy's flexibility for interacting with data coming from other systems. In most cases they provide a mapping directly onto an underlying disk or memory representation, which makes it possible to read \& write binary streams of data to disk \&  to connect to code written in a low-level language like C or FORTRAN. Numerical data types are named same way: a type name, like {\tt float} or {\tt int}, followed by a number indicating number of bits per element. A standard double-precision floating-point value (what's used under hood in Python's {\tt float} object) takes up 8 bytes or 64 bits. Thus, this type is known in NumPy as {\tt float64}. See {\sf Table 4.2: NumPy data types} for a full listing of NumPy's supported data types.
				\begin{remark}
					Don't worry about memorizing NumPy data types, especially if you're a new user. Often only necessary to care about general \emph{kind} of data you're dealing with, whether floating point, complex, integer, Boolean, string, or general Python object. When need more control over how data is stored in memory \& on disk, especially large datasets, good to know what you have control over storage type.
				\end{remark}
				
				\begin{remark}
					There are both \emph{signed, unsigned} integer types, \& many readers will not be familiar with this terminology. A \emph{signed} integer can represent both positive \& negative integers, while an \emph{unsigned} integer can only represent nonzero integers. E.g., {\tt int8} (signed 8-bit integer) can represent integers from $-128$ to $127$ (inclusive), while {\tt uint8} (unsigned 8- bit integer) can represent  0 through 255.
				\end{remark}
				Can explicitly convert or {\it cast} an array from 1 data type to another using ndarray's {\tt astype} method:
				\begin{verbatim}
					In [37]: arr = np.array([1, 2, 3, 4, 5])
					In [38]: arr.dtype
					Out[38]: dtype('int64')
					In [39]: float_arr = arr.astype(np.float64)
					In [40]: float_arr
					Out[40]: array([1., 2., 3., 4., 5.])
					In [41]: float_arr.dtype
					Out[41]: dtype('float64')
				\end{verbatim}
				In this example, integers were cast to floating point. If cast some floating-point numbers to be of integer data type, decimal part will be truncated:
				\begin{verbatim}
					In [42]: arr = np.array([3.7, -1.2, -2.6, 0.5, 12.9, 10.1])
					In [43]: arr
					Out[43]: array([ 3.7, -1.2, -2.6,
					0.5, 12.9, 10.1])
					In [44]: arr.astype(np.int32)
					Out[44]: array([ 3, -1, -2, 0, 12, 10], dtype=int32)
				\end{verbatim}
				If have an array of strings representing numbers, can use {\tt astype} to convert them to numeric form:
				\begin{verbatim}
					In [45]: numeric_strings = np.array(["1.25", "-9.6", "42"], dtype=np.string_)
					In [46]: numeric_strings.astype(float)
					Out[46]: array([ 1.25, -9.6 , 42. ])
				\end{verbatim}
				
				\begin{remark}
					Be cautious when using \verb|numpy.string_| type, as string data in NumPy is fixed size \& may truncate input without warning. pandas has more intuitive out-of-box behavior or non-numeric data.
				\end{remark}
				If casting were to fail for some reason (like a string that cannot be converted to {\tt float64}), a {\tt ValueError} will be raised. Before, was a bit lazy \& wrote {\tt float} instead of {\tt np.float64}; NumPy aliases Python types to its own equivalent data types.
				
				Can also use another array's {\tt dtype} attribute:
				\begin{verbatim}
					In [47]: int_array = np.arange(10)
					In [48]: calibers = np.array([.22, .270, .357, .380, .44, .50], dtype=np.float64)
					In [49]: int_array.astype(calibers.dtype)
					Out[49]: array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])
				\end{verbatim}
				There are shorthand type code strings you can also use to refer to a {\tt dtype}:
				\begin{verbatim}
					In [50]: zeros_uint32 = np.zeros(8, dtype="u4")
					In [51]: zeros_uint32
					Out[51]: array([0, 0, 0, 0, 0, 0, 0, 0], dtype=uint32)
				\end{verbatim}
				
				\begin{remark}
					Call {\tt astype} \emph{always} creates a new array (a copy of data), even if new data type is same as old data type.
				\end{remark}
				\item {\sf Arithmetic with NumPy Arrays.} Arrays are important because they enable you to express batch operations on data without writing any {\tt for} loops. NumPy users call this {\it vectorization}. Any arithmetic operations between equal-size arrays apply operation element-wise:
				\begin{verbatim}
					In [52]: arr = np.array([[1., 2., 3.], [4., 5., 6.]])
					In [53]: arr
					Out[53]:
					array([[1., 2., 3.],
					       [4., 5., 6.]])
					In [54]: arr * arr
					Out[54]:
					array([[ 1., 4., 9.],
					       [16., 25., 36.]])
					In [55]: arr - arr
					Out[55]:
					array([[0., 0., 0.],
					       [0., 0., 0.]])
				\end{verbatim}
				Arithmetic operations with scalars propagate scalar argument to each element in array:
				\begin{verbatim}
					In [56]: 1 / arr
					Out[56]:
					array([[1.   , 0.5, 0.3333],
					       [0.25 , 0.2, 0.1667]])
					
					
					In [57]: arr ** 2
					Out[57]:
					array([[ 1., 4., 9.],
					      [16., 25., 36.]])
				\end{verbatim}
				Comparisons between arrays of same size yield Boolean arrays:
				\begin{verbatim}
					In [58]: arr2 = np.array([[0., 4., 1.], [7., 2., 12.]])
					In [59]: arr2
					Out[59]:
					array([[ 0., 4., 1.],
					       [ 7., 2., 12.]])
					In [60]: arr2 > arr
					Out[60]:
					array([[False, True, False],
					       [ True, False, True]])
				\end{verbatim}
				Evaluating operations between differently sized arrays is called {\it broadcasting} (see Appendix A). Having a deep understanding of broadcasting is not necessary for most of this book.
				\item {\sf Basic Indexing \& Slicing.} NumPy array indexing is a deep topic, as there are many ways you may want to select a subset of your data or individual elements. 1D arrays are simple; on surface they act similarly to Python lists:
				\begin{verbatim}
					In [61]: arr = np.arange(10)
					In [62]: arr
					Out[62]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
					In [63]: arr[5]
					Out[63]: 5
					In [64]: arr[5:8]
					Out[64]: array([5, 6, 7])
					In [65]: arr[5:8] = 12
					In [66]: arr
					Out[66]: array([ 0, 1, 2, 3, 4, 12, 12, 12, 8, 9])	
				\end{verbatim}
				If assign a scalar value to a slice, as in {\tt arr[5:8] = 12}, value is propagated (or {\it broadcast} henceforth) to entire selection.
				\begin{remark}
					An important 1st distinction from Python's built-in lists: array slices are views on original array. I.e., data is not copied, \& any modifications to view will be reflected in source array.
				\end{remark}
				E.g., 1st create a slice of {\tt arr}:
				\begin{verbatim}
					In [67]: arr_slice = arr[5:8]
					In [68]: arr_slice
					Out[68]: array([12, 12, 12])
				\end{verbatim}
				Now, when change values in \verb|arr_slice|, mutations are reflected in original array {\tt arr}:
				\begin{verbatim}
					In [69]: arr_slice[1] = 12345
					In [70]: arr
					Out[70]:
					array([ 0, 1, 2, 3, 4, 12, 12345, 12, 8, 9])
				\end{verbatim}
				``Bare'' slice {\tt[:]} will assign to all values in an array:
				\begin{verbatim}
					In [71]: arr_slice[:] = 64
					In [72]: arr
					Out[72]: array([ 0, 1, 2, 3, 4, 64, 64, 64, 8, 9])
				\end{verbatim}
				If new to NumPy, might be surprised by this, especially if have used other array programming languages that copy data more eagerly. As NumPy has been designed to be able to work with very large arrays, could imagine performance \& memory problems if NumPy insisted on always copying data.
				\begin{remark}
					If want to copy of a slice of an ndarray instead of a view, will need to explicitly copy array -- e.g., {\tt arr[5:8].copy()}. pandas works this way, too.
				\end{remark}
				With higher dimensional arrays, have many more options. In a 2D array, elements at each index are no longer scalars but rather 1D arrays:
				\begin{verbatim}
					In [73]: arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
					In [74]: arr2d[2]
					Out[74]: array([7, 8, 9])
				\end{verbatim}
				Thus, individual elements can be accessed recursively. But that is a bit too much work, so can pass a comma-separated list of indices to select individual elements. So these are equivalent:
				\begin{verbatim}
					In [75]: arr2d[0][2]
					Out[75]: 3
					In [76]: arr2d[0, 2]
					Out[76]: 3
				\end{verbatim}
				See {\sf Fig. 4.1: Indexing elements in a NumPy array} for an illustration of indexing on a 2D array. Find it helpful to think of axis 0 as ``rows'' of array \& axis 1 as ``columns.''
				
				In multidimensional arrays, if omit later indices, returned object will be a lower dimensional ndarray consisting of all data along higher dimensions. So in $2\times2\times3$ array {\tt arr3d}:
				\begin{verbatim}
					In [77]: arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])
					In [78]: arr3d
					Out[78]:
					array([[[ 1, 2, 3],
					        [ 4, 5, 6]],
					       [[ 7, 8, 9],
					        [10, 11, 12]]])
				\end{verbatim}
				{\tt arr3d[0]} is a $2\times3$ array:
				\begin{verbatim}
					In [79]: arr3d[0]
					Out[79]:
					array([[1, 2, 3],
					       [4, 5, 6]])
				\end{verbatim}
				Both scalar values \& arrays can be assigned to {\tt arr3d[0]}:
				\begin{verbatim}
					In [80]: old_values = arr3d[0].copy()
					In [81]: arr3d[0] = 42
					In [82]: arr3d
					Out[82]:
					array([[[42, 42, 42],
					        [42, 42, 42]],
					       [[ 7, 8, 9],
					        [10, 11, 12]]])
					In [83]: arr3d[0] = old_values
					In [84]: arr3d
					Out[84]:
					array([[[ 1, 2, 3],
					        [ 4, 5, 6]],
					       [[ 7, 8, 9],
					        [10, 11, 12]]])
				\end{verbatim}
				Similarly, {\tt arr3d[1, 0]} gives all of values whose indices start with {\tt(1, 0)}, forming a 1D array:
				\begin{verbatim}
					In [85]: arr3d[1, 0]
					Out[85]: array([7, 8, 9])
				\end{verbatim}
				This expression is same as though had indexed in 2 steps:
				\begin{verbatim}
					In [86]: x = arr3d[1]
					In [87]: x
					Out[87]:
					array([[ 7, 8, 9],
					       [10, 11, 12]])
					In [88]: x[0]
					Out[88]: array([7, 8, 9])
				\end{verbatim}
				Note: in all of these cases where subsections of array have been selected, returned arrays are views.
				\begin{remark}
					This multidimensional indexing syntax for NumPy arrays will not work with regular Python objects, e.g. lists of lists.
				\end{remark}
				\begin{itemize}
					\item {\sf Indexing with slices.} Like 1D objects e.g. Python lists, ndarrays can be sliced with familiar syntax:
					\begin{verbatim}
						In [89]: arr
						Out[89]: array([ 0, 1, 2, 3, 4, 64, 64, 8, 9])
						In [90]: arr[1:6]
						Out[90]: array([ 1, 2, 3, 4, 64])
					\end{verbatim}
					Consider 2D array from before, {\tt arr2d}. Slicing this array is a bit different:
					\begin{verbatim}
						In [91]: arr2d
						Out[91]:
						array([[1, 2, 3],
						      [4, 5, 6],
						      [7, 8, 9]])
						In [92]: arr2d[:2]
						Out[92]:
						array([[1, 2, 3],
						       [4, 5, 6]])
					\end{verbatim}
					It has sliced along axis 0, 1st axis. A slice, therefore, selects a range of elements along an axis. It can be helpful to read expression {\tt arr2d[:2]} as ``select 1st 2 rows of {\tt arr2d}.''
					
					Can pass multiple slices just like you can pass multiple indexes:
					\begin{verbatim}
						In [93]: arr2d[:2, 1:]
						Out[93]:
						array([[2, 3],
						       [5, 6]])
					\end{verbatim}
					When slicing like this, always obtain array reviews of same number of dimensions. By mixing integer indexes \& slices, get lower dimensional slices.
				
					E.g., can select 2nd row but only 1st 2 columns, like so:
					\begin{verbatim}
						In [94]: lower_dim_slice = arr2d[1, :2]
					\end{verbatim}
					Here, while {\tt arr2d} is 2D, \verb|lower_dim_slice| is 1D, \& its shape is a tuple with 1 axis size:
					\begin{verbatim}
						In [95]: lower_dim_slice.shape
						Out[95]: (2,)
					\end{verbatim}
					Similarly, can select 3rd column but only 1st 2 rows, like so:
					\begin{verbatim}
						In [96]: arr2d[:2, 2]
						Out[96]: array([3, 6])
					\end{verbatim}
					See {\sf Fig. 4.2: 2D array slicing} for an illustration. note: a colon by itself means to take entire axis, so can slice only higher dimensional axes by doing:
					\begin{verbatim}
						In [97]: arr2d[:, :1]
						Out[97]:
						array([[1],
						       [4],
						       [7]])
					\end{verbatim}
					Of course, assigning to a slice expression assigns to whole selection:
					\begin{verbatim}
						In [98]: arr2d[:2, 1:] = 0
						In [99]: arr2d
						Out[99]:
						array([[1, 0, 0],
						       [4, 0, 0],
						       [7, 8, 9]])
					\end{verbatim}
				\end{itemize}
				\item {\sf Boolean Indexing.} Consider an example where have some data in an array \& an array of names with duplicates:
				\begin{verbatim}
					In [100]: names = np.array(["Bob", "Joe", "Will", "Bob", "Will", "Joe", "Joe"])
					In [101]: data = np.array([[4, 7], [0, 2], [-5, 6], [0, 0], [1, 2],
					   .....:                   [-12, -4], [3, 4]])
					In [102]: names
					Out[102]: array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'], dtype='<U4')
					In [103]: data
					Out[103]:
					array([[ 4, 7],
						   [ 0, 2],
						   [-5, 6],
						   [ 0, 0],
						   [ 1, 2],
						   [-12, -4],
						   [ 3, 4]]),
				\end{verbatim}
				Suppose each name corresponds to a row in {\tt data} array \& wanted to select all rows with corresponding name {\tt"Bob"}. Like arithmetic operations, comparisons (e.g. {\tt==}) with arrays are also vectorized. Thus, comparing {\tt names} with string {\tt"Bob"} yields a Boolean array:
				\begin{verbatim}
					In [104]: names == "Bob"
					Out[104]: array([ True, False, False, True, False, False, False])
				\end{verbatim}
				This Boolean array can be passed when indexing array:
				\begin{verbatim}
					In [105]: data[names == "Bob"]
					Out[105]:
					array([[4, 7],
					      [0, 0]])
				\end{verbatim}
				Boolean array must be of same length as array axis it's indexing. Can even mix \& match Boolean arrays with slices or integers (or sequences of integers; more on this later).
				
				In these examples, select from rows where {\tt names == "Bob"} \& index columns, too:
				\begin{verbatim}
					In [106]: data[names == "Bob", 1:]
					Out[106]:
					array([[7],
					       [0]])
					In [107]: data[names == "Bob", 1]
					Out[107]: array([7, 0])
				\end{verbatim}
				To select everything but {\tt"Bob"} can either use {\tt!=} or negate condition using \verb|~|:
				\begin{verbatim}
					In [108]: names != "Bob"
					Out[108]: array([False, True, True, False, True, True, True])
					In [109]: ~(names == "Bob")
					Out[109]: array([False, True,
					True, False, True, True, True])
					In [110]: data[~(names == "Bob")]
					Out[110]:
					array([[ 0, 2],
					       [-5, 6],
					       [ 1, 2],
					       [-12,-4],
					       [ 3, 4]])
				\end{verbatim}
				\verb|~| operator can be useful when want to invert a Boolean array referenced by a variable:
				\begin{verbatim}
					In [111]: cond = names == "Bob"
					In [112]: data[~cond]
					Out[112]:
					array([[ 0, 2],
					[-5, 6],
					[ 1, 2],
					[-12,-4],
					[ 3, 4]])
				\end{verbatim}
				To select 2 of 3 names to combine multiple Boolean conditions, use Boolean arithmetic operators like {\tt\&} (and) \& {\tt|} (or):
				\begin{verbatim}
					In [113]: mask = (names == "Bob") | (names == "Will")
					In [114]: mask
					Out[114]: array([ True, False,
					True, True, True, False, False])
					In [115]: data[mask]
					Out[115]:
					array([[ 4, 7],
					       [-5, 6],
					       [ 0, 0],
					       [ 1, 2]])
				\end{verbatim}
				Selecting data from an array by Boolean indexing \& assigning result to a new variable {\it always} create a copy of data, even if returned array is unchanged.
				\begin{remark}
					Python keywords {\tt and, or} do not work with Boolean arrays. Use {\tt\&} (and) \& {\tt|} (or) instead.
				\end{remark}
				Setting values with Boolean arrays works by substituting value or values on RHS into locations where Boolean array's  values are {\tt True}. To set all of negative value in {\tt data} to 0, need only do:
				\begin{verbatim}
					In [116]: data[data < 0] = 0
					In [117]: data
					Out[117]:
					array([[4, 7],
					       [0, 2],
					       [0, 6],
					       [0, 0],
					       [1, 2],
					       [0, 0],
					       [3, 4]])
				\end{verbatim}
				Can also set whole rows or columns using a 1D Boolean array:
				\begin{verbatim}
					In [118]: data[names != "Joe"] = 7
					In [119]: data
					Out[119]:
					array([[7, 7],
					       [0, 2],
					       [7, 7],
					       [7, 7],
					       [7, 7],
					       [0, 0],
					       [3, 4]])
				\end{verbatim}
				These types of operations on 2D data are convenient to do with pandas.
				\item {\sf Fancy Indexing.} {\it Fancy indexing} is a term adopted by NumPy to describe indexing using integer arrays. Suppose had an $8\times4$ array:
				\begin{verbatim}
					In [120]: arr = np.zeros((8, 4))
					In [121]: for i in range(8):
					   .....:
					arr[i] = i
					In [122]: arr
					Out[122]:
					array([[0., 0., 0., 0.],
					       [1., 1., 1., 1.],
					       [2., 2., 2., 2.],
					       [3., 3., 3., 3.],
					       [4., 4., 4., 4.],
					       [5., 5., 5., 5.],
					       [6., 6., 6., 6.],
					       [7., 7., 7., 7.]])
				\end{verbatim}
				To select a subset of rows in a particular order, can simply pass a list or ndarray of integers specifying desired order:
				\begin{verbatim}
					In [123]: arr[[4, 3, 0, 6]]
					Out[123]:
					array([[4., 4., 4., 4.],
					       [3., 3., 3., 3.],
					       [0., 0., 0., 0.],
					       [6., 6., 6., 6.]])
				\end{verbatim}
				Hopefully this code did what you expected! Using negative indices select rows from end:
				\begin{verbatim}
					In [124]: arr[[-3, -5, -7]]
					Out[124]:
					array([[5., 5., 5., 5.],
					       [3., 3., 3., 3.],
					       [1., 1., 1., 1.]])
				\end{verbatim}
				Passing multiple index arrays does something slightly different; it selects a 1D array of elements corresponding to each tuple of indices:
				\begin{verbatim}
					In [125]: arr = np.arange(32).reshape((8, 4))
					In [126]: arr
					Out[126]:
					array([[ 0, 1, 2, 3],
					       [ 4, 5, 6, 7],
					       [ 8, 9, 10, 11],
					       [12, 13, 14, 15],
					       [16, 17, 18, 19],
					       [20, 21, 22, 23],
					       [24, 25, 26, 27],
					       [28, 29, 30, 31]])
					In [127]: arr[[1, 5, 7, 2], [0, 3, 1, 2]]
					Out[127]: array([ 4, 23, 29, 10])
				\end{verbatim}
				To learn more about {\tt reshape} method, have a look at Appendix A.
				
				Here elements {\tt(1, 0), (5, 3), (7, 1), (2, 2)} were selected. Result of fancy indexing with as many integer arrays as there are axes is always 1D.
				
				Behavior of fancy indexing in this case is a bit different from what some users might have expected, which is rectangular region formed by selecting a subset of matrix's rows \& columns. 1 way to get that:
				\begin{verbatim}
					In [128]: arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]
					Out[128]:
					array([[ 4, 7, 5, 6],
					       [20, 23, 21, 22],
					       [28, 31, 29, 30],
					       [ 8, 11, 9, 10]])
				\end{verbatim}
				Keep in mind: fancy indexing, unlike slicing, always copies data into a new array when assigning result to a new variable. If assign values with fancy indexing, indexed values will be modified:
				\begin{verbatim}
					In [129]: arr[[1, 5, 7, 2], [0, 3, 1, 2]]
					Out[129]: array([ 4, 23, 29, 10])
					In [130]: arr[[1, 5, 7, 2], [0, 3, 1, 2]] = 0
					In [131]: arr
					Out[131]:
					array([[ 0, 1, 2, 3],
					       [ 0, 5, 6, 7],
					       [ 8, 9, 0, 11],
					       [12, 13, 14, 15],
					       [16, 17, 18, 19],
					       [20, 21, 22, 0],
					       [24, 25, 26, 27],
					       [28, 0, 30, 31]])
				\end{verbatim}
				\item {\sf Transposing Arrays \& Swapping Axes.} Transposing is a special form of reshaping that similarly returns a view on underlying data without copying anything. Arrays have {\tt transpose} method \& special {\tt T} attribute:
				\begin{verbatim}
					In [132]: arr = np.arange(15).reshape((3, 5))
					In [133]: arr
					Out[133]:
					array([[ 0, 1, 2, 3, 4],
					       [ 5, 6, 7, 8, 9],
					[10, 11, 12, 13, 14]])
					In [134]: arr.T
					Out[134]:
					array([[ 0, 5, 10],
					       [ 1, 6, 11],
					       [ 2, 7, 12],
					       [ 3, 8, 13],
					       [ 4, 9, 14]])
				\end{verbatim}
				When doing matrix computations, may do this very often -- e.g., when computing inner matrix product using {\tt numpy.dot}:
				\begin{verbatim}
					In [135]: arr = np.array([[0, 1, 0], [1, 2, -2], [6, 3, 2], [-1, 0, -1], [1, 0, 1]])
					
					In [16]: arr
					Out[16]: 
					array([[ 0,  1,  0],
					       [ 1,  2, -2],
					       [ 6,  3,  2],
					       [-1,  0, -1],
					       [ 1,  0,  1]])
					
					In [17]: np.dot(arr.T, arr)
					Out[17]: 
					array([[39, 20, 12],
					       [20, 14,  2],
					       [12,  2, 10]])
				\end{verbatim}
				\verb|@infix| operator is another way to do matrix multiplication:
				\begin{verbatim}
					In [138]: arr.T @ arr
					Out[138]:
					array([[39, 20, 12],
					       [20, 14, 2],
					       [12, 2, 10]])
				\end{verbatim}
				Simple transposing with {\tt.T} is a special case of swapping axes. ndarray has method {\tt swapaxes}, which takes a pair of axis numbers \& switches indicated axes to rearrange data:
				\begin{verbatim}
					In [139]: arr
					Out[139]:
					array([[ 0, 1, 0],
					       [ 1, 2, -2],
					       [ 6, 3, 2],
					       [-1, 0, -1],
					       [ 1, 0, 1]])
					In [140]: arr.swapaxes(0, 1)
					Out[140]:
					array([[ 0, 1, 6, -1, 1],
					       [ 1, 2, 3, 0, 0],
					       [ 0, -2, 2, -1, 1]])
				\end{verbatim}
				{\tt swapaxes} similarly returns a view on data without making a copy.
			\end{itemize}
			\item {\sf4.2. Pseudorandom Number Generation.} {\tt numpy.random} module supplements built-in Python {\tt random} module with functions for efficiently generating whole arrays of sample values from many kinds of probability distributions. e.g., can get a $4\times4$ array of samples from standard normal distribution using \verb|numpy.random.standard_normal|:
			\begin{verbatim}
				In [141]: samples = np.random.standard_normal(size=(4, 4))
				In [142]: samples
				Out[142]:
				array([[-0.2047, 0.4789, -0.5194, -0.5557],
				       [ 1.9658, 1.3934, 0.0929, 0.2817],
				       [ 0.769 , 1.2464, 1.0072, -1.2962],
				       [ 0.275 , 0.2289, 1.3529, 0.8864]])
			\end{verbatim}
			Python's built-in {\tt random} module, by contrast, samples only 1 value at a time. As can see from this benchmark, {\tt numpy.random} is well over an order of magnitude faster for generating very large samples:
			\begin{verbatim}
				In [143]: from random import normalvariate
				In [144]: N = 1_000_000
				In [145]: %timeit samples = [normalvariate(0, 1) for _ in range(N)]
				1.04 s +- 11.4 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)
				In [146]: %timeit np.random.standard_normal(N)
				21.9 ms +- 155 us per loop (mean +- std. dev. of 7 runs, 10 loops each)
			\end{verbatim}
			These random numbers are not truly random (rather, {\it pseudorandom}) but instead are generated by a configurable random number generator that determines deterministically what values are created. Functions like \verb|numpy.random.standard_normal| use {\tt numpy.random} module's default random number generator, but your code can be configured to use an explicit generator:
			\begin{verbatim}
				In [147]: rng = np.random.default_rng(seed=12345)
				In [148]: data = rng.standard_normal((2, 3))
			\end{verbatim}
			{\tt seed} argument is what determines initial state of generator, \& state changes each time {\tt rng} object is used to generate data. Generator object {\tt rng} is also isolated from other code which might use {\tt numpy.random} module:
			\begin{verbatim}
				In [149]: type(rng)
				Out[149]: numpy.random._generator.Generator
			\end{verbatim}
			See {\sf Table 4.3: NumPy random number generator methods} for a partial list of methods available on random generator objects like {\tt rng}. Will use {\tt rng} object created above to generate random data throughout rest of chap. {\sf Method: Description}
			\begin{itemize}
				\item {\tt permutation}: Return a random permutation of a sequence, or return a permuted range
				\item {\tt shuffle}: Randomly permute a sequence in place
				\item {\tt uniform}: Draw samples from a uniform distribution
				\item {\tt integers}: Draw random integers from a given low-to-high range
				\item \verb|standard_normal|: Draw samples from a normal distribution with mean 0 \& standard deviation 1
				\item {\tt binomial}: Draw samples from a binomial distribution
				\item {\tt normal}: Draw samples from a normal (Gaussian) distribution
				\item {\tt beta}: Draw samples from a beta distribution
				\item {\tt chisquare}: Draw samples from a chi-square distribution
				\item {\tt gamma}: Draw samples from a gamma distribution
				\item {\tt uniform}: Draw samples from a uniform $[0,1)$ distribution
			\end{itemize}
			\item {\sf4.3. Universal Functions: Fast Element-Wise Array Functions.} A A universal function, or {\tt ufunc}, is a function that performs element-wise operations on data in ndarrays. Can think of them as fast vectorized wrappers for simple functions that take 1 or more scalar values \& produce 1 or more scalar results.
			
			Many ufuncs are simple element-wise transformations, like {\tt numpy.sqrt} or {\tt numpy.exp}:
			\begin{verbatim}
				In [150]: arr = np.arange(10)
				In [151]: arr
				Out[151]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
				In [152]: np.sqrt(arr)
				In [152]: np.sqrt(arr)
				Out[152]: 
				array([0.        , 1.        , 1.41421356, 1.73205081, 2.        ,
				2.23606798, 2.44948974, 2.64575131, 2.82842712, 3.        ])
				
				In [153]: np.exp(arr)
				Out[153]: 
				array([1.00000000e+00, 2.71828183e+00, 7.38905610e+00, 2.00855369e+01,
				5.45981500e+01, 1.48413159e+02, 4.03428793e+02, 1.09663316e+03,
				2.98095799e+03, 8.10308393e+03])
			\end{verbatim}
			These are referred to as {\it unary} ufuncs. Others, e.g. {\tt numpy.add} or {\tt numpy.maximum}, take 2 arrays (thus, {\it binary} ufuncs) \& return a single array as result:
			\begin{verbatim}
				In [154]: x = rng.standard_normal(8)
				
				In [155]: y = rng.standard_normal(8)
				
				In [156]: x
				Out[156]: 
				array([-1.3677927 ,  0.6488928 ,  0.36105811, -1.95286306,  2.34740965,
				0.96849691, -0.75938718,  0.90219827])
				
				In [157]: y
				Out[157]: 
				array([-0.46695317, -0.06068952,  0.78884434, -1.25666813,  0.57585751,
				1.39897899,  1.32229806, -0.29969852])
				
				In [158]: np.maximum(x, y)
				Out[158]: 
				array([-0.46695317,  0.6488928 ,  0.78884434, -1.25666813,  2.34740965,
				1.39897899,  1.32229806,  0.90219827])
			\end{verbatim}
			In this example, {\tt numpy.maximum} computed element-wise maximum of elements in {\tt x, y}.
			
			While not common, a ufunc can return multiple arrays. {\tt numpy.modf} is 1 example: a vectorized version of built-in Python {\tt math.modf}, it returns fractional \& integral parts of a floating-point array:
			\begin{verbatim}
				In [35]: arr = rng.standard_normal(7) * 5
				
				In [36]: arr
				Out[36]: 
				array([ 4.51459671, -8.10791367, -0.7909463 ,  2.24741966, -6.71800536,
				-0.40843795,  8.62369966])
				
				In [37]: remainder, whole_part = np.modf(arr)
				
				In [38]: remainder
				Out[38]: 
				array([ 0.51459671, -0.10791367, -0.7909463 ,  0.24741966, -0.71800536,
				-0.40843795,  0.62369966])
				
				In [39]: whole_part
				Out[39]: array([ 4., -8., -0.,  2., -6., -0.,  8.])
			\end{verbatim}
			Ufuncs accept an optional {\tt out} argument that allows them to assign their results into an existing array rather than create a new one:
			\begin{verbatim}
				In [40]: arr
				Out[40]: 
				array([ 4.51459671, -8.10791367, -0.7909463 ,  2.24741966, -6.71800536,
				-0.40843795,  8.62369966])
				
				In [41]: out = np.zeros_like(arr)
				
				In [42]: np.add(arr, 1)
				Out[42]: 
				array([ 5.51459671, -7.10791367,  0.2090537 ,  3.24741966, -5.71800536,
				0.59156205,  9.62369966])
				
				In [43]: np.add(arr, 1, out=out)
				Out[43]: 
				array([ 5.51459671, -7.10791367,  0.2090537 ,  3.24741966, -5.71800536,
				0.59156205,  9.62369966])
				
				In [44]: out
				Out[44]: 
				array([ 5.51459671, -7.10791367,  0.2090537 ,  3.24741966, -5.71800536,
				0.59156205,  9.62369966])
			\end{verbatim}
			See {\sf Table 4.4: Some unary universal functions} \& {\sf Table 4.5: Some binary universal functions} for a listing of some of NumPy's ufuncs. New ufuncs continue to be added to NumPy, so consulting online NumPy documentation is best way to get a comprehensive listing \& stay up to date.
			\item {\sf4.4. Array-Oriented Programming with Arrays.} Using NumPy arrays enables you to express many kinds of data processing tasks as concise array expressions that might otherwise require writing loops. This practice of replacing explicit loops with array expressions is referred to by some people as {\it vectorization}. In general, vectorized array operations will usually be significantly faster than their pure Python equivalents, with biggest impact in any kind of numerical computations. Later, in Appendix A, explain {\it broadcasting}, a powerful method for vectorizing computations.
			
			E.g., suppose wished to evaluate function \verb|sqrt(x^2 + y^2)| across a regular grid of values. {\tt numpy.meshgrid} function takes 2 1D arrays \& produces 2 2D matrices corresponding to all pairs of {\tt(x, y)} in 2 arrays:
			\begin{verbatim}
				In [169]: points = np.arange(-5, 5, 0.01) # 100 equally spaced points
				In [170]: xs, ys = np.meshgrid(points, points)
				In [171]: ys
				Out[171]:
				array([[-5. , -5. , -5. , ..., -5. , -5. , -5. ],
				       [-4.99, -4.99, -4.99, ..., -4.99, -4.99, -4.99],
				       [-4.98, -4.98, -4.98, ..., -4.98, -4.98, -4.98],
				       ...,
				       [ 4.97, 4.97, 4.97, ..., 4.97, 4.97, 4.97],
				       [ 4.98, 4.98, 4.98, ..., 4.98, 4.98, 4.98],
				       [ 4.99, 4.99, 4.99, ..., 4.99, 4.99, 4.99]])
			\end{verbatim}
			Now, evaluating function is a matter of writing same expression you would write with 2 points:
			\begin{verbatim}
				In [172]: z = np.sqrt(xs ** 2 + ys ** 2)
				In [173]: z
				Out[173]:
				array([[7.0711, 7.064 , 7.0569, ..., 7.0499, 7.0569, 7.064 ],
				       [7.064 , 7.0569, 7.0499, ..., 7.0428, 7.0499, 7.0569],
				       [7.0569, 7.0499, 7.0428, ..., 7.0357, 7.0428, 7.0499],
				       ...,
				       [7.0499, 7.0428, 7.0357, ..., 7.0286, 7.0357, 7.0428],
				       [7.0569, 7.0499, 7.0428, ..., 7.0357, 7.0428, 7.0499],
				       [7.064 , 7.0569, 7.0499, ..., 7.0428, 7.0499, 7.0569]])
			\end{verbatim}
			As a preview of Chap. 9, use matplotlib to create visualizations of this 2D array:
			\begin{verbatim}
				In [174]: import matplotlib.pyplot as plt
				In [175]: plt.imshow(z, cmap=plt.cm.gray, extent=[-5, 5, -5, 5])
				Out[175]: <matplotlib.image.AxesImage at 0x7f624ae73b20>
				In [176]: plt.colorbar()
				Out[176]: <matplotlib.colorbar.Colorbar at 0x7f6253e43ee0>
				In [177]: plt.title("Image plot of $\sqrt{x^2 + y^2}$ for a grid of values")
				Out[177]: Text(0.5, 1.0, 'Image plot of $\\sqrt{x^2 + y^2}$ for a grid of values')
			\end{verbatim}
			In {\sf Fig. 4.3: Plot of function evaluated on a grid}, used matplotlib function {\tt imshow} to create an image plot from a 2D array of function values.
			
			If working in IPython, can close all open plot windows by executing {\tt plt.close("all")}:
			\begin{verbatim}
				In [179]: plt.close("all")
			\end{verbatim}
			
			\begin{remark}
				Term \emph{vectorization} is used to describe some other computer science concepts, but in this book use it to describe operations on whole arrays of data at once rather than going value by value using a Python {\tt for} loop.
			\end{remark}
			\begin{itemize}
				\item {\sf Expressing Conditional Logic as Array Operations.} {\tt numpy.where} function is a vectorized version of ternary expression {\tt x if condition else y}. Suppose had a Boolean array \& 2 arrays of values:
				\begin{verbatim}
					In [180]: xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])
					In [181]: yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])
					In [182]: cond = np.array([True, False, True, True, False])
				\end{verbatim}
				Suppose wanted to take a value from {\tt xarr} whenever corresponding value in {\tt cond} is {\tt True}, \& otherwise take value from {\tt yarr}. A list comprehension doing this might look like:
				\begin{verbatim}
					In [183]: result = [(x if c else y)
					   .....:           for x, y, c in zip(xarr, yarr, cond)]
					In [184]: result
					Out[184]: [1.1, 2.2, 1.3, 1.4, 2.5]
				\end{verbatim}
				This has multiple problems. 1st, it will not be very fast for large arrays (because all work is being done in interpreted Python code). 2nd, it will not work with multidimensional arrays. With {\tt numpy.where} you can do this with a single function call:
				\begin{verbatim}
					In [185]: result = np.where(cond, xarr, yarr)
					In [186]: result
					Out[186]: array([1.1, 2.2, 1.3, 1.4, 2.5])
				\end{verbatim}
				2nd \& 3rd arguments to {\tt numpy.where} don't need to be arrays; 1 or both of them can be scalars. A typical use of {\tt where} in data analysis is to produce a new array of values based on another array. Suppose had a matrix of randomly generated data \& wanted to replace all positive values with 2 \& all negative values with $-2$. This is possible to do with {\tt numpy.where}:
				\begin{verbatim}
					In [187]: arr = rng.standard_normal((4, 4))
					In [188]: arr
					Out[188]:
					array([[ 2.6182, 0.7774, 0.8286, -0.959 ],
					       [-1.2094, -1.4123, 0.5415, 0.7519],
					       [-0.6588, -1.2287, 0.2576, 0.3129],
					       [-0.1308, 1.27 , -0.093 , -0.0662]])
					In [189]: arr > 0
					Out[189]:
					array([[ True, True, True, False],
					       [False, False, True, True],
					       [False, False, True, True],
					       [False, True, False, False]])
					In [190]: np.where(arr > 0, 2, -2)
					Out[190]:
					array([[ 2, 2, 2, -2],
					       [-2, -2, 2, 2],
					       [-2, -2, 2, 2],
					       [-2, 2, -2, -2]])
				\end{verbatim}
				Can combine scalars \& arrays when using {\tt numpy.where}. E.g., can replace all positive values in {\tt arr} with constant 2, like so:
				\begin{verbatim}
					In [191]: np.where(arr > 0, 2, arr) # set only positive values to 2
				\end{verbatim}
				\item {\sf Mathematical \& Statistical Methods.} A set of mathematical functions that compute statistics about an entire array or about data along an axis are accessible as methods of array class. Can use aggregations (sometimes called {\it reductions}) like {\tt sum, mean, std} (standard deviation) either by calling array instance method or using top-level NumPy function. When use NumPy function, like {\tt numpy.sum}, have to pass array you want to aggregate as 1st argument -- phải truyền mảng bạn muốn tổng hợp làm đối số thứ nhất.
				
				Here generate some normally distributed random data \& compute some aggregate statistics:
				\begin{verbatim}
					In [192]: arr = rng.standard_normal((5, 4))
					In [193]: arr
					Out[193]:
					array([[-1.1082, 0.136 , 1.3471, 0.0611],
					       [ 0.0709, 0.4337, 0.2775, 0.5303],
					       [ 0.5367, 0.6184, -0.795 , 0.3
					],
					       [-1.6027, 0.2668, -1.2616, -0.0713],
					       [ 0.474 , -0.4149, 0.0977, -1.6404]])
					In [194]: arr.mean()
					Out[194]: -0.08719744457434529
					In [195]: np.mean(arr)
					Out[195]: -0.08719744457434529
					In [196]: arr.sum()
					Out[196]: -1.743948891486906
				\end{verbatim}
				Functions like {\tt mean, sum} take an optional {\tt axis} argument that computes statistic over given axis, resulting in an array with 1 less dimension:
				\begin{verbatim}
					In [197]: arr.mean(axis=1)
					Out[197]: array([ 0.109 , 0.3281, 0.165 , -0.6672, -0.3709])
					In [198]: arr.sum(axis=0)
					Out[198]: array([-1.6292, 1.0399, -0.3344, -0.8203])
				\end{verbatim}
				Here, {\tt arr.mean(axis=1)} means ``compute mean across columns,'' where {\tt arr.sum(axis=0)} means ``compute sum down rows.''
				
				Other methods like {\tt cumsum} (tổng xuất tinh!) \& {\tt cumprod} (sản phẩm{\tt/}tích tụ xuất tinh!) do not aggregate, instead producing an array of intermediate results:
				\begin{verbatim}
					In [199]: arr = np.array([0, 1, 2, 3, 4, 5, 6, 7])
					In [200]: arr.cumsum()
					Out[200]: array([ 0, 1, 3, 6, 10, 15, 21, 28])
				\end{verbatim}
				In multidimensional arrays, accumulation functions like {\tt cumsum} return an array of same size but with partial aggregates computed along indicated axis according to each lower dimensional slice:
				\begin{verbatim}
					In [201]: arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
					In [202]: arr
					Out[202]:
					array([[0, 1, 2],
					       [3, 4, 5],
					       [6, 7, 8]])
				\end{verbatim}
				Expression {\tt arr.cumsum(axis=0)} computes cumulative sum along rows, while {\tt arr.cumsum(axis=1)} computes sums along columns:
				\begin{verbatim}
					In [203]: arr.cumsum(axis=0)
					Out[203]:
					array([[ 0, 1, 2],
					       [ 3, 5, 7],
					       [ 9, 12, 15]])
					In [204]: arr.cumsum(axis=1)
					Out[204]:
					array([[ 0, 1, 3],
					       [ 3, 7, 12],
					       [ 6, 13, 21]])
				\end{verbatim}
				See {\sf Table 4.6: Basic array statistical methods} for a full listing. See many examples of these methods in action in later chaps. {\sf Method: Description}
				\begin{itemize}
					\item {\tt sum}: Sum of all elements in array or along an axis; zero-length arrays have sum 0
					\item {\tt mean}: Arithmetic mean; invalid (returns {\tt NaN}) on zero-length arrays
					\item {\tt std, var}: Standard deviation \& variance, resp.
					\item {\tt min, max}: Minimum \& maximum
					\item {\tt argmin, argmax}: Indices of minimum \& maximum elements, resp.
					\item {\tt cumsum}: Cumulative sum of elements starting from 0
					\item {\tt cumprod}: Cumulative product of elements starting from 1
				\end{itemize}
				\item {\sf Methods for Boolean Arrays.} Boolean values are coerced to 1 ({\tt True}) \& 0 ({\tt False}) in preceding methods. Thus, {\tt sum} is often used as a means of counting {\tt True} values in a Boolean array:
				\begin{verbatim}
					In [205]: arr = rng.standard_normal(100)
					In [206]: (arr > 0).sum() # Number of positive values
					Out[206]: 48
					In [207]: (arr <= 0).sum() # Number of non-positive values
					Out[207]: 52
				\end{verbatim}
				Parentheses here in expression {\tt (arr > 0).sum()} are necessary to be able to call {\tt sum()} on temporary result of {\tt arr > 0}.
				
				2 additional methods, \fbox{$\forall,\exists$} {\tt any, all} are useful especially for Boolean arrays. {\tt any} tests whether 1 or more values in an array is {\tt True}, while {\tt all} checks if every value is {\tt True}:
				\begin{verbatim}
					In [208]: bools = np.array([False, False, True, False])
					In [209]: bools.any()
					Out[209]: True
					In [210]: bools.all()
					Out[210]: False
				\end{verbatim}
				These methods also work with non-Boolean arrays, where nonzero elements are treated as {\tt True}.
				\item {\sf Sorting.} Like Python's built-in list type, NumPy arrays can be sorted in place with {\tt sort} method:
				\begin{verbatim}
					In [45]: arr = rng.standard_normal(6)
					
					In [46]: arr
					Out[46]: 
					array([ 2.61815943,  0.77736134,  0.8286332 , -0.95898831, -1.20938829,
					-1.41229201])
					
					In [47]: arr.sort()
					
					In [48]: arr
					Out[48]: 
					array([-1.41229201, -1.20938829, -0.95898831,  0.77736134,  0.8286332 ,
					2.61815943])
				\end{verbatim}
				Can sort each 1D section of values in a multidimensional array in place along an axis by passing axis number to {\tt sort}. In this example data:
				\begin{verbatim}
					In [49]: arr = rng.standard_normal((5, 3))
					
					In [50]: arr
					Out[50]: 
					array([[ 0.54154683,  0.7519394 , -0.65876032],
					[-1.22867499,  0.25755777,  0.31290292],
					[-0.13081169,  1.26998312, -0.09296246],
					[-0.06615089, -1.10821447,  0.13595685],
					[ 1.34707776,  0.06114402,  0.0709146 ]])
				\end{verbatim}
				{\tt arr.sort(axis=0)} sorts values within each column, while {\tt arr.sort(axis=1)} sorts across each row:
				\begin{verbatim}
					In [51]: arr.sort(axis=0)
					
					In [52]: arr
					Out[52]: 
					array([[-1.22867499, -1.10821447, -0.65876032],
					[-0.13081169,  0.06114402, -0.09296246],
					[-0.06615089,  0.25755777,  0.0709146 ],
					[ 0.54154683,  0.7519394 ,  0.13595685],
					[ 1.34707776,  1.26998312,  0.31290292]])
					
					In [53]: arr.sort(axis=1)
					
					In [54]: arr
					Out[54]: 
					array([[-1.22867499, -1.10821447, -0.65876032],
					[-0.13081169, -0.09296246,  0.06114402],
					[-0.06615089,  0.0709146 ,  0.25755777],
					[ 0.13595685,  0.54154683,  0.7519394 ],
					[ 0.31290292,  1.26998312,  1.34707776]])
				\end{verbatim}
				Top-level method {\tt numpy.sort} returns a sorted copy of an array (like Python built-in function {\tt sorted}) instead of modifying array in place. E.g.:
				\begin{verbatim}
					In [221]: arr2 = np.array([5, -10, 7, 1, 0, -3])
					In [222]: sorted_arr2 = np.sort(arr2)
					In [223]: sorted_arr2
					Out[57]: array([-10,  -3,   0,   1,   5,   7])
				\end{verbatim}
				For more details on using NumPy's sorting methods, \& more advanced techniques like indirect sorts, see Appendix A. Several other kinds of data manipulations related to sorting (e.g., sorting a table of data by 1 or more columns) can also be found in pandas.
				\item {\sf Unique \& Other Set Logic.} NumPy has some basic set operations for 1D ndarrays. A commonly used one is {\tt numpy.unique}, which returns sorted unique values in an array:
				\begin{verbatim}
					In [224]: names = np.array(["Bob", "Will", "Joe", "Bob", "Will", "Joe", "Joe"])
					In [225]: np.unique(names)
					Out[225]: array(['Bob', 'Joe', 'Will'], dtype='<U4')
					In [226]: ints = np.array([3, 3, 3, 2, 2, 1, 1, 4, 4])
					In [227]: np.unique(ints)
					Out[227]: array([1, 2, 3, 4])
				\end{verbatim}
				Contrast {\tt numpy.unique} with pure Python alternative:
				\begin{verbatim}
					In [228]: sorted(set(names))
					Out[228]: ['Bob', 'Joe', 'Will']
				\end{verbatim}
				In many cases, NumPy version is faster \& returns a NumPy array rather than a Python list.
				
				Another function, {\tt numpy.in1d}, tests membership of values in 1 array in another, returning a Boolean array"
				\begin{verbatim}
					In [229]: values = np.array([6, 0, 0, 3, 2, 5, 6])
					In [230]: np.in1d(values, [2, 3, 6])
					Out[230]: array([ True, False, False, True, True, False, True])
				\end{verbatim}
				See {\sf Table 4.7: Array set operations} for a listing of array set operations in NumPy.
			\end{itemize}
			\item {\sf4.5. File Input \& Output with Arrays.}
			\item {\sf4.6. Linear Algebra.}
			\item {\sf4.7. Example: Random Walks.}
			\item {\sf4.8. Conclusion.}
		\end{itemize}
		\item {\sf5. Getting Started with pandas.}
		\begin{itemize}
			\item {\sf5.1. Introduction to {\tt pandas} Data Structures.}
			\item {\sf5.2. Essential Functionality.}
			\item {\sf5.3. Summarizing \& Computing Descriptive Statistics.}
			\item {\sf5.4. Conclusion.}
		\end{itemize}
		\item {\sf6. Data Loading, Storage, \& File Formats.}
		\begin{itemize}
			\item {\sf6.1. Reading \& Writing Data in Text Format.}
			\item {\sf6.2. Binary Data Formats.}
			\item {\sf6.3. Interacting with Web APIs.}
			\item {\sf6.4. Interacting with Databases.}
			\item {\sf6.5. Conclusion.}
		\end{itemize}
		\item {\sf7. Data Cleaning \& Preparation.}
		\begin{itemize}
			\item {\sf7.1. Handling Missing Data.}
			\item {\sf7.2. Data Transformation.}
			\item {\sf7.3. Extension Data Types.}
			\item {\sf7.4. String Manipulation.}
			\item {\sf7.5. Categorical Data.}
			\item {\sf7.6. Conclusion.}
		\end{itemize}
		\item {\sf8. Data Wrangling: Join, Combine, \& Reshape.}
		\begin{itemize}
			\item {\sf8.1. Hierarchical Indexing.}
			\item {\sf8.2. Combining \& Merging Datasets.}
			\item {\sf8.3. Reshaping \& Pivoting.}
			\item {\sf8.4. Conclusion.}
		\end{itemize}
		\item {\sf9. Plotting \& Visualization.}
		\begin{itemize}
			\item {\sf9.1. A Brief matplotlib API Primer.}
			\item {\sf9.2. Plotting with {\tt pandas} \& seaborn.}
			\item {\sf9.3. Other Python Visualization Tools.}
			\item {\sf9.4. Conclusion.}
		\end{itemize}
		\item {\sf10. Data Aggregation \& Group Operations.}
		\begin{itemize}
			\item {\sf10.1. How to Think About Group Operations.}
			\item {\sf10.2. Data Aggregation.}
			\item {\sf10.3. Apply: General split-apply-combine.}
			\item {\sf10.4. Group Transforms \& ``Upwrapped'' GroupBys.}
			\item {\sf10.5. Pivot Tables \& Cross-Tabulation.}
			\item {\sf10.6. Conclusion.}
		\end{itemize}
		\item {\sf11. Time Series.}
		\begin{itemize}
			\item {\sf11.1. Date \& Time Data Types \& Tools.}
			\item {\sf11.2. Time Series Basics.}
			\item {\sf11.3. Data Ranges, Frequencies, \& Shifting.}
			\item {\sf11.4. Time Zone Handling.}
			\item {\sf11.5. Periods \& Period Arithmetic.}
			\item {\sf11.6. Resampling \& Frequency Conversion.}
			\item {\sf11.7. Moving Window Functions.}
			\item {\sf11.8. Conclusion.}
		\end{itemize}
		\item {\sf12. Introduction to Modeling Libraries in Python.}
		\begin{itemize}
			\item {\sf12.1. Interfacing Between {\tt pandas} \& Model Code.}
			\item {\sf12.2. Creating Model Descriptions with Patsy.}
			\item {\sf12.3. Introduction to statsmodels.}
			\item {\sf12.4. Introduction to scikit-learn.}
			\item {\sf12.5. Conclusion.}
		\end{itemize}
		\item {\sf13. Data Analysis Examples.}
		\begin{itemize}
			\item {\sf13.1. Bitly Data from 1.USA.gov.}
			\item {\sf13.2. MovieLens 1M Dataset.}
			\item {\sf13.3. US Baby Names 1880--2010.}
			\item {\sf13.4. USDA Food Database.}
			\item {\sf13.5. 2012 Federal Election Commission Database.}
			\item {\sf13.6. Conclusion.}
		\end{itemize}
		\item {\sf A. Advanced NumPy.}
		\begin{itemize}
			\item {\sf A.1. {\tt ndarray} Object Internals.}
			\item {\sf A.2. Advanced Array Manipulation.}
			\item {\sf A.3. Broadcasting.}
			\item {\sf A.4. Advanced {\tt ufunc} Usage.}
			\item {\sf A.5. Structured \& Record Arrays.}
			\item {\sf A.6. More About Sorting.}
			\item {\sf A.7. Writing Fast NumPy Functions with Numba.}
			\item {\sf A.8. Advanced Array Input \& Output.}
			\item {\sf A.9. Performance Tips.}
		\end{itemize}
		\item {\sf B. More on IPython System.}
		\begin{itemize}
			\item {\sf B.1. Terminal Keyboard Shortcuts.}
			\item {\sf B.2. About Magic Commands.}
			\item {\sf B.3. Using Command History.}
			\item {\sf B.4. Interacting with OS.}
			\item {\sf B.5. Software Development Tools.}
			\item {\sf B.6. Tips for Productive Code Development Using IPython.}
			\item {\sf B.7. Advanced IPython Features.}
			\item {\sf B.8. Conclusion.}
		\end{itemize}
	\end{itemize}	
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Miscellaneous}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}