\documentclass{article}
\usepackage[backend=biber,natbib=true,style=alphabetic,maxbibnames=50]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[utf8]{vietnam}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,enumitem,float,graphicx,mathtools,tikz}
\usetikzlibrary{angles,calc,intersections,matrix,patterns,quotes,shadings}
\allowdisplaybreaks
\newtheorem{assumption}{Assumption}
\newtheorem{baitoan}{}
\newtheorem{cauhoi}{Câu hỏi}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{dangtoan}{Dạng toán}
\newtheorem{definition}{Definition}
\newtheorem{dinhly}{Định lý}
\newtheorem{dinhnghia}{Định nghĩa}
\newtheorem{example}{Example}
\newtheorem{ghichu}{Ghi chú}
\newtheorem{hequa}{Hệ quả}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{lemma}{Lemma}
\newtheorem{luuy}{Lưu ý}
\newtheorem{nhanxet}{Nhận xét}
\newtheorem{notation}{Notation}
\newtheorem{note}{Note}
\newtheorem{principle}{Principle}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{question}{Question}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{vidu}{Ví dụ}
\usepackage[left=1cm,right=1cm,top=5mm,bottom=5mm,footskip=4mm]{geometry}
\def\labelitemii{$\circ$}
\DeclareRobustCommand{\divby}{%
	\mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\title{Mathematical Optimization -- Toán Tối Ưu}
\author{Nguyễn Quản Bá Hồng\footnote{A Scientist {\it\&} Creative Artist Wannabe. E-mail: {\tt nguyenquanbahong@gmail.com}. Bến Tre City, Việt Nam.}}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
	This text is a part of the series {\it Some Topics in Advanced STEM \& Beyond}:
	
	{\sc url}: \url{https://nqbh.github.io/advanced_STEM/}.
	
	Latest version:
	\begin{itemize}
		\item {\it Mathematical Optimization -- Toán Tối Ưu}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/optimization/NQBH_mathematical_optimization.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/optimization/NQBH_mathematical_optimization.tex}.
	\end{itemize}
\end{abstract}
\tableofcontents

%------------------------------------------------------------------------------%

\section{Basic}

%------------------------------------------------------------------------------%

\section{Optimal Control -- Điều Khiển Tối Ưu}

%------------------------------------------------------------------------------%

\section{Shape Optimization -- Tối Ưu Hình Dạng}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Allaire_Henrot2001}. {\sc Gr\'egoire Allaire, Antoine Henrot}. {\it On some recent advances in shape optimization}.
	\item \cite{Azegami2020}. {\sc Hideyuki Azegami}. {\it Shape Optimization Problems}.
	\item \cite{Bandle_Wagner2023}. {\sc Catherine Bandle, Alfred Wagner}. {\it Shape Optimization: Variations of Domains \& Applications}.
	\item \cite{Delfour_Zolesio2001,Delfour_Zolesio2011}. {\sc Michael C. Delfour, Jean-Paul Zol\'{e}sio}. {\it Shapes \& Geometries}.
	\item \cite{Haslinger_Makinen2003}. {\sc J. Haslinger, R. A. E. M\"{a}kinen}. {\it Introduction to Shape Optimization}.
	\item \cite{Mohammadi_Pironneau2010}. {\sc Bijan Mohammadi, Olivier Pironneau}. {\it Applied Shape Optimization for Fluids}.
	\item \cite{Moubachir_Zolesio2006}. {\sc Marwan Moubachir, Jean-Paul Zol\'{e}sio}. {\it Moving Shape Analysis \& Control}.
	\item {\sc Stephan Schmidt}. Master course: {\it Shape \& Geometry}. Humboldt University of Berlin. [written in German, taught in English \& German].
	\item \cite{Sokolowski_Zolesio1992}. {\sc Jan Soko\l owski, Jean-Paul Zol\'{e}sio}. {\it Introduction to Shape Optimization}.
	\item \cite{Walker2015}. {\sc Shawn W. Walker}. {\it The Shapes of Things}.
	
	{\bf Differential equations on surfaces.} Differential geometry is useful for understanding mathematical models containing geometric PDEs, e.g., surface{\tt/}manifold version of the standard Laplace equation, which requires the development of the surface gradient \& surface Laplacian operators -- the usual gradient $\nabla$ \& Laplacian $\Delta = \nabla\cdot\nabla$ operators defined on a surface (manifold) instead of standard Euclidean space $\mathbb{R}^n$. {\it Advantage}: provide alternative formulas for geometric quantities, e.g., the summed (mean) curvature, that are much clearer than the usual presentation of texts on differential geometry.
	
	{\bf Differentiating w.r.t. Shape.} The approach to differential geometry is advantageous for developing the framework of {\it shape differential calculus} -- the study of how quantities change w.r.t. changes of independent ``shape variable''.
	
	``The framework of shape differential calculus provides the tools for developing the equations of mean curvature flow \& Willmore flow, which are geometric flows occurring in many applications such as fluid dynamics \& biology.'' -- \cite[p. 2]{Walker2015}
	
	The shape perturbation $\delta J(\Omega;V)$ is similar to the gradient operator, which is a directional derivative, analogous to $V\cdot\nabla f$ where $V$ is a given direction, providing information about the local slope, or the sensitivity of a quantity w.r.t. some parameters.
	
	It takes only 2 or 3 numbers to specify a point $(x,y)$ in 2D \& a point $(x,y,z)$ in 3D, whereas an ``infinite'' number of coordinate pairs is needed to specify a domain $\Omega$. $V$ is a 2D{\tt/}3D vector in the scalar function setting; for a shape functional, $V$ is a full-blown function requiring definition at every point in $\Omega$. This ``infinite dimensionality'' is the reason for using the notation $\delta J(\Omega;V)$ to denote a shape perturbation. $\delta J(\Omega;V)$ indicates how we should change $\Omega$ to decrease $J$, similarly to how $\nabla f(x,y)$ indicates how the coordinate pair $(x,y)$ should change to decrease $f$, which opens up the world of shape optimization.
	
	{\bf3 schools of shape optimization.} Cf. engineering shape optimization vs. applied shape optimization \cite{Mohammadi_Pironneau2010} vs. theoretical shape optimization \cite{Sokolowski_Zolesio1992,Delfour_Zolesio2011}.
\end{enumerate}

\begin{example}[\cite{Walker2015}, Sect. 1.2.1, pp. 1--2]
	Let $f = f(r,\theta)$ be a smooth function defined on the disk $B_{R,2}(0,0)$ of radius $R$ in terms of polar coordinates. The integral of $f$ over $B_{2,R}(0,0)$ $J\coloneqq\int_{B_{2,R}(0,0)} f\,{\rm d}{\bf x} = \int_0^{2\pi}\int_0^R f(r,\theta)\,{\rm d}r\,{\rm d}\theta$ depends on $R$. Assume $f$ also depends on $R$, i.e., $f = f(r,\theta,R)$ with a physical example: $J$ is the \emph{net flow rate} of liquid through a pipe with cross-section $\Omega$, then $f$ is the flow rate per unit area \& could be the solution of a PDE defined on $\Omega$, e.g., a Navier--Stokes fluid flowing in a circular pipe. Advantageous to know the \emph{sensitivity} of $J$ w.r.t. $R$, e.g., for optimization purposes. Differentiate $J$ w.r.t. $R$:
	\begin{equation*}
		\frac{d}{dR}J = \int_0^{2\pi}\left(\frac{d}{dR}\int_0^R f(r,\theta;R)r\,{\rm d}r\right){\rm d}\theta = \int_0^{2\pi}\int_0^R f'(r,\theta;R)r\,{\rm d}r\,{\rm d}\theta + \int_0^{2\pi} f(R,\theta;R)\,{\rm d}\theta.
	\end{equation*}
	The dependence of $f$ on $R$ can more generally be viewed as dependence on $B_{R,2}(0,0)$, i.e., $f(\cdot;R)\equiv f(\cdot;B_{R,2}(0,0))$. Rewriting $d/dR J$ using Cartesian coordinates ${\bf x}$:
	\begin{equation}
		\frac{d}{dR}J = \int_{B_{R,2}(0,0)} f'({\bf x};\Omega)\,{\rm d}{\bf x} + \int_{S_{R,2}(0,0)} f({\bf x};\Omega)\,{\rm d}S({\bf x}),
	\end{equation}
	where ${\rm d}{\bf x}$ is the volume measure, ${\rm d}S({\bf x})$ is the surface area measure.
\end{example}

\begin{example}[Surface height function of a hill]
	Let $f = f(x,y)$ be a function describing the surface height of the hill, where $(x,y)$ are the coordinates of our position. Then, by using basic multivariate calculus, finding a direction that will move us downhill is equivalent to computing the gradient (vector) of $f$ \& moving in the opposite direction to the gradient. In this sense, we do not need to ``see'' the whole function. We just need to \emph{locally} compute the gradient $\nabla f$, analogous to feeling the ground beneath.
\end{example}

%------------------------------------------------------------------------------%

\section{Topology Optimization -- Tối Ưu Tôpô}

%------------------------------------------------------------------------------%

\section{Miscellaneous}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}