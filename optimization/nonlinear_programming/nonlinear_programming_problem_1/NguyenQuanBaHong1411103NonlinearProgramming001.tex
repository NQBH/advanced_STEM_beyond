\documentclass[a4paper]{article}
\usepackage{longtable,float,hyperref,color,amsmath,amsxtra,amssymb,latexsym,amscd,amsthm,amsfonts,graphicx}
\numberwithin{equation}{section}
\allowdisplaybreaks
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[RE,LO]{\footnotesize \textsc \leftmark}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0.5pt}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\usepackage{imakeidx}
\makeindex[columns=2, title=Alphabetical Index, 
           options= -s index.ist]
\title{\huge Nonlinear Programming Assignment 001}
\author{\textsc{Nguyen Quan Ba Hong}\footnote{Student ID: 1411103.}\\
{\small Students at Faculty of Math and Computer Science,}\\ 
{\small Ho Chi Minh University of Science, Vietnam} \\
{\small \texttt{email. nguyenquanbahong@gmail.com}}\\
{\small \texttt{blog. \url{www.nguyenquanbahong.com}} 
\footnote{Copyright \copyright\ 2016-2017 by Nguyen Quan Ba Hong, Student at Ho Chi Minh University of Science, Vietnam. This document may be copied freely for the purposes of education and non-commercial research. Visit my site \texttt{\url{www.nguyenquanbahong.com}} to get more.}}}
\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
\section{Problems}
\textbf{Problem 1.} \textit{Let $f:\mathbb{R}\to \mathbb{R}^2$ be a mapping defined by}
\begin{align}
\label{1.1}
f\left( x \right) = \left\{ {\begin{array}{*{20}{c}}
{\left( {x,{x^2}} \right)\mbox{ if } x \ne 0},\\
{\left( {0,0} \right)\hspace{0.3cm}\mbox{ if } x = 0}.
\end{array}} \right.
\end{align}
\begin{enumerate}
\item \textit{Is $f$ directional differentiable at $x_0 =0$?}
\item \textit{Is $f$ G\^{a}teaux differentiable at $x_0 =0$?}
\item \textit{Is $f$ Fr\'{e}chet differentiable at $x_0=0$?}
\end{enumerate}
\textsc{Solution.} 
\begin{enumerate}
\item Let $d\in \mathbb{R}$, at $x_0 =0$, we have
\begin{align}
\mathop {\lim }\limits_{t \to 0} \frac{{f\left( {{x_0} + td} \right) - f\left( {{x_0}} \right)}}{t} &= \mathop {\lim }\limits_{t \to 0} \frac{{f\left( {td} \right) - f\left( 0 \right)}}{t}\\
& = \mathop {\lim }\limits_{t \to 0} {\left( {d,t{d^2}} \right)^T}\\
& = {\left( {d,0} \right)^T},
\end{align}
i.e., $f$ is directional differentiable at $x_0=0$ and its directional derivative is given by $f'\left( {0;d} \right) = \left( {d,0} \right)^T$.
\item We write the vector-valued function $f:\mathbb{R} \to {\mathbb{R}^2}$ defined by \eqref{1.1} as
\begin{align}
f\left( x \right) = \left( {\begin{array}{*{20}{c}}
{{f_1}\left( x \right)}\\
{{f_2}\left( x \right)}
\end{array}} \right),
\end{align}
where the coordinate functions of $f$ are given by $f_1\left(x\right)=x,f_2\left(x\right)=x^2$. From the above result, we have
\begin{align}
f'\left( {0;d} \right) = \left( {d,0} \right) = \left( {\begin{array}{*{20}{c}}
1\\
0
\end{array}} \right)d ,\hspace{0.2cm} \forall d\in \mathbb{R},
\end{align}
which is linear in $d$. Hence, $f$ is G\^{a}teaux differentiable at $x_0=0$. 
\item Since $f$ is Fr\'{e}chet differentiable at $x$ if and only if each coordinate function $f_i$ is. So it suffices to prove that $f_1,f_2$ are Fr\'{e}chet continuous at $x_0=0$. This is obvious since $f_1,f_2 \in C^{\infty}\left(\mathbb{R}\right)$. Hence, $f$ is Fr\'{e}chet differentiable at $x_0=0$. Moreover, $Df\left( 0 \right) = \left( {{f_1}'\left( 0 \right),{f_2}'\left( 0 \right)} \right) = \left( {1,0} \right)$.
\end{enumerate}
This completes our solution. \hfill $\square$\\
\\
\textbf{Problem 2.} \textit{Let $f:\mathbb{R}^2\to \mathbb{R}$ be a mapping defined by}
\begin{align}
f\left( {x,y} \right) = \left\{ {\begin{array}{*{20}{c}}
{\dfrac{{{x^2}{y^4}}}{{{x^4} + {y^8}}}\mbox{ if }\left( {x,y} \right) \ne \left( {0,0} \right),}\\
{0 \hspace{1cm}\mbox{ if } \left( {x,y} \right) = \left( {0,0} \right).}
\end{array}} \right.
\end{align}
\begin{enumerate}
\item \textit{Is $f$ directional differentiable at $x_0 =\left(0,0\right)$?}
\item \textit{Is $f$ G\^{a}teaux differentiable at $x_0 =\left(0,0\right)$?}
\item \textit{Is $f$ Fr\'{e}chet differentiable at $x_0=\left(0,0\right)$?}
\end{enumerate}
\textsc{Solution.} 
\begin{enumerate}
\item Let $d\in \mathbb{R}^2$ be a vector $d=\left(d_1,d_2\right)^T$, and $x_0 =\left(0,0\right)$. If $d=\left(0,0\right)$, we have $f'\left( {{x_0};\left( {0,0} \right)} \right) = 0$ by the definition of directional derivative. If $d\ne \left(0,0\right)$, we compute
\begin{align}
\mathop {\lim }\limits_{t \to 0} \frac{{f\left( {{x_0} + td} \right) - f\left( {{x_0}} \right)}}{t} &= \mathop {\lim }\limits_{t \to 0} \frac{{f\left( {t{d_1},t{d_2}} \right) - f\left( {0,0} \right)}}{t}\\
 &= \mathop {\lim }\limits_{t \to 0} \frac{{td_1^2d_2^4}}{{d_1^4 + {t^4}d_2^8}}. \label{1.9}
\end{align}
We consider the following two cases depending on $d_1$. If $d_1=0$, then the limit in \eqref{1.9} equals $0$. If $d_1\ne 0$, we estimate this limit as follows.
\begin{align}
\mathop {\lim }\limits_{t \to 0} \left| {\frac{{td_1^2d_2^4}}{{d_1^4 + {t^4}d_2^8}}} \right| \le \mathop {\lim }\limits_{t \to 0} \frac{{\left| t \right|d_1^2d_2^4}}{{d_1^4}} = 0,
\end{align}
i.e., the limit in \eqref{1.9} also equals $0$ in this case. Combining both cases, we deduce that $f$ is directional differentiable at $x_0$ and its directional derivative is given by $f'\left( {{x_0};d} \right) = 0$ for all $d \in {\mathbb{R} ^2}$. 
\item From the above result, we have
\begin{align}
f'\left( {{x_0};d} \right) = 0 = \left( {\begin{array}{*{20}{c}}
0&0
\end{array}} \right)d ,\hspace{0.2cm} \forall d\in \mathbb{R}^2,
\end{align}
which is linear in $d$. Hence, $f$ is G\^{a}teaux differentiable at $x_0=\left(0,0\right)$. 
\item We claim that $f$ is not Fr\'{e}chet differentiable at $x_0=\left(0,0\right)$. To this end, we suppose for the contrary that $f$ is Fr\'{e}chet differentiable at $x_0=\left(0,0\right)$, by definition, there exists a linear function $l:\mathbb{R}^2\to \mathbb{R}$, $l\left( x \right) = \left\langle {l,x} \right\rangle  = {l_1}{x_1} + {l_2}{x_2}$ such that 
\begin{align}
\label{1.12}
\mathop {\lim }\limits_{\left\| h \right\| \to 0} \frac{{f\left( {{x_0} + h} \right) - f\left( {{x_0}} \right) - \left\langle {l,h} \right\rangle }}{{\left\| h \right\|}} = 0.
\end{align}
Denote $h=\left(h_1,h_2\right)^T \in \mathbb{R}^2$, then \eqref{1.12} becomes
\begin{align}
\label{1.13}
\mathop {\lim }\limits_{\left\| h \right\| \to 0} \frac{1}{{\left\| h \right\|}}\left( {\frac{{h_1^2h_2^4}}{{h_1^4 + h_2^8}} - {l_1}{h_1} - {l_2}{h_2}} \right) = 0.
\end{align}
In particular, if we take $h=\left(h_1,0\right)$ for which $h_1 \ne 0$ and $h_1\to 0$, then \eqref{1.13} gives $ \mathop {\lim }\limits_{{h_1} \to 0} \frac{{{l_1}{h_1}}}{{\left| {{h_1}} \right|}} = 0$, i.e., $l_1 =0$. Similarly, taking  $h=\left(0,h_2\right)$ for which $h_2 \ne 0$ and $h_2\to 0$ gives $l_2 =0$. Substituting $l_1=l_2=0$ back to \eqref{1.13} gives
\begin{align}
\label{1.14}
\mathop {\lim }\limits_{\left\| h \right\| \to 0} \frac{{h_1^2h_2^4}}{{\left( {h_1^4 + h_2^8} \right)\sqrt {h_1^2 + h_2^2} }} = 0.
\end{align}
But \eqref{1.14} is not true since, for instance, taking $h_2^2=h_1$ in \eqref{1.14}, i.e., $h=\left(h_1,\sqrt{h_1}\right)$, gives
\begin{align}
\label{1.15}
\mathop {\lim }\limits_{{h_1} \to 0} \frac{1}{{2\sqrt {h_1^2 + {h_1}} }} = 0,
\end{align}
which is absurd, since the limit in the left-hand side of \eqref{1.15} is $+\infty$. 
\end{enumerate}
This contradiction ends our proof. \hfill $\square$\\
\\
\textbf{Problem 3.} \textit{Let $X$ be a normed space, $M\subset X$ and $x_0\in X$. The contingent cone (or tangent cone, Bouligand cone) of $M$ at $x_0$ is defined by the following formula}
\begin{align}
\label{1.16}
T\left( {M,{x_0}} \right) = \left\{ {u \in X|\exists {t_n} \to {0^ + },{u_n} \to u,{x_0} + {t_n}{u_n} \in M,\hspace{0.2cm}\forall n \in \mathbb{N}} \right\}.
\end{align}
\textit{By this definition, compute the following contingent cones of}
\begin{enumerate}
\item $M = \left\{ {\left( {{x_1},{x_2}} \right) \in {\mathbb{R}^2}|x_1^3 + x_2^2 = 0} \right\}$ and $x_0 =\left(0,0\right)$.
\item $M = \left\{ {\left( {{x_1},{x_2}} \right) \in {\mathbb{R}^2}|{x_1} + {x_2} \ge 2,{x_2} \le x_1^3} \right\}$ and $x_0 =\left(1,1\right)$.
\end{enumerate}
\textsc{Solution.} An alternative definition of \textit{tangent cone} can be found in \cite{1}, Def. 2.28, p.47.
\begin{enumerate}
\item Setting $X=\mathbb{R}^2$, we notice $x_0 =\left(0,0\right) \in M$. We claim that 
\begin{align}
\label{1.17}
T\left( {M,{x_0}} \right) = \widehat T\left( {M,{x_0}} \right): = \left\{ {\left( {x,0} \right) \in {\mathbb{R} ^2}|x \le 0} \right\}.
\end{align}
To prove \eqref{1.17}, we prove the following inclusions. 
\begin{enumerate}
\item \textit{Prove $T\left( {M,{x_0}} \right) \subset \widehat T\left( {M,{x_0}} \right)$.} Taking $u = \left( {x,y} \right) \in T\left( {M,{x_0}} \right)$, by definition \eqref{1.16}, there exist a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty$ such that  $t_n\to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset {\mathbb{R}^2}$ such that $u_n\to u$ as $n\to \infty$ and ${x_0} + t_n{u_n} \in M$ for all $n\in \mathbb{N}$. Set $u_n:=\left(x_n,y_n\right)$, the fact $u_n\to u$ implies that $x_n\to x$ and $y_n\to y$, and the fact $x_0 + t_nu_n \in M$ for all $n\in \mathbb{N}$ gives
\begin{align}
\label{1.18}
t_n^3x_n^3 + t_n^2y_n^2 = 0, \hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
Since $t_n >0$ for all $n\in \mathbb{N}$, \eqref{1.18} then implies
\begin{align}
\label{1.19}
{t_n}x_n^3 + y_n^2 = 0, \hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
We see at a glance from \eqref{1.19} that $x_n \le 0$ for all $n\in \mathbb{N}$. Hence, $x\le 0$ (since $x_n \to x$ as $n\to \infty$). Now let $n\to \infty$ in \eqref{1.19} and use the given limits $x_n\to x, y_n\to y$ and $t_n\to 0^+$, we obtain $y=0$. Hence, $u \in \widehat T\left(M,x_0\right)$ and our first inclusion is proved.
\item \textit{Prove $\widehat T\left( {M,{x_0}} \right) \subset T\left( {M,{x_0}} \right)$.} Taking $u = \left( {x,0} \right)$ satisfying $x\le 0$, we claim that $u \in T\left(M,{x_0}\right)$. To this end, we now choose ${x_n} = x - \frac{1}{n} < 0,{y_n} = \frac{1}{{{n^2}}}$\footnote{If $x<0$, we can choose $x_n=x,y_n=\frac{1}{n}$ and then \eqref{1.19} gives $t_n=-\frac{1}{n^2x^3} \to 0^+$ as $n\to \infty$, as desired. Unfortunately, this choice does not work for $x=0$, so we used the above choice.}. This choice ensures that $u_n:=\left(x_n,y_n\right)\to u:=\left(x,0\right)$ as $n\to \infty$. It then suffices to prove that there exists a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n \to 0^+$ and $x_0+t_nu_n\in M$ for all $n\in \mathbb{N}$. The latter gives, using \eqref{1.19} again, 
\begin{align}
{t_n}{\left( {x - \frac{1}{n}} \right)^3} + \frac{1}{{{n^4}}} = 0,\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
i.e., 
\begin{align}
{t_n} =  - \frac{1}{{{n^4}{{\left( {x - \frac{1}{n}} \right)}^3}}},\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
It is easy to check that $t_n>0$ (since $x\le 0$) and $t_n \to 0^+$ as $n\to \infty$.\footnote{If $x=0$, then $t_n=\frac{1}{n}\to 0$ as $n\to \infty$. If $x<0$, then ${t_n} \to  - \frac{1}{{{x^3}}}\mathop {\lim }\limits_{n \to \infty } \frac{1}{{{n^4}}} = 0$.} Hence, $u\in T\left(M,x_0\right)$, the second inclusion is also proved.
\end{enumerate}
Combining these, we conclude that \eqref{1.17} holds, i.e., 
\begin{align}
T\left( {M,{x_0}} \right) = \left\{ {\left( {x,0} \right) \in {\mathbb{R}^2}|x \le 0} \right\}.
\end{align}
\item Let $X=\mathbb{R}^2$ again, note that $x_0=\left(1,1\right)\in M$, we claim that
\begin{align}
\label{1.23}
T\left( {M,{x_0}} \right) = \widehat T\left( {M,{x_0}} \right): = \left\{ {\left( {{x_1},{x_2}} \right) \in {\mathbb{R}^2}|{x_1} + {x_2} \ge 0,{x_2} \le 3{x_1}} \right\}.
\end{align}
We also prove the following two inclusions as before.
\begin{enumerate}
\item \textit{Prove $T\left( {M,{x_0}} \right) \subset \widehat T\left( {M,{x_0}} \right)$.} Taking $u=\left(x,y\right) \in T\left(M,x_0\right)$, by \eqref{1.16}, there exist a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset {\mathbb{R}^2}$ such that $u_n\to u$ as $n\to \infty$ and $x_0+t_nu_n\in M$ for all $n\in \mathbb{N}$. Set $u_n:=\left(x_n,y_n\right)$, the fact $u_n\to u$ implies that $x_n\to x$ and $y_n\to y$, and the fact $x_0 + t_nu_n =\left(1+t_nx_n,1+t_ny_n\right) \in M$ for all $n\in \mathbb{N}$ gives
\begin{align}
\label{1.24}
\left( {1 + {t_n}{x_n}} \right) + \left( {1 + {t_n}{y_n}} \right) \ge 2\mbox{ and } 1 + {t_n}{y_n} \le {\left( {1 + {t_n}{x_n}} \right)^3},
\end{align}
for all $n \in \mathbb{N}$, equivalently,\footnote{It can be deduced from \eqref{1.24} that $ {t_n}\left( {{x_n} + {y_n}} \right) \ge 0$. Since $t_n\to 0^+$, $t_n>0$ for all $n\in \mathbb{N}$ and the factor $t_n$ can be dropped as in \eqref{1.25}.}
\begin{align}
\label{1.25}
{x_n} + {y_n} \ge 0\mbox{ and } {y_n} \le 3{x_n} + 3{t_n}x_n^2 + t_n^2x_n^3,\hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
Now let $n\to \infty$ in \eqref{1.25} and use the given limits $x_n\to x,y_n\to y$ and $t_n\to 0^+$, we obtain $x+y\ge 0$ and $y\le 3x$. Hence, $u\in \widehat T\left(M,x_0\right)$ and our first inclusion is proved.
\item \textit{Prove $\widehat T\left( {M,{x_0}} \right) \subset T\left( {M,{x_0}} \right)$.} Taking $u=\left(x,y\right)\in \widehat T\left(M,x_0\right)$, i.e., $x,y$ satisfy $x+y\ge 0$ and $y\le 3x$, we claim that $u\in T\left(M,x_0\right)$. To this end, first notice $4x\ge x+y\ge 0$, so $x\ge 0$. We then choose $u_n=\left(x_n,y_n\right)$ where $x_n=x+\frac{1}{n}\ge \frac{1}{n},y_n=y$ and $t_n\to 0^+$ arbitrarily, so that $u_n\to u$ as $n\to \infty$. It is easy to check that \eqref{1.25} holds for chosen $x_n,y_n$ and $t_n$:
\begin{align}
{x_n} + {y_n} &= x + y + \frac{1}{n} \ge \frac{1}{n} > 0,\\
3{x_n} + 3{t_n}x_n^2 + t_n^2x_n^3 &= 3x + \frac{3}{n} + 3{t_n}x_n^2 + t_n^2x_n^3 > 3x \ge y = {y_n}.
\end{align} 
Hence, $u\in T\left(M,x_0\right)$, the second inclusion is also proved.
\end{enumerate}
Combining these cases, we conclude that \eqref{1.23} holds, i.e.,
\begin{align}
\label{1.28}
T\left( {M,{x_0}} \right) = \left\{ {\left( {{x_1},{x_2}} \right) \in {\mathbb{R}^2}|{x_1} + {x_2} \ge 0,{x_2} \le 3{x_1}} \right\}.
\end{align}
\end{enumerate}
This completes our proof. \hfill $\square$\\

The following exercise will show us some properties of contingent cone of first order.\\
\\
\textbf{Problem 4.} \textit{Let $X$ be a normed space, $M\subset X$ and $x_0 \in X$.}
\begin{enumerate}
\item \textit{If $T\left(M,x_0\right) \ne \emptyset$ then $x_0 \in \overline{M}$ (where $\overline{M}$ is the closure of the set $M$).}
\item \textit{$T\left(M,x_0\right)$ is a closed cone.}
\item \textit{$T\left( {M,{x_0}} \right) \subset \overline {\mbox{cone}\left( {M - {x_0}} \right)}$.}

\textit{Moreover, if $M$ is a convex set then}
\item $T\left( {M,{x_0}} \right) = \overline {\mbox{cone}\left( {M - {x_0}} \right)} $, and hence, $T\left(M,x_0\right)$ is a convex set.
\item $T\left( {M,{x_0}} \right) = \left\{ {v \in X|\forall {t_n} \to {0^ + },\forall {v_n} \to v,{x_0} + {t_n}{v_n} \in M} \right\}$.
\end{enumerate}
\textsc{Solution.}
\begin{enumerate}
\item Suppose that $T\left( {M,{x_0}} \right) \ne \emptyset $, we can take, for instance, $u\in T\left(M,x_0\right)$. Then there exist a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n \to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset X$ such that $u_n\to u$ and $x_0+t_n u_n\in M$ for all $n\in \mathbb{N}$. Set $x_n:=x_0+t_nu_n \in M$. Since $u_n\to u$, there exists $N\in \mathbb{N}$ such that 
\begin{align}
n \ge N \Rightarrow \left\| {{u_n} - u} \right\| \le 1.
\end{align}
We now prove that $x_n\to x_0$ as $n\to \infty$. Indeed, for $n\ge N$,
\begin{align}
\label{1.30}
\left\| {{x_n} - {x_0}} \right\| = \left\| {{t_n}{u_n}} \right\| = {t_n}\left\| {{u_n}} \right\| \le {t_n}\left( {\left\| u \right\| + 1} \right).
\end{align}
Since $t_n\to 0^+$, \eqref{1.30} implies that $x_n \to x_0$ as $n\to \infty$, i.e., $x_0\in \overline{M}$. 
\item We first prove that $T\left(M,x_0\right)$ is a cone. Let $u\in T\left(M,x_0\right)$ arbitrarily, we need to prove that $tu\in T\left(M,x_0\right)$ for all $t>0$. By \eqref{1.16}, there exist a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset X$ such that $u_n\to u$ and ${x_0} + {t_n}{u_n} \in M$ for all $n\in \mathbb{N}$. Fix $t>0$ arbitrarily, if we set ${v_n}: = t{u_n}$ and ${s_n} = \frac{{{t_n}}}{t}$ for all $n\in \mathbb{N}$, then $s_n\to 0^+$, ${v_n} \to tu$ and ${x_0} + {s_n}{v_n} = {x_0} + {t_n}{u_n} \in M$ for all $n\in \mathbb{N}$, i.e., $tu\in T\left(M,x_0\right)$. Since $t>0$ and $u\in T\left(M,x_0\right)$ are chosen arbitrarily, this implies that $T\left(M,x_0\right)$ is a cone. 

To prove that $T\left(M,x_0\right)$ is closed, let $\left\{ {{u_n}} \right\}_{m = 0}^\infty  \subset T\left( {M,{x_0}} \right)$ such that $u_m \to u$ as $m\to \infty$. We need to prove that $u\in T\left(M,x_0\right)$. To this end, by definition \eqref{1.16}, for each $m\in \mathbb{N}$, there exist a sequence $t_{m,n} \to 0^+$ as $n\to \infty$ and a sequence $\left\{ {{u_{m,n}}} \right\}_{n = 0}^\infty  \subset X$ such that $u_{m,n}\to u_m$ as $n\to \infty$ and $x_0+t_{m,n}u_{m,n} \in M$ for all $n\in \mathbb{N}$, in addition, $\left\| {{u_{m,m}} - {u_m}} \right\| \le \frac{1}{m}$ for all $m\in \mathbb{N}$\footnote{This is possible, since for each $m\in \mathbb{N}$, there exists a sequence $\left\{ {{u_{m,n}}} \right\}_{n = 0}^\infty  \subset X$ such that $u_{m,n}\to u_m$ as $n\to \infty$. By definition of limits, there exists $N\in \mathbb{N}$ such that 
\begin{align}
n \ge N \Rightarrow \left\| {{u_{m,n}} - {u_m}} \right\| \le \frac{1}{m}.
\end{align}
Hence, we can drop all the terms $u_{m,1},\ldots,u_{m,n-1}$ from the sequence. Re-indexing ${\widehat u_{m,n}}: = {u_{m,N + n - 1}}$ for all $n\in \mathbb{N}$, we have, in particular, 
\begin{align}
\left\| {{{\widehat u}_{m,m}} - {u_m}} \right\| = \left\| {{{\widehat u}_{m,N + m - 1}} - {u_m}} \right\| \le \frac{1}{m}.
\end{align}
We now ignore the old sequence $\left\{ {{u_{m,n}}} \right\}_{n = 0}^\infty $ and use the new sequence, by abuse notation, $\left\{ {{u_{m,n}}} \right\}_{n = 0}^\infty $ which is exactly $\left\{ {{{\widehat u}_{m,n}}} \right\}_{n = 0}^\infty $ just defined.}. We claim that
\begin{align}
\label{1.33}
{u_{m,m}} \to u \mbox{ and } {x_0} + {t_{m,m}}{u_{m,m}} \in M,\hspace{0.2cm}\forall m \in \mathbb{N}.
\end{align} 
The latter is obvious since ${x_0} + {t_{m,n}}{u_{m,n}} \in M$ for all $m,n \in \mathbb{N}$. We now prove the former in \eqref{1.33}. With the help of triangle inequality for the norm of $X$, 
\begin{align}
\left\| {{u_{m,m}} - u} \right\| &\le \left\| {{u_{m,m}} - {u_m}} \right\| + \left\| {{u_m} - u} \right\|\\
& \le \frac{1}{m} + \left\| {{u_m} - u} \right\| \to 0\mbox{ as } m \to \infty ,
\end{align}
i.e., $u\in T\left(M,x_0\right)$. Hence, $T\left(M,x_0\right)$ is a closed cone. 
\item The convex conical hull of $M-x_0$ is given by (see, e.g., \cite{1}, Def. 4.19, p.94)
\begin{align}
\label{1.36}
\mbox{cone}\left( {M - {x_0}} \right): = \left\{ {\sum\limits_{i = 1}^k {{\lambda _i}{x_i}} :{x_i} \in M - {x_0},{\lambda _i} > 0,k \ge 1} \right\}.
\end{align}
Take $u\in T\left(M,x_0\right)$ arbitrarily, we need to prove that $u \in \overline {\mbox{cone}\left( {M - {x_0}} \right)} $. By \eqref{1.16} again, there exist a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n \to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset X$ such that $u_n\to u$ and $x_0+t_n u_n\in M$ for all $n\in \mathbb{N}$. The fact that $x_0+t_nu_n\in M$ for all $n\in \mathbb{N}$ gives us $t_nu_n\in M- {x_0}$ for all $n\in \mathbb{N}$. Choosing $k = 1,{\lambda _1} = \frac{1}{{{t_n}}} > 0,{x_1} = {t_n}{u_n} \in M - {x_0}$ in \eqref{1.36} gives ${u_n} \in \mbox{cone}\left( {M - {x_0}} \right)$ for all $n\in \mathbb{N}$. Combining this with the fact that $u_n\to u$, we conclude that $u \in \overline {\mbox{cone}\left( {M - {x_0}} \right)} $. Therefore,
\begin{align}
\label{1.37}
T\left( {M,{x_0}} \right) \subset \overline {\mbox{cone}\left( {M - {x_0}} \right)} .
\end{align}
\item \textsc{First Proof.} We now assume (until the end of the proof of this problem) that $M$ is a convex set and $x_0\in M$\footnote{The definition of tangent cone in \cite{1} also requires this.}. To prove $T\left( {M,{x_0}} \right) = \overline {\mbox{cone}\left( {M - {x_0}} \right)} $, due to \eqref{1.37}, it suffices to prove that $T\left( {M,{x_0}} \right) \supset \overline {\mbox{cone}\left( {M - {x_0}} \right)} $. First, we need the following lemma (see, e.g., \cite{2}, Lemma 2.4.11, p.41).\\
\\
\textbf{Lemma 4.1.} \textit{Let $M$ be a nonempty convex set and $x_0\in M$. Then}
\begin{align}
M - {x_0} \subset T\left( {M,{x_0}} \right).
\end{align}
\textit{Proof of Lemma 4.1.} Let $u \in M$. We need to show that $u-{x_0} \in T\left(M,x_0\right)$. To this end, choose $\left\{ {{t_n}} \right\}_{n = 1}^\infty  \subset \left[ {0,1} \right]$ such that $t_n\to 0^+$, and put $u_n:=u-x_0$ (hence $u_n\to u-x_0$ obviously) and put
\begin{align}
{x_n}: &= {x_0} + {t_n}\left( {u - {x_0}} \right)\\
 &= \left( {1 - {t_n}} \right){x_0} + {t_n}u \in M ,\hspace{0.2cm} \forall n\in \mathbb{N},
\end{align}
as $M$ is convex. By \eqref{1.16}, $u-{x_0}\in T\left(M,x_0\right)$. \hfill $\square$\\

Return to our proof, since we have proved that $T\left(M,x_0\right)$ is a closed cone, we only need to prove prove that $T\left( {M,{x_0}} \right) \supset \mbox{cone}\left( {M - {x_0}} \right)$. Using the fact that the convex conical hull of an arbitrary nonempty set is the intersection of all closed convex cones that contain that sets, it suffices to prove that $T\left(M,x_0\right)$ is convex (and thus is a closed convex cone). Take $u,v\in T\left(M,x_0\right)$, we need to prove that $\lambda u + \left( {1 - \lambda } \right)v \in T\left( {M,{x_0}} \right)$ for all $\lambda \in \left[0,1\right]$. But since $T\left(M,x_0\right)$ is a cone, we deduce that $\lambda u \in T\left( {M,{x_0}} \right)$ and $\left( {1 - \lambda } \right)v \in T\left( {M,{x_0}} \right)$. Hence, it suffices to prove the following stronger statement\footnote{\textit{A cone $K$ is convex if and only if $K+K\subset K$.} (see, e.g., \cite{2}, Proposition 2.4.2, p.38.)}
\begin{align}
u + v \in T\left( {M,{x_0}} \right),\hspace{0.2cm} \forall u,v \in T\left( {M,{x_0}} \right).
\end{align}
By \eqref{1.16}, there exists sequences of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty ,\left\{ {{s_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and $s_n\to 0^+$ and sequences $\left\{ {{u_n}} \right\}_{n = 1}^\infty ,\left\{ {{v_n}} \right\}_{n = 1}^\infty $ such that $u_n\to u,v_n\to v$ and
\begin{align}
\label{1.42}
{x_0} + {t_n}{u_n} \in M,\hspace{0.2cm} {x_0} + {s_n}{v_n} \in M ,\hspace{0.2cm} \forall n\in \mathbb{N}.
\end{align}
Since $M$ is convex, it is deduced from \eqref{1.42} that
\begin{align}
\label{1.43}
\alpha \left( {{x_0} + {t_n}{u_n}} \right) + \left( {1 - \alpha } \right)\left( {{x_0} + {s_n}{v_n}} \right) \in M, \hspace{0.2cm} \forall \alpha  \in \left[ {0,1} \right],n\in \mathbb{N}.
\end{align}
In particular, choosing $\alpha  = \frac{{{s_n}}}{{{t_n} + {s_n}}}$ in \eqref{1.43} gives
\begin{align}
{x_0} + \frac{{{t_n}{s_n}}}{{{t_n} + {s_n}}}\left( {{u_n} + {v_n}} \right) \in M, \hspace{0.2cm} \forall n  \in \mathbb{N}.
\end{align}
Hence, if we choose ${w_n}: = {u_n} + {v_n} \to u + v$ and ${r_n}: = \frac{{{t_n}{s_n}}}{{{t_n} + {s_n}}} \to {0^ + }$\footnote{Indeed, $0 < {r_n} = {t_n}\underbrace {\frac{{{s_n}}}{{{t_n} + {s_n}}}}_{ < 1} < {t_n} \to {0^ + }$ as $n\to \infty$.}. By \eqref{1.16}, $u+v \in T\left(M,x_0\right)$. This completes our proof. \hfill $\square$\\
\\
\textsc{Second Proof.} We have the following result (see, e.g., \cite{2}, Proposition 2.4.8, p.40)
\begin{align}
\mbox{cone}S = {\mathbb{R}_ + }\left( {\mbox{conv}S} \right) = \mbox{conv} \left( {{\mathbb{R}_ + }S} \right),
\end{align}
for an arbitrary nonempty set $S$. Since $M$ is convex, $M-x_0$ is also convex (as a Minkowski sum of convex sets), hence $\mbox{conv}\left( {M - {x_0}} \right) = M - {x_0}$ (see \cite{1}, Corollary 4.12, p.91) and 
\begin{align}
\overline {\mbox{cone}\left( {M - {x_0}} \right)}  = \overline {{\mathbb{R}_ + }\left( {\mbox{conv}\left( {M - {x_0}} \right)} \right)}  = \overline {{\mathbb{R}_ + }\left( {M - {x_0}} \right)}.
\end{align}
It suffices to prove $\overline {{\mathbb{R}_ + }\left( {M - {x_0}} \right)}  \subset T\left( {M,{x_0}} \right)$. By Lemma 4.1, we have $M - {x_0} \subset T\left( {M,{x_0}} \right)$. Since $T\left(M,x_0\right)$ is a closed cone, this yields $\overline {{\mathbb{R}_ + }\left( {M - {x_0}} \right)}  \subset T\left( {M,{x_0}} \right)$. A direct consequence of this fact is that $T\left(M,x_0\right)$ is a closed convex cone.
\item \textit{(Need correcting)} Suppose the set in the right-hand side is nonempty, i.e., there exists $v\in X$ such that 
\begin{align}
\label{1.47}
\forall {t_n} \to {0^ + },\forall {v_n} \to v,{x_0} + {t_n}{v_n} \in M,\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
If we take $t_1$ and $v_1$ arbitrarily, then $x_0+t_1 v_1$ still belongs to $M$. Hence, $M=X$? Should \eqref{1.47} be corrected as ``$\forall {t_n} \to {0^ + },\forall {v_n} \to v,{x_0} + {t_n}{v_n} \in M$ \textit{for $n$ large enough}''? This problem needs correcting.
\end{enumerate}
We end our proof. \hfill $\square$\\
\\
\textbf{Problem 5 (Formula for computing contingent cone of a system of constrained inequalities).} \textit{Suppose $g_i:\mathbb{R}^n \to \mathbb{R}$ are Fr\'{e}chet differentiable functions for all $i=1,\ldots,m$. The set $M$ is defined by}
\begin{align}
M = \left\{ {x \in {\mathbb{R}^n}|{g_i}\left( x \right) \le 0,\hspace{0.2cm}\forall i = 1, \ldots ,m} \right\}.
\end{align}
\textit{Take $x_0 \in M$, set the index set}
\begin{align}
I\left( {{x_0}} \right) = \left\{ {i \in \left\{ {1, \ldots ,m} \right\}|{g_i}\left( {{x_0}} \right) = 0} \right\}.
\end{align}
\textit{Then, we have}
\begin{enumerate}
\item \textit{If $I\left(x_0\right) =\emptyset$ then $T\left(M,x_0\right) = \mathbb{R}^n$.}
\item \textit{If $I\left(x_0\right) \ne \emptyset$ then}
\begin{align}
\label{1.50}
T\left( {M,{x_0}} \right) \subset \left\{ {v \in {\mathbb{R}^n}|\nabla {g_i}\left( {{x_0}} \right)\left( v \right) \le 0, \hspace{0.2cm} \forall i \in I\left( {{x_0}} \right)} \right\}.
\end{align}
\item \textit{Moreover, if the following condition is satisfied}
\begin{align}
\label{1.51}
\exists \bar v \in {\mathbb{R}^n}\mbox{ s.t. }\nabla {g_i}\left( {{x_0}} \right)\left( {\bar v} \right) < 0,\hspace{0.2cm}\forall i \in I\left( {{x_0}} \right),
\end{align}
\textit{then we have}
\begin{align}
\label{1.52}
T\left( {M,{x_0}} \right) = \left\{ {v \in {\mathbb{R}^n}|\nabla {g_i}\left( {{x_0}} \right)\left( v \right) \le 0,\hspace{0.2cm} \forall i \in I\left( {{x_0}} \right)} \right\},
\end{align}
\textit{where ${\nabla {g_i}\left( {{x_0}} \right)\left( v \right)}$ is Fr\'{e}chet derivative of $g_i$ at $x_0$ applying to vector $v$.}
\end{enumerate}
\textsc{Solution.} 
\begin{enumerate}
\item We assume $I\left(x_0\right)=\emptyset$, i.e., $g_i\left(x_0\right) <0$ for all $i=1,\ldots,m$. For each $i \in \left\{ {1, \ldots ,m} \right\}$, since $g_i$ is Fr\'{e}chet differentiable and thus continuous, there exists $\delta _i>0$ such that
\begin{align}
x \in {B_{{\delta _i}}}\left( {{x_0}} \right) \Rightarrow {g_i}\left( x \right) < 0.
\end{align}
Choosing $\delta : = \min \left\{ {{\delta _i}|i = 1, \ldots ,m} \right\} >0$, we have
\begin{align}
\label{1.54}
{g_i}\left( x \right) < 0, \hspace{0.2cm}\forall i = 1, \ldots ,m, \hspace{0.2cm}\forall x \in {B_\delta }\left( {{x_0}} \right).
\end{align}
Taking $u\in \mathbb{R}^n$ arbitrarily, we prove that $u\in T\left(M,x_0\right)$. The case $u=\mathbf{0} \in \mathbb{R}^n$ is obvious (take $u_n:=0$ and $t_n\to 0^+$ arbitrarily). If $u\ne 0$, we choose $u_n:=u$ and a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that 
\begin{align}
\label{1.55}
{t_n} < \frac{\delta }{{\left\| u \right\|}} , \hspace{0.2cm} \forall n  \in \mathbb{N} \mbox{ and } t_n\to 0^+, 
\end{align}
for instance, we can choose a monotone decreasing sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that ${t_1} < \frac{\delta }{{\left\| u \right\|}}$. The choice \eqref{1.55} ensures that ${x_0} + {t_n}{u_n} \in {B_\delta }\left( {{x_0}} \right)$ for all $n\in\mathbb{N}$. Combining this with \eqref{1.54} gives ${g_i}\left( {{x_0} + {t_n}{u_n}} \right) < 0$ for all $i=1,\ldots,m$, i.e., ${x_0} + {t_n}{u_n} \in M$ for all $n\in \mathbb{N}$. Hence, by \eqref{1.16}, $u\in T\left(M,x_0\right)$. Since $u$ is chosen arbitrarily, we conclude that $T\left(M,x_0\right)=\mathbb{R}^n$.
\item Suppose that $I\left(x_0\right)\ne \emptyset$, we take $u\in T\left(M,x_0\right)$ and try to prove that 
\begin{align}
\label{1.56}
\left\langle {\nabla {g_i}\left( {{x_0}} \right),u} \right\rangle  \le 0, \hspace{0.2cm} \forall i \in I\left( {{x_0}} \right).
\end{align}
By \eqref{1.16}, there exist a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset {\mathbb{R}^n}$ such that $u_n\to u$ as $n\to \infty$ and $x_0+t_n u_n\in M$ for all $n\in \mathbb{N}$, i.e., 
\begin{align}
\label{1.57}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) \le 0,\hspace{0.2cm}\forall i = 1, \ldots ,m,\hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
To prove \eqref{1.56}, we have $g_i\left(x_0\right)=0$ for all $i\in I\left(x_0\right)$. Combining this with \eqref{1.57} and the following first  order multivariate Taylor's formula (see, e.g., \cite{1}, Theorem 1.23, p.15) 
\begin{align}
\label{1.58}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) = {g_i}\left( {{x_0}} \right) + {t_n}\left\langle {\nabla {g_i}\left( {{x_0} + \alpha _n {t_n}{u_n}} \right),{u_n}} \right\rangle ,
\end{align}
for some $\alpha _n \in \left(0,1\right)$, for all $i\in I\left(x_0\right)$ and for all $n\in \mathbb{N}$, we deduce that 
\begin{align}
\label{1.59}
\left\langle {\nabla {g_i}\left( {{x_0} + \alpha _n {t_n}{u_n}} \right),{u_n}} \right\rangle  \le 0,\hspace{0.2cm}\forall i \in I\left( {{x_0}} \right), \hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
Letting $n\to \infty$ in \eqref{1.59} gives \eqref{1.56} as desired. Therefore, \eqref{1.50} holds.
\item First of all, the existence of $\overline{v}$ satisfying \eqref{1.51} implies that the set in the right-hand side of \eqref{1.52} is nonempty (at least $\overline{v}$ belongs to that set). Since we have proved \eqref{1.50}, it suffices to prove the reverse inclusion
\begin{align}
\label{1.60}
T\left( {M,{x_0}} \right) \supset \left\{ {v \in {\mathbb{R}^n}|\nabla {g_i}\left( {{x_0}} \right)\left( v \right) \le 0,\forall i \in I\left( {{x_0}} \right)} \right\}.
\end{align}
Taking $u$ belonging to the right-hand side of \eqref{1.60}, i.e., 
\begin{align}
\label{1.61}
\nabla {g_i}\left( {{x_0}} \right)\left( u \right) \le 0, \hspace{0.2cm}\forall i \in I\left( {{x_0}} \right),
\end{align}
we need to prove that $u\in T\left(M,x_0\right)$. We choose 
\begin{align}
{u_n}: = \frac{1}{n}\overline v  + \frac{{n - 1}}{n}u \to u \mbox{ as } n\to \infty .
\end{align} 
It suffices to prove that there exists a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and ${x_0} + {t_n}{u_n} \in M$ for all $n\in \mathbb{N}$, i.e., 
\begin{align}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) \le 0,\hspace{0.2cm} \forall i = 1, \ldots ,m, \hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
We consider the following two cases depending on the index $i$.\\
\\
\textbf{Case $i\in I\left(x_0\right)$.} For each $i\in I\left(x_0\right)$, $g_i\left(x_0\right)=0$ and \eqref{1.58} then gives
\begin{align}
\label{1.64}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) =&\ {t_n}\left\langle {\nabla {g_i}\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),{u_n}} \right\rangle \\
 =&\ \frac{{{t_n}}}{n}\left\langle {\nabla {g_i}\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),\overline v } \right\rangle \\
 & + \frac{{n - 1}}{n}{t_n}\left\langle {\nabla {g_i}\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),u} \right\rangle . \label{1.66}
\end{align}
Combining the fact that $g_i$ is Fr\'{e}chet differentiable, \eqref{1.51} and \eqref{1.61} yields that there exists $\delta _i >0$ such that
\begin{align}
x \in {B_{{\delta _i}}}\left( {{x_0}} \right) \Rightarrow \left\langle {\nabla {g_i}\left( x \right),\overline v } \right\rangle  < 0,\left\langle {\nabla {g_i}\left( x \right),u} \right\rangle  \le 0.
\end{align}
Take $\delta : = \min \left\{ {{\delta _i}|i \in I\left( {{x_0}} \right)} \right\}$, then 
\begin{align}
\label{1.68}
x \in {B_\delta }\left( {{x_0}} \right) \Rightarrow \left\langle {\nabla {g_i}\left( x \right),\overline v } \right\rangle  < 0,\left\langle {\nabla {g_i}\left( x \right),u} \right\rangle  \le 0,\hspace{0.2cm}\forall i \in I\left( {{x_0}} \right).
\end{align}
We then take $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and
\begin{align}
\label{1.69}
{t_n} < \frac{\delta }{{\frac{{\left\| {\overline v } \right\|}}{n} + \frac{{n - 1}}{n}\left\| u \right\|}},\hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
Then
\begin{align}
\left\| {{\alpha _n}{t_n}{u_n}} \right\| &\le {t_n}\left\| {{u_n}} \right\| = {t_n}\left\| {\frac{1}{n}\overline v  + \frac{{n - 1}}{n}u} \right\|\\
 &\le {t_n}\left( {\frac{{\left\| {\overline v } \right\|}}{n} + \frac{{n - 1}}{n}\left\| u \right\|} \right) < \delta ,\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
i.e., ${x_0} + {\alpha _n}{t_n}{u_n} \in {B_\delta }\left( {{x_0}} \right)$ for all $n\in \mathbb{N}$. Combining this with \eqref{1.64}-\eqref{1.66} and \eqref{1.68} yields
\begin{align}
\label{1.72}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) \le 0,\hspace{0.2cm} \forall i \in I\left( {{x_0}} \right),\hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
\textbf{Case $i\notin I\left(x_0\right)$.} For each $i\notin I\left(x_0\right)$, we have $g_i\left(x_0\right)\ne 0$. In addition, $x_0\in M$, i.e., $g_i\left(x_0\right) \le 0$, then we must have $g_i\left(x_0\right) <0$. By \eqref{1.59} again, 
we have
\begin{align}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) =&\ {g_i}\left( {{x_0}} \right) + \frac{{{t_n}}}{n}\left\langle {\nabla {g_i}\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),\overline v } \right\rangle \\
& + \frac{{n - 1}}{n}{t_n}\left\langle {\nabla {g_i}\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),u} \right\rangle .
\end{align}
In order that ${g_i}\left( {{x_0} + {t_n}{u_n}} \right) \le 0$ for all $n\in \mathbb{N}$, we choose $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that
\begin{align}
\label{1.75}
& - \frac{{{t_n}}}{n}\left\langle {\nabla {g_i}\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),\overline v } \right\rangle  - {g_i}\left( {{x_0}} \right)\\
& \ge  \frac{{n - 1}}{n}{t_n}\left| {\left\langle {\nabla {g_i}\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),u} \right\rangle } \right|,\hspace{0.2cm}\forall n \in \mathbb{N}. \label{1.76}
\end{align}
To \eqref{1.75}-\eqref{1.76} holds, we can make a stronger assumption on $t_n$'s, that is
\begin{align}
{t_n}\left\| {{u_n}} \right\| &\le 1,\hspace{0.2cm}\forall n \in \mathbb{N}\mbox{ and } \\
 - {g_i}\left( {{x_0}} \right) &\ge \frac{{n - 1}}{n}{t_n}\left\| u \right\|\mathop {\sup }\limits_{x \in {B_1}\left( {{x_0}} \right)} \left\| {\nabla {g_i}\left( x \right)} \right\|,\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
i.e.,
\begin{align}
\label{1.79}
{t_n} \le \min \left\{ {\frac{1}{{\left\| {{u_n}} \right\|}}, - \frac{n}{{n - 1}} \cdot \frac{{{g_i}\left( {{x_0}} \right)}}{{\left\| u \right\|\mathop {\sup }\limits_{x \in {B_1}\left( {{x_0}} \right)} \left\| {\nabla {g_i}\left( x \right)} \right\|}}} \right\},\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
If we choose $t_n$'s satisfying \eqref{1.79} then ${g_i}\left( {{x_0} + {t_n}{u_n}} \right) \le 0$ for all $n\in \mathbb{N}$. Hence, if we choose $t_n$'s such that
\begin{align}
\label{1.80}
{t_n} \le \min \left\{ {\frac{1}{{\left\| {{u_n}} \right\|}}, - \frac{n}{{n - 1}} \cdot \frac{{{g_i}\left( {{x_0}} \right)}}{{\left\| u \right\|\mathop {\sup }\limits_{x \in {B_1}\left( {{x_0}} \right)} \left\| {\nabla {g_i}\left( x \right)} \right\|}}:i \in \left\{ {1, \ldots ,m} \right\}\backslash I\left\{ {{x_0}} \right\}} \right\},
\end{align}
then 
\begin{align}
\label{1.81}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) \le 0,\hspace{0.2cm} \forall i \in \left\{ {1, \ldots ,m} \right\}\backslash I\left\{ {{x_0}} \right\},\hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
\vspace{0.2cm} 

Combining two discussed cases, we now choose $t_n$'s such that $t_n\to 0^+$ and satisfy both \eqref{1.69} and \eqref{1.80}, i.e.,
\begin{align}
{t_n} \le \min \left\{ \begin{array}{l}
\frac{1}{{\left\| {{u_n}} \right\|}},\dfrac{\delta }{{\frac{{\left\| {\overline v } \right\|}}{n} + \frac{{n - 1}}{n}\left\| u \right\|}},\\
 - \frac{n}{{n - 1}} \cdot \dfrac{{{g_i}\left( {{x_0}} \right)}}{{\left\| u \right\|\mathop {\sup }\limits_{x \in {B_1}\left( {{x_0}} \right)} \left\| {\nabla {g_i}\left( x \right)} \right\|}}:i \in \left\{ {1, \ldots ,m} \right\}\backslash I\left\{ {{x_0}} \right\}
\end{array} \right\}.
\end{align}
Then \eqref{1.72} and \eqref{1.81} gives
\begin{align}
{g_i}\left( {{x_0} + {t_n}{u_n}} \right) \le 0, \hspace{0.2cm} \forall i = 1, \ldots ,m, \hspace{0.2cm} \forall n \in \mathbb{N},
\end{align}
i.e., ${x_0} + {t_n}{u_n} \in M$ for all $n\in \mathbb{N}$. By definition of tangent cone, we deduce that $u\in T\left(M,x_0\right)$.
\end{enumerate}
This completes our proof. \hfill $\square$\\
\\
\textbf{Remark 5.1.} The assumption of existence of $\overline v$ \eqref{1.51} can be removed. Indeed, suppose for the contrary that there does not exist $\overline v$ satisfying \eqref{1.51}, we then choose 
\begin{align}
{u_n}: = \frac{1}{n}{u_0} + \frac{{n - 1}}{n}u \to u \mbox{ as } n \to \infty ,
\end{align}
for arbitrarily chosen point $u_0$. Since we have assumed that \eqref{1.51} fails, then there exists an index $i_0\in I\left(x_0\right)$ depending on $u_0$ such that 
\begin{align}
\nabla {g_{{i_0}}}\left( {{x_0}} \right)\left( {{u_0}} \right) \ge 0.
\end{align}
We now let $n=1$, with replacing $\overline v$ by $u_0$, in \eqref{1.64}-\eqref{1.66} gives
\begin{align}
{g_{{i_0}}}\left( {{x_0} + {t_1}{u_1}} \right) = {t_1}\left\langle {\nabla {g_{{i_0}}}\left( {{x_0} + {\alpha _1}{t_1}{u_1}} \right),u_0 } \right\rangle .
\end{align}
Since $\nabla {g_{{i_0}}}\left( {{x_0}} \right)\left( {{u_0}} \right) \ge 0$, we can not make any assumption on $t_1$ in order that ${g_{{i_0}}}\left( {{x_0} + {t_1}{u_1}} \right) \le 0$ (it is possible that ${t_1}\left\langle {\nabla {g_{{i_0}}}\left( {{x_0} + {\alpha _1}{t_1}{u_1}} \right),{u_0}} \right\rangle  \ge 0$ for all $t_1\in \mathbb{R}$, and our entire argument collapses). This is the reason why the assumption \eqref{1.51} cannot be excluded.\\
\\
\textbf{Problem 6.} \textit{Use the results of Problem 5 to compute contingent cones in Problem 3.2.}\\
\\
\textsc{Solution.} Applying the result in Problem 5.3 to 
\begin{align}
M = \left\{ {\left( {{x_1},{x_2}} \right) \in {\mathbb{R}^2}|{g_i}\left( x \right) \le 0,\hspace{0.2cm} i = 1,2} \right\},
\end{align}
where ${g_1},{g_2}:{\mathbb{R}^2} \to \mathbb{R}$ are Fr\'{e}chet differentiable functions defined by
\begin{align}
{g_1}\left( x \right) &= 2 - {x_1} - {x_2},\\
{g_2}\left( x \right) &= {x_2} - x_1^3,
\end{align}
for all $x=\left(x_1,x_2\right) \in \mathbb{R}^2$. With $x_0=\left(1,1\right)\in M$, the index set $I\left(x_0\right)$ is given by
\begin{align}
I\left( {{x_0}} \right) = \left\{ {i \in \left\{ {1,2} \right\}|{g_i}\left( {1,1} \right) = 0} \right\} = \left\{ {1,2} \right\}.
\end{align} 
Next, we have 
\begin{align}
\nabla {g_1}\left( x \right) = {\left( { - 1, - 1} \right)^T},\nabla {g_2}\left( x \right) = {\left( { - 3x_1^2,1} \right)^T},\hspace{0.2cm} \forall x = \left( {{x_1},{x_2}} \right) \in {\mathbb{R}^2}.
\end{align}
Take $\overline v=\left(1,0\right)^T \in \mathbb{R}^2$, we have
\begin{align}
\nabla {g_1}\left( {{x_0}} \right)\left( {\overline v } \right) &= \left\langle {{{\left( { - 1, - 1} \right)}^T},{{\left( {1,0} \right)}^T}} \right\rangle  =  - 1,\\
\nabla {g_2}\left( {{x_0}} \right)\left( {\overline v } \right) &= \left\langle {{{\left( { - 3,1} \right)}^T},{{\left( {1,0} \right)}^T}} \right\rangle  =  - 3,
\end{align}
i.e., \eqref{1.51} holds. Now we apply the result in Problem 5.3 to our setting to to obtain
\begin{align}
T\left( {M,{x_0}} \right) &= \left\{ {v \in {\mathbb{R}^2}|\nabla {g_i}\left( {{x_0}} \right)\left( v \right) \le 0,\hspace{0.2cm} i = 1,2} \right\}\\
& = \left\{ {{{\left( {{v_1},{v_2}} \right)}^T} \in {\mathbb{R}^2}| - {v_1} - {v_2} \le 0, - 3{v_1} + {v_2} \le 0} \right\}\\
 &= \left\{ {{{\left( {{v_1},{v_2}} \right)}^T} \in {\mathbb{R}^2}|{v_1} + {v_2} \ge 0,{v_2} \le 3{v_1}} \right\},
\end{align}
which is exactly \eqref{1.28}. \hfill $\square$\\
\\
\textbf{Problem 7 (Geometric form of first order optimality condition for unconstrained problem).} \textit{Consider the following problem $\left(P\right)$}
\begin{align}
\left( P \right)\hspace{0.5cm}\min f\left( x \right)\mbox{ s.t. } x \in \Omega .
\end{align}
\textit{where $f:\mathbb{R}^n\to \mathbb{R}$ and $\Omega  \subseteq {\mathbb{R}^n}$. Prove the following geometric form of the first order optimality condition}
\begin{align}
\label{1.98}
\mbox{ If } {x_0}\mbox{ is a local minimum of }\left( P \right) \mbox{ then } \forall u \in T\left( {\Omega ,{x_0}} \right):\left\langle {\nabla f\left( {{x_0}} \right),u} \right\rangle  \ge 0.
\end{align}
\textsc{Solution.} Assume that $x_0$ is a local minimizer of $f$ in $\Omega$, (see, e.g., \cite{1}, Def. 2.1, p.32) there exists $r>0$ such that ${B_r}\left( {{x_0}} \right) \subset \Omega $ and 
\begin{align}
\label{1.99}
x \in {B_r}\left( {{x_0}} \right) \Rightarrow f\left( {{x_0}} \right) \le f\left( x \right).
\end{align}
Take $u\in T\left(\Omega,x_0\right)$ arbitrarily, by \eqref{1.16}, there exist a sequence of real positive $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n \to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset {\mathbb{R}^n}$ such that $u_n\to u$ as $n\to \infty$ and $x_0+t_nu_n\in \Omega$ for all $n\in \mathbb{N}$. Then there exists $N\in \mathbb{N}$ such that 
\begin{align}
\label{1.100}
{x_0} + {t_n}{u_n} \in {B_r}\left( {{x_0}} \right),\hspace{0.2cm}\forall n \ge N.
\end{align}
Combining \eqref{1.99} with \eqref{1.100} yields
\begin{align}
\label{1.101}
f\left( {{x_0}} \right) \le f\left( {{x_0} + {t_n}{u_n}} \right),\hspace{0.2cm}\forall n \ge N.
\end{align}
By the first order multivariate Taylor formula, we have
\begin{align}
\label{1.102}
f\left( {{x_0} + {t_n}{u_n}} \right) = f\left( {{x_0}} \right) + {t_n}\left\langle {\nabla f\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),{u_n}} \right\rangle ,\hspace{0.2cm}\forall n \in \mathbb{N},
\end{align}
for some $\alpha _n\in \left(0,1\right)$. Combining \eqref{1.101} with \eqref{1.102} yields
\begin{align}
\label{1.103}
\left\langle {\nabla f\left( {{x_0} + {\alpha _n}{t_n}{u_n}} \right),{u_n}} \right\rangle  \ge 0,\hspace{0.2cm} \forall n \ge N.
\end{align}
Letting $n\to \infty$ in \eqref{1.103}, we obtain
\begin{align}
\left\langle {\nabla f\left( {{x_0}} \right),u} \right\rangle  \ge 0.
\end{align}
Since $u$ is taken from $T\left(\Omega, x_0\right)$ arbitrarily, \eqref{1.98} holds and we complete our proof. \hfill $\square$\\
\\
\textbf{Problem 8.} \textit{Consider the following problem}
\begin{align}
\left( P \right)\hspace{0.5cm}\min {x^2} + y\mbox{ s.t. } \left( {x,y} \right) \in \Omega : = \left\{ {\left( {x,y} \right) \in {\mathbb{R}^2}|{x^2} + {y^3} = 0} \right\}.
\end{align}
\begin{enumerate}
\item \textit{Compute the tangent cone of $\Omega$ at $x_0=\left(0,0\right)$. }
\item \textit{Applying the result of Problem 7, prove that $x_0=\left(0,0\right)$ is not a local minimizer of $\left(P\right)$.}
\end{enumerate}
\textsc{Solution.}
\begin{enumerate}
\item We have computed the tangent cone of $\Omega$ at $x_0=\left(0,0\right)$ in Problem 3.1 with the interchange of $x_1$ and $x_2$
\begin{align}
T\left( {\Omega ,{x_0}} \right) = \left\{ {\left( {0,y} \right) \in {\mathbb{R}^2}|y \le 0} \right\}.
\end{align}
\item Suppose for the contrary\footnote{A shorter proof is as follows. Take $u=\left(0,-1\right) \in T\left(\Omega,x_0\right)$, then
\begin{align}
\left\langle {\nabla f\left( {{x_0}} \right),u} \right\rangle  = \left\langle {\left( {0,1} \right),\left( {0, - 1} \right)} \right\rangle  =  - 1 < 0.
\end{align}
then \eqref{1.98} implies that $x_0$ is not a local minimizer of $\left(P\right)$. \hfill $\square$} that $x_0=\left(0,0\right)$ is a local minimizer of $\left(P\right)$. Set 
\begin{align}
f\left( {x,y} \right) = {x^2} + y,\hspace{0.2cm}\forall \left( {x,y} \right) \in {\mathbb{R} ^2}.
\end{align}
which has $\nabla f\left( {x,y} \right) = \left( {2x,1} \right)$ for all $\left( {x,y} \right) \in {\mathbb{R} ^2}$. Then \eqref{1.98} gives
\begin{align}
\forall u \in T\left( {\Omega ,{x_0}} \right):\left\langle {\nabla f\left( {{x_0}} \right),u} \right\rangle  \ge 0,
\end{align}
equivalently,
\begin{align}
\forall x \le 0:0 \le \left\langle {\nabla f\left( {{x_0}} \right),\left( {0,x} \right)} \right\rangle  = \left\langle {\left( {0,1} \right),\left( {0,x} \right)} \right\rangle  = x,
\end{align}
which is absurd. Therefore, $x_0$ is not a local minimizer of $\left(P\right)$. 
\end{enumerate}
This completes our proof. \hfill $\square$\\
\\
\textbf{Problem 9.} \textit{Consider the following problem}
\begin{align}
\left( P \right)\hspace{0.5cm}\min x + 2y \mbox{ s.t. } {x^2} + {y^2} \le 1,x + y \le 1.
\end{align}
\textit{Applying the result in Problem 7, check whether $x_0=\left(0,1\right)$ is a local minimizer of $\left(P\right)$.}\\
\\
\textsc{Solution.} Setting
\begin{align}
f\left( {x,y} \right) &= x + 2y,\forall \left( {x,y} \right) \in {\mathbb{R}^2},\\
M  &= \left\{ {\left( {x,y} \right) \in {\mathbb{R}^2}|{g_i}\left( {x,y} \right) \le 0,\hspace{0.2cm} i = 1,2} \right\},
\end{align}
where $g_1,g_2:\mathbb{R}^2\to \mathbb{R}$ are Fr\'{e}chet differentiable functions defined by
\begin{align}
{g_1}\left( {x,y} \right) &= {x^2} + {y^2} - 1,\\
{g_2}\left( {x,y} \right) &= x + y - 1,
\end{align}
for all $\left(x,y\right) \in \mathbb{R}^2$, we first compute the tangent cone of $M$ at $x_0=\left(0,1\right)\in M$ by using the result of Problem 5. The index set $I\left(x_0\right)$ is given by
\begin{align}
I\left( {{x_0}} \right) = \left\{ {i \in \left\{ {1,2} \right\}|{g_i}\left( {0,1} \right) = 0} \right\} = \left\{ {1,2} \right\}.
\end{align}
Next, we have
\begin{align}
\nabla {g_1}\left( {x,y} \right) = \left( {2x,2y} \right),\nabla {g_2}\left( {x,y} \right) = \left( {1,1} \right),\hspace{0.2cm}\forall \left( {x,y} \right) \in {\mathbb{R}^2}.
\end{align}
Take $\overline v=\left(0,-1\right)^T \in \mathbb{R}^2$, we have
\begin{align}
\nabla {g_1}\left( {{x_0}} \right)\left( {\overline v } \right) &= \left\langle {\left( {0,2} \right),\left( {0, - 1} \right)} \right\rangle  =  - 2,\\
\nabla {g_2}\left( {{x_0}} \right)\left( {\overline v } \right) &= \left\langle {\left( {1,1} \right),\left( {0, - 1} \right)} \right\rangle  =  - 1,
\end{align}
i.e., \eqref{1.51} holds. Now we apply the result in Problem 5.3 to our setting to obtain
\begin{align}
T\left( {M,{x_0}} \right) &= \left\{ {v \in {\mathbb{R}^2}|\nabla {g_i}\left( {{x_0}} \right)\left( v \right) \le 0,\hspace{0.2cm} i = 1,2} \right\}\\
 &= \left\{ {\left( {{v_1},{v_2}} \right) \in {\mathbb{R}^2}|{v_2} \le 0,{v_1} + {v_2} \le 0} \right\}.
\end{align}
Take $u=\left(-1,0\right)\in T\left(M,x_0\right)$, we have 
\begin{align}
\left\langle {\nabla f\left( {{x_0}} \right),u} \right\rangle  = \left\langle {\left( {1,2} \right),\left( { - 1,0} \right)} \right\rangle  =  - 1 < 0.
\end{align}
Hence, by \eqref{1.98}, we deduce that $x_0$ is not a local minimizer of $\left(P\right)$. \hfill $\square$\\
\\
\textbf{Problem 10.} \textit{Consider the following problem}
\begin{align}
\left( P \right)\hspace{0.5cm} - xy \mbox{ s.t. } x + y = 8,\hspace{0.2cm} x \ge 0,y \ge 0.
\end{align}
\textit{Applying the result in Problem 7, check whether $x_0=\left(4,4\right)$ is a local minimizer of $\left(P\right)$.}\\
\\
\textsc{Solution.} We apply the well-known Cauchy-Schwarz inequality 
\begin{align}
xy \le {\left( {\frac{{x + y}}{2}} \right)^2} = \frac{{{8^2}}}{4} = 16.
\end{align}
Hence, $-xy \ge -16$ for all $x,y$ such that $x+y=8,x\ge 0,y\ge 0$. The equality happens if and only if $x=y=4$. Thus, $x_0=\left(4,4\right)$ is a local minimizer. \hfill $\square$\\
\\
\textbf{Remark 10.1.} The result in Problem 7 is only an necessary but not sufficient condition. Hence, we can only use it to disprove the statement ``$x_0$ is a local minimizer of $\left(P\right)$'' (i.e., prove that $x_0$ is not a local minimizer as we did in Problem 8, 9) but can not use it to check whether $x_0$ is a local minimizer of $\left(P\right)$.\\
\\
\textbf{Problem 11.} \textit{Consider the following problem}
\begin{align}
\label{1.125}
\left( P \right)\hspace{0.5cm}\min {x^2} + {y^2}\mbox{ s.t. } {x^2} - {\left( {y - 1} \right)^3} = 0.
\end{align}
\begin{enumerate}
\item \textit{Use algebraic or geometrical methods to solve $\left(P\right)$.}
\item \textit{Examine the necessary condition in Problem 7.}
\end{enumerate}
\textsc{Solution.} 
\begin{enumerate}
\item We deduce from \eqref{1.125} that 
\begin{align}
\label{1.126}
{x^2} = {\left( {y - 1} \right)^3} \ge 0.
\end{align}
The last inequality implies $y\ge 1$. Substituting $x^2$ giving by \eqref{1.126} into our problem yields
\begin{align}
{x^2} + {y^2} = f\left( y \right): = {\left( {y - 1} \right)^3} + {y^2},\hspace{0.2cm}\forall y \ge 1.
\end{align}
The first order derivative of $f$ is 
\begin{align}
f'\left( y \right) = 3{\left( {y - 1} \right)^2} + 2y > 0,\hspace{0.2cm}\forall y \ge 1.
\end{align}
Hence,
\begin{align}
\mathop {\min }\limits_{{x^2} - {{\left( {y - 1} \right)}^3} = 0} \left( {{x^2} + {y^2}} \right) = \mathop {\min }\limits_{y \ge 1} f\left( y \right) = f\left( 1 \right) = 1,
\end{align}
which holds if and only if $x=0,y=1$. 
\item Setting $x_0=\left(0,1\right)$ and
\begin{align}
f\left( {x,y} \right) &= {x^2} + {y^2},\hspace{0.2cm}\forall \left( {x,y} \right) \in {\mathbb{R}^2},\\
M &= \left\{ {\left( {x,y} \right) \in {\mathbb{R}^2}|{x^2} - {{\left( {y - 1} \right)}^3} = 0} \right\},
\end{align}
we have $\nabla f\left( {x,y} \right) = \left( {2x,2y} \right)$ for all $\left(x,y\right) \in \mathbb{R}^2$. Now we compute the tangent cone $T\left(M,x_0\right)$ as in Problem 3. Notice that $x_0\in M$, we claim that
\begin{align}
\label{1.132}
T\left( {M,{x_0}} \right) = \widehat T\left( {M,{x_0}} \right): = \left\{ {\left( {0,y} \right) \in {\mathbb{R}^2}|y \ge 0} \right\}.
\end{align}
To this end, we prove the following inclusions.
\begin{enumerate}
\item \textit{Prove $T\left( {M,{x_0}} \right) \subset \widehat T\left( {M,{x_0}} \right)$.} Taking $u=\left(x,y\right) \in T\left(M,x_0\right)$, by \eqref{1.16}, there exist a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and a sequence $\left\{ {{u_n}} \right\}_{n = 1}^\infty  \subset {\mathbb{R}^2}$ such that $u_n\to u$ as $n\to \infty$ and $x_0+t_nu_n \in M$ for all $n\in \mathbb{N}$. Set $u_n:=\left(x_n,y_n\right)$, the fact $u_n\to u$ implies that $x_n\to x$ and $y_n \to y$, and the fact $x_0+t_nu_n$ for all $n\in \mathbb{N}$ gives
\begin{align}
\label{1.133}
t_n^2x_n^2 = t_n^3y_n^3,\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
Since $t_n>0$ for all $n\in \mathbb{N}$, \eqref{1.133} then implies 
\begin{align}
\label{1.134}
x_n^2 = {t_n}y_n^3,\hspace{0.2cm}\forall n \in \mathbb{N}.
\end{align}
We see at a glance from \eqref{1.134} that $y_n\ge 0$ for all $n\in \mathbb{N}$. Hence, $y\ge 0$ (since $y_n\to y$ as $n\to \infty$). Now let $n\to \infty$ in \eqref{1.134} and use the given limits $x_n\to x,y_n\to y$ and $t_n\to 0^+$, we obtain $x=0$. Hence, $u\in \widehat{T}\left(M,x_0\right)$ and our first inclusion is proved.
\item \textit{Prove $\widehat T\left( {M,{x_0}} \right) \subset T\left( {M,{x_0}} \right)$.} Taking $\left(0,y\right)$ satisfying $y\ge 0$, we claim that $u\in T\left(M,x_0\right)$. To this end, we choose $x_n=\frac{1}{n^2},y_n=y+\frac{1}{n}>0$. This choice ensures that $u_n:=\left(x_n,y_n\right)\to u:=\left(0,y\right)$ as $n\to \infty$. It then suffices to prove that there exists a sequence of positive reals $\left\{ {{t_n}} \right\}_{n = 1}^\infty $ such that $t_n\to 0^+$ and $x_0+t_nu_n\in M$ for all $n\in \mathbb{N}$. The latter gives, using \eqref{1.134} again, 
\begin{align}
\frac{1}{{{n^4}}} = {t_n}{\left( {y + \frac{1}{n}} \right)^3},\hspace{0.2cm}\forall n \in \mathbb{N},
\end{align}
i.e., 
\begin{align}
{t_n} = \frac{1}{{{n^4}{{\left( {y + \frac{1}{n}} \right)}^3}}},\hspace{0.2cm} \forall n \in \mathbb{N}.
\end{align}
It is easy to check that $t_n >0$ (since $y\ge 0$) and $t_n \to 0^+$ as $n\to \infty$. Hence, $u\in T\left(M,x_0\right)$, the second inclusion is also proved.
\end{enumerate}
Combining these cases, we conclude that \eqref{1.132} holds, i.e.,
\begin{align}
T\left( {M,{x_0}} \right) = \left\{ {\left( {0,y} \right) \in {\mathbb{R}^2}|y \ge 0} \right\}.
\end{align}
We now prove the necessary condition stated in Problem 7 for our setting, i.e.,
\begin{align}
\forall u \in T\left( {M,{x_0}} \right):\left\langle {\nabla f\left( {{x_0}} \right),u} \right\rangle  \ge 0,
\end{align}
equivalently,
\begin{align}
\forall y \ge 0:\left\langle {\left( {0,2} \right),\left( {0,y} \right)} \right\rangle  = 2y \ge 0,
\end{align}
which is obvious. Hence, the necessary condition in Problem 7 holds in our setting.
\end{enumerate}
This completes our proof. \hfill $\square$\\
\\
\textbf{Problem 12.} \textit{Let $X=\mathbb{R}^n$ (a finite-dimensional space), consider the norm function}
\begin{align}
f\left( x \right) = \left\| x \right\|.
\end{align}
\begin{enumerate}
\item \textit{Prove that $\nabla f\left( a \right) = {\left\| a \right\|^{ - 1}}a$ for all $a\ne 0$.}
\item \textit{Prove that $f$ is not Fr\'{e}chet differentiable at $x=\mathbf{0}$.}
\end{enumerate}
\textsc{Solution.}
\begin{enumerate}
\item For $x\ne 0$, write $x = \left( {{x_1}, \ldots ,{x_n}} \right) \in {\mathbb{R}^n}$, we have
\begin{align}
f\left( x \right) &= {\left( {\sum\limits_{i = 1}^n {x_i^2} } \right)^{\frac{1}{2}}},\\
\frac{{\partial f}}{{\partial {x_i}}}\left( x \right) &= \frac{{{x_i}}}{{{{\left( {\sum\limits_{i = 1}^n {x_i^2} } \right)}^{\frac{1}{2}}}}}  \\
&= \frac{{{x_i}}}{{\left\| x \right\|}}, \hspace{0.2cm}\forall i = 1, \ldots ,n.
\end{align}
Hence,
\begin{align}
\nabla f\left( a \right) = \frac{a}{{\left\| a \right\|}},\hspace{0.2cm}\forall a \ne 0.
\end{align}
\item Suppose for the contrary that $f$ is Fr\'{e}chet differentiable at $x=\mathbf{0}$, by definition, there exists a linear function $l:\mathbb{R}^n\to \mathbb{R}$, $l\left( x \right) = \left\langle {l,x} \right\rangle $, such that
\begin{align}
\label{1.145}
\mathop {\lim }\limits_{\left\| h \right\| \to 0} \frac{{f\left( h \right) - f\left( 0 \right) - \left\langle {l,h} \right\rangle }}{{\left\| h \right\|}} = 0.
\end{align}
Write $h = \left( {{h_1}, \ldots ,{h_n}} \right),\left\langle {l,h} \right\rangle  = \sum\limits_{i = 1}^n {{l_i}{h_i}} $, \eqref{1.145} becomes
\begin{align}
\label{1.146}
\mathop {\lim }\limits_{\left\| h \right\| \to 0} \frac{1}{{\left\| h \right\|}}\sum\limits_{i = 1}^n {{l_i}{h_i}}  = 1.
\end{align}
In particular, for an arbitrary index $i$, if we choose ${h_i} = \frac{1}{n},{h_j} = 0$ for all $j\ne i$, \eqref{1.146} gives $l_i=1$. Otherwise, if we choose ${h_i} = -\frac{1}{n},{h_j} = 0$ for all $j\ne i$, \eqref{1.146} gives $l_i=-1$, which is absurd. Hence, $f$ is not Fr\'{e}chet differentiable at $x=\mathbf{0}$. This completes our proof. \hfill $\square$
\end{enumerate}
\newpage
\begin{thebibliography}{999}
\bibitem {1} O. G\"{u}ler, \textit{Foundations of Optimization}, Graduate Texts in Mathematics 258, Springer.
\bibitem {2} Tim Hoheisel, \textit{Convex Analysis}, University of W\"{u}rzburg, Germany, Lecture Notes, Summer term 2016.
\end{thebibliography}
\end{document}