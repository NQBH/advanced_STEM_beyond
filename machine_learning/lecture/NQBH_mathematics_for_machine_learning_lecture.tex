\documentclass{article}
\usepackage[backend=biber,natbib=true,style=alphabetic,maxbibnames=50]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[utf8]{vietnam}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,enumitem,float,graphicx,mathtools,tikz}
\usetikzlibrary{angles,calc,intersections,matrix,patterns,quotes,shadings}
\allowdisplaybreaks
\newtheorem{assumption}{Assumption}
\newtheorem{baitoan}{Bài toán}
\newtheorem{cauhoi}{Câu hỏi}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{dangtoan}{Dạng toán}
\newtheorem{definition}{Definition}
\newtheorem{dinhly}{Định lý}
\newtheorem{dinhnghia}{Định nghĩa}
\newtheorem{example}{Example}
\newtheorem{ghichu}{Ghi chú}
\newtheorem{hequa}{Hệ quả}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{lemma}{Lemma}
\newtheorem{luuy}{Lưu ý}
\newtheorem{nhanxet}{Nhận xét}
\newtheorem{notation}{Notation}
\newtheorem{note}{Note}
\newtheorem{principle}{Principle}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{question}{Question}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{vidu}{Ví dụ}
\usepackage[left=1cm,right=1cm,top=5mm,bottom=5mm,footskip=4mm]{geometry}
\def\labelitemii{$\circ$}
\DeclareRobustCommand{\divby}{%
	\mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\title{Lecture Note: Mathematics for Machine Learning\\Bài Giảng: Toán Học Cho Học Máy}
\author{Nguyễn Quản Bá Hồng\footnote{A Scientist {\it\&} Creative Artist Wannabe. E-mail: {\tt nguyenquanbahong@gmail.com}. Bến Tre City, Việt Nam.}}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
	This text is a part of the series {\it Some Topics in Advanced STEM \& Beyond}:
	
	{\sc url}: \url{https://nqbh.github.io/advanced_STEM/}.
	
	Latest version:
	\begin{itemize}
		\item {\it Lecture Note: Mathematics for Machine Learning}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/machine_learning/lecture/NQBH_mathematics_for_machine_learning_lecture.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/machine_learning/lecture/NQBH_mathematics_for_machine_learning_lecture.tex}.
		\item {\it Slide: Mathematics for Machine Learning -- Toán Học cho Học Máy}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/machine_learning/slide/NQBH_mathematics_for_machine_learning_slide.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/machine_learning/slide/NQBH_mathematics_for_machine_learning_slide.tex}.
		\item {\it Personal Expository Notes on Machine Learning}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/draft/blob/master/machine_learning/NQBH_machine_learning.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/draft/blob/master/machine_learning/NQBH_machine_learning.tex}.
		\item Codes:
		\begin{itemize}
			\item Python for Machine Learning: \url{https://github.com/NQBH/advanced_STEM_beyond/tree/main/machine_learning/Python}.
			\item C{\tt/}C++ for Machine Learning:
		\end{itemize}
	\end{itemize}
\end{abstract}
\tableofcontents

%------------------------------------------------------------------------------%

\section{Basic \& Big Pictures}

\subsection{Abbreviation, Notations}

\begin{itemize}
	\item AI: Artificial Intelligence
	\item ANN: Artificial Neural Networks
	\item DL: Deep Learning
	\item ML: Machine Learning
\end{itemize}

\subsection{Main components}
\begin{figure}[H]
	\centering
	\includegraphics[width=12cm]{4_ML_pillars}
	\caption{Foundations \& 4 pillars of ML. Source: \cite[Fig. 1.1, p. 14]{Deisenroth_Faisal_Ong2024}.}
\end{figure}

\begin{itemize}
	\item 3 major components of a ML system: data, models, \& learning.
	\item 4 pillars of machine learning -- 4 trụ cột của máy học:
	\begin{enumerate}
		\item Regression -- Hồi quy
		\item Dimensionality reduction -- Giảm kích thước\footnote{I was used to work in project ROMSOC: Reduced Order Modelling, Simulation \& Optimization of Coupled Systems. Maybe ``dimensionality reduction'' is related to ``reduced order modeling'' in some sense of mathematics?}
		\item Density estimation -- Ước tính mật độ
		\item Classification -- Phân loại
	\end{enumerate}
\end{itemize}

\begin{question}[Main question of ML]
	What do we mean by ``good'' ``models''?
\end{question}
See, e.g., \cite[Chap. 8, Sect. 8.1: Data, Models, \& Learning]{Deisenroth_Faisal_Ong2024}.

\subsection{Data as vectors}
Input data can be considered as a vector of features of the problem considered.

See, e.g., \cite[Chap. 8, Sect. 8.1.1: Data as Vectors]{Deisenroth_Faisal_Ong2024}.

\subsection{How to describe models}
2 major approaches:
\begin{itemize}
	\item a predictor as a function
	\item a predictor as a probabilistic model.
\end{itemize}

\subsubsection{Models as functions -- Mô hình như hàm số}
See, e.g., \cite[Chap. 8, Sect. 8.1.2: Models as Functions]{Deisenroth_Faisal_Ong2024}.

A predictor is a function that, when given a particular input example produces an output:
\begin{align*}
	\mbox{predictor}:\mbox{Input Space}&\to\mbox{Output Space},\\
	\mbox{input example}&\mapsto\mbox{output}\coloneqq\mbox{predictor}(\mbox{input example}).
\end{align*}
Input- \& Output Spaces in this formula are usually vector spaces. If they are, we usually take $\mbox{Input Space}\coloneqq\mathbb{R}^{n_{\rm input}}$, $\mbox{Output Space}\coloneqq\mathbb{R}^{n_{\rm output}}$, or $\mbox{Input Space}\coloneqq\mathbb{C}^{n_{\rm input}}$, $\mbox{Output Space}\coloneqq\mathbb{C}^{n_{\rm output}}$, but each complex number can be decomposed as $z = \Re z + i\Im z$, $\forall z\in\mathbb{C}$, so it is equivalent to consider $\mbox{Input Space}\coloneqq\mathbb{R}^{2n_{\rm input}}$, $\mbox{Output Space}\coloneqq\mathbb{R}^{2n_{\rm output}}$ instead of $\mbox{Input Space}\coloneqq\mathbb{C}^{n_{\rm input}}$, $\mbox{Output Space}\coloneqq\mathbb{C}^{n_{\rm output}}$. Briefly, a pair of Euclidean spaces $(\mathbb{R}^{n_{\rm input}},\mathbb{R}^{n_{\rm output}})$ is good enough to represent input- \& output spaces.

For simplicity, consider the output to be a single real number, i.e., a real-valued scalar output, which can be written as
\begin{equation*}
	f:\mathbb{R}^D\to\mathbb{R},
\end{equation*}
where the input vector ${\bf x}$ is $D$-dimensional (has $D$ features), \& the function $f$ then applied to it (written as $f({\bf x})$) returns a real number.

\subsubsection{Models as probability distributions -- Mô hình như phân phối xác suất}
See, e.g., \cite[Chap. 8, Sect. 8.1.3: Models as Probability Distributions]{Deisenroth_Faisal_Ong2024}.

\section{Introduction to Supervised Learning -- Giới Thiệu về Học Có Giám Sát}
\textbf{\textsf{References -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Bach2024}. {\sc Francis Bach}. {\it Learning Theory from First Principles}. Chap. 2: Introduction to Supervised Learning.
\end{enumerate}
{\bf Main goal.} Give some observations $(x_i,y_i)\in{\cal X}\times{\cal Y},i = 1,\ldots,n$, of inputs{\tt/}outputs, features{\tt/}labels, covariates{\tt/}responses (which are referred to as ``training data''), main goal of supervised learning is to predict a new $y\in{\cal Y}$ given a new previously unseen $x\in{\cal X}$. Unobserved data are usually referred to as ``testing data''.

-- Đưa ra 1 số quan sát $(x_i,y_i)\in{\cal X}\times{\cal Y},i = 1,\ldots,n$, của các đầu vào{\tt/}đầu ra, các nhãn{\tt/}tính năng, các phản hồi của biến phụ thuộc{\tt/}(được gọi là ``dữ liệu huấn luyện{\tt/}đào tạo''), mục tiêu chính của học có giám sát là dự đoán 1 $y\in{\cal Y}$ mới khi biết trước 1 $x\in{\cal X}$ mới chưa từng thấy. Dữ liệu chưa quan sát thường được gọi là ``dữ liệu thử nghiệm''.

{\bf Examples.} Supervised learning is used in many areas of science, engineering, \& industry. There are thus many examples where ${\cal X},{\cal Y}$ can be very diverse:
\begin{itemize}
	\item {\bf Inputs $x\in{\cal X}$}: They can be images, sounds, videos, text documents, proteins, sequences of DNA bases, web pages, social network activities, sensors from industry, financial time series, etc. Set ${\cal X}$ may thus have a variety of structures that can be leveraged. All learning methods presented in this textbook will use at 1 point a vector space representation of inputs, either by building an explicit mapping from ${\cal X}$ to a vector space, e.g., $\mathbb{R}^d$, or implicitly by using a notion of pairwise dissimilarity or similarity between pairs of inputs. Choice of these representations is highly domain-dependent. However, note:
	\begin{itemize}
		\item common topologies are encountered in many diverse areas (e.g. sequences or 2D or 3D objects), \& thus common tools are used, \&
		\item learning these representations is an active area of research.
	\end{itemize}
	In this textbook, will primarily consider that inputs are $d$-dimensional vectors, with $d$ potentially large, up to $10^6$ or $10^9$.
	\item {\bf Outputs $y\in{\cal Y}$.} Most classical examples are binary labels ${\cal Y} = \{0,1\}$ or ${\cal Y} = \{\pm1\}$, multicategory classification problems with ${\cal Y} = \{1,\ldots,k\}$, \& classical regression with real responses{\tt/}outputs ${\cal Y} = \mathbb{R}$. These will be main examples examined in most of book. Note, however: most of concepts extend to more general \emph{structured prediction} setup, where more general structured outputs (e.g., graph prediction, visual scene analysis, source separation, ranking) can be considered.
\end{itemize}
{\bf Why difficult?} Supervised learning is difficult (\& thus interesting) for a variety of reasons:
\begin{itemize}
	\item Label $y$ may not be a deterministic function of $x$: Given $x\in{\cal X}$, outputs are noisy, i.e., $y$ is a random function of $x$. When $y\in\mathbb{R}$, will often make simplifying ``additive noise'' assumption: $y = f(x) + \varepsilon$ with some zero-mean noise $\varepsilon$, but in general, only assume: there is a conditional distribution of $y$ given $x$. This stochasticity is typically due to diverging views between labelers or dependence on random external unobserved quantities (i.e., $y = f(x,z)$, with $z$ random \& not observed, which is common, e.g., in medical applications, where need to predict a future occurrence of a disease based on limited information about patients).
	\item Prediction function $f$ may be quite complex, highly nonlinear when ${\cal X}$ is a vector space, \& even hard to define when ${\cal X}$ is not a vector space.
	\item Only a few $x$'s are observed: thus need interpolation \& potentially extrapolation ({\sf diagram for an illustration for ${\cal X} = {\cal Y} = \mathbb{R}$}), \& therefore overfitting (predicting well on training data but not as well on testing data) is always a possibility.
	
	Moreover, training observations may not be uniformly distributed in ${\cal X}$. In this book, they will be assumed to be random, but some analyzes will rely on deterministically located inputs to simplify some theoretical arguments.
	\item Input space ${\cal X}$ may be very large (i.e., with high dimension when this is a vector space). This leads to both computational issues (scalability) \& statistical issues (generalization to unseen data). One usually refers to this problem as {\it curse of dimensionality}.
	\item There may be a weak link between training \& testing distributions. I.e., data at training time can have different characteristics than data at testing time.
	\item Criterion for performance is not always well defined.
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{Decision Theory}
See, e.g., \href{https://en.wikipedia.org/wiki/Decision_theory}{Wikipedia{\tt/}decision theory}.

\begin{question}[Optimal performance]
	What is optimal performance, regardless of the finiteness of the training data? Or what should be done if we have a perfect knowledge of the underlying probability distribution of the data?
\end{question}

\subsubsection{Supervised Learning Problems \& Loss Functions}
We consider a {\it loss function} $l:{\cal Y}\times{\cal Y}\to\mathbb{R}$ (often $\mathbb{R}_+\coloneqq(0,\infty)$), where $l(y,z)$ is the loss of predicting $z$ while the true label is $y$. Some related research communities (e.g., economics) use the concept of ``utility'' which is then maximized.

{\it Meaning of loss function.} Hàm mất mát $l(y,z)$ đóng vai trò như 1 phép đo khoảng cách (a measurement of distances) từ nhãn đúng đến giá trị dự đoán thu được bởi thuật toán học máy.

The loss function only concerns the output space ${\cal Y}$ independent of the input space ${\bf X}$ (check its definition!).
\begin{example}
	\item(i) {\bf Binary classification.} ${\cal Y} = \{0,1\}$ (or often ${\cal Y} = \{\pm1\}$, or, less often, when seen as a subcase of multicategory situation ${\cal Y} = \{1,2\}$); the ``0--1 loss'' defined as
	\begin{equation*}
		l(y,z) = 1_{y\ne z} = \left\{\begin{split}
			&0&&\mbox{if } y = z\mbox{ (no mistake)},\\
			&1&&\mbox{otherwise (mistake)}.
		\end{split}\right.
	\end{equation*}
	is the most commonly used.
	\item {\bf Multicategory classification.} ${\cal Y} = \{1,\ldots,k\}$, $l(y,z) = 1_{y\ne z}$ ($0$--$1$ loss).
	\item {\bf Regression.} ${\cal Y} = \mathbb{R}$, $l(y,z) = (y - z)^2$ (square loss). The absolute loss $l(y,z) = |y - z|$ is often used for robust estimation (đánh giá{\tt/}ước tính mạnh mẽ) (since the penalty for large errors is smaller).
	\item {\bf Structured prediction.} There are many practical problems where ${\cal Y}$ is more complicated, with associated algorithms \& theoretical results. E.g., when ${\cal Y} = \{0,1\}^k$ (leading to \emph{multilabel classification}), the \emph{Hamming loss} $l(y,z) = \sum_{j=1}^k 1_{y_j\ne z_j}$ is commonly used; also, ranking problems involve losses on permutations, see, e.g., \cite[Chap. 13: Structured Prediction]{Bach2024}.
\end{example}

\begin{assumption}[Loss function $l$]
	Assume that the loss function is given to us.
\end{assumption}
In practice, the final user imposes the loss function, as this is how models will be evaluated. Clearly, a single real number may not be enough to characterize the entire prediction behavior. E.g., in binary classification, there are 2 types of errors, false positives \& false negatives, which can be considered simultaneously. Since we now have 2 performance measures (\& in any case with $\ge2$ performance measures), we typically need a curve to characterize the performance of a prediction function.

%------------------------------------------------------------------------------%

\section{Linear Regression -- Hồi Quy Tuyến Tính}
\textbf{\textsf{References -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Bach2024}. {\sc Francis Bach}. {\it Learning Theory from First Principles}. Chap. 3: Linear Least-Squares Regression.
	\item \cite{Deisenroth_Faisal_Ong2024}. {\sc Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong}. {\it Mathematics for Machine Learning}. Chap. 9: Linear Regression.
	\item {\sc Andrew Ng}'s Machine Learning Specialization slides: \url{}.
	\item \cite{Tiep_ML_co_ban}. {\sc Vũ Hữu Tiệp}. {\it Machine Learning Cơ Bản}. Chap. 7: Hồi Quy Tuyến Tính.
	\item Wikipedia: \href{https://en.wikipedia.org/wiki/Linear_function}{Wikipedia{\tt/}linear function}. \href{https://en.wikipedia.org/wiki/Linear_regression}{Wikipedia{\tt/}linear regression}.
\end{enumerate}
{\sf A general idea -- 1 ý tưởng tổng quát.} Ý tưởng này có vẻ được mượn từ Lý Thuyết Thống Kê Có Tham Số (Parametric Statistics Theory), see, e.g., \href{https://en.wikipedia.org/wiki/Parametric_statistics}{Wikipedia{\tt/}parametric statistics}.

For $d\in\mathbb{N}^\star$ pairs $({\bf x}_i,y_i)_{i=1}^d$ of input-output, we represent some (mathematically reasonable) hypotheses $h$ about the data using the parameters $\boldsymbol{\theta} = (\theta_1,\theta_2,\ldots,\theta_{\rm p})$ where ${\rm p} = \operatorname{size}\boldsymbol{\theta}$ is the size{\tt/}dimension (kích thước{\tt/}số chiều) of the vector of parameters, i.e., the total number of parameters in the chosen hypotheses $h$. If the data is correctly predicted according to hypothesis $h_{\boldsymbol{\theta}}$, then $y\approx h_{\boldsymbol{\theta}}({\bf x})$.

\begin{example}[Some examples of hypothesis function $h_{\boldsymbol{\theta}}$ -- Vài ví dụ về hàm giả thiết $h_{\boldsymbol{\theta}}$]
	\item(i) {\rm(Simplest: Linear function{\tt/}affine mapping)} We assume $h_{\boldsymbol{\theta}}$ be a linear function, i.e., $h_{\boldsymbol{\theta}}(x) = \theta_0 + \theta_1x$ for $d = 1$ \& $h_{\boldsymbol{\theta}}({\bf x}) = \theta_0 + [\theta_1,\theta_2,\ldots,\theta_d]\cdot{\bf x}$ for $d\ge2$.
	\item(ii) {\rm(Polynomial)}: When $d = 1$, we can assume $h_{\boldsymbol{\theta}}\in\mathbb{R}[{\bf x}]$ or even $h_{\boldsymbol{\theta}}\in\mathbb{C}[{\bf x}]$, i.e., a polynomial with real{\tt/}complex coefficients in the variable $x$:
	\begin{equation*}
		h_{\boldsymbol{\theta}}(x) = \sum_{i=0}^{\rm p} \theta_ix^i = \theta_0 + \theta_1x + \theta_2x^2 + \cdots + \theta_{\rm p}x^{\rm p}.
	\end{equation*}
	\item(iii) {\rm(Hàm phân thức)} When $d = 1$, we can assume
	\begin{equation*}
		h_{\boldsymbol{\theta}}(x) = \frac{\sum_{i=0}^m \theta_ix^i}{\sum_{m+1}^{\rm p} \theta_ix^{i-m-1}} = \frac{\theta_0 + \theta_1x + \theta_2x^2 + \cdots + \theta_mx^m}{\theta_{m+1} + \theta_{m+2}x + \cdots + \theta_{\rm p}x^{p - m - 1}}.
	\end{equation*}
	\item(iv) {\rm(Hàm căn thức)} We can assume
	\begin{align*}
		h_{\boldsymbol{\theta}}(x) &= \sqrt[n]{\sum_{i=0}^{\rm p} \theta_ix^i} = \sqrt[n]{\theta_0 + \theta_1x + \theta_2x^2 + \cdots + \theta_{\rm p}x^{\rm p}},\\
		h_{\boldsymbol{\theta}}(x) &= \sqrt[n]{\frac{\sum_{i=0}^m \theta_ix^i}{\sum_{m+1}^{\rm p} \theta_ix^{i-m-1}}} = \sqrt[n]{\frac{\theta_0 + \theta_1x + \theta_2x^2 + \cdots + \theta_mx^m}{\theta_{m+1} + \theta_{m+2}x + \cdots + \theta_{\rm p}x^{{\rm p} - m - 1}}},
	\end{align*}
	for a given (fixed) $n\in\mathbb{R}$ or an adjustable $n$, i.e., $n$ itself is also a component of $\boldsymbol{\theta}$.
	\item(v) {\rm(Elementary function -- Hàm sơ cấp)} We can assume $h_{\boldsymbol{\theta}}({\bf x})$ to be an elementary function of the variable ${\bf x}$. For elementary functions, see, e.g., \href{https://en.wikipedia.org/wiki/Elementary_function}{Wikipedia{\tt/}elementary function}.
\end{example}
A typical learning algorithm finds the best hypothesis $h_{\boldsymbol{\theta}}$ for the training set $({\bf x}_i,y_i)_{i=1}^N$. We can then estimate the values of $y$ for the test set $({\bf x}_i,y_i)_{i=N+1}^d$ using the ``optimal'' hypothesis $h_{\boldsymbol{\theta}}({\bf x})$ obtained from our learning algorithm. In particular, if $h_{\boldsymbol{\theta}}$ is a linear function of $x\in\mathbb{R}$, this procedure is called {\it linear regression}.

\subsection{Introduction to linear regression -- Giới thiệu về hồi quy tuyến tính}
{\it1st impression.} Hồi quy tuyến tính (linear regression) là:
\begin{itemize}
	\item 1 thuật toán hồi quy mà đầu ra là 1 hàm số tuyến tính (linear function, i.e., $y = ax + b$, $a,b\in\mathbb{R}$, $a\ne0$) của đầu vào. A brief notation:
	\begin{equation*}
		{\rm output} = \left\{\begin{split}
			&{\tt linear\_function}({\rm input}) = a\,{\rm input} + b&&\mbox{if } d = 1,\\
			&{\tt linear\_function}({\bf inputs}) = {\bf w}\cdot{\bf inputs} + b&&\mbox{if } d\ge2,\\
		\end{split}\right.
	\end{equation*}
	\item Thuật toán đơn giản nhất trong nhóm các thuật toán học có giám sát (supervised learning algorithms).
\end{itemize}

\begin{problem}[Housing prices -- giá cả nhà đất{\tt/}bất động sản]
	Let $m\in\mathbb{N}^\star$. Suppose we have a 2-column table whose the 1st column consists of sizes of $m$ houses: ${\bf x} = (x_1,x_2,\ldots,x_m)$ \& the 2nd one consists of their corresponding housing prices ${\bf y} = (y_1,y_2,\ldots,y_m)$. Here $m$ is the number of training examples, ${\bf x}$ is the vector of input variable or features (size), \& ${\bf y}$ is the vector of output variables or target variables (price).
\end{problem}

\begin{baitoan}[Housing price estimation -- Ước lượng giá nhà, \cite{Tiep_ML_co_ban}, Sect. 7.1, p. 100]
	Xét bài toán ước lượng giá của 1 căn phòng rộng $x_1\ {\rm m}^2$, có $x_2$ phòng ngủ, \& cách trung tâm thành phố $x_3$ km. Giả sử có 1 tập dữ diệu của $N = 10000$ căn nhà trong thành phố đó. Liệu có thể dự đoán được giá $y$ của 1 căn nhà mới (i.e., khác $N$ căn nhà đã có dữ liệu) thông qua 3 thông số về diện tích $x_1\in(0,\infty)$, số phòng ngủ $x_2\in\mathbb{N}$, \& khoảng cách tới trung tâm thành phố $x_3\in[0,\infty)$?
\end{baitoan}
{\sf Mathematical notations -- Ký hiệu toán học.} Đặt ${\bf x} = [x_1,x_2,x_3]^\top\in(0,\infty)\times\mathbb{N}\times[0,\infty)$ là 1 vector cột chứa dữ liệu đầu vào (inputs) gồm 3 thông số diện tích $x_1$, số phòng ngủ $x_2$, \& khoảng cách đến trung tâm thành phố $x_3$; ${\bf x}$ được gọi là {\it vector đặc trưng}. Đặt giá nhà (đầu ra{\tt/}output) $y\in(0,\infty)$.

{\sf Reasoning -- Biện luận.} Nếu diện tích nhà càng lớn thì giá nhà càng cao: $x_1\uparrow\Rightarrow y\uparrow$, nếu nhà có càng nhiều phòng ngủ thì giá nhà càng cao: $x_2\uparrow\Rightarrow y\uparrow$, \& nếu nhà càng ở gần trung tâm thành phố thì giá nhà càng cao: $x_3\downarrow0\Rightarrow y\uparrow$ (why? economics!). Có thể sử dụng mô hình đầu ra là 1 hàm tuyến tính đơn giản của đầu vào:
\begin{equation}
	\label{linear relation}
	\tag{lnr}
	y\approx\hat{y}\coloneqq f({\bf x}) = w_1x_1 + w_2x_2 + w_3x_3 = \sum_{i=1}^3 w_ix_i = {\bf x}^\top{\bf w} = {\bf w}^\top{\bf x} = {\bf x}\cdot{\bf w} = \langle{\bf x},{\bf w}\rangle,
\end{equation}
với ${\bf w} = [w_1,w_2,w_2]^\top$ là {\it vector trọng số} (weight vector) với $w_1,w_2\in(0,\infty),w_3\in(-\infty,0)$ (why?) cần tìm. Mối quan hệ cho bởi \eqref{linear relation} là 1 mối quan hệ tuyến tính.

\begin{question}[Regression factor]
	Why is it called \emph{regression}?
\end{question}
{\it Bản chất.} 2 bài toán dự đoán giá nhà trên là 2 bài toán dự đoán giá trị đầu ra dưa trên vector đặc trưng đầu vào. Ngoài ra, giá trị của đầu ra $y$ có thể nhận rất nhiều giá trị thực dương khác nhau. Nên ta cần tính đi tính lại, tính kết quả đầu ra mới dựa trên các kết quả đầu ra cũ, để nhận được 1 kết quả được xem là tối ưu theo nghĩa nào đó. Vì vậy, đây cũng là 1 bài toán hồi quy. Kết hợp bản chất hồi quy với mối quan hê tuyến tính $\hat{y} = {\bf x}^\top{\bf w}$ cho ra tên gọi {\it hồi quy tuyến tính}. Về hàm tuyến tính, see, e.g., \href{https://en.wikipedia.org/wiki/Linear_function}{Wikipedia{\tt/}linear function}.

{\sf Some reasons to study linear least-squares regression.} From \cite[Sect. 3.1, pp. 45--46]{Bach2024}.
\begin{itemize}
	\item Linear least-squares regression already captures many of the concepts in learning theory, e.g. bias-variance trade-off, as well as dependence of generalization performance on the underlying dimension of the problem with no regularization, or on dimensionless quantities when regularization is added.
	
	-- Hồi quy tuyến tính bình phương nhỏ nhất đã nắm bắt được nhiều khái niệm trong lý thuyết học tập, ví dụ như sự đánh đổi giữa độ lệch và phương sai, cũng như sự phụ thuộc của hiệu suất tổng quát vào chiều cơ bản của vấn đề không có chính quy hóa hoặc vào các đại lượng không có thứ nguyên khi chính quy hóa được thêm vào.
	\item Because of its simplicity, many results can be easily derived without the need for complicated mathematics, both in terms of algorithms \& statistical analysis (simple linear algebra for the simplest results in the fixed design setting).
	
	-- Do tính đơn giản của nó, nhiều kết quả có thể dễ dàng thu được mà không cần đến các phép toán phức tạp, cả về mặt thuật toán \& phân tích thống kê (đại số tuyến tính đơn giản cho kết quả đơn giản nhất trong bối cảnh thiết kế cố định).
	\item Using nonlinear features, it can lead to arbitrary nonlinear predictions.
	
	-- Sử dụng các tính năng phi tuyến tính, nó có thể dẫn đến những dự đoán phi tuyến tính tùy ý.
\end{itemize}

\begin{question}[Optimal choice of parameters $\boldsymbol{\theta}$]
	How to choose parameters $\boldsymbol{\theta}$ ``optimally''? ``Optimal'' in which sense?
	
	-- Làm thế nào để chọn tham số $\boldsymbol{\theta}$ ``tối ưu''? ``Tối ưu'' theo nghĩa nào?
\end{question}

\subsection{A general mathematical setting}
Tổng quát, nếu mỗi điểm dữ liệu được mô tả bởi 1 vector đặc trưng $d$ chiều $x\in\mathbb{R}^d$, hàm dự đoán đầu ra được viết dưới dạng
\begin{equation*}
	y = {\bf x}^\top{\bf w} = {\bf x}\cdot{\bf w} = \sum_{i=1}^d w_ix_i = w_1x_1 + \cdots + w_dx_d.
\end{equation*}
Nếu tính thêm bias (e.g., tiện đặt cọc, chi phí phát sinh, giảm giá, voucher discount, etc.) $b\in\mathbb{R}$ thì thêm vào thành:
\begin{equation*}
	y = {\bf x}^\top{\bf w} + b = {\bf x}\cdot{\bf w} + b = \sum_{i=1}^d w_ix_i + b = w_1x_1 + \cdots + w_dx_d + b.
\end{equation*}

Với bài toán hồi quy nói chung, ta cần cực tiểu sự sai khác $e$ (error) giữa đầu ra thực sự $y$ \& đầu ra dự đoán $\hat{y}$ với $e$ thường được chọn khoảng cách giữa 2 điểm $y$ \& $\hat{y}$, e.g.:
\begin{equation*}
	\frac{1}{2}e^2 = \frac{1}{2}(y - \hat{y})^2 = \frac{1}{2}(y - {\bf x}^\top{\bf w} - b)^2.
\end{equation*}
(Hệ số $\frac{1}{2}$ đóng vai trò là scaling factor, giúp khi tính đạo hàm thì sẽ đơn giản được hệ số, thật vậy: vì $\left(\frac{1}{2}x^2\right)' = x$ nên hệ số $\frac{1}{2}$ sẽ bị triệ tiêu khi lấy đạo hàm của $e$ theo tham số mô hình ${\bf w}$.) Các cách chọn sai số $e$ khác:
\begin{enumerate}
	\item $e = y - \hat{y}$: Khuyết điểm: $y - \hat{y}$ có thể âm, do đó việc cực tiểu hóa $e$ không có ý nghĩa.
	\item $e = |y - \hat{y}|$: Khuyết điểm: Hàm trị tuyệt đối (absolute value function) $f:\mathbb{R}\to[0,\infty)$, $f(x) = |x|$ tuy liên tục nhưng không khả vi tại gốc tọa độ (why?), không thuận tiện cho việc tối ưu.
	\item $e = \frac{1}{p}|y - \hat{y}|^p$ với $p\in(1,\infty)$. Hàm số $f(x) = \frac{1}{p}x^p$ có đạo hàm $f'(x) =|x|^{p-1}$. Khuyết điểm: Cần nhiều tính toán hơn số với hàm bình phương, i.e., khi $p = 2$.
\end{enumerate}

Hàm mất mát đóng vai trò là tiêu chí cho việc tối ưu mô hình: việc tìm mô hình tốt nhất{\tt/}tối ưu nhất (best{\tt/}optimal) tương đương với việc tìm ${\bf w}$ để cực tiểu hàm số:
\begin{equation*}
	L({\bf w}) = \frac{1}{2N}\sum_{i=1}^N (y_i - {\bf x}_i^\top{\bf w})^2.
\end{equation*}
Optimization problem -- Bài toán tối ưu:
\begin{equation*}
	\min_{\bf w} L({\bf w}).
\end{equation*}
Nếu bài toán có nghiệm duy nhất, ký hiệu:
\begin{equation*}
	{\bf w}^* = {\arg\min}_{\bf w} L({\bf w}).
\end{equation*}

%------------------------------------------------------------------------------%

\section{Overfitting -- Quá Khớp}

%------------------------------------------------------------------------------%

\section{$K$ Neighbors -- $K$ Lân Cận}

%------------------------------------------------------------------------------%

\section{Phân Cụm $K$-Means}

%------------------------------------------------------------------------------%

\section{Artificial Neural Networks (ANNs) -- Mạng Neuron Nhân Tạo}

Distinguish: Artificial Neural Network (ANN) vs. Biological Neural Network (BNN), see, e.g., \href{https://en.wikipedia.org/wiki/Neural_network_(machine_learning)}{Wikipedia{\tt/}neural network (machine learning)} vs. \href{https://en.wikipedia.org/wiki/Neural_network_(biology)}{Wikipedia{\tt/}neural network (biology)}, \href{https://psychology.fandom.com/wiki/Biological_neural_networks}{Psychology Wiki{\tt/}biological neural network}.

\begin{definition}[Activation function $\sigma(\cdot)$]
	
\end{definition}

\begin{figure}[H]
	\centering
	\includegraphics[height=6cm]{neuron_activation_anime}\includegraphics[height=6cm]{neuron_activation}
	\caption{A typical monkey's (maybe man also?) biological neural networks (BNN) gets activated by 2D{\tt/}anime girl's strong abs.}
\end{figure}

%------------------------------------------------------------------------------%

\section{Perception Learning Algorithm -- Thuật Toán Học Perceptron}

%------------------------------------------------------------------------------%

\section{Logistic Regression -- Hồi Quy Logistic}

%------------------------------------------------------------------------------%

\section{Softmax Regression -- Hồi Quy Softmax}

%------------------------------------------------------------------------------%

\section{Deep Neural Networks \& Backpropagation -- Mạng Neuron Đa Tầng \& Lan Truyền Ngược}

%------------------------------------------------------------------------------%

\section{Miscellaneous}

\subsection{Contributors}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}