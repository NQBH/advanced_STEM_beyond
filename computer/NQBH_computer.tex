\documentclass{article}
\usepackage[backend=biber,natbib=true,style=alphabetic,maxbibnames=50]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[utf8]{vietnam}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,enumitem,float,graphicx,mathtools,tikz}
\usetikzlibrary{angles,calc,intersections,matrix,patterns,quotes,shadings}
\allowdisplaybreaks
\newtheorem{assumption}{Assumption}
\newtheorem{baitoan}{}
\newtheorem{cauhoi}{Câu hỏi}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{dangtoan}{Dạng toán}
\newtheorem{definition}{Definition}
\newtheorem{dinhly}{Định lý}
\newtheorem{dinhnghia}{Định nghĩa}
\newtheorem{example}{Example}
\newtheorem{ghichu}{Ghi chú}
\newtheorem{hequa}{Hệ quả}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{lemma}{Lemma}
\newtheorem{luuy}{Lưu ý}
\newtheorem{nhanxet}{Nhận xét}
\newtheorem{notation}{Notation}
\newtheorem{note}{Note}
\newtheorem{principle}{Principle}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{question}{Question}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{vidu}{Ví dụ}
\usepackage[left=1cm,right=1cm,top=5mm,bottom=5mm,footskip=4mm]{geometry}
\def\labelitemii{$\circ$}
\DeclareRobustCommand{\divby}{%
	\mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\title{Computer -- Máy Tính}
\author{Nguyễn Quản Bá Hồng\footnote{A Scientist {\it\&} Creative Artist Wannabe. E-mail: {\tt nguyenquanbahong@gmail.com}. Bến Tre City, Việt Nam.}}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
	This text is a part of the series {\it Some Topics in Advanced STEM \& Beyond}:
	
	{\sc url}: \url{https://nqbh.github.io/advanced_STEM/}.
	
	Latest version:
	\begin{itemize}
		\item {\it Computer -- Máy Tính}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/computer/NQBH_computer.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/computer/NQBH_computer.tex}.
	\end{itemize}
\end{abstract}
\tableofcontents

%------------------------------------------------------------------------------%

\section{{\sc Donald Knuth}. The Art of Computer Programming. Volume 1: Fundamental Algorithms}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Knuth1997}. {\sc Donald Knuth}. {\it The Art of Computer Programming. Volume 1: Fundamental Algorithms}.
	
	Với bản dịch tiếng Việt chứa nhiều lỗi chính tả đến mức đáng bị cảnh sát ghé thăm:
	\item \cite{Khoa_art_programming}. {\sc Nguyễn Văn Khoa}. {\it Nghệ Thuật Lập Trình Máy Tính}.
\end{enumerate}
This series of books is affectionately dedicated to the Type 650 computer once installed at Case Institute of Technology, in remembrance of many pleasant evenings.

The author \& publisher have taken care in the preparation of this book, but make no expressed or implied warranty of any kind \& assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.

\subsection{Preface}
{\it``Here is your book, the one your thousands of letters have asked us to publish. It has taken us years to do, checking \& rechecking countless recipes to bring you only the best, only the interesting, only the perfect. Now we can say, without a shadow of a doubt, that every single 1 of them, if you follow the directions to the letter, will work for you exactly as well as it did for us, even if you have never cooked before.''} -- {\sc McCall}'s Cookbook (1963)

``The process of preparing programs for a digital computer is especially attractive, not only because it can be economically \& scientifically rewarding, but also because it can be an aesthetic experience much like composing poetry or music. This book is the 1st volume of a multi-volume set of books that has been designed to train the reader in various skills that go into a programmer's craft.

The following chapters are {\it not} meant to serve as an introduction to computer programming; the reader is supposed to have had some previous experience. The prerequisites are actually very simple, but a beginner requires time \& practice in order to understand the concept of a digital computer. The reader should
possess:
\begin{enumerate}
	\item Some idea of how a stored-program digital computer works; not necessarily the electronics, rather the manner in which instructions can be kept in the machine's memory \& successively executed.
	\item An ability to put the solutions to problems into such explicit terms that a computer can ``understand'' them. (These machines have no common sense; they do exactly as they are told, no more \& no less. This fact is the hardest concept to grasp when one 1st tries to use a computer.)
	\item Some knowledge of the most elementary computer techniques, e.g. looping (performing a set of instructions repeatedly), the use of subroutines, \& the use of indexed variables.
	\item A little knowledge of common computer jargon -- ``memory,'' ``registers,'' ``bits,'' ``floating point,'' ``overflow,'' ``software.'' Most words not defined in the text are given brief definitions in the index at the close of each volume.
\end{enumerate}
These 4 prerequisites can perhaps be summed up into the single requirement that the reader should have written \& tested at least, say, 4 programs for at least 1 computer.

I have tried to write this set of books in such a way that it will fill several needs. In the 1st place, these books are reference works that summarize the knowledge that has been acquired in several important fields. In the 2nd place, they can be used as textbooks for self-study or for college courses in the computer \& information sciences. To meet both of these objectives, I have incorporated a large number of exercises into the text \& have furnished answers for most of them. I have also made an effort to fill the pages with facts rather than with vague, general commentary.

This set of books is intended for people who will be more than just casually interested in computers, yet it is by no means only for the computer specialist. Indeed, 1 of my main goals has been to make these programming techniques more accessible to the many people working in other fields who can make fruitful use of computers, yet who cannot afford the time to locate all of the necessary information that is buried in technical journals.

We might call the subject of these books \fbox{``nonumerical analysis.''} Computers have traditionally been associated with the solution of numerical problems e.g. calculation of roots of an equation, numerical interpolation \& integration, etc., but such topics are not treated here except in passing. Numerical computer programming is an extremely interesting \& rapidly expanding field, \& many books have been written about it. Since the early 1960s, however, computers have been used even more often for problems in which numbers occur only by coincidence; the computer's decision-making capabilities are being used, rather than its ability to do arithmetic. We have some use for addition \& subtraction in nonnumerical problems, but we rarely feel any need for multiplication \& division. Of course, even a person who is primarily concerned with numerical computer programming will benefit from a study of the nonnumerical techniques, for they are present in the background of numerical programs as well.

The results of research in nonnumerical analysis are scattered throughout numerous technical journals. My approach has been to try to distill this vast literature by studying the techniques that are most basic, in the sense that they can be applied to many types of programming situations. I have attempted to coordinate the ideas into more or less of a ``theory,'' as well as to show how the theory applies to a wide variety of practical problems.

Of course, ``nonnumerical analysis'' is a terribly negative name for this field of study; it is much better to have a positive, descriptive term that characterizes the subject. ``Information processing'' is too broad a designation for the material I am considering, \& ``programming techniques'' is too narrow. Therefore I wish to propose \fbox{\it analysis of algorithms} as an appropriate name for the subject matter covered in these books. This name is meant to imply ``the theory of the properties of particular computer algorithms.''

The complete set of books, entitled {\it The Art of Computer Programming}, has the following general outline:
\begin{enumerate}
	\item {\it Vol. 1: Fundamental Algorithms}. Chap. 1: Basic Concepts. Chap. 2: Information Structures.
	\item {\it Vol. 2: Seminumerical Algorithms}. Chap. 3: Random Numbers. Chap. 4: Arithmetic.
	\item {\it Vol. 3: Sorting \& Searching}. Chap. 5: Sorting. Chap. 6: Searching.
	\item {\it Vol. 4: Combinatorial Algorithms}. Chap. 7: Combinatorial Searching. Chap. 8: Recursion.
	\item {\it Vol. 5: Syntactical Algorithms}. Chap. 9: Lexical Scanning. Chap. 10: Parsing.
\end{enumerate}
Vol. 4 deals with such a large topic, it actually represents several separate books (Vols. 4A, 4B, etc.). 2 additional volumes on more specialized topics are also planned: Vol. 6: {\it The theory of Languages} (Chap. 11)' Vol. 7: {\it Compilers} (Chap. 12).

I started out in 1962 to write a single book with this sequence of chapters, but I soon found that it was more important to treat the subjects in depth rather than to skim over them lightly. The resulting length of the text has meant that each chapter by itself contains more than enough material for a 1-semester college course; so it has become sensible to publish the series in separate volumes. I know that it is strange to have only 1 or 2 chapters in an entire book, but I have decided to retain the original chapter numbering in order to facilitate cross references. A shorter version of Vols. 1--5 is planned, intended specifically to serve as a more general reference \&{\tt/}or text for undergraduate computer courses; its contents will be a subset of the material in these books, with the more specialized information omitted. The same chapter numbering will be used in the abridged edition as in the complete work.

The present volume may be considered as the ``intersection'' of the entire set, in the sense that it contains basic material that is used in all the other books. Vols. 2--5, on the other hand, may be read independently of each other. Vol. 1 is not only a reference book to be used in connection with the remaining volumes; it may also be used in college courses or for self-study as a text on the subject of {\it data structures} (emphasizing the material of Chap. 2), or as a text on the subject of {\it discrete mathematics}, or as a text on the subject of {\it machine-language programming}.

The point of view I have adopted while writing these chapters differs from that taken in most contemporary books about computer programming in that I am not trying to teach the reader how to use somebody else's software. I am concerned rather with teaching people how to write better software themselves.

My original goal was to bring readers to the frontiers of knowledge in every subject that was treated. But it is extremely difficult to keep up with a field that is economically profitable, \& the rapid rise of computer science has made such a dream impossible. The subject has become a vast tapestry\footnote{tấm thảm.} with $a\cdot10^4$ of subtle results contributed by $a\cdot10^4$ of talented people all over the world. Therefore my new goal has been to concentrate on ``classic'' techniques that are likely to remain important for many more decades, \& to describe them as well as I can. In particular, I have tried to trace the history of each subject, \& to provide a solid foundation for future progress. I have attempted to choose terminology that is concise \& consistent with current usage. I have tried to include all of the known ideas about sequential computer programming that are both beautiful \& easy to state.

A few words are in order about the mathematical content of this set of books. The material has been organized so that persons with no more than a knowledge of high-school algebra may read it, skimming briefly over the more mathematical portions; yet a reader who is mathematically inclined will learn about many interesting mathematical techniques related to discrete mathematics. This dual level of presentation has been achieved in part by assigning ratings to each of the exercises so that the primarily mathematical ones are marked specifically as such, \& also by arranging most sections so that the main mathematical results are stated {\it before} their proofs. The proofs are either left as exercises (with answers to be found in a separate section) or they are given at the end of a section.

A reader who is interested primarily in programming rather than in the associated mathematics may stop reading most sections as soon as the mathematics becomes recognizably difficult. On the other hand, a mathematically oriented reader will find a wealth of interesting material collected here. Much of the published mathematics about computer programming has been faulty, \& 1 of the purposes of this book is to instruct readers in proper mathematical approaches to this subject. Since I profess to be a mathematician, it is my duty to \fbox{maintain mathematical integrity} as well as I can.

A knowledge of elementary calculus will suffice for most of the mathematics in these books, since most of the other theory that is needed is developed herein. However, I do need to use deeper theorems of complex variable theory, probability theory, number theory, etc., at times, \& in such cases I refer to appropriate textbooks where those subjects are developed.

The hardest decision that I had to make while preparing these books concerned the manner in which to present the various techniques. The advantages of flow charts \& of an informal step-by-step description of an algorithm are well known; for a discussion of this, see the article ``Computer-Drawn Flowcharts'' in the ACM {\it Communications}, Vol. 6 (Sep. 1963), pp. 555--563. Yet a formal, precise language is also necessary to specify any computer algorithm, \& I needed to decide whether to use an algebraic language, e.g. ALGOL or FORTRAN, or to use a machine-oriented language for this purpose. Perhaps many of today's computer experts will disagree with my decision to use a machine-oriented language, but I have become convinced that it was definitely the correct choice, for the following reasons:
\begin{enumerate}
	\item A programmer is greatly influenced by the language in which programs are written; there is an overwhelming tendency to prefer constructions that are simplest in that language, rather than those that are best for the machine. By understanding a machine-oriented language, the programmer will tend to use a much more efficient method; it is much closer to reality.
	\item The programs we require are, with a few exceptions, all rather short, so with a suitable computer there will be no trouble understanding the programs.
	\item High-level languages are inadequate for discussing important low-level details e.g. coroutine linkage, random number generation, multi-precision arithmetic, \& many problems involving the efficient usage of memory.
	\item A person who is more than casually interested in computers should be well schooled in machine language, since it is a fundamental part of a computer.
	\item Some machine language would be necessary anyway as output of the software programs described in many of the examples.
	\item New algebraic languages go in \& out of fashion every 5 years or so, while I am trying to emphasize concepts that are timeless.
\end{enumerate}
From the other point of view, I admit that it is somewhat easier to write programs in higher-level programming languages, \& it is considerably easier to debug the programs. Indeed, I have rarely used low-level machine language for my own programs since 1970, now that computers are so large \& so fast. Many of the problems of interest to us in this book, however, are those for which the programmer's art is most important. E.g., some combinatorial calculations need to be repeated a trillion times, \& we save about 11.6 days of computation for every microsecond we can squeeze out of their inner loop. Similarly, it is worthwhile to put an additional effort into the writing of software that will be used many times each day in many computer installations, since the software needs to be written only once.

Given the decision to use a machine-oriented language, which language should be used? I could have chosen the language of a particular machine $X$, but then those people who do not possess machine $X$ would think this book is only for $X$-people. Furthermore, machine $X$ probably has a lot of idiosyncrasies\footnote{đặc điểm riêng.} that are completely irrelevant to the material in this book yet which must be explained; \& in 2 years the manufacturer of machine $X$ will put out machine $X + 1$ or machine $10X$, \& machine $X$ will no longer be of interest to anyone.

To avoid this dilemma, I have attempted to design an ``ideal'' computer with very simple rules of operation (requiring, say, only an hour to learn), which also resembles actual machines very closely. There is no reason why a student should be afraid of learning the characteristics of $> 1$ computer; once 1 machine language has been mastered, others are easily assimilated. Indeed, serious programmers may expect to meet different machine languages in the course of their careers. So the only remaining disadvantage of a mythical machine is the difficulty of executing any programs written for it. Fortunately, that is not really a problem, because many volunteers have come toward to write simulators for the hypothetical machine. Such simulators are ideal for instructional purposes, since they are even easier to use than a real computer would be. I have attempted to cite the best early papers in each subject, together with a sampling of more recent work. When referring to the literature, I use standard abbreviations for the names of periodicals, except that the most commonly cited journals are abbreviated as follows:
\begin{enumerate}
	\item CACM $=$ Communications of the Association for Computing Machinery
	\item CACMJACM $=$ Journal of the Association for Computing Machinery
	\item CACMComp. J. $=$ The Computer Journal (British Computer Society)
	\item CACMMath. Comp. $=$ Mathematics of Computation
	\item CACMAMM $=$ American Mathematical Monthly
	\item CACMSICOMP $=$ SIAM Journal on Computing
	\item CACMFOCS $=$ IEEE Symposium on Foundations of Computer Science
	\item CACMSODA $=$ ACM–SIAM Symposium on Discrete Algorithms
	\item CACMSTOC $=$ ACM Symposium on Theory of Computing
	\item CACMCrelle $=$ Journal für die reine und angewandte Mathematik
\end{enumerate}
I also use ``CMath'' to stand for the book {\it Concrete Mathematics}.

{\bf Preface to the 3rd Edition.} After having spent 10 years developing the \TeX\ \& METAFONT systems for computer typesetting, I am now able to fulfill the dream that I had when I began that work, by applying those systems to {\it The Art of Computer Programming}. At last the entire text of this book has been captured inside my personal computer, in an electronic form that will make it readily adaptable to future changes in printing \& display technology. The new setup has allowed me to make literally thousands of improvements that I've been wanting to incorporate for a long time.

In this new edition I have gone over every word of the text, trying to retain the youthful exuberance\footnote{sự hồ hởi.} of my original sentences while perhaps adding some more mature judgment. Dozens of new exercises have been added; dozens of old exercises have been given new \& improved answers.

{\it The Art of Computer Programming} is, however, still a work in progress. Therefore some parts of this book are headed by an ``under construction'' icon, to apologize for the fact that the material is not up-to-date. My files are bursting with important material that I plan to include in the final, glorious, 4th edition of Vol. 1, perhaps 15 years from now; but I must finish Vols. 4 --5 1st, \& I do not want to delay their publication any more than absolute necessary.

My efforts to extend \& enhance these volumes have been enormously enhanced since 1980 by the wise guidance of Addison--Wesley's editor {\sc Peter Gordon}. He has become not only my ``publishing partner'' but also a close friend, while continually nudging me to move in fruitful directions. Indeed, my interactions with dozens of Addison--Wesley people during $> 3$ decades have been much better than any author deserves. The tireless support of managing editor {\sc John Fuller}, whose meticulous attention to detail has maintained the highest standards of production quality in spite of frequent updates, has been particularly praiseworthy.
\begin{quote}
	{\it``Things have changed in the past 2 decades.''} -- {\sc Bill Gates} (1995)
	
	{\it``Woe be to him that reads but one book.''} -- {\sc George Herbert}, {\it Jacula Prudentum}, 1144 (1640)
	
	{\it``Le défaut unique de tous les ouvrages c'est d'être trop longs.''} -- {\sc Vauvenargues}, {\it R\'eflexions}, 628 (1746)
	
	{\it``Books are a triviality\footnote{sự tầm thường.}. Life alone is great.''} -- {\sc Thomas Carlyle}, {\it Journal} (1839)
\end{quote}
{\bf Notes on the Exercises.} The exercises in this set of books have been designed for self-study as well as for classroom study. It is difficult, if not impossible, for anyone to learn a subject purely by reading about it, without applying the information to specific problems \& thereby being encouraged to think about what has been read. Furthermore, we all learn best the things that we have discovered for ourselves. Therefore the exercises form a major part of this work; a definite attempt has been made to keep them as informative as possible \& to select problems that are enjoyable as well as instructive.

In many books, easy exercises are found mixed randomly among extremely difficult ones. A motley\footnote{sặc sỡ.} mixture is, however, often unfortunate because readers like to know in advance how long a problem ought to take -- otherwise they may just skip over all the problems. A classic example of such a situation is the book {\it Dynamic Programming} by {\sc Richard Bellman}; this is an important, pioneering work in which a group of problems is collected together at the end of some chapters under the heading ``Exercises \& Research Problems,'' with extremely trivial questions appearing in the midst of deep, unsolved problems. It is rumored that someone once asked Dr. {\sc Bellman} how to tell the exercises apart from the research problems, \& he replied, ``If you can solve it, it is an
exercise; otherwise it's a research problem.''

Good arguments can be made for including both research problems \& very easy exercises in a book of this kind; therefore, to save the reader from the possible dilemma of determining which are which, {\it rating numbers} have been provided to indicate the level of difficulty. These numbers have the following general significance: {\sf Rating: Interpretation}
\begin{itemize}
	\item 00: An extremely easy exercise that can be answered immediately if the material of the text has been understood; such an exercise can almost always be worked ``in your head.''
	\item 10: A simple problem that makes you think over the material just read, but is by no means difficult. You should be able to do this in one minute at most; pencil \& paper may be useful in obtaining the solution.
	\item 20: An average problem that tests basic understanding of the text material, but you may need about 15 or 20 minutes to answer it completely.
	\item 30: A problem of moderate difficulty \&{\tt/}or complexity; this one may involve $> 2$ hours' work to solve satisfactorily, or even more if the TV is on.
	\item 40: Quite a difficult or lengthy problem that would be suitable for a term project in classroom situations. A student should be able to solve the problem in a reasonable amount of time, but the solution is not trivial.
	\item 50: A research problem that has not yet been solved satisfactorily, as far as the author knew at the time of writing, although many people have tried. If you have found an answer to such a problem, you ought to write it up for publication; furthermore, the author of this book would appreciate hearing about the solution as soon as possible (provided that it is correct).
\end{itemize}
By interpolation in this ``logarithmic'' scale, the significance of other rating numbers becomes clear. E.g., a rating of 17 would indicate an exercise that is a bit simpler than average. Problems with a rating of 50 that are subsequently solved by some reader may appear with a 40 rating in later editions of the book, \& in the errata posted on the Internet.

The remainder of the rating number divided by 5 indicates the amount of detailed work required. Thus, an exercise rated 24 may take longer to solve than an exercise that is rated 25, but the latter will require more creativity. All exercises with ratings of 46 or more are open problems for future research, rated according to the number of different attacks that they've resisted so far.

The author has tried earnestly to assign accurate rating numbers, but it is difficult for the person who makes up a problem to know just how formidable it will be for someone else to find a solution; \& everyone has more aptitude for certain types of problems than for others. It is hoped that the rating numbers represent a good guess at the level of difficulty, but the should be taken as general guidelines, not as absolute indicators.

This book has been written for readers with varying degrees of mathematical training \& sophistication; as a result, some of the exercises are intended only for the use of more mathematically inclined readers. The rating is preceded by an $M$ if the exercise involves mathematical concepts or motivation to a greater extent than necessary for someone who is primarily interested only in programming the algorithms themselves. An exercise is marked with the letters ``$HM$'' if its solution necessarily involves a knowledge of calculus or other higher mathematics not developed in this book. An ``$HM$'' designation does {\it not} necessarily imply difficulty.

Some exercises are preceded by an arrowhead, $\triangleright$; this designates problems that are especially instructive \& especially recommended. Of course, no reader{\tt/}student is expected to work {\it all} of the exercises, so those that seem to be the most valuable have been singled out. (This distinction is not meant to detract from the other exercises!) Each reader should at least make an attempt to solve all of the problems whose rating is 10 or less; \& the arrows may help to indicate which of the problems with a higher rating should be given priority.

Solutions to most of the exercises appear in the answer section. Please use them wisely; do not turn to the answer until you have made a genuine effort to solve the problem by yourself, or unless you absolutely do not have time to work this particular problem. {\it After} getting your own solution or giving the problem a decent try, you may find the answer instructive \& helpful. The solution given will often be quite short, \& it will sketch the details under the assumption that you have earnestly tried to solve it by your own means 1st. Sometimes the solution gives less information than was asked; often it gives more. It is quite possible that you may have a better answer than the one published here, or you may have found an error in the published solution; in such a case, the author will be pleased to know the details. Later printings of this book will give the improved solutions together with the solver's name where appropriate.

When working an exercise you may generally use the answers to previous exercises, unless specifically forbidden from doing so. The rating numbers have been assigned with this in mind; thus it is possible for exercise $n + 1$ to have a lower rating than exercise $n$, even though it includes the result of exercise $n$ as a special case.

{\sf Summary of codes.} $\triangleright$: Recommended. $M$: Mathematical oriented. $HM$: Requiring ``higher math''. 00: Intermediate. 10: Simple (1 min). 20: Medium (15 mins). 30: Moderately hard. 40: Term project. 50: Research problem.

{\bf2.} [10] Of what value can the exercises in a textbook be to the reader? {\bf3.} Generalize your answer. [This is an example of a horrible kind of problem that the author has tried to avoid.]
\begin{quotation}
	{\it``We can face our problem. We can arrange such facts as we have with order \& method.''} -- {\sc Hercule Poirot}, in {\it Murder on the Orient Express} (1934)
\end{quotation}

\subsection{Chap. 1: Basic Concepts}

\begin{quotation}
	{\it``Many persons who are not conversant with mathematical studies imagine that because the business of [Babbage's Analytical Engine] is to give its results in numerical notation, the nature of its processes must consequently be arithmetical \& numerical, rather than algebraical \& analytical. This is an error. The engine can arrange \& combine its numerical quantities exactly as if they were letters or any other general symbols; \& in fact it might bring out its results in algebraical notation, were provisions made accordingly.''} -- {\sc Augusta Ada}, {\it Countess of Lovelace} (1843)
	
	{\it``Practice yourself, for heaven's sake, in little things; \& thence proceed to greater.''} -- {\sc Epictetus}, {\it Discourses} IV.i
\end{quotation}

\subsubsection{Algorithms}
The notion of an {\it algorithm} is basic to all of computer programming, so we should begin with a careful analysis of this concept.

The word ``algorithm'' itself is quite interesting; at 1st glance it may look as though someone intended to write ``logarithm'' but jumbled up the 1st 4 letters. The word did not appear in {\it Webster's New World Dictionary} as late as 1957; we find only the older form ``algorism'' with its ancient meaning, the process of doing arithmetic using Arabic numerals. During the Middle Ages, abacists computed on the abacus \& algorists computed by algorism. By the time of the Renaissance, the origin of this word was in doubt, \& early linguists attempted to guess at its derivation by making combinations like {\it algiros} [painful] $+$ {\it arithmos} [number]; others said no, the word comes from ``King Algor of Castile.'' Finally, historians of mathematics found the true origin of the word algorism: It comes from the name of a famous Persian textbook author, Abu `Abd Allah Muh ammad ibn Musa al-Khwarizmi (c. 825) -- literally, ``Father of Abdullah, Mohammed,
son of Moses, native of Khwarizm.'' The Aral Sea in Central Asia was once known as Lake Khwarizm, \& the Khwarizm region is located in the Amu River basin just south of that sea. Al-Khwarizmi wrote the celebrated Arabic text {\it Kitab al-jabr wa'l-muqabala} (``Rules of restoring \& equating''); another word, ``algebra,'' stems from the title of that book, which was a systematic study of the solution of linear \& quadratic equations.

Gradually the form \& meaning of {\it algorism} became corrupted; as explained by the {\it Oxford English Dictionary}, the word ``passed through many pseudo-etymological perversions, including a recent {\it algorithm}, in which it is learnedly confused'' with the Greek root of the word {\it arithmetic}. This change from ``algorism'' to ``algorithm'' is not hard to understand in view of the fact that people had forgotten the original derivation of the word. An early German mathematical dictionary, {\it Vollständiges mathematisches Lexicon} (Leipzig: 1747), gave the following definition for the word {\it Algorithmus}: ``Under this designation are combined the notions of the 4 types of arithmetic calculations, namely addition, multiplication, subtraction, \& division.'' The Latin phrase {\it algorithmus infinitesimalis} was at that time used to denote ``ways of calculation with infinitely small quantities, as invented by {\sc Leibniz}.''

By 1950, the word algorithm was most frequently associated with {\sc Euclid}'s algorithm, a process for finding the greatest common divisor of 2 numbers appearing in {\sc Euclid}'s {\it Elements} (Book 7, Props. 1--2), see \cite[Algorithm E: {\sc Euclid}'s algorithm, p. 2]{Knuth1997}.

Each algorithm we consider has been given an identifying letter (E in the preceding example), \& the steps of the algorithm are identified by this letter followed by a number (E1, E2, E3).

Each step of an algorithm, e.g. step E1 above, begins with a phrase in brackets that sums up as briefly as possible the principal content of that step. This phrase also usually appears in an accompanying {\it flow chart} so that the reader will be able to picture the algorithm more readily.

After the summarizing phrase comes a description in words \& symbols of some {\it action} to be performed or some decision to be made. Parenthesized {\it comments}, like the 2nd sentence in step E1, may also appear. Comments are included as explanatory information about that step, often indicating certain invariant characteristics of the variables or the current goals. They do not specify actions belonging to the algorithm, but are meant only for the reader's benefit as possible aids to comprehension.

\subsection{Chap. 2: Information Structures}

%------------------------------------------------------------------------------%

\section{Competitive Programming (CP)}

\subsection{\cite{Durr_Vie2021}. {\sc Christoph D\"urr, Jill-J\^enn Vie}. Competitive Programming in Python: 128 Algorithms to Develop Your Coding Skills. 2021}
Want to kill it at your job interview in tech industry? Want to win that coding competition? Learn all algorithmic techniques \& programming skills you need from 2 experienced coaches, problem-setters, \& judges for coding competitions. Authors highlight versatility of each algorithms by considering a variety of problems \& show how to implement algorithms in simple \& efficient code. What to expect:
\begin{itemize}
	\item Master 128 algorithms in Python.
	\item Discover right way to tackle a problem \& quickly implement a solution of low complexity
	\item Understand classic problems like Dijkstra's shortest path algorithm \& Knuth--Morris--Pratt's string matching algorithm, plus lesser-known data structures like Fenwick trees \& Knuth's dancing links.
	\item Develop a framework to tackle algorithmic problem solving, including: Def, Complexity, Applications, Algorithm, Key Information, Implementation, Variants, In Practice, \& Problems.
	\item Python code included in book \& on companion website.
\end{itemize}
{\sc Christoph D\"urr} is a senior researcher at French National Center for Scientific Research (CNRS), affiliated with Sorbonne University in Paris. After a PhD in 1996 at Paris-Sud University, worked for 1 year as a postdoctoral researcher at International CS Institute in Berkeley \& 1 year in School of CS \& Engineering in Hebrew University of Jerusalem in Israel. Has worked in fields of quantum computation, discrete tomography (chụp cắt lớp rời rạc), \& algorithmic game theory, \& his current research activity focuses on algorithms \& optimization. From 2007--2014: taught a preparation course for programming contests at engineering school \'Ecole Polytechnique, \& acts regularly as a problem setter, trainer, or competitor for various coding competitions. Love carrot cake.

{\sc Jill-J\^enn Vie} is a research scientist at Inria in ML. An alumnus from \'Ecole normale sup\'erieure Paris-Saclay, where founded algorithmic club of Paris-Saclay (CAPS) \& coached several teams for International Collegiate Programming Contest (ICPC). Published a book in theoretical CS to help students prepare for prestigious French competitive exams e.g. {\it Grandes \'Ecoles} pr {\it agr\'egation}, \& directed a television show ``Blame the Algorithm'' about algorithms that govern our lives. He is part of advisory board of French CS Society (SIF), itself a member of International Federation for Information Processing (IFIP).
\begin{itemize}
	\item {\sf Preface.} Algorithms play an important role in our society, solving numerous mathematical problems which appear in a broad spectrum of situations. To give a few examples, think of planning taxi routes given a set of reservations (Sect. 9.1.2); assigning students to schools in a large urban school district, e.g. New York (Sect. 9.4); or identifying a bottleneck in a transportation network (Sect. 9.8). This is why job interviews in IT industry test candidates for their problem-solving skills. Many programming contests are organized by companies e.g. Google, Facebook, \& Microsoft to spot gifted candidates \& then send them job offers. This book will help students to develop a culture of algorithms \& data structures, so that they know how to apply them properly when faced with new mathematical problems.
	
	Designing right algorithm to solve a given problem is only half of work; to complete job, algorithm needs to be implemented efficiently. This is why this book also emphasizes implementation issues, \& provides full source code for most of algorithms presented. Have chosen Python for these implementations. What makes this language so enticing: Python allows a particularly clear \& refined expression, illustrating essential steps of algorithm, without obscuring things behind burdensome notations describing data structures. Surprisingly, Python is actually possible to re-read code written several months ago \& even understand it!
	
	Have collected 128 algorithmic problems, indexed by theme rather than by technique. Many are classic, whereas certain are atypical (khác biệt). This work should prove itself useful when preparing to solve wide variety of problems posed in programming contests e.g. ICPC, Google Code Jam, Facebook Hacker Cup, Prologin, France-ioi, etc. Hope: could serve as a basis for an advanced course in programming \& algorithms, where even certain candidates for `agr\'egation de math\'ematiques option informatique' (French competitive exam for highest teacher's certification) will find a ew original developments. Website \url{https://tryalgo.org/}, maintained by authors, contains links to code of this book $+$ selected problems at various online contests. This allows readers to verity their freshly acquired skills.
	
	Hope: reader will pass many long hours tackling algorithmic problems that at 1st glance appear insurmountable (không thể vượt qua), \& in end feel profound joy when a solution, especially an elegant solution, suddenly becomes apparent. Attention, it's all systems go!
	\item {\sf1. Introduction.}
	\begin{quote}
		You, my young friend, are going to learn to program algorithms of this book, \& then go on to win programming contests, sparkle during job interviews, \& finally roll up your sleeves, get to work, \& greatly improve gross national product!
	\end{quote}
	Mistakenly, computer scientists are still often considered magicians of modern times. Computers have slowly crept into our businesses, our homes, \& our machines, \& have become important enablers in functioning of our world. However, there are many that use these devices without really mastering them, \& hence, they do not fully enjoy their benefits. Knowing how to program provides ability to fully exploit their potential to solve problems in an efficient manner. Algorithms \& programming techniques have become a necessary background for many professions. Their mastery allows development of creative \& efficient computer-based solutions to problems encountered every day.
	
	This text presents a variety of algorithmic techniques to solve a number of classic problems. It describes practical situations where these problems arise, \& presents simple implementations written in programming language Python. Correctly implementing an algorithm is not always easy: there are numerous traps to avoid \& techniques to apply to guarantee announced running times. Examples in text are embellished with explanations of important implementation details which must be respected.
	
	For last several decades, programming competitions have sprung up at every level all over world, in order to promote a broad culture of algorithms. Problems proposed in these contests are often variants of classic algorithmic problems, presented as frustrating enigmas that will never let you give up until you solve them!
	\begin{itemize}
		\item {\sf1.1. Programming Competitions.} In a programming competition, candidates must solve several problems in a fixed time. Problems are often variants of classic problems, e.g. those addressed in this book, dressed up with a short story. Inputs to problems are called {\it instances}. An instance can be, e.g., adjacency matrix of a graph for a shortest path problem. In general, a small example of an instance is provided, along with its solution. Source code of a solution can be uploaded to a server via a web interface, where it is compiled \& tested against instances hidden from public. For some problems code is called for each instance, whereas for others input begins with an integer indicating number of instances occurring in input. In latter case, program must then loop over each instance, solve it, \& display results. A submission is accepted if it gives correct results in a limited time, on order of a few secs. {\sf Fi.1.1: Logo of ICPC nicely shows steps in resolution of a problem. A helium balloon is presented to team for each problem solved.} To give a list of all programming competitions \& training sites is quite impossible, \& such a list would quickly become obsolete. Nevertheless, review some of most important ones.
		\begin{itemize}
			\item {\bf ICPC.} Oldest of these competitions was founded by {\it Association for Computing Machinery} i 1977 \& supported by them up until 2017. This contest, known as ICPC, for {\it International Collegiate Programming Contest}, is organized in form of a tournament. Starting point is 1 of regional competitions, e.g. {\it South-West European Regional Contest} (SWERC), where 2 best teams qualify for worldwide final. Particularity of this contest: each 3-person team has only a single computer at their disposal (xử lý). Have only 5 hours to solve a maximum number of problems among 10 proposed. 1st ranking criterion: number of submitted solutions accepted (i.e. tested successfully against a set of unknown instances). Next criterion: sum over submitted problems of time between start of contest \& moment of accepted submission. For each erroneous submission, a penalty of 20 minutes is added.
			
			There are several competing theories on what ideal composition of a team is. In general, a good programmer \& someone familiar with algorithms is required, along with a specialist in different domains e.g. graph theory, dynamic programming, etc. \&, of course, team members need to get along together, even in stressful situations!
			
			For contest, each team can bring 25 pages of reference code printed in an 8-point font. They can also access online documentation of Java API \& C++ standard library.
		\end{itemize}
	\end{itemize}
	\item {\sf2. Character Strings.}
	\item {\sf3. Sequences.}
	\item {\sf4. Arrays.}
	\item {\sf5. Intervals.}
	\item {\sf6. Graphs.}
	\item {\sf7. Cycles in Graphs.}
	\item {\sf8. Shortest Paths.}
	\item {\sf9. Matchings \& Flows.}
	\item {\sf10. Trees.}
	\item {\sf11. Sets.}
	\item {\sf12. Points \& Polygons.}
	\item {\sf13. Rectangles.}
	\item {\sf14. Numbers \& Matrices.} Present a few efficient implementations of classic manipulations of numbers: arithmetical operations, evaluation of expressions, resolution of linear systems, \& sequences of multiplication of matrices.
	\begin{itemize}
		\item {\sf14.1. GCD.} Given $a,b\in\mathbb{Z}$, seek largest integer $p$ s.t. $a,b$ can be expressed as integer multiples of $p$; this is their {\it greatest common divisor} (GCD).
		
		Calculation of GCD can be implemented recursively to be very efficient. A mnemonic trick (mẹo ghi nhớ): from 2nd iteration on, arrange to always have 2nd argument smaller than 1st: $a\mod b < b$.
		\begin{verbatim}
			def pgcd(a, b):
			    return a if b == 0 else pgcd(b, a % b)
		\end{verbatim}
		Complexity of this division version of Euclid's algorithm is $O(\log a + \log b)$. Indeed, 1st parameter diminishes by at least a factor of 2 every 2nd iteration.
		\item {\sf14.2. B\'ezout Coefficients.} Def: For $a,b\in\mathbb{Z}$, would like to find $u,v\in\mathbb{Z}$ s.t. $au + bv = d$ where $d = \gcd(a,b)$.
		
		This calculation is based on an observation similar to above. If $a = bq + r$, then $au + bv = d$ corresponds to $(bq + r)u + bv = d$, or $bu' + rv' = d$ for $u' = qu + v,v' = u\Leftrightarrow u = v',v = u' - qv'$. This calculation also terminates in $O(\log a + \log b)$ steps.
		
		{\it Variant.} Certain problems involve calculation of extremely large numbers, \& consequently require a response modulo a large prime number $p$ in order to test if solution is correct. Since $p$ is prime, can easily divide by an integer $a$ non-multiple of $p$: $(a,p) = 1$, hence their B\'ezout coefficients satisfy $au + pv = 1$, hence $au = 1(\mod p)$, \& $u$ is inverse of $a$. Hence, to divide by $a$, can instead multiply by $u(\mod p)$.
		\item {\sf14.3. Binomial Coefficients.} In calculation of $\binom{n}{k}$, equal to $\frac{n!}{k!(n - k)!}$, risky to calculate $n(n - 1)\cdots(n - k + 1)$ \& $k!$ separately, given possibility of an overflow. Can exploit fact: product of $i$ consecutive integers always contains a term divisible by $i$.
		\begin{verbatim}
			def binom(n, k):
			    prod = 1
			    for i in range(k):
			        prod = (prod * (n - i)) // (i + 1)
			    return prod
		\end{verbatim}
		For most of these problems, calculation of binomial coefficients needs to be taken modulo a prime number $p$. Code then becomes as follows, with complexity $O(k(\log k + \log p))$, relying on calculation of B\'ezout coefficients.
		\begin{verbatim}
			def binom_modulo(n, k, p):
			    prod = 1
			    for i in range(k):
			        prod = (prod * (n - i) * inv(i + 1, p)) % p
			    return prod
		\end{verbatim}
		An alternative: calculate Pascal's triangle by dynamic programming, which could be interesting if $\binom{n}{k}$ needs to be calculated for numerous pairs $n,k$.
		\item {\sf14.4. Fast Exponentiation.} Def: Given $a,b$ wish to calculate $a^b$. Again, as result risks being enormous, often asked to perform calculation module a given integer $p$, but this does not change nature of problem.
		
		{\it Algorithm in $O(\log b)$.} Naive approach performs $b - 1$ multiplications by $a$. However, can rapidly calculate powers of $a$ of form $a^1,a^2,a^4,a^8,\ldots$ using relation $a^{2^k}\cdot a^{2^k} = a^{2^{k+1}}$. A trick consists of combining these values according to binary decomposition of $b$. E.g.: $a^{13} = a^{8 + 4 + 1} = a^8\cdot a^4\cdot a^1$. For this calculation, suffice to generate $O(\log_2 b)$ powers of $a$. Implementation below is reproduced with gracious permission of {\sc Louis Abraham}. At $i$th iteration, variable {\tt a} contains $a_0^{2^i}\mod p$ \& variable {\tt b} contains $\lfloor\frac{b_0}{2^i}\rfloor$, where $a_0,b_0$: inputs to function. Thus, it suffices to test parity bit of {\tt b} in body of loop to determine binary decomposition of $b$. Operation {\tt b >>= 1} $\Leftrightarrow$ performing an integer division of $b$ by 2.
		\begin{verbatim}
			def fast_exponentiation(a, b, q):
			    assert a >= 0 and b >= 0 and q >= 1
			    result = 1
			    while b:
			        if b % 2 == 1:
			            result = (result * a) % q
			        a = (a * a) % q
		        	b >>= 1
			    return result
		\end{verbatim}
		{\it Variant.} This technique can also be applied to matrix multiplications. Let $A$: a matrix, $b\in\mathbb{N}^\star$. Rapid exponentiation allows calculation of $A^b$ with only $O(\log b)$ matrix multiplications.
		
		\begin{problem}[Last digit \href{https://www.spoj.com/problems/LASTDIG/}{spoj:LASTDIG}]
			
		\end{problem}
		
		\begin{problem}[Tiling a grid with dominoes \href{http://www.spoj.com/problems/GNY07H/}{spoj:GNY07H]}]
			
		\end{problem}
		\item {\sf14.5. Prime numbers.} {\it Sieve of Eratosthenes.} Given $n$, seek all prime numbers $< n$. Sieve of Eratosthenes is a simple method to execute this task. Begin with a list of all integers $< n$, with initially 0 \& 1 marked. Then, for each $p = 2,3,4,\ldots,n - 1$, if $p$ is not marked, then $p$ is prime, \& in this case mark all multiples of $p$. Complexity of this procedure is delicate to analyze: $O(n\log\log n)$.
		
		{\it Implementation Details.} Proposed implementation skips marking 0, 1 as well as multiples of 2. This is why iteration over $p$ is done with a step of 2, in order to test only odd numbers.
		\begin{verbatim}
			def eratosthene(n):
			    P = [True] * n
			    answ = [2]
			    for i in range(3, n, 2):
			        if P[i]:
			            answ.append(i)
			            for j in range(2 * i, n, i):
			                P[j] = False
			    return answ
		\end{verbatim}
		{\sf Gries--Misra Sieve.} A deficiency of preceding algorithm: it marks same composite number several times. An improvement was proposed by {\sc David Gries \& Jayadev Misra} in 1978 [Ref] that gets around this deficiency \& has a theoretical complexity of $O(n)$. Thus gain a factor of $\log\log n$. Their algorithm is not much longer but multiplicative constant in complexity is a bit larger. Our experiments have shown an improvement in execution time with, in general, a factor $\frac{1}{2}$ for interpretor {\tt pypy}, but a deterioration by a factor 3 for interpretor {\tt python3}.
		
		{\sc Dexter Kozen} showed: algorithm could at same time produce an array {\tt factor} associating with every integer $2\le x < n$ smallest nontrivial integer factor of $x$. This array is very useful in generation of decomposition in prime factors of a given integer.
		
		Algorithm is based on unique prime decomposition of a composite integer (fundamental theorem of arithmetic). Indeed, an integer $y$ can be written in form $y = {\tt factor}[y]\cdot x$ with ${\tt factor}[y]\le{\tt factor}[x]$.
		
		Algorithm enumerates all of composite integers by looping 1st on $x = 2,\ldots,n - 1$, \& then over all prime numbers $p$, with $p\le{\tt factor}[x]$, where $p$ plays role of ${\tt factor}[y]$ in expression $y = p\cdot x$. Algorithm is correct, since at time of processing $x$, all prime numbers $\le x$ have been found, as well as smallest factor of $x$. As every number $y$ between 2 \& $n - 1$ is examined exactly once, complexity of algorithm is $O(n)$.
		\begin{verbatim}
			def gries_misra(n):
			    primes = []
			    factor = [0] * n
			    for x in range(2, n):
			        if not factor[x]: # no factor found
			            factor[x] = x # meaning x is prime
			            primes.append(x)
			        for p in primes:  # loop over primes found so far
			            if p > factor[x] or p * x >= n:
			                break
			            factor[p * x] = p # p is smallest factor of p * x
			    return primes, factor
		\end{verbatim}
		
		\begin{problem}[Spiral of primes \href{https://icpcarchive.ecs.baylor.edu/index.php?option=com_onlinejudge&Itemid=8&category=79&page=show_problem&problem=121}{[icpcarchive:2120]}]
			
		\end{problem}
		
		\begin{problem}[Prime or not \href{https://www.spoj.com/problems/PON/}{[spoj:PON]}]
			
		\end{problem}
		
		\begin{problem}[Bazinga! \href{https://www.spoj.com/problems/DCEPC505/}{[spoj:DCEPC505]}]
			
		\end{problem}
		
		\item {\sf14.6. Evaluate an Arithmetic Expression.} Def: Given an expression obeying a certain fixed syntax, construct syntax (parse) tree or evaluate value of expression, see {\sf Fig. 14.1: Syntax tree associated with expression $2 + (3\times 4)/2$.}
		
		{\it Approaches.} p. 218
		\item {\sf14.7. System of Linear Equations.}
		\item {\sf14.8: Multiplication of a Matrix Sequence.}
	\end{itemize}	
	\item {\sf15. Exhaustive Search.}
	\item {\sf16. Conclusion.}
	\begin{itemize}
		\item {\sf16.1. Combine Algorithms to Solve a Problem.} At times, problem may require to find an optimal value. Can this value be found by dichotomy (sự phân đôi)?  If it lies between 0 \& $N$ \& if condition verifies a certain property, this adds only a factor $\log N$ to complexity. This is why it is always profitable to know how to efficiently code a binary search. Try your skills on this problem, 1 of most difficult: it can be arranged \href{https://open.kattis.com/problems/itcanbearranged}{[kattis:itcanbearranged]}.
		
		Do you have to count number of subsequences, or some other combinatorial structure, module some large prime number? Then, a recurrence relation by dynamic programming can be combined with replacing every division by a multiplication with inverse modulo $p$ (Sect. 14).
		
		Is a greedy algorithm sufficient, or are we faced with a problem of dynamic programming? What is recurrence? Is recursive structure of problem at hand a special case of some known problem? It is only by solving lots \& lots of problems that you can build \& hone these reflexes.
		
		Finally, size of instances can sometimes provide a clue as to expected complexity, see table in Sect. 1.4.
		\item {\sf16.2. For Further Reading.} A selection of works completing subjects treated in this book.
		\begin{itemize}
			\item An essential ref for fundamental algorithms: substantial {\it Introduction to Algorithms} by {\sc T.H. Cormen, C. E. Leiserson, R. L. Rivest, \& C. Stein}, MIT Press.
			\item For a variety of more specialized algorithms, see {\it Encyclopedia of Algorithms}, a collective work edited by {\sc Ming-Yang Kao}, Springer Verlag, 2e, 2016.
			\item Flow algorithms are studied from top to bottom in {\it Network Flows: Theory, Algorithms, \& Applications} by {\sc R.K. Ahuja, T. L. Magnanti, \& J. B. Orlin}, Pearson, 2013.
			\item A good introduction to algorithms for problems in geometry is {\it Computational Geometry: Algorithms \& Applications} by {\sc M. de Berg, O. Cheung, M. van Kreveld, M. Overmars}, Springer Verlag 2008.
			\item If would like to learn more about tricky manipulations with binary representation of integers, a delightful ref: {\it Hacker's Delight} by {\sc Henry S. Warren, Jr}, Addison-Wesley, 2013.
			\item A very good introduction to programming in Python: {\it Think Python: How to Think Like a Computer Scientist} by {\sc Allen Downey}, O'Reilly Media, 2015.
			\item Other highly appreciated books include {\it Python Essential Reference} by {\sc David M. Beazley}, Pearson Education, 2009 \& {\it Python Cookbook} by {\sc Brian K. Jones}, O'Reilly Media, 2013.
			\item 2 texts more adapted to preparation for programming contests: {\it Competitive Programming} by {\sc Steven \& Felix Halim}, Lulu, 2013 \& {\it The Algorithm Design Manual} by {\sc Steven S. Skiena}, Springer Verlag, 2009.
		\end{itemize}
		\item {\sf16.3. Rendez-vous on \url{tryalgo.org}.} This book is accompanied by a website \url{https://tryalgo.org/}, where code of all Python programs described here can be found $+$ test data, training exercises \& solutions that, of course, must not be read before having attempted problems. Package {\tt tryalgo} is available on GitHub \& PyPI under MIT license, \& can be installed under Python 2 or 3 via {\tt pip install tryalgo}.
		\begin{verbatim}
			>>> import tryalgo
			>>> help(tryalgo)		 # for the list of modules
			>>> help(tryalgo.arithm) # for a particular module
		\end{verbatim}
	\end{itemize}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{\cite{Laaksonen2020}. {\sc Antti Laaksonen}. Guide to Competitive Programming: Learning \& Improving Algorithms Through Contests}

%------------------------------------------------------------------------------%

\section{Conda}

\subsection{Should I use Anaconda Distribution or Miniconda?}
\url{https://docs.anaconda.com/distro-or-miniconda/}. Both Anaconda Distribution \& Miniconda installers include conda package \& environment manager, but how you plan to use software will determine which installer you want to choose. {\sf Table of Cfs.}

\noindent{\bf What's your experience level?}
\begin{itemize}
	\item {\it I'm just starting out \& don't know what packages I should use.} Install Anaconda Distribution! It includes over \href{https://docs.anaconda.com/anaconda/release-notes/}{300 standard DS \& ML packages}, which will give you a kickstart in your development journey.
	\item {\it I don't have much experience with the command line.} Install Anaconda Distribution! The install includes Anaconda Navigator, a desktop application that is built on top of conda. You can use Navigator's graphical user interface (GUI) to create environments, install packages, \& launch development applications like Jupyter Notebooks \& Spyder. For more information on Navigator, see \href{https://docs.anaconda.com/navigator/getting-started/}{Getting started with Navigator}.
	\item {\it I know exactly what packages I want to use \& I don't want a large download.} Install Miniconda! Miniconda is a minimal installer that only includes a very small installation of Anaconda's distribution--conda, Python, \& a few other packages. For more information, see \href{https://docs.anaconda.com/miniconda/}{Miniconda documentation}.
	\item {\it I only use the command line.} Install Miniconda or Anaconda Distribution! Both installations include conda, the command line package \& environment manager. For more information on conda, see \href{https://conda.io/projects/conda/en/latest/user-guide/getting-started.html}{conda Getting Started page} or download \href{https://docs.conda.io/projects/conda/en/latest/user-guide/cheatsheet.html}{conda cheatsheet}.
\end{itemize}

\subsection{Anaconda Distribution}
{\it The Most Trusted Distribution for Data Science}. Anaconda Distribution is a Python{\tt/}R data science distribution that contains:
\begin{itemize}
	\item \href{https://docs.conda.io/en/latest}{conda} - a package \& environment manager for your command line interface
	\item \href{https://docs.anaconda.com/navigator/}{Anaconda Navigator} - a desktop application built on conda, with options to launch other development applications from your managed environments.
	\item \href{https://docs.anaconda.com/anaconda/release-notes/}{$> 300$ automatically-installed packages} that work well together out of box
	\item Access to \href{https://repo.anaconda.com/pkgs/}{Anaconda Public Repository}, with 8000 open-source DS \& ML packages
\end{itemize}

\subsubsection{System requirements}

\begin{itemize}
	\item License: Free for individuals \& small organizations ($< 200$ employees). A paid license is required for larger organizations \& anyone embedding or mirroring Anaconda. See \href{https://legal.anaconda.com/policies/en/}{TOS} for details.
	\item OS: Windows 10 or later, 64-bit macOS 10.15+ (for Intel) or 64-bit macOS 11.1+ (for Apple Silicon), or Linux, including Ubuntu, RedHat, CentOS 7+, \& others.
	\item If OS is older than what is currently supported, can find older versions of Anaconda installers in \href{https://repo.anaconda.com/archive/}{archive} that might work for you. See \href{https://docs.anaconda.com/anaconda/advanced-install/old-os/#older-versions-distro}{Using Anaconda on older OSs} for version recommendations.
	\item System architecture: Windows - 64-bit x86; MacOS - 64-bit x86 or Apple Silicon (ARM64); Linux - 64-bit x86, 64-bit aarch64 (AWS Graviton2), or s390x (Linux on IBM Z \& LinuxONE).
	\item {\tt linux-aarch64} Miniconda installer requires {\tt glibc >=2.26} \& thus will not work with CentOS 7, Ubuntu 16.04, or Debian 9 (``stretch'').
	\item {\tt linux-aarch64} package builds might not be compatible with certain Raspberry Pi setups, as Anaconda uses compiler options that target server-class Neoverse N1{\tt/}N2 microarchitecture.
	\item Minimum 5 GB disk space to download \& install.
\end{itemize}

\begin{remark}
	Best practice to install Anaconda Distribution for local user, which does not require administrator permissions \& is most robust type of installation. However, if have administrator permissions, can install Anaconda Distribution system-wide.
\end{remark}

\subsubsection{Installing Anaconda Distribution}
Provides instructions for installing Anaconda Distribution on Windows, macOS, \& Linux.

\begin{remark}
	If prefer an installation without extensive collection of packages included in Anaconda Distribution, install Miniconda instead.
	
	Miniconda is a free, miniature installation of Anaconda Distribution that includes only conda, Python, packages they both depend on, \& a small number of other useful packages.
\end{remark}

\begin{itemize}
	\item {\sf Basic install instructions.}
	
	\begin{remark}
		If you've installed multiple versions of Anaconda Distribution, system defaults to using most current version, as long as you haven't altered default install path.
	\end{remark}
	{\sf Linux installer.} Anaconder Navigator is included with Anaconda Distribution by default. However, following extended dependencies might be required for certain versions of Anaconda Distribution in order to use Anaconda Navigator (\& other GUI packages) with Linux:
	\begin{itemize}
		\item {\bf Debian.}
		\begin{verbatim}
			nqbh@nqbh-dell:~$ sudo apt-get install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6
			sudo: unable to resolve host nqbh-dell: Name or service not known
			[sudo] password for nqbh: 
			Reading package lists... Done
			Building dependency tree... Done
			Reading state information... Done
			Package libasound2 is a virtual package provided by:
			liboss4-salsa-asound2 4.2-build2020-1ubuntu3
			libasound2t64 1.2.11-1build2 (= 1.2.11-1build2)
			You should explicitly select one to install.
			
			Package libgl1-mesa-glx is not available, but is referred to by another package.
			This may mean that the package is missing, has been obsoleted, or
			is only available from another source
			
			E: Package 'libgl1-mesa-glx' has no installation candidate
			E: Unable to locate package libegl1-mesa
			E: Package 'libasound2' has no installation candidate
			
			nqbh@nqbh-dell:~$ curl -O https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh
		\end{verbatim}
		Ensure that you are downloading an installer that is compatible with your operating system!
		
		(Recommended) Verify the integrity of your installer to ensure that it was not corrupted or tampered with during download. To ensure that your downloaded installer has not been tampered with or corrupted, generate its SHA-256 hash value \& compare it to the official hash provided in \href{https://repo.anaconda.com/archive/}{archive}. E.g.,
		\begin{verbatim}
			nqbh@nqbh-dell:~$ shasum -a 256 ~/Anaconda3-2024.10-1-Linux-x86_64.sh
			3ba0a298155c32fbfd80cbc238298560bf69a2df511783054adfc151b76d80d8  /home/nqbh/Anaconda3-2024.10-1-Linux-x86_64.sh
		\end{verbatim}
		Note: generated SHA-256 hash value from the output. Visit \url{repo.anaconda.com/archive} to find the official SHA-256 hash for your installer. Compare the hash values. If they match, the installer is safe to use.
		
		Install Anaconda Distribution by running 1 of following commands (depending on your Linux architecture):
		\begin{verbatim}
			bash ~/Anaconda3-2024.10-1-Linux-x86_64.sh
		\end{verbatim}
		Press return to review license agreement \& hold return to scroll. Enter yes to agree to the license agreement.
		\begin{verbatim}
			Downloading and Extracting Packages:
			
			Preparing transaction: done
			Executing transaction: done
			installation finished.
			Do you wish to update your shell profile to automatically initialize conda?
			This will activate conda on startup and change the command prompt when activated.
			If you'd prefer that conda's base environment not be activated on startup,
			run the following command when conda is activated:
			
			conda config --set auto_activate_base false
			
			You can undo this by running `conda init --reverse $SHELL`? [yes|no]
			[no] >>>
			
			You have chosen to not have conda modify your shell scripts at all.
			To activate conda's base environment in your current shell session:
			
			eval "$(/home/nqbh/anaconda3/bin/conda shell.YOUR_SHELL_NAME hook)" 
			
			To install conda's shell functions for easier access, first activate, then:
			
			conda init
			
			Thank you for installing Anaconda3!
		\end{verbatim}
		Press return to accept default install location (\verb|PREFIX=/Users/<USER>/anaconda3|), or enter another file path to specify an alternate installation directory. Installation might take a few minutes to complete. Choose an initialization options:
		\begin{itemize}
			\item Yes - conda modifies your shell configuration to initialize conda whenever you open a new shell \& to recognize conda commands automatically.
			\item No - conda will not modify your shell scripts. After installation, if you want to initialize, you must do so manually. For more information, see \href{https://docs.anaconda.com/anaconda/install/#manual-shell-init-linux}{Manual Shell Initialization}.
		\end{itemize}
		Installer finishes and displays, ``Thank you for installing Anaconda3!'' Close \& re-open your terminal window for the installation to fully take effect, or use the following command to refresh the terminal, depending on your shell: \verb|source ~/.bashrc|.
		
		{\bf Manual Shell Initialization.} Once installation has successfully completed, initialize your shell by running following command:
		\begin{verbatim}
			# Replace <PATH_TO_CONDA> with the path to your conda install
			source <PATH_TO_CONDA>/bin/activate
			conda init
			
			qbh@nqbh-dell:~$ source ~/anaconda3/bin/activate 
			(base) nqbh@nqbh-dell:~$ conda init
			no change     /home/nqbh/anaconda3/condabin/conda
			no change     /home/nqbh/anaconda3/bin/conda
			no change     /home/nqbh/anaconda3/bin/conda-env
			no change     /home/nqbh/anaconda3/bin/activate
			no change     /home/nqbh/anaconda3/bin/deactivate
			no change     /home/nqbh/anaconda3/etc/profile.d/conda.sh
			no change     /home/nqbh/anaconda3/etc/fish/conf.d/conda.fish
			no change     /home/nqbh/anaconda3/shell/condabin/Conda.psm1
			no change     /home/nqbh/anaconda3/shell/condabin/conda-hook.ps1
			no change     /home/nqbh/anaconda3/lib/python3.12/site-packages/xontrib/conda.xsh
			no change     /home/nqbh/anaconda3/etc/profile.d/conda.csh
			modified      /home/nqbh/.bashrc
			
			==> For changes to take effect, close and re-open your current shell. <==
			
			(base) nqbh@nqbh-dell:~$
		\end{verbatim}
		
		\begin{remark}
			You can also control whether or not your shell has the base environment activated each time it opens. Following commands only work if conda has been initialized 1st:
			\begin{itemize}
				\item Activated by default: \verb|conda config --set auto_activate_base True|
				\item Not activated by default: \verb|conda config --set auto_activate_base False|
			\end{itemize}
		\end{remark}
		{\bf Verify install.} Anaconda Navigator, Graphical User Interface (GUI) for conda, should automatically open after successful installation of Anaconda Distribution. If it does not, verify your installation by opening the application manually, or by using the CLI:
		\begin{itemize}
			\item Opening Navigator manually: Open Navigator by running the following command: \verb|anaconda-navigator|
			\item Using conda to verify manually: Access the CLI for your operating system. You should see (base) in the command line prompt. This tells you that you're in your base conda environment. To learn more about environments, see \href{https://docs.anaconda.com/working-with-conda/environments/}{Environments}. Run any conda command, e.g.:
			\begin{itemize}
				\item {\tt conda list} - Displays a list of packages installed in your active environment \& their versions.
				\item {\tt anaconda-navigator} - Opens Anaconda Navigator.
			\end{itemize}
		\end{itemize}
	\end{itemize}
	\item {\sf Advanced install options.} For more advanced installation instructions, such as installing with silent mode, installing on older operating systems, or multi-user installs, see \href{https://docs.anaconda.com/anaconda/advanced-install/}{Advanced installation}.
	\item {\sf Other ways to get Anaconda or Miniconda.} For instructions on using Anaconda Docker images or the Anaconda Cloudera Distributed Hadoop cluster, see  \href{https://docs.anaconda.com/working-with-conda/applications/}{Applications{\tt/}Integrations}.
\end{itemize}

\subsubsection{Advanced installation}

\subsubsection{Getting started}
This document is here to help you get started with Anaconda Distribution, which includes conda \url{https://conda.io/en/latest/}, \href{https://docs.anaconda.com/navigator/}{Anaconda Navigator}, and over 300 scientific and machine learning packages.
\begin{itemize}
	\item {\sf Should I use Anaconda Navigator or conda?} Anaconda Navigator is a desktop application that is included with every installation of Anaconda Distribution. It is built on top of conda, open-source \& environment manager, \& allows you to manage your packages \& environments from a graphical user interface (GUI). This is especially helpful when you're not comfortable with command line.
	
	A command line interface (or CLI) is a program on your computer that processes text commands to do various tasks. Conda is a CLI program, which means it can only be used via command line. On Windows computers, Anaconda recommends: use Anaconda Prompt CLI to work with conda. MacOS \& Linux users can use their built-in command line applications.
	\begin{remark}
		If installed Miniconda instead of Anaconda Distribution, Anaconda Navigator is not included. Use command {\tt conda install anaconda-navigator} to manually install Navigator onto your computer.
	\end{remark}
	\item {\sf Free Anaconda Learning course - Get Started with Anaconda.} Learn to use Anaconda Navigator to launch an application. Then, create \& run a simple Python program with Spyder \& Jupyter Notebook. Watch short training videos on Anaconda Learning to get up \& running with Jupyter Notebook \& JupyterLab, along with several other popular integrated development environments (IDEs): \href{https://learning.anaconda.cloud/get-started-with-anaconda?utm_campaign=learning&utm_medium=documentation&utm_source=anacondadocs&utm_content=getstartedbutton}{Anaconda Learning}.
\end{itemize}

\subsubsection{Anaconda Distribution release notes}

\subsubsection{Uninstalling Anaconda Distribution}

\subsection{Miniconda}
\url{https://docs.anaconda.com/miniconda/}. Miniconda is a free, miniature installation of Anaconda Distribution that includes only conda, Python, packages they both depend on, \& a small number of other useful packages.

If need more packages, use {\tt conda install} command to install from thousands of packages available by default in Anaconda's public repo, or from other channels, like conda-forge or bioconda.

\subsubsection{Latest Miniconda installer links}
For latest Miniconda installers for Python 3.12, go to \url{https://www.anaconda.com/download/}. Miniconda installers are on same page as Anaconda Distribution installers, past registration.

For a list of Miniconda hashes \& an archive of Miniconda versions, including installers or older versions of Python, see \url{https://repo.anaconda.com/miniconda}.

\subsubsection{Quick command line install}

%------------------------------------------------------------------------------%

\section{\LaTeX}

\subsection{Overleaf{\tt/}glossaries}
``


'' -- \href{https://www.overleaf.com/learn/latex/Glossaries}{Overleaf{\tt/}glossaries}

%------------------------------------------------------------------------------%

\section{Linux}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Shotts2019}. {\sc William Shotts}. {\it The Linux Command Line: A Complete Introduction}.
\end{enumerate}
I used SUSE \& OpenSUSE in WIAS Berlin but I do not like them \& the like, so I go back to Ubuntu.

%------------------------------------------------------------------------------%

\section{Programming}

\subsection{C{\tt/}C++}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Ngoc_C}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình C}.
	\item \cite{Ngoc_C++}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình C++}.
	\item \cite{Stroustrup2013}. {\sc Bjarne Stroustrup}. {\it The C++ Programming Language}.
	\item \cite{Stroustrup2018}. {\sc Bjarne Stroustrup}. {\it A Tour of C++}.
\end{enumerate}

\subsection{Pascal}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Ngoc_Pascal}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình Pascal}.
	\item \cite{Ngoc_BT_Pascal}. {\sc Quách Tuấn Ngọc}. {\it Bài Tập Ngôn Ngữ Lập Trình Pascal}.
	\item \cite{Doanh_Tuan_Pascal}. {\sc Lê Văn Doanh, Trần Khắc Tuấn}. {\it101 Thuật Toán \& Chương Trình Bài Toán Khoa Học Kỹ Thuật \& Kinh Tế Bằng Ngôn Ngữ Turbo-Pascal}.
\end{enumerate}

\subsection{Python}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Duc_200_BT_Python}. {\sc Nguyễn Tiến Đức}. {\it Tuyển Tập 200 Bài Tập Lập Trình Bằng Ngôn Ngữ Python}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_1}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 1}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_2}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 2}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_3}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 3}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_4}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 4}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_5}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 5}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_6}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 6}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_7}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 7}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Software}

\subsection{FeNiCS}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Dokken_Mitusch_Funke2020}. {\sc J\o rgen S. Dokken}. {\it Automatic shape derivatives for transient PDEs in FEniCS \& Firedrake}.
	\item \cite{Langtangen_Logg2016}. {\sc Hans Petter Langtangen, Anders Logg}. {\it Solving PDEs in Python}.
\end{enumerate}

\subsection{Firedrake}

\subsection{Fireshape}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Paganini_Wechsung_Fireshape2020}. {\sc Alberto Paganini, Florian Wechsung}. {\it Fireshape Documentation, Release 0.0.1}.
	\item \cite{Paganini_Wechsung2020}. {\sc Alberto Paganini, Florian Wechsung}. {\it Fireshape: a shape optimization toolbox for Firedrake}.
\end{enumerate}

\subsection{Git}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Chacon_Straub2014}. {\sc Scott Chacon, Ben Straub}. {\it Pro Git}.
\end{enumerate}

\subsection{Gmsh}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Geuzaine_Remacle2009}. {\sc Christophe Geuzaine, Jean-Fran\c{c}ois Remacle}. {\it Gmsh: A 3D finite element mesh generator with built-in pre- \& post-processing facilities}.
\end{enumerate}

\subsection{OpenFOAM}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item There are 3 variants of OpenFOAM:
	\begin{enumerate}
		\item OpenFOAM.com: Commercial.
		\item OpenFOAM.org: Open-source with a large community.
		\item Extended OpenFOAM.
	\end{enumerate}
	\item \cite{Greenshields_Weller2022}. {\sc Christopher Greenshields, Henry Weller}. {\it Notes on Computational Fluid Dynamics: General Principles}.
	\item \cite{Towara_Naumann2013}. {\sc M. Towara, U. Naumann}. {\it A Discrete Adjoint Model for OpenFOAM}.
\end{enumerate}

\subsection{ParMooN}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{ParMooN2017}. {\sc Ulrich Wilbrandt, Clemens Bartsch, Naveed Ahmed, Volker John}. {\it ParMooN -- a modernized program package based on mapped finite elements}.
\end{enumerate}

\subsection{SU2}

\subsection{Sublime Text}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Bos2014}. {\sc Wes Bos}. {\it Sublime Text Power User: A Complete Guide}.
	\item \cite{Peleg2014}. {\sc Dan Peleg}. {\it Mastering Sublime Text}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{SymPy}

\subsection{Matrices}
A module that handles matrices. Includes functions for fast creating matrices like zero, one/eye, random matrix, etc.
\begin{itemize}
	\item {\sf Matrices (linear algebra).}
	\begin{itemize}
		\item {\sf Creating Matrices.} Linear algebra module is designed to be as simple as possible. 1st, import \& declare 1st {\tt Matrix} object:
		\begin{verbatim}
			>>> from sympy.interactive.printing import init_printing
			>>> init_printing(use_unicode=False)
			>>> from sympy.matrices import Matrix, eye, zeros, ones, diag, GramSchmidt
			>>> M = Matrix([[1,0,0], [0,0,0]]); M
			[1  0  0]
			[       ]
			[0  0  0]
			>>> Matrix([M, (0, 0, -1)])
			[1  0  0 ]
			[        ]
			[0  0  0 ]
			[        ]
			[0  0  -1]
			>>> Matrix([[1, 2, 3]])
			[1 2 3]
			>>> Matrix([1, 2, 3])
			[1]
			[ ]
			[2]
			[ ]
			[3]
		\end{verbatim}
		In addition to creating a matrix from a list of appropriately-sized lists \&{\tt/}or matrices, SymPy also supports more advanced methods of matrix creation including a single list of values \& dimension inputs:
		\begin{verbatim}
			>>> Matrix(2, 3, [1, 2, 3, 4, 5, 6])
			[1  2  3]
			[       ]
			[4  5  6]
		\end{verbatim}
		More interesting (\& useful), is ability to use a 2-variable function (or {\tt lambda}) to create a matrix. Create an indicator function which is 1 on diagonal \& then use it to make identity matrix:
		\begin{verbatim}
			>>> def f(i,j):
			...     if i == j:
			...         return 1
			...     else:
			...         return 0
			>>> Matrix(4, 4, f)
			[1  0  0  0]
			[          ]
			[0  1  0  0]
			[          ]
			[0  0  1  0]
			[          ]
			[0  0  0  1]
		\end{verbatim}
		Use {\tt lambda} to create a 1-line matrix with 1's in even permutation entries:
		\begin{verbatim}
			>>> Matrix(3, 4, lambda i,j: 1 - (i+j) % 2)
			[1  0  1  0]
			[          ]
			[0  1  0  1]
			[          ]
			[1  0  1  0]
		\end{verbatim}
		There are also a couple of special constructors for quick matrix construction: {\tt eye}: identity matrix, {\tt zeros, ones} for matrices of all 0s \& 1s, resp., \& {\tt diag} to put matrices or elements along diagonal:
		\begin{verbatim}
			>>> eye(4)
			[1  0  0  0]
			[          ]
			[0  1  0  0]
			[          ]
			[0  0  1  0]
			[          ]
			[0  0  0  1]
			>>> zeros(2)
			[0  0]
			[    ]
			[0  0]
			>>> zeros(2, 5)
			[0  0  0  0  0]
			[             ]
			[0  0  0  0  0]
			>>> ones(3)
			[1  1  1]
			[       ]
			[1  1  1]
			[       ]
			[1  1  1]
			>>> ones(1, 3)
			[1  1  1]
			>>> diag(1, Matrix([[1, 2], [3, 4]]))
			[1  0  0]
			[       ]
			[0  1  2]
			[       ]
			[0  3  4]
		\end{verbatim}
		\item {\sc Basic Manipulation.} While learning to work with matrices, choose one where entries are readily identifiable. 1 useful thing to know: while matrices are 2D, storage is not \& so it is allowable -- though one should be careful -- to access entries as if they were a 1D list.
		\begin{verbatim}
			>>> M = Matrix(2, 3, [1, 2, 3, 4, 5, 6])
			>>> M[4]
			5
		\end{verbatim}
		More standard entry access is a pair of indices which will always return value at corresponding row \& column of matrix"
		\begin{verbatim}
			>>> M[1, 2]
			6
			>>> M[0, 0]
			1
			>>> M[1, 1]
			5
		\end{verbatim}
		Since this is Python, also able to slice submatrices; slices always give a matrix in return, even if dimension is $1\times1$:
		\begin{verbatim}
			>>> M[0:2, 0:2]
			[1  2]
			[    ]
			[4  5]
			>>> M[2:2, 2]
			[]
			>>> M[:, 2]
			[3]
			[ ]
			[6]
			>>> M[:1, 2]
			[3]
		\end{verbatim}
		In 2nd example above notice: slice 2:2 gives an empty range. Note also (in keeping with 0-based indexing of Python) 1st row{\tt/}column is 0.
		
		Cannot access rows or columns that are not present unless they are in a slice:
		\begin{verbatim}
			>>> M[:, 10] # the 10-th column (not there)
			Traceback (most recent call last):
			...
			IndexError: Index out of range: a[[0, 10]]
			>>> M[:, 10:11] # the 10-th column (if there)
			[]
			>>> M[:, :10] # all columns up to the 10-th
			[1  2  3]
			[       ]
			[4  5  6]
		\end{verbatim}
		Slicing an empty matrix works as long as use a slice for coordinate that has no size:
		\begin{verbatim}
			>>> Matrix(0, 3, [])[:, 1]
			[]
		\end{verbatim}
		Slicing gives a copy of what is sliced, so modifications of 1 object do not affect the other:
		\begin{verbatim}
			>>> M2 = M[:, :]
			>>> M2[0, 0] = 100
			>>> M[0, 0] == 100
			False			
		\end{verbatim}
		Notice: changing {\tt M2} didn't change {\tt M}. Since can slice, can also assign entries:
		\begin{verbatim}
			>>> M = Matrix(([1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]))
			>>> M
			[1   2   3   4 ]
			[              ]
			[5   6   7   8 ]
			[              ]
			[9   10  11  12]
			[              ]
			[13  14  15  16]
			>>> M[2,2] = M[0,3] = 0
			>>> M
			[1   2   3   0 ]
			[              ]
			[5   6   7   8 ]
			[              ]
			[9   10  0   12]
			[              ]
			[13  14  15  16]
		\end{verbatim}
		as well as assign slices:
		\begin{verbatim}
			>>> M = Matrix(([1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]))
			>>> M[2:,2:] = Matrix(2,2,lambda i,j: 0)
			>>> M
			[1   2   3  4]
			[            ]
			[5   6   7  8]
			[            ]
			[9   10  0  0]
			[            ]
			[13  14  0  0]
		\end{verbatim}
		All standard arithmetic operations are supported:
		\begin{verbatim}
			>>> M = Matrix(([1,2,3],[4,5,6],[7,8,9]))
			>>> M - M
			[0  0  0]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
			>>> M + M
			[2   4   6 ]
			[          ]
			[8   10  12]
			[          ]
			[14  16  18]
			>>> M * M
			[30   36   42 ]
			[             ]
			[66   81   96 ]
			[             ]
			[102  126  150]
			>>> M2 = Matrix(3,1,[1,5,0])
			>>> M*M2
			[11]
			[  ]
			[29]
			[  ]
			[47]
			>>> M**2
			[30   36   42 ]
			[             ]
			[66   81   96 ]
			[             ]
			[102  126  150]
		\end{verbatim}
		As well as some useful vector operations:
		\begin{verbatim}
			>>> M.row_del(0)
			>>> M
			[4  5  6]
			[       ]
			[7  8  9]
			>>> M.col_del(1)
			>>> M
			[4  6]
			[    ]
			[7  9]
			>>> v1 = Matrix([1,2,3])
			>>> v2 = Matrix([4,5,6])
			>>> v3 = v1.cross(v2)
			>>> v1.dot(v2)
			32
			>>> v2.dot(v3)
			0
			>>> v1.dot(v3)
			0			
		\end{verbatim}
		Recall: \verb|row_del(), col_del()| operations don't return a value -- they simply change matrix object. Can also ``glue'' together matrices of appropriate size:
		\begin{verbatim}
			>>> M1 = eye(3)
			>>> M2 = zeros(3, 4)
			>>> M1.row_join(M2)
			[1  0  0  0  0  0  0]
			[                   ]
			[0  1  0  0  0  0  0]
			[                   ]
			[0  0  1  0  0  0  0]
			>>> M3 = zeros(4, 3)
			>>> M1.col_join(M3)
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
		\end{verbatim}
		\item {\sf Operations on entries.} Not restricted to have multiplication between 2 matrices:
		\begin{verbatim}
			>>> M = eye(3)
			>>> 2*M
			[2  0  0]
			[       ]
			[0  2  0]
			[       ]
			[0  0  2]
			>>> 3*M
			[3  0  0]
			[       ]
			[0  3  0]
			[       ]
			[0  0  3]
		\end{verbatim}
		but can also apply functions to our matrix entries using {\tt applyfunc()}. Declare a function that double any input number. Then apply it to $3\times3$ identity matrix:
		\begin{verbatim}
			>>> f = lambda x: 2*x
			>>> eye(3).applyfunc(f)
			[2  0  0]
			[       ]
			[0  2  0]
			[       ]
			[0  0  2]
		\end{verbatim}
		If want to extract a common factor from a matrix, can do so by applying {\tt gcd} to data of matrix:
		\begin{verbatim}
			>>> from sympy.abc import x, y
			>>> from sympy import gcd
			>>> m = Matrix([[x, y], [1, x*y]]).inv('ADJ'); m
			[  x*y       -y    ]
			[--------  --------]
			[ 2         2      ]
			[x *y - y  x *y - y]
			[                  ]
			[  -1         x    ]
			[--------  --------]
			[ 2         2      ]
			[x *y - y  x *y - y]
			>>> gcd(tuple(_))
			   1
			--------
			 2
			x *y - y
			>>> m/_
			[x*y  -y]
			[       ]
			[-1   x ]			
		\end{verbatim}
		1 more useful matrix-wide entry application function: substitution function. Declare a matrix with symbolic entries then substitute a value. Remember: can substitute anything -- even another symbol!
		\begin{verbatim}
			>>> from sympy import Symbol
			>>> x = Symbol('x')
			>>> M = eye(3) * x
			>>> M
			[x  0  0]
			[       ]
			[0  x  0]
			[       ]
			[0  0  x]
			>>> M.subs(x, 4)
			[4  0  0]
			[       ]
			[0  4  0]
			[       ]
			[0  0  4]
			>>> y = Symbol('y')
			>>> M.subs(x, y)
			[y  0  0]
			[       ]
			[0  y  0]
			[       ]
			[0  0  y]
		\end{verbatim}
		\item {\sf Linear algebra.} Now have basics out of way, see what can do with actual matrices. Determinant:
		\begin{verbatim}
			>>> M = Matrix(( [1, 2, 3], [3, 6, 2], [2, 0, 1] ))
			>>> M.det()
			-28
			>>> M2 = eye(3)
			>>> M2.det()
			1
			>>> M3 = Matrix(( [1, 0, 0], [1, 0, 0], [1, 0, 0] ))
			>>> M3.det()
			0
		\end{verbatim}
		Another common operation is inverse: In SymPy, this is computed by Gaussian elimination by default (for dense matrices) but can specify it be done by $LU$ decomposition as well:
		\begin{verbatim}
			>>> M2.inv()
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
			>>> M2.inv(method="LU")
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
			>>> M.inv(method="LU")
			[-3/14  1/14  1/2 ]
			[                 ]
			[-1/28  5/28  -1/4]
			[                 ]
			[ 3/7   -1/7   0  ]
			>>> M * M.inv(method="LU")
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
		\end{verbatim}
		Can perform a $QR$ factorization which is handy for solving systems:
		\begin{verbatim}
			>>> A = Matrix([[1,1,1],[1,1,3],[2,3,4]])
			>>> Q, R = A.QRdecomposition()
			>>> Q
			[  ___     ___      ___ ]
			[\/ 6   -\/ 3    -\/ 2  ]
			[-----  -------  -------]
			[  6       3        2   ]
			[                       ]
			[  ___     ___      ___ ]
			[\/ 6   -\/ 3     \/ 2  ]
			[-----  -------   ----- ]
			[  6       3        2   ]
			[                       ]
			[  ___     ___          ]
			[\/ 6    \/ 3           ]
			[-----   -----      0   ]
			[  3       3            ]
			>>> R
			[           ___         ]
			[  ___  4*\/ 6       ___]
			[\/ 6   -------  2*\/ 6 ]
			[          3            ]
			[                       ]
			[          ___          ]
			[        \/ 3           ]
			[  0     -----      0   ]
			[          3            ]
			[                       ]
			[                   ___ ]
			[  0       0      \/ 2  ]
			>>> Q*R
			[1  1  1]
			[       ]
			[1  1  3]
			[       ]
			[2  3  4]
		\end{verbatim}
		In addition to solvers in {\tt solver.py} file, can solve system $A{\bf x} = {\bf b}$ by passing vector ${\bf b}$ to matrix $A$'s {\tt LUsolve} function. Here cheat a little choose $A$ \& ${\bf x}$ then multiply to get ${\bf b}$. Then can solve for ${\bf x}$ \& check it's correct:
		\begin{verbatim}
			>>> A = Matrix([ [2, 3, 5], [3, 6, 2], [8, 3, 6] ])
			>>> x = Matrix(3,1,[3,7,5])
			>>> b = A*x
			>>> soln = A.LUsolve(b)
			>>> soln
			[3]
			[ ]
			[7]
			[ ]
			[5]
		\end{verbatim}
		***STOP HERE***
	\end{itemize}
	\item {\sf Matrix Kind.}
	\item {\sf Dense Matrices.}
	\item {\sf Sparse Matrices.}
	\item {\sf Sparse Tools.}
	\item {\sf Immutable Matrices.}
	\item {\sf Matrix Expressions.}
	\item {\sf Matrix Normal Forms.}
\end{itemize}

%------------------------------------------------------------------------------%

\section{Miscellaneous}

%------------------------------------------------------------------------------%

%------------------------------------------------------------------------------%

\section{Wikipedia}

\subsection{Wikipedia{\tt/}abstraction (computer science)}
``In \href{https://en.wikipedia.org/wiki/Software_engineering}{software engineering} \& \href{https://en.wikipedia.org/wiki/Computer_science}{computer science}, {\it abstraction} is the process of \href{https://en.wikipedia.org/wiki/Generalization}{generalizing} \href{https://en.wikipedia.org/wiki/Abstract_and_concrete}{concrete} details, e.g. \href{https://en.wikipedia.org/wiki/Attribute_(computing)}{attributes}, away from the study of \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{objects} \& \href{https://en.wikipedia.org/wiki/System}{systems} to focus attention on details of greater importance. \href{https://en.wikipedia.org/wiki/Abstraction}{Abstraction} is a fundamental concept in computer science \& \href{https://en.wikipedia.org/wiki/Software_engineering}{software engineering}, especially within the \href{https://en.wikipedia.org/wiki/Object-oriented_programming}{object-oriented programming} paradigm. E.g.:
\begin{itemize}
	\item the usage of \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data types} to separate usage from working representations of \href{https://en.wikipedia.org/wiki/Data_(computer_science)}{data} within \href{https://en.wikipedia.org/wiki/Computer_program}{programs}.
	\item the concept of \href{https://en.wikipedia.org/wiki/Procedure_(computer_science)}{functions} or subroutines which represent a specific way of implementing \href{https://en.wikipedia.org/wiki/Control_flow}{control flow};
	\item the process of reorganizing common behavior from groups of non-abstract \href{https://en.wikipedia.org/wiki/Class_(computer_programming)}{classes} into abstract classes using \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance} \& \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)#Subclasses_and_superclasses}{subclasses}, as seen in object-oriented programming languages.
\end{itemize}

\subsubsection{Rationale}

\begin{quote}
	``The essence of abstraction is preserving information that is relevant in a given context, \& forgetting information that is irrelevant in that context.'' -- \href{https://en.wikipedia.org/wiki/John_Guttag}{\sc John V. Guttag}
\end{quote}
Computing mostly operates independently of the concrete world. The hardware implements a \href{https://en.wikipedia.org/wiki/Model_of_computation}{model of computation} that is interchangeable with others. The software is structured in \href{https://en.wikipedia.org/wiki/Software_architecture}{architectures} to enable humans to create the enormous systems by concentrating on a few issues at a time. These architectures are made of specific choices of abstractions. \href{https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule}{Greenspun's 10th rule} is an \href{https://en.wikipedia.org/wiki/Aphorism}{aphorism} on how such an architecture is both inevitable \& complex.

Language abstraction is a central form of abstraction in computing: new artificial languages are developed to express specific aspects of a system. \href{https://en.wikipedia.org/wiki/Modeling_languages}{\it Modeling languages} help in planning. \href{https://en.wikipedia.org/wiki/Computer_language}{\it Computer language} from the \href{https://en.wikipedia.org/wiki/First-generation_programming_language}{machine language} to the \href{https://en.wikipedia.org/wiki/Second-generation_programming_language}{assembly language} \& the \href{https://en.wikipedia.org/wiki/Third-generation_programming_language}{high-level language}. Each stage can be used as a stepping stone for the next stage. The language abstraction continues e.g. in \href{https://en.wikipedia.org/wiki/Scripting_language}{scritping languages} \& \href{https://en.wikipedia.org/wiki/Domain-specific_programming_language}{domain-specific programming languages}.

Within a programming language, some features let the programmer create new abstractions. These include \href{https://en.wikipedia.org/wiki/Subroutine}{subroutines}, \href{https://en.wikipedia.org/wiki/Module_(programming)}{modules}, \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism}, \& \href{https://en.wikipedia.org/wiki/Software_component}{software components}. Some other abstractions such as \href{https://en.wikipedia.org/wiki/Software_design_pattern}{software design pattens} \& \href{https://en.wikipedia.org/wiki/Software_architecture#Architectural_styles_and_patterns}{architectural styles} remain invisible to a \href{https://en.wikipedia.org/wiki/Translator_(computing)}{translator} \& operate only in the design of a system.

Some abstractions try to limit the range of concepts a programmer needs to be aware of, by completely hiding the abstractions they are built on. The software engineer \& writer \href{https://en.wikipedia.org/wiki/Joel_Spolsky}{\sc Joel Spolsky} has criticized these efforts by claiming that all abstractions are \href{https://en.wikipedia.org/wiki/Leaky_abstraction}{\it leaky} -- that they can never completely hide the details below; however, this does not negate the usefulness of abstraction.

Some abstractions are designed to inter-operate with other abstractions -- e.g., a programming language may contain a \href{https://en.wikipedia.org/wiki/Foreign_function_interface}{foreign function interface} for making calls to the lower-level language.

\subsubsection{Abstraction features}

\paragraph{Programming languages.} Main article: \href{https://en.wikipedia.org/wiki/Programming_language}{Wikipedia{\tt/}programming language}. Different programming languages provide different types of abstraction, depending on the intended applications for the language. E.g.:
\begin{itemize}
	\item In \href{https://en.wikipedia.org/wiki/Object-oriented_programming_language}{OOP languages} e.g. \href{https://en.wikipedia.org/wiki/C%2B%2B}{C++}, \href{https://en.wikipedia.org/wiki/Object_Pascal}{Object Pascal}, or \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}, the concept of {\it abstraction} has itself become a declarative statement -- using the \href{https://en.wikipedia.org/wiki/Syntax_(programming_languages)}{syntax} \verb|function(parameters) = 0;| (in C++) or the \href{https://en.wikipedia.org/wiki/Keyword_(computer_programming)}{keywords} {\tt abstract} \& {\tt interface} (in \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}). After such a declaration, it is the responsibility of the programmer to implement a \href{https://en.wikipedia.org/wiki/Class_(computer_science)}{class} to instantiate the \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{object} of the declaration.
	\item \href{https://en.wikipedia.org/wiki/Functional_programming_language}{Functional programming languages} commonly exhibit abstractions related to functions, e.g. \href{https://en.wikipedia.org/wiki/Lambda_abstraction}{lambda abstractions} (making a term into a function of some variable) \& \href{https://en.wikipedia.org/wiki/Higher-order_function}{higher-order functions} (parameters are functions).
	\item Modern members of the Lisp programming language family e.g. \href{https://en.wikipedia.org/wiki/Clojure}{Clojure}, \href{https://en.wikipedia.org/wiki/Scheme_(programming_language)}{Scheme}, \& \href{https://en.wikipedia.org/wiki/Common_Lisp}{Common Lisp} support \href{https://en.wikipedia.org/wiki/Macro_(computer_science)#Syntactic_macros}{macro systems} to allow syntactic abstraction. Other programming languages such as \href{https://en.wikipedia.org/wiki/Scala_(programming_language)}{Scala} also have macros, or very similar \href{https://en.wikipedia.org/wiki/Metaprogramming}{metaprogramming} features (e.g., \href{https://en.wikipedia.org/wiki/Haskell_(programming_language)}{Haskell} has \href{https://en.wikipedia.org/wiki/Template_Haskell}{Template Haskell}, \& \href{https://en.wikipedia.org/wiki/OCaml}{OCaml} has \href{https://en.wikipedia.org/wiki/MetaOCaml}{MetaOCaml}). These can allow a programmer to eliminate \href{https://en.wikipedia.org/wiki/Boilerplate_code}{boilerplate code}, abstract away tedious function call sequences, implement new \href{https://en.wikipedia.org/wiki/Control_flow}{control flow structures}, \& implement \href{https://en.wikipedia.org/wiki/Domain-specific_language}{Domain Specific Languages (DSLs)}, which allow domain-specific concepts to be expressed in concise \& elegant ways. All of these, when used correctly, improve both the programmer's efficiency \& the clarity of the code by making the intended purpose more explicit. A consequence of syntactic abstraction is also that any Lisp dialect \& in fact almost any programming language can, in principle, be implemented in any modern Lisp with significantly reduced (but still nontrivial in most cases) effort when compared to ``more traditional'' programming languages such as Python, C, or Java.
\end{itemize}

\paragraph{Specification methods.} Main article: \href{https://en.wikipedia.org/wiki/Formal_specification}{Wikipedia{\tt/}formal specification}. Analysts have developed various methods to formally specify software systems. Some known methods include:
\begin{itemize}
	\item Abstract-model based method (VDM, Z);
	\item Algebraic techniques (Larch, CLEAR, OBJ, ACT ONE, CASL);
	\item Process-based techniques (LOTOS, SDL, Estelle);
	\item Trace-based techniques (SPECIAL, TAM);
	\item Knowledge-based techniques (Refine, Gist).
\end{itemize}

\paragraph{Specification languages}
Main article: \href{https://en.wikipedia.org/wiki/Specification_language}{Wikipedia{\tt/}specification language}. Specification languages generally rely on abstractions of 1 kind or another, since specifications are typically defined earlier in a project, (\& at a more abstract level) than an eventual implementation. The \href{https://en.wikipedia.org/wiki/Unified_Modeling_Language}{UML} specification language, e.g., allows the definition of {\it abstract} classes, which in a waterfall project, remain abstract during the architecture \& specification phrase of the project.

\subsubsection{Control abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Control_flow}{Wikipedia{\tt/}control flow}. Programming languages offer control abstraction as 1 of the main purposes of their use. Computer machines understand operations at the very low level such as moving some bits from 1 location of the memory to another location \& producing the sum of 2 sequences of bits. Programming languages allow this to be done in the higher level. E.g., consider this statement written in a Pascal-like fashion: \verb|a := (1 + 2) * 5|. To a human, this seems a fairly simple \& obvious calculation. However, the lower-level steps necessary to carry out this evaluation, \& return the value 15, \& then assign that value to the variable {\tt a}, are actually quite subtle \& complex. The values need to be converted to binary representation (often a much more complicated task than one would think) \& the calculations decomposed (by the compiler or interpreter) into assembly instructions (again, which are much less intuitive to the programmer: operations such as shifting a binary register left, or adding the binary complement of the contents of 1 register to another, are simply not how humans think about the abstract arithmetical operations of addition or multiplication). Finally, assigning the resulting value of 15 to the variable labeled {\tt a}, so that {\tt a} can be used later, involves additional `behind-the-scenes' steps of looking up a variable's label \& the resultant location in physical or virtual memory, storing the binary representation of 15 to that memory location, etc.

Without control abstraction, a programmer would need to specify {\it all} the register{\tt/}binary-level steps each time they simply wanted to add or multiply a couple of numbers \& assign the result to a variable. Such duplication of effort has 2 serious negative consequences:
\begin{enumerate}
	\item it forces the programmer to constantly repeat fairly common tasks every time a similar operation is needed.
	\item it forces the programmer to program for the particular hardware \& instruction set.
\end{enumerate}

\paragraph{Structured programming.} Main article: \href{https://en.wikipedia.org/wiki/Structured_programming}{Wikipedia{\tt/}structured programming}. Structured programming involves the splitting of complex program tasks into smaller pieces with clear flow-control \& interfaces between components, with a reduction of the complexity potential for side-effects.

In a simple program, this may aim to ensure that loops have single or obvious exit points \& (where possible) to have single exit points from functions \& procedures.

In a larger system, it may involve breaking down complex tasks into many different modules. Consider a system which handles payroll on ships \& at shore offices:
\begin{itemize}
	\item The uppermost level may feature a menu of typical end-user operations.
	\item Within that could be standalone executables or libraries for tasks such as signing on \& off employees or printing checks.
	\item Within each of those standalone components there could be many different source files, each containing the program code to handle a part of the problem, with only selected interfaces available to other parts of the program. A sign on program could have source files for each data entry screen \& the database interface (which may itself be a standalone 3rd party library or a statically linked set of library routines).
	\item Either the database or the payroll application also has to initiate the process of exchanging data with between ship \& shore, \& that data transfer task will often contain many other components.
\end{itemize}
These layers produce the effect of isolating the implementation details of 1 component \& its assorted internal methods from the others. Object-oriented programming embraces \& extends this concept.

\subsubsection{Data abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Abstract_data_type}{Wikipedia{\tt/}abstract data type}. Data abstraction enforces a clear separation between the {\it abstract} properties of a \href{https://en.wikipedia.org/wiki/Data_type}{data type} \& the {\it concrete} details of its implementation. The abstract properties are those that are visible to client code that makes use of the data type -- the {\it interface} to the data type -- while the concrete implementation is kept entirely private, \& indeed can change, e.g. to incorporate efficiency improvements over time. The idea is that such chances are not supposed to have any impact on client code, since they involve no difference in the abstract behavior.

E.g., one could define an \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data type} called {\it lookup table} which uniquely associates {\it keys} with values, \& in which values may be retrieved by specifying their corresponding keys. Such a lookup table may be implemented in various ways: as a \href{https://en.wikipedia.org/wiki/Hash_table}{hash table}, a \href{https://en.wikipedia.org/wiki/Binary_search_tree}{binary search tree}, or even a simple linear \href{https://en.wikipedia.org/wiki/List_(computing)}{list} of {\tt(key:value)} pairs. As far as client code is concerned, the abstract properties of the type are the same in each case.

Of course, this all relies on getting the details of the interface right in the 1st place, since any changes there can have major impacts on client code. As 1 way to look at this: the interface forms a {\it contract} on agreed behavior between the data type \& client code; anything not spelled out in the contract is subject to change without notice.

\subsubsection{Manual data abstraction}
While much of data abstraction occurs through computer science \& automation, there are times when this process is done manually \& without programming intervention. 1 way this can be understood is through data abstraction within the process of conducting a \href{https://en.wikipedia.org/wiki/Systematic_review}{systematic review} of the literature. In this methodology, data is abstracted by 1 or several abstractors when conducting a \href{https://en.wikipedia.org/wiki/Meta-analysis}{meta-analysis}, with errors reduced through dual data abstraction followed by independent checking, known as \href{https://en.wikipedia.org/wiki/Adjudication}{adjudication}.

\subsubsection{Abstraction in OOP}
Main article: \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{Wikipedia{\tt/}object (computer science)}. In \href{https://en.wikipedia.org/wiki/Object-oriented_programming}{OOP} theory, {\it abstraction} involves the facility to define objects that represent abstract ``actors'' that can perform work, report on \& change their state, \& ``communicate'' with other objects in the system. The term \href{https://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming)}{encapsulation} refers to the hiding of \href{https://en.wikipedia.org/wiki/State_(computer_science)}{state} details, but extending the concept of {\it data type} from earlier programming languages to associate {\it behavior} most strongly with the data, \& standardizing the way that different data types interact, is the beginning of {\it abstraction}. When abstraction proceeds into the operations defined, enabling objects of different types to be substituted, it is called \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism}. When it proceeds in the opposite direction, inside the types or classes, structuring them to simplify a complex set of relationships, it is called \href{https://en.wikipedia.org/wiki/Delegation_(object-oriented_programming)}{delegation} or \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance}.

Various OOP languages offer similar facilities for abstraction, all to support a general strategy of \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism} in object-oriented programming, which includes the substitution of 1 type for another in the same or similar role. Although not as generally supported, a configuration or image or package may predetermine a great many of these \href{https://en.wikipedia.org/wiki/Name_binding}{bindings} at \href{https://en.wikipedia.org/wiki/Compile-time}{compile-time}, \href{https://en.wikipedia.org/wiki/Link-time}{link-time}, or \href{https://en.wikipedia.org/wiki/Loadtime}{loadtime}. This would leave only a minimum of such bindings to change at \href{https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)}{run-time}.

\href{https://en.wikipedia.org/wiki/Common_Lisp_Object_System}{Commmon Lisp Object System} or \href{https://en.wikipedia.org/wiki/Self_(programming_language)}{Self}, e.g., feature less of a class-instance distinction \& more use of delegation for \href{https://en.wikipedia.org/wiki/Polymorphism_in_object-oriented_programming}{polymorphism}. Individual objects \& functions are abstracted more flexibly to better fit with a shared functional heritage from \href{https://en.wikipedia.org/wiki/Lisp_programming_language}{Lisp}.

C++ exemplifies another extreme: it relies heavily on \href{https://en.wikipedia.org/wiki/Generic_programming}{templates} \& \href{https://en.wikipedia.org/wiki/Method_overloading}{overloading} \& other static bindings at compile-time, which in turn has certain flexibility problems.

Although these examples offer alternate strategies for achieving the same abstraction, they do not fundamentally alter th need to support abstract nouns in code -- all programming relies on an ability to abstract verbs as functions, nouns as data structures, \& either as processes.

Consider e.g. a sample Java fragment to represent some common farm ``animals'' to a level of abstraction suitable to model simple aspects of their hunger \& feeding. It defines an {\tt Animal} class to represent both the state of the animal \& its functions:
\begin{verbatim}
	public class Animal extends LivingThing
	{
		private Location loc;
		private double energyReserves;
		
		public boolean isHungry() {
			return energyReserves < 2.5;
		}
		
		public void eat(Food food) {
			// Consume food
			energyReserves += food.getCalories();
		}
		
		public void moveTo(Location location) {
			// Move to new location
			this.loc = location;
		}
	}
\end{verbatim}
With the above definition, one could create objects of type {\tt Animal} \& call their methods like this:
\begin{verbatim}
	thePig = new Animal();
	theCow = new Animal();
	if (thePig.isHungry()) {
		thePig.eat(tableScraps);
	}
	if (theCow.isHungry()) {
		theCow.eat(grass);
	}
	theCow.moveTo(theBarn);
\end{verbatim}
In the above example, the class {\tt Animal} is an abstraction used in place of an actual animal, {\tt LivingThing} is a further abstraction (in this case a generalization) of {\tt Animal}.

If one requires a more differentiated hierarchy of animals -- to differentiate, say, those who provide milk from those ho provide nothing except meat at the end of their lives -- that is an intermediary level of abstraction, probably {\tt DairyAnimal(cows,goats)} who would eat foods suitable to giving good milk, \& {\tt MeatAnimal(pigs,steers)} who would eat foods to give the best meat-quality.

Such an abstraction could remove the need for the application coder to specify the type of food, so they could concentrate instead on the feeding schedule. The 2 classes could be related using \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance} or stand alone, \& the programmer could define varying degrees of \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism} between the 2 types. These facilities tend to vary drastically between languages, but in general each can achieve anything that is possible with any of the others. A great many operation overloads, data type by data type, can have the same effect at compile-time as any degree of inheritance or other means to achieve polymorphism. The class notation is simply a coder's convenience.

\paragraph{Object-oriented design.} Main article: \href{https://en.wikipedia.org/wiki/Object-oriented_design}{Wikipedia{\tt/}object-oriented design}. Decisions regarding what to abstract \& what to keep under the control of the coder become the major concern of object-oriented design \& \href{https://en.wikipedia.org/wiki/Domain_analysis}{domain analysis} -- actually determining the relevant relationships in the real world is the concern of \href{https://en.wikipedia.org/wiki/Object-oriented_analysis_and_design}{object-oriented analysis} or legacy analysis.

In general, to determine appropriate abstraction, one must make many small decisions about scope (domain analysis), determine what other systems one must cooperate with (legacy analysis), then perform a detailed object-oriented analysis which is expressed within project time \& budget constraints as an object-oriented design. In our simple example, the domain is the barnyard, the live pigs \& cows \& their eating habits are the legacy constraints, the detailed analysis is that coders must have the flexibility to feed the animals what is available \& thus there is no reason to code the type of food into the class itself, \& the design is a single simple {\tt Animal} class of which pigs \& cows are instances with the same functions. A decision to differentiate {\tt DairyAnimal} would change the detailed analysis but the domain \& legacy analysis would be unchanged -- thus it is entirely under the control of the programmer, \& it is called an abstraction in object-oriented programming as distinct from abstraction in domain or legacy analysis.

\subsubsection{Considerations}
When discussing \href{https://en.wikipedia.org/wiki/Formal_semantics_of_programming_languages}{formal semantics of programming languages}, \href{https://en.wikipedia.org/wiki/Formal_methods}{formal methods} or \href{https://en.wikipedia.org/wiki/Abstract_interpretation}{abstract interpretation}, {\it abstraction} refers to the act of considering a less detailed, but safe, definition of the observed program behaviors. E.g., one may observe only the final result of program executions instead of considering all the intermediate steps of executions. Abstraction is defined to a {\it concrete} (more precise) model of execution.

Abstraction may be {\it exact} or {\it faithful} w.r.t. a property if one can answer a question about the property equally well on the concrete or abstract model. E.g., if one wishes to know what the result of the evaluation of a mathematical expression involving only integers $+,-,\cdot$, is worth \href{https://en.wikipedia.org/wiki/Modular_arithmetic}{module} $n$, then one needs only perform all operations module $n$ (a familiar form of this abstraction is \href{https://en.wikipedia.org/wiki/Casting_out_nines}{casting out nines}).

Abstractions, however, though not necessarily {\it exact}, should be {\it sound}. I.e., it should be possible to get sound answers from them -- even though the abstraction may simply yield a result of \href{https://en.wikipedia.org/wiki/Undecidable_problem}{undecidability}. E.g., students in a class may be abstracted by their minimal \& maximal ages; if one asks whenever a certain person belongs to that class, one may simply compare that person's age with the minimal \& maximal ages; if his age lies outside the range, one may safely answer that the person does not belong to the class; if it does not, one may only answer ``I don't know''.

The level of abstraction included in a programming language can influence its overall \href{https://en.wikipedia.org/wiki/Usability}{usability}. The \href{https://en.wikipedia.org/wiki/Cognitive_dimensions}{Cognitive dimensions} framework includes the concept of {\it abstraction gradient} in a formalism. This framework allows the designer of a programming language to study the trade-offs between abstraction \& other characteristics of the design, \& how changes in abstraction influence the language usability.

Abstractions can prove useful when dealing with computer programs, because nontrivial properties of computer programs are essentially \href{https://en.wikipedia.org/wiki/Undecidable_problem}{undecidable} (\href{https://en.wikipedia.org/wiki/Rice%27s_theorem}{Rice's theorem}). As a consequence, automatic methods for deriving information on the behavior of computer programs either have to drop termination (on some occasions, they may fail, crash or never yield out a result), soundness (they may provide false information), or precision (they may answer ``I don't know'' to some questions).

Abstraction is the core concept of \href{https://en.wikipedia.org/wiki/Abstract_interpretation}{abstract interpretation}. \href{https://en.wikipedia.org/wiki/Model_checking}{Model checking} generally takes place on abstract versions of the studied systems.

\subsubsection{Levels of abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Abstraction_layer}{Wikipedia{\tt/}abstraction layer}. Computer science commonly presents {\it levels} (or, less commonly, {\it layers}) of abstraction, wherein each level represents a different model of the same information \& processes, but with varying amounts of detail. Each level uses a system of expression involving a unique set of objects \& compositions that apply only to a particular domain. Each relatively abstract, ``higher'' level builds on a relatively concrete, ``lower'' level, which tends to provide an increasingly ``granular'' representation. E.g., gates build on electronic circuits, binary on gates, machine language on binary, programming language on machine language, applications \& operating systems on programming languages. Each level is embodied, but not determined, by the level beneath it, making it a language of description that is somewhat self-contained.

\paragraph{Database systems.} Main article: \href{https://en.wikipedia.org/wiki/Database_management_system}{Wikipedia{\tt/}database management system}. {\sf Data abstraction levels of a database system}. Since many users of database systems lack in-depth familiarity with computer data-structures, database developers often hide complexity through the following levels"
\begin{itemize}
	\item {\bf Physical level.} The lowest level of abstraction describes {\it how} a system actually stores data. The physical level describes complex low-level data structures in detail.
	\item {\bf Logical level.} The next higher level of abstraction describes {\it what} data the database stores, \& what relationships exist among those data. The logical level thus describes an entire database in terms of a small number of relatively simple structures. Although implementation of the simple structures at the logical level may involve complex physical level structures, the user of the logical level does not need to be aware of this complexity. This is referred to as \href{https://en.wikipedia.org/wiki/Physical_data_independence}{physical data independence}. \href{https://en.wikipedia.org/wiki/Database_administrator}{Database administrators}, who must decide what information to keep in a database, use the logical level of abstraction.
	\item {\bf View level.} The highest level of abstraction describes only part of the entire database. Even though the logical level uses simpler structures, complexity remains because of the variety of information stored in a large database. Many users of a database system do not need all this information; instead, they need to access only a part of the database. The view level of abstraction exists to simplify their interaction with the system. The system may provide may \href{https://en.wikipedia.org/wiki/View_(database)}{views} for the same database.
\end{itemize}

\paragraph{Layered architecture.} Main article: \href{https://en.wikipedia.org/wiki/Abstraction_layer}{Abstraction layer}. The ability to provide a \href{https://en.wikipedia.org/wiki/Design}{design} of different levels of abstraction can
\begin{itemize}
	\item simplify the design considerably
	\item enable different role players to effectively work at various levels of abstraction
	\item support the portability of \href{https://en.wikipedia.org/wiki/Software_artifact}{software artifacts} (model-based ideally)
\end{itemize}
\href{https://en.wikipedia.org/wiki/Systems_design}{System designs} \& \href{https://en.wikipedia.org/wiki/Business_process_modeling}{business process design} can both use this. Some \href{https://en.wikipedia.org/wiki/Software_modeling}{design processes} specifically generate designs that contain various levels of abstraction.

Layered architecture partitions the concerns of the application into stacked groups (layers). It is a technique used in designing computer software, hardware, \& communications in which system or network components are isolated in layers so that changes can be made in 1 layer without affecting the others.'' -- \href{https://en.wikipedia.org/wiki/Abstraction_(computer_science)}{Wikipedia{\tt/}abstraction (computer science)}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Anaconda}
``{\it Anaconda} is an \href{https://en.wikipedia.org/wiki/Open_source}{open source} \href{https://en.wikipedia.org/wiki/Data_science}{data science} \& AI \href{https://en.wikipedia.org/wiki/Software_distribution}{distribution} platform for Python \& R programming languages. Developed by Anaconda, Inc., an American company founded in 2012, platform is used to develop \& manage data science \& AI projects. In 2024, Anaconda Inc. has about 300 employees \& 45 million users.

\subsubsection{History}
Co-founded in \href{https://en.wikipedia.org/wiki/Austin,_Texas}{Austin, Texas} in 2012 as Continuum Analytics by {\it Peter Wang} \& \href{https://en.wikipedia.org/wiki/Travis_Oliphant}{\sc Travis Oliphant}, Anaconda Inc. operates from US \& Europe.

Anaconda Inc. developed \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda}, a \href{https://en.wikipedia.org/wiki/Cross-platform}{cross-platform}, language-agnostic binary \href{https://en.wikipedia.org/wiki/Package_manager}{package manager}. It also launched PyData community workshops \& Jupyter Cloud Notebook service (Wakari.io). In 2013, it received funding from \href{https://en.wikipedia.org/wiki/DARPA}{DARPA}. In 2015, company had 2 million users including 200 of \href{https://en.wikipedia.org/wiki/Fortune_500}{Fortune 500} companies \& raised \$24 million in a \href{https://en.wikipedia.org/wiki/Series_A}{Series A} funding round led by \href{https://en.wikipedia.org/wiki/General_Catalyst}{General Catalyst} \& BuildGroup. Anaconda secured an additional \$30 million in funding in 2021.

Continuum Analytics rebranded as Anaconda in 2017. That year, it announced release of Anaconda Enterprise 5, an integration with \href{https://en.wikipedia.org/wiki/Microsoft_Azure}{Microsoft Azure}, \& had over 13 million users by year's end.

In 2022, it released Anaconda Business; new integrations with Snowflake \& others; \& open-source PyScript. It also required PythonAnywhere, while Anaconda's user base exceeded 30 million in 2022. In 2023, Anaconda released Python in Excel, a new integration with \href{https://en.wikipedia.org/wiki/Microsoft_Excel}{Microsoft Excel}, \& launched \url{PyScript.com}.

Company made a series of investments in AI during 2024. Feb, Anaconda partnered with \href{https://en.wikipedia.org/wiki/IBM}{IBM} to import its repository of Python packages into \href{https://en.wikipedia.org/wiki/Watsonx}{Watsonx}, IBM's \href{https://en.wikipedia.org/wiki/Generative_AI}{generative AI} platform. Same year, Anaconda joined IBM's AI Alliance \& releasedan integration with \href{https://en.wikipedia.org/wiki/Teradata}{Teradata} \& \href{https://en.wikipedia.org/wiki/Lenovo}{Lenovo}.

In 2024, Anaconda's user base reached 45 million users \& {\sc Barry Libert} was named company CEO, after serving on Anaconda's board of directors.

\subsubsection{Overview}
{\it Anaconda distribution} comes with $> 300$ packages automatically installed, \& $> 7500$ additional open-source packages can be installed from Anaconda repository as well as Conda package \& \href{https://en.wikipedia.org/wiki/Virtual_environment_software}{virtual environment} manager. It also includes a \href{https://en.wikipedia.org/wiki/Graphical_user_interface}{GUI}, {\it Anaconda Navigator}, as a graphical alternative to \href{https://en.wikipedia.org/wiki/Command-line_interface}{command-line interface} (CLI).

\href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda} was developed to address dependency conflicts native to \href{https://en.wikipedia.org/wiki/Pip_(package_manager)}{pip package manager}, which would automatically install any dependent Python packages without checking for conflicts with previously installed packages (until its version 20.3, which later implemented consistent dependency resolution). Conda package manager's historical differentiation analyzed \& resolved these installation conflicts.

Anaconda is a distribution of Python \& R programming languages for \href{https://en.wikipedia.org/wiki/Scientific_computing}{scientific computing} (DS, ML applications, large-scale \href{https://en.wikipedia.org/wiki/Data_processing}{data processing}, \href{https://en.wikipedia.org/wiki/Predictive_analytics}{predictive analysis}, etc.), that aims to simplify \href{https://en.wikipedia.org/wiki/Package_management}{package management} \& \href{https://en.wikipedia.org/wiki/Deployment_environment}{deployment}. Anaconda distribution includes data-science packages suitable for Windows, Linux, \& macOS. Other company products include Anaconda Free, \& subscription-based Starter, Business, \& Enterprise. Anaconda's business tier offers Package Security Manager.

Package versions in Anaconda are managed by package management system \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda}, which was spun out as a separate open-source package as useful both independently \& for applications other than Python. There is also a small, \href{https://en.wikipedia.org/wiki/Bootstrapping}{bootstrap} version of Anaconda called {\it Miniconda}, which includes only Conda, Python, packages they depend on, \& a small number of other packages.

Open source packages can be individually installed from Anaconda repository, Anaconda Cloud (\url{anaconda.org}), or user's own private repository or mirror, using {\tt conda install} command. Anaconda, Inc. compiles \& builds packages available in Anaconda repository itself, \& provides \href{https://en.wikipedia.org/wiki/Binary_file}{binaries} for Windows 32{\tt/}64 bit, Linux 64 bit \& MacOS 64-bit (Intel, Apple Silicon). Anything available on PyPI may be installed into a Conda environment using {\tt pip}, \& Conda will keep track of what it has installed \& what pip has installed. Custom packages can be made using {\tt conda build} command, \& can be shared with others by uploading them to Anaconda Cloud, PyPI or other repositories.

Default installation of Anaconda2 includes Python 2.7 \& Anaconda3 includes Python 3.7. However, possible to create new environments that include any version of Python packaged with Conda.
\begin{itemize}
	\item {\sf Anaconda Navigator.} Anaconda Navigator is a desktop graphical user interface (GUI) included in Anaconda distribution that allows users to launch applications \& manage Conda packages, environments \& channels without using \href{https://en.wikipedia.org/wiki/Command-line_interface}{command-line commands}. Navigator can search for packages on Anaconda Cloud or in a local Anaconda Repository, install them in an environment, run the packages \& update them. Available for Windows, macOS \& Linux.
	
	Applications are available by default in Navigator:
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Project_Jupyter#JupyterLab}{JupyterLab}
		\item \href{https://en.wikipedia.org/wiki/Project_Jupyter#Jupyter_Notebook}{Jupyter Notebook}
		\item QtConsole
		\item \href{https://en.wikipedia.org/wiki/Spyder_(software)}{Spyder}
		\item \href{https://en.wikipedia.org/wiki/Glue_(software)}{Glue}
		\item \href{https://en.wikipedia.org/wiki/Orange_(software)}{Orange}
		\item \href{https://en.wikipedia.org/wiki/RStudio}{RStudio}
		\item \href{https://en.wikipedia.org/wiki/Visual_Studio_Code}{Visual Studio Code}
	\end{itemize}
	\item {\sf Conda.} \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda} is an open source, \href{https://en.wikipedia.org/wiki/Cross-platform}{cross-platform}, language-agnostic \href{https://en.wikipedia.org/wiki/Package_manager}{package manager} \& environment management system that installs, runs, \& updates packages \& their dependencies. It was created for Python programs, but it can package \& distribute software for any language (e.g., R), including multi-language projects. Conda package \& environment manager is included in all versions of Anaconda, Miniconda, \& Anaconda Repository.
\end{itemize}

\subsubsection{Anaconda.org}
Anaconda Cloud is a package management service by Anaconda where users can find, access, store \& share public \& private notebooks, environments, \& Conda \& PyPI packages. Cloud hosts useful Python packages, notebooks \& environments for a wide variety of applications. Users do not need to log in or to have a Cloud account, to search for public packages, download \& install them. Users can build new Conda packages using Conda-build \& then use Anaconda Client CLI upload packages to \url{Anaconda.org}. Notebooks users can be aided with writing \& debugging code with Anaconda's AI Assistant.'' -- \href{https://en.wikipedia.org/wiki/Anaconda_(Python_distribution)}{Wikipedia{\tt/}Anaconda}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}computational learning theory}
``In CS, {\it computational learning theory} (or just {\it learning theory}) is a subfield of AI devoted to studying design \& analysis of ML algorithms.

\subsubsection{Overview}
Theoretical results in ML mainly deal with a type of inductive learning called \href{https://en.wikipedia.org/wiki/Supervised_learning}{supervised learning}. In supervised learning, an algorithm is given samples that are \href{https://en.wikipedia.org/wiki/Labeled_data}{labeled} in some useful way. E.g., samples might be descriptions of mushrooms, \& labels could be whether or not mushrooms are edible. Algorithm takes these previously labeled samples \& uses them to induce a classifier. This classifier is a function that assigns labels to samples, including samples that have not been seen previously by algorithm. Goal of supervised learning algorithm: optimize some measure of performance e.g. minimizing number of mistakes made on new samples.

In addition to performance bounds, computational learning theory studies time complexity \& feasibility of learning. In computational learning theory, a computation is considered {\it feasible} (khả thi) if it can be done in \href{https://en.wikipedia.org/wiki/Polynomial_time}{polynomial time}. There are 2 kinds of time complexity results:
\begin{itemize}
	\item Positive results -- showing: a certain class of functions is learnable in polynomial time.
	\item Negative results -- showing: certain classes cannot be learned in polynomial time.
\end{itemize}
Negative results often rely on commonly believed, but yet unproven assumptions, e.g.:
\begin{itemize}
	\item Computational complexity - \href{https://en.wikipedia.org/wiki/P_versus_NP_problem}{P$\ne$NP (P vs. NP problem)}
	\item \href{https://en.wikipedia.org/wiki/Cryptography}{Cryptographic} -- \href{https://en.wikipedia.org/wiki/One-way_function}{1-way functions} exist.
\end{itemize}
There are several different approaches to computational learning theory based on making different assumptions about \href{https://en.wikipedia.org/wiki/Inference}{inference} principles used to generalize from limited data. This includes different definitions of probability (see \href{https://en.wikipedia.org/wiki/Frequency_probability}{frequency probability}, \href{https://en.wikipedia.org/wiki/Bayesian_probability}{Bayesian probability}) \& different assumptions on generation of samples. Different approaches include:
\begin{itemize}
	\item Exact learning, proposed by \href{https://en.wikipedia.org/wiki/Dana_Angluin}{\sc Dana Angluin}
	\item \href{https://en.wikipedia.org/wiki/Probably_approximately_correct_learning}{Probably approximately correct learning} (PAC learning), proposed by \href{https://en.wikipedia.org/wiki/Leslie_Valiant}{\sc Leslie Valiant}
	\item \href{https://en.wikipedia.org/wiki/VC_theory}{VC theory}, proposed by \href{https://en.wikipedia.org/wiki/Vladimir_Vapnik}{\sc Vladimir Vapnik} \& \href{https://en.wikipedia.org/wiki/Alexey_Chervonenkisv}{\sc Alexey Chervonenkis}
	\item \href{https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference}{Inductive inference} as developed by \href{https://en.wikipedia.org/wiki/Ray_Solomonoff}{\sc Ray Solomonoff}
	\item \href{https://en.wikipedia.org/wiki/Algorithmic_learning_theory}{Algorithmic learning theory}, from work of \href{https://en.wikipedia.org/wiki/E._Mark_Gold}{\sc E. Mark Gold}.
	\item \href{https://en.wikipedia.org/wiki/Online_machine_learning}{Online ML}, from work of {\sc Nick Littlestone}.
\end{itemize}
While its primary goal is to understand learning abstractly, computational learning theory has led to development of practical algorithms. E.g., PAC theory inspired \href{https://en.wikipedia.org/wiki/Boosting_(meta-algorithm)}{boosting}, VC theory led to \href{https://en.wikipedia.org/wiki/Support_vector_machine}{support vector machines}, \& Bayesian inference led to \href{https://en.wikipedia.org/wiki/Belief_networks}{belief networks}.'' -- \href{https://en.wikipedia.org/wiki/Computational_learning_theory}{Wikipedia{\tt/}computational learning theory}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Conda (package manager)}
``{\it Conda} is an open-source, \href{https://en.wikipedia.org/wiki/Cross-platform}{cross-platform}, \href{https://en.wikipedia.org/wiki/Language-agnostic}{language-agnostic} \href{https://en.wikipedia.org/wiki/Package_manager}{package manager} \& environment management system. It was originally developed to solve package management challenges faced by Python data scientists, \& today is a popular package manager for Python \& R. At 1st, \href{https://en.wikipedia.org/wiki/Anaconda_(Python_distribution)}{Anaconda Python distribution} was developed by Anaconda Inc.; later, it was spun out as a separate package, released under \href{https://en.wikipedia.org/wiki/BSD_licenses}{BSD license}. Conda package \& environment manager is included in all versions of \href{https://en.wikipedia.org/wiki/Anaconda_(Python_distribution)}{Anaconda}, \href{https://en.wikipedia.org/wiki/Miniconda}{Miniconda}, \& Anaconda Repository. Conda is a NumFOCUS affiliated project.

\subsubsection{Features}
As a package manger, Conda allows users to install different versions of \href{https://en.wikipedia.org/wiki/Binary_file}{binary} software packages \& their required software \href{https://en.wikipedia.org/wiki/Coupling_(computer_programming)}{dependencies} appropriate for their \href{https://en.wikipedia.org/wiki/Computing_platform}{computing platform} from a \href{https://en.wikipedia.org/wiki/Software_repository}{software repository}. Conda checks everything that has been installed, any version limitations that user specifies (e.g., user wants a specific package to be at least version 2.1.3), \& determines a set of versions for all requested packages \& their dependencies that makes total set compatible with 1 another. If there is no set of compatible dependencies, it will tell user: requested combination of software packages at requested versions is not possible.

Secondly, Conda allows users to create such a set of software packages in isolation from rest of computing platform, in what Conda calls an {\it environment}. This allows user to create various sets of software packages for different projects. When users switches between those projects, they switch to relevant environment, thereby avoiding re-installation or removal of conflicting packages. To further facilitate setup of such environments, Conda can also install Python, interpreter for software packages itself.

Conda is written in Python programming language, but can manage projects containing code written in any language, including multi-language projects.

A popular Conda channel for \href{https://en.wikipedia.org/wiki/List_of_bioinformatics_software}{bioinformatics software} is {\it Bioconda}, which provides multiple software distributions for computational biology.'' -- \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Wikipedia{\tt/}Conda (package manager)}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}data structure}
{\sf A data structure known as a \href{https://en.wikipedia.org/wiki/Hash_table}{hash table}.} ``In computer science, a {\it data structure} is a \href{https://en.wikipedia.org/wiki/Data}{data} organization \& storage format that is usually chosen for \href{https://en.wikipedia.org/wiki/Efficiency}{efficient} \href{https://en.wikipedia.org/wiki/Data_access}{access} to data. More precisely, a data structure is a collection of data values, the relationships among them, \& the \href{https://en.wikipedia.org/wiki/Function_(computer_programming)}{functions} or \href{https://en.wikipedia.org/wiki/Operator_(computer_programming)}{operations} that can be applied to the data, i.e., it is an \href{https://en.wikipedia.org/wiki/Algebraic_structure}{algebraic structure} about \href{https://en.wikipedia.org/wiki/Data}{data}.

\subsubsection{Usage}
Data structures serve as the basis for \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data types} (ADT). The ADT defines the logical form of the data type. The data structure implements the physical form of the \href{https://en.wikipedia.org/wiki/Data_type}{data type}.

Different types of data structures are suited to different kinds of applications, \& some are highly specialized to specific tasks. E.g., \href{https://en.wikipedia.org/wiki/Relational_database}{relational databases} commonly use \href{https://en.wikipedia.org/wiki/B-tree}{B-tree} indexes for data retrieval, while \href{https://en.wikipedia.org/wiki/Compiler}{compiler} \href{https://en.wikipedia.org/wiki/Implementation}{implementations} usually use \href{https://en.wikipedia.org/wiki/Hash_table}{hash tables} to look up \href{https://en.wikipedia.org/wiki/Identifier_(computer_languages)}{identifiers}.

Data structures provide a means to manage large amounts of data efficiently for uses such as large \href{https://en.wikipedia.org/wiki/Database}{databases} \& internet indexing services. Usually, efficient data structures are key to designing efficient \href{https://en.wikipedia.org/wiki/Algorithm}{algorithms}. Some formal design methods \& \href{https://en.wikipedia.org/wiki/Programming_language}{programming language} emphasize data structures, rather than algorithms, as the key organizing factor in software design. Data structures can be used to organize the storage \& retrieval (thu hồi) of information stored in both \href{https://en.wikipedia.org/wiki/Main_memory}{main memory} \& \href{https://en.wikipedia.org/wiki/Computer_data_storage}{secondary memory}.

\subsubsection{Implementation}
Data structures can be implemented using a variety of programming languages \& techniques, but they all share the common goal of efficiently organizing \& storing data. Data structures are generally based on the ability of a \href{https://en.wikipedia.org/wiki/Computer}{computer} to fetch \& store data at any place in its memory, specified by a \href{https://en.wikipedia.org/wiki/Pointer_(computer_programming)}{pointer} -- a \href{https://en.wikipedia.org/wiki/Bit}{bit} \href{https://en.wikipedia.org/wiki/String_(computer_science)}{string}, representing a \href{https://en.wikipedia.org/wiki/Memory_address}{memory address}, that can be itself stored in memory \& manipulated by the program. Thus, the \href{https://en.wikipedia.org/wiki/Array_data_structure}{array} \& \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{record} data structures are based on computing the addresses of data items with \href{https://en.wikipedia.org/wiki/Arithmetic_operations}{arithmetic operations}, while the \href{https://en.wikipedia.org/wiki/Linked_data_structure}{linked data structures} are based on storing addresses of data items within the structure itself. This approach to data structuring has profound implications for the efficiency \& scalability of algorithms. E.g., the contiguous memory allocation in arrays facilitates rapid access \& modification operations, leading to optimized performance in sequential data processing scenarios.

The implementation of a data structure usually requires writing a set of \href{https://en.wikipedia.org/wiki/Subroutine}{procedures} that create \& manipulate instances of that structure. The efficiency of a data structure cannot ne analyzed separately from those operations. This observation motivates the theoretical concept of an \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data type}, a data structure that is defined indirectly by the operations that may be performed on it, \& the mathematical properties of those operations (including their space \& time cost).

\subsubsection{Examples}
{\sf The standard \href{https://en.wikipedia.org/wiki/Data_type}{type} hierarchy of the programming language \href{https://en.wikipedia.org/wiki/Python_(programming_language)}{Python 3}.} Main article: \href{https://en.wikipedia.org/wiki/List_of_data_structures}{Wikipedia{\tt/}list of data structures}. There are numerous types of data structures, generally built upon simpler \href{https://en.wikipedia.org/wiki/Primitive_data_type}{primitive data types}. Well known examples are:
\begin{itemize}
	\item An \href{https://en.wikipedia.org/wiki/Array_(data_structure)}{array} is a number of elements in a specific order, typically all of the same type (depending on the language, individual elements may either all be forced to be the same type, or may be of almost any type). Elements are accessed using an integer index to specify which element is required. Typical implementations allocate contiguous memory words for the elements of arrays (but this is not always a necessity). Arrays may be fixed-length or resizable.
	\item A \href{https://en.wikipedia.org/wiki/Linked_list}{linked list} (also just called {\it list}) is a linear collection of data elements of any type, called {\it nodes}, where each node has itself a value, \& points to the next node in the linked list. The principal advantage of a linked list over an array is that values can always be efficiently inserted \& removed without relocating the rest of the list. Certain other operations, e.g. \href{https://en.wikipedia.org/wiki/Random_access}{random access} to a certain element, are however slower on lists than on arrays.
	\item A \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{record} (also called {\it tuple} or {\it struct}) is an \href{https://en.wikipedia.org/wiki/Aggregate_data}{aggregate data} structure. A record is a value that contains other values, typically in fixed number \& sequence \& typically indexed by names. The elements of records are usually called {\it fields} or {\it members}. In the context of OOP, records are known as \href{https://en.wikipedia.org/wiki/Plain_old_data_structure}{plain old data structures} to distinguish them from objects.
	\item \href{https://en.wikipedia.org/wiki/Hash_table}{Hash tables}, also known as hash maps, are data structures that provide fast retrieval of values based on keys. They use a hashing function to map keys to indexes in an array, allowing for constant-time access in the average case. Hash tables are commonly used in dictionaries, caches, \& database indexing. However, hash collisions can occur, which can impact their performance. Techniques like chaining \& open addressing are employed to handle collisions.
	\item \href{https://en.wikipedia.org/wiki/Graph_(abstract_data_type)}{Graphs} are collections of nodes connected by edges, representing relationships between entities. Graphs can be used to model social networks, computer networks, \& transportation networks, among other things. They consist of vertices (nodes) \& edges (connections between nodes). Graphs can be directed or undirected, \& they can have cycles or be acylic. Graph traversal algorithms include breadth-1st search \& depth-1st search.
	\item \href{https://en.wikipedia.org/wiki/Stack_(abstract_data_type)}{Stacks} \& \href{https://en.wikipedia.org/wiki/Queue_(abstract_data_type)}{queues} are abstract data types that can be implemented using arrays or linked lists. A stack has 2 primary operations: push (adds an element to the top of the stack) \& pop (removes the topmost element from the stack), that follow the Last In, First Out (LIFO) principle. Queues have 2 main operations: enqueue (adds an element to the rear of the queue) \& dequeue (removes an element from the front of the queue) that follow the First In, First Out (FIFO) principle.
	\item \href{https://en.wikipedia.org/wiki/Tree_(data_structure)}{Trees} represents a hierarchical organization of elements. A tree consists of nodes connected by edges, with 1 node being the root \& all other nodes forming subtrees. Trees are widely used in various algorithms \& data storage scenarios. \href{https://en.wikipedia.org/wiki/Binary_tree}{Binary trees} (particularly \href{https://en.wikipedia.org/wiki/Heap_(data_structure)}{heaps}), \href{https://en.wikipedia.org/wiki/AVL_tree}{AVL trees}, \& \href{https://en.wikipedia.org/wiki/B-tree}{B-trees} are some popular types of trees. They enable efficient \& optimal searching, sorting, \& hierarchical representation of data.
\end{itemize}
A \href{https://en.wikipedia.org/wiki/Trie}{trie}, or prefix tree, is a special type of tree used to efficiently retrieve strings. In a trie, each node represents a character of a string, \& the edges between nodes represent the characters that connect them. This structure is especially useful for tasks like autocomplete, spell-checking, \& creating dictionaries. Tries allow for quick searches \& operations based on string prefixes.

\subsubsection{Language support}
Most \href{https://en.wikipedia.org/wiki/Assembly_language}{assembly languages} \& some \href{https://en.wikipedia.org/wiki/Low-level_programming_language}{low-level languages}, such as \href{https://en.wikipedia.org/wiki/BCPL}{BCPL} (Basic Combined Programming Language), lack built-in support for data structures. On the other hand, many \href{https://en.wikipedia.org/wiki/High-level_programming_language}{high-level programming languages} \& some higher-level assembly languages, e.g. \href{https://en.wikipedia.org/wiki/MASM}{MASM}, have special syntax or other built-in support for certain data structures, e.g. records \& arrays. E.g., the \href{https://en.wikipedia.org/wiki/C_(programming_language)}{C} (a direct descendant of BCPL) \& \href{https://en.wikipedia.org/wiki/Pascal_(programming_language)}{Pascal} languages support \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{structs} \& records, respectively, in addition to vectors (1D \href{https://en.wikipedia.org/wiki/Array_data_type}{arrays}) \& multi-dimensional arrays.

Most programming languages feature some sort of \href{https://en.wikipedia.org/wiki/Library_(computing)}{library} mechanism that allows data structure implementations to be reused by different programs. Modern languages usually come with standard libraries that implement the most common data structures. E.g., \href{https://en.wikipedia.org/wiki/Standard_Template_Library}{C++ Standard Template Library}, \href{https://en.wikipedia.org/wiki/Java_Collections_Framework}{Java Collections Framework}, \& \href{https://en.wikipedia.org/wiki/Microsoft}{Microsoft} \href{https://en.wikipedia.org/wiki/.NET_Framework}{.NET Framework}.

Modern languages also generally support \href{https://en.wikipedia.org/wiki/Modular_programming}{modular programming}, the separation between the \href{https://en.wikipedia.org/wiki/Interface_(computing)}{interface} of a library module \& its implementation. Some provide \href{https://en.wikipedia.org/wiki/Opaque_data_type}{apaque data types} that allow clients to hide implementation details. \href{https://en.wikipedia.org/wiki/Object-oriented_programming_language}{OOP languages}, e.g. C++, Java, \& \href{https://en.wikipedia.org/wiki/Smalltalk}{Smalltalk}, typically use \href{https://en.wikipedia.org/wiki/Classes_(computer_science)}{classes} for this purpose.

Many known data structures have \href{https://en.wikipedia.org/wiki/Concurrent_data_structure}{concurrent} versions which allow multiple computing threads to access a single concrete instance of a data structure simultaneously.'' -- \href{https://en.wikipedia.org/wiki/Data_structure}{Wikipedia{\tt/}data structure}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}level set (data structures)}
``In computer science, a \href{https://en.wikipedia.org/wiki/Level_set}{level set} \href{https://en.wikipedia.org/wiki/Data_structure}{data structure} is designed to represent discretely \href{https://en.wikipedia.org/wiki/Sampling_(statistics)}{sampled} dynamic level sets functions. A common use of this form of data structure is in efficient image \href{https://en.wikipedia.org/wiki/Rendering_(computer_graphics)}{rendering}. The underlying method constructs a \href{https://en.wikipedia.org/wiki/Distance_transform}{signed distance field} that extends the boundary, \& can be used to solve the motion of the boundary in this field.

\subsubsection{Chronological developments}
The powerful \href{https://en.wikipedia.org/wiki/Level-set_method}{level-set method} is due to \href{https://en.wikipedia.org/wiki/Stanley_Osher}{\sc Osher} \& \href{https://en.wikipedia.org/wiki/James_Sethian}{\sc Sethian} 1988. However, the straightforward implementation via a dense $d$-dimensional \href{https://en.wikipedia.org/wiki/Array_data_structure}{array} of values, results in both time \& storage complexity of $O(n^d)$, where $n$ is the cross sectional resolution of the spatial extents of the domain \& $d$ is the number of spatial dimensions of the domain.
\begin{enumerate}
	\item {\bf Narrow band.} The narrow band level set method, introduced in 1995 by {\sc Adalsteinsson \& Sethian}, restricted most computations to a thin band of active \href{https://en.wikipedia.org/wiki/Voxel}{voxels} immediately surrounding the interface, thus reducing the time complexity in 3D to $O(n^2)$ for most operations. Periodic updates of the narrowband structure, to rebuild the list of active voxels, were required which entailed an $O(n^3)$ operation in which voxels over the entire volume were accessed. The storage complexity for this narrowband scheme was still $O(n^3)$. Differential constructions over the narrow band domain edge require careful interpolation \& domain alternation schemes to stabilize the solution.
	\item {\bf Sparse field.} This $O(n^3)$ time complexity was eliminated in the approximate ``sparse field'' level set method introduced by {\sc Whitaker} in 1998. The sparse field level set method employs a set of linked list to track the active voxels around the interface. This allows incremental extension of the active region as needed without incurring any significant overhead. While consistently $O(n^2)$ efficient in time, $O(n^3)$ storage space is still required by the sparse field level set method.
	\item {\bf Sparse block grid.} The sparse block grid method, introduced by {\sc Bridson} in 2003, divides the entire \href{https://en.wikipedia.org/wiki/Bounding_volume}{bounding volume} of size $n^3$ into small cubic blocks of $m^3$ voxels each. A coarse grid of size $\left(\frac{n}{m}\right)^3$ then stores pointers only to those blocks that intersect that narrow band of the level set. Block allocation \& deallocation occur as the surface propagates to accommodate to the deformations. This method has a suboptimal storage complexity of $O(\left(\frac{n}{m}\right)^3 + m^3n^2)$, but retains the constant time access inherent to dense grids.
	\item {\bf Octree.} The \href{https://en.wikipedia.org/wiki/Octree}{octree} level set method, introduced by {\sc Strain} in 1999 \& refined by {\sc Losasso, Gibu, \& Fedkiw}, \& more recently by {\sc Min \& Gibou} uses a tree of nested cubes of which the leaf nodes contain signed distance values. Octree level sets currently require uniform refinement along the interface (i.e., the narrow band) in order to obtain sufficient precision. This representation is efficient in terms of storage, $O(n^2)$, \& relatively efficient in terms of access queries, $O(\log n)$. A advantage of the level method on octree data structures is that one can solve the PDEs associated with typical free boundary problems that use the level set method. The CASL research group has developed this line of work in computational materials, CFD, electrokinetics, image guided surgery \& controls.
	\item {\bf Run-length encoded.} The \href{https://en.wikipedia.org/wiki/Run-length_encoding}{run-length encoding} (RLE) level set method, introduced in 2004, applies the RLE scheme to compress regions away from the narrow band to just their sign representation while storing with full precision the narrow band. The sequential traversal of the narrow band is optimal \& storage efficiency is further improved over the octree level set. The additional of an acceleration lookup table allows for fast $O(\log r)$ random access, where $r$ is the number of runs per cross section. Additional efficiency is gained by applying the RLE scheme in a dimensional recursive fashion, a technique introduced by {\sc Nielsen \& Museth}'s similar DT-Grid.
	\item {\bf Hash Table Local Level Set.} The Hash Table Local Level Set method, introduced in 2011 by {\sc Eyiyurekli \& Breen} \& extended in 2012 by {\sc Brun, Guittet, \& Gibou}, only computes the level set data in a band around the interface, as in the Narrow Band Level-Set Method, but also only stores the data in that same band. A hash table data structure is used, which provides an $O(1)$ access to the data. However, {\sc Brun} et al. conclude that their method, while being easier to implement, performs worse than a quadtree implementation. They find that
	\begin{quote}
		as it is, [$\ldots$] a quadtree data structure seems more adapted than the hash table data structure for level-set algorithms.
	\end{quote}
	3 main reasons for worse efficiency are listed:
	\begin{enumerate}
		\item to obtain accurate results, a rather large band is required close to the interface, which counterbalances the absence of grid nodes far from the interface;
		\item the performances are deteriorated by extrapolation procedures on the outer edges of the local grid \&
		\item the width of the band restricts the time step \& slows down the method.
		\item {\bf Point-based.} {\sc Corbett} in 2005 introduced the point-based level set method. Instead of using a uniform sampling of the level set, the continuous level set function is reconstructed from a set of unorganized point samples via \href{https://en.wikipedia.org/wiki/Moving_least_squares}{moving least squares}.'' -- \href{https://en.wikipedia.org/wiki/Level_set_(data_structures)}{Wikipedia{\tt/}level set (data structures)}
	\end{enumerate}
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}pip (package manager)}
``{\tt pip} (also known by \href{https://en.wikipedia.org/wiki/Python_3}{Python 3}'s alias {\tt pip3}) is a \href{https://en.wikipedia.org/wiki/Package_manager}{package-management system} written in Python \& is used to install \& mange \href{https://en.wikipedia.org/wiki/Package_(package_management_system)}{software packages}. \href{https://en.wikipedia.org/wiki/Python_Software_Foundation}{Python Software Foundation} recommends using pip for installing Python applications \& its dependencies during deployment. Pip connects to an \href{https://en.wikipedia.org/wiki/Software_repository}{online repository} of public packages, called \href{https://en.wikipedia.org/wiki/Python_Package_Index}{Python Package Index}. Pip can be configured to connect to other package repositories (local or remote), provided that they comply to \href{https://en.wikipedia.org/wiki/Python_Enhancement_Proposal}{Python Enhancement Proposal} 503.

Most distributions of Python come with pip preinstalled. Python 2.7.9 \& later (on python2 series), \& Python 3.4 \& later include pip by default.

\subsubsection{History}
1st introduced as {\tt pyinstall} in 2008 by {\sc Ian Bicking} (creator of {\tt virtualenv} package) as an alternative to easy install, pip was chosen as new name from 1 of several suggestions: creator received on his blog post. According to {\sc Bicking} himself, the name is a \href{https://en.wikipedia.org/wiki/Recursive_acronym}{recursive acronym} for ``Pip Installs Packages''. In 2011, Python Packaging Authority (PyPA) was created to take over maintenance of pip \& virtualenv from {\sc Bicking}, led by {\sc Carl Meyer, Brian Rosner, \& Jannis Leidel}.

With release of pip version 6.0 (2014-12-22), the version naming process was changed to have version in X.Y format \& drop preceding 1 from version label.

\subsubsection{Command-line interface}
{\sf An output of {\tt pip install virtualenv}}. Pip's \href{https://en.wikipedia.org/wiki/Command-line_interface}{command-line interface} allows install of Python software packages by issuing a command: {\tt pip install some-package-name}. Users can also remove package by issuing a command: {\tt pip uninstall some-package-name}. pip has a feature to manage full lists of packages \& corresponding version numbers, possible through a ``requirements'' file. This permits efficient re-creation of an entire group of packages in a separate environment (e.g. another computer) or \href{https://en.wikipedia.org/wiki/Virtualization}{virtual environment}. This can be achieved with a properly formatted file \& following command, where {\tt requirements.txt} is name of file: {\tt pip install -r requirements.txt}.

To install some package for a specific python version, pip provides following command, where \verb|${version}| is replaced by 2, 3, 3.4, etc.: \verb|pip${version} install some-package-name|.

\begin{itemize}
	\item {\sf Using {\tt setup.py}.} Pip provides a way to install user-defined projects locally with use of {\tt setup.py} file. This method requires python project to have following {\sf file structure}.
	
	Within this structure, user can add {\tt setup.py} to root of project (i.e. \verb|example_project| for above structure) with following content:
	\begin{verbatim}
		from setuptools import setup, find_packages
		
		setup(
		    name='example',  # Name of the package. This will be used, when the project is imported as a package.
		    version='0.1.0',
		    packages=find_packages(include=['exampleproject', 'exampleproject.*'])  # Pip will automatically install the dependencies provided here.
		)
	\end{verbatim}
	After this, pip can install this custom project by running following command, from project root directory: {\tt pip install -e}.
\end{itemize}

\subsubsection{Custom repository}
Besides default PyPI repository, Pip supports custom repositories as well. Such repositories can be located on an HTTP(s) URL or on a file system location. A custom repository can be specified using the {\tt-i} or {\tt--index-url} option, like so:
\begin{verbatim}
	pip install -i https://your-custom-repo/simple <package name>
\end{verbatim}
or with a filesystem: \verb|pip install -i /path/to/your/custom-repo/simple <package name>|.'' -- \href{https://en.wikipedia.org/wiki/Pip_(package_manager)}{Wikipedia{\tt/}pip (package manager)}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}