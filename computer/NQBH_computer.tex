\documentclass{article}
\usepackage[backend=biber,natbib=true,style=alphabetic,maxbibnames=50]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[utf8]{vietnam}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,enumitem,float,graphicx,mathtools,tikz}
\usetikzlibrary{angles,calc,intersections,matrix,patterns,quotes,shadings}
\allowdisplaybreaks
\newtheorem{assumption}{Assumption}
\newtheorem{baitoan}{}
\newtheorem{cauhoi}{Câu hỏi}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{dangtoan}{Dạng toán}
\newtheorem{definition}{Definition}
\newtheorem{dinhly}{Định lý}
\newtheorem{dinhnghia}{Định nghĩa}
\newtheorem{example}{Example}
\newtheorem{ghichu}{Ghi chú}
\newtheorem{hequa}{Hệ quả}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{lemma}{Lemma}
\newtheorem{luuy}{Lưu ý}
\newtheorem{nhanxet}{Nhận xét}
\newtheorem{notation}{Notation}
\newtheorem{note}{Note}
\newtheorem{principle}{Principle}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{question}{Question}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{vidu}{Ví dụ}
\usepackage[left=1cm,right=1cm,top=5mm,bottom=5mm,footskip=4mm]{geometry}
\def\labelitemii{$\circ$}
\DeclareRobustCommand{\divby}{%
	\mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\title{Computer -- Máy Tính}
\author{Nguyễn Quản Bá Hồng\footnote{A Scientist {\it\&} Creative Artist Wannabe. E-mail: {\tt nguyenquanbahong@gmail.com}. Bến Tre City, Việt Nam.}}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
	This text is a part of the series {\it Some Topics in Advanced STEM \& Beyond}:
	
	{\sc url}: \url{https://nqbh.github.io/advanced_STEM/}.
	
	Latest version:
	\begin{itemize}
		\item {\it Computer -- Máy Tính}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/computer/NQBH_computer.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/computer/NQBH_computer.tex}.
	\end{itemize}
\end{abstract}
\tableofcontents

%------------------------------------------------------------------------------%

\section{Algorithms}

\subsection{\cite{Cormen_Leiserson_Rivest_Stein_algorithm}. Introduction to Algorithms. 4e}
{\sf[630 Amazon ratings][9071 Goodreads ratings]}
\begin{itemize}
	\item {\sf Amazon review.} ``A comprehensive update of the leading algorithms text, with new material on matchings in bipartite graphs, online algorithms, ML, \& other topics. Some books on algorithms are rigorous but incomplete; others cover masses of material but lack rigor. {\it Introduction to Algorithms} uniquely combines rigor \& comprehensiveness. It covers a broad range of algorithms in depth, yet makes their design \& analysis accessible to all levels of readers, with self-contained chapters \& algorithms in pseudocode. Since the publication of 1e, {\it Introduction to Algorithms} has become the leading algorithms text in universities worldwide as well as the standard reference for professionals. This 4e has been updated throughout. New for 4e:
	\begin{itemize}
		\item New chapters on matching in bipartite graphs, online algorithms, \& ML
		\item New material on topics including solving recurrence equations, hash tables, potential functions, \& suffix arrays
		\item 140 new exercises \& 22 new problems
		\item Reader feedback-informed improvements to odd problems
		\item Clearer, more personal, \& gender-neutral writing style
		\item Color added to improve visual presentation
		\item Notes, bibliography, \& index updated to reflect developments in the field
		\item Website with new supplementary material
	\end{itemize}
	This book is a comprehensive update of the leading algorithms text, covering a broad range of algorithms in depth, yet making their design \& analysis accessible to all levels of readers, with self-contained chapters \& algorithms in pseudocode.''
	\begin{itemize}
		\item ``A data structure is a way to store \& organize data in order to facilitate access \& modifications.''
		\item ``Machine learning can be thought of as a method for performing algorithmic tasks without explicitly designing an algorithm, but instead inferring patterns from data \& thereby automatically learning a solution.''
		\item ``The running time of an algorithm on a particular input is the number of instructions \& data accesses executed.''
	\end{itemize}
	{\sf About Author.} {\sc Thomas H. Cormen} is Emeritus Professor of Computer Science at Dartmouth College. {\sc Charles E. Leiserson} is Edwin Sibley Webster Professor in Electrical Engineering \& Computer Science at MIT. {\sc Ronald L. Rivest} is Institute Professor at MIT. {\sc Clifford Stein} is Wai T. Chang Professor of Industrial Engineering \& Operations Research, \& of Computer Science at Columbia University.
	\item {\sf Preface.} Not so long ago, anyone who had heard word ``algorithm'' has almost certainly a computer scientist or mathematician. With computers having become prevalent in our modern lives, however, term is no longer esoteric (bí truyền). If look around home, find algorithms running in most mundane (tầm thường) places: microwave oven, washing machine, \&, of course, computer. Ask algorithms to make recommendations to you: what music might like or what route to take when driving. Our society, for better or for worse, asks algorithms to suggest sentences for convicted criminals. Even rely on algorithms to keep you alive, or at least not to kill you: control systems in car or in medical equipment [To understand many of ways in which algorithms influence our daily lives, see book by {\sc Fry} [162].]. Word ``algorithm'' appears somewhere in news seemingly every day.
	
	Therefore, it behooves you to understand algorithms not just as a student or practitioner of computer science, but as a citizen of world. Once understand algorithms, can educate others about what algorithms are, how they operate, \& what their limitations are.
	
	This book provides a comprehensive introduction to modern study of computer algorithms. It presents many algorithms \& covers them in considerable depth, yet makes their design accessible to all levels of readers. All analyses are laid out, some simple, some more involved. Have tried to keep explanations clear without sacrificing depth of coverage or mathematical rigor.
	
	Each chap presents an algorithm, a design technique, an application area, or a related topic. Algorithms are described in English \& in a pseudocode designed to be readable by anyone who has done a little programming. Book contains 231 figures -- many with multiple parts -- illustrating how algorithms work. Since emphasize {\it efficiency} as a design criterion, include careful analyses of running times of algorithms.
	
	Text is intended primarily for use in undergraduate or graduate courses in algorithms or data structures. Because it discusses engineering issues in algorithm design, as well as mathematical aspects, it is equally well suited for self-study by technical professionals.
	
	In this, 4e, have once again updated entire book. Changes cover a broad spectrum, including new chaps \& sects, color illustrations, \& what hope you'll find to be a more engaging writing style.
	\begin{itemize}
		\item {\sf To teacher.} Have designed this book to be both versatile \& complete. Should find it useful for a variety of courses, from an undergraduate course in data structures up through a graduate course in algorithms. Because have provided considerably more material than can fit in a typical 1-term course, can select material that best supports course wish to teach.
		
		Should find it easy to organize your course around just chaps you need. Have made chaps relatively self-contained, so that you need not worry about an unexpected \& unnecessary dependence of 1 chap on another. Whereas in an undergraduate course, might use only some secs from a chap, in a graduate course, might cover entire chap.
		
		Have included 931 exercises \& 162 problems. Each sect ends with exercises, \& each chap ends with problems. Exercises are generally short questions that test basic mastery of material. Some are simple self-check thought exercises, but many are substantial \& suitable as assigned homework. Problems include more elaborate case studies which often introduce new material. They often consist of several parts that lead student through steps required to arrive at a solution.
		
		As with 3e of this book, have made publicly available solutions to some, but by no means all, of problems \& exercises. Can find these solutions on our website, \url{http://mitpress.mit.edu/algorithms/}. Want to check this site to see whether it contains solution to an exercise or problem that you plan to assign. Since set of solutions that post might grow over time, recommend: check site each time teach course.
		
		Have starred sects \& exercises that are more suitable for graduate students than for undergraduates. A starred sect is not necessarily more difficult than an unstarred one, but it may require an understanding of more advanced mathematics. Likewise, starred exercises may require an advanced background or more than average creativity.
		\item {\sf To student.} Hope: this textbook provides you with an enjoyable introduction to field of algorithms. Have attempted to make every algorithm accessible \& interesting. To help you when encounter unfamiliar or difficult algorithms, describe each one in a step-by-step manner. Also provide careful explanations of mathematics needed to understand analysis of algorithms \& supporting figures to help visualize what is going on.
		
		Since this book is large, your class will probably cover only a portion of its material. Although hope: will find this book helpful to you as a course textbook now, have also tried to make it comprehensive enough to warrant space on your future professional bookshelf.
		
		What are prerequisites for reading this book?
		\begin{itemize}
			\item Need some programming experience. In particular, should understand recursive procedures \& simple data structures, e.g. arrays \& linked lists (although Sect. 10.2 covers linked lists \& a variant that you may find new).
			\item You should have some facility with mathematical proofs, \& especially proofs by mathematical induction. A few portions of book rely on some knowledge of elementary calculus. Although this book uses mathematics throughout, Part I \& Appendices A--D teach you all mathematical techniques you will need.
		\end{itemize}
		Website \url{http://mitpress.mit.edu/algorithms/}, links to solutions for some of problems \& exercises. Feel free to check your solutions against ours.		
		\item {\sf To the professional.} Wide range of topics in this book makes it an excellent handbook on algorithms. Because each chap is relatively self-contained, can focus on topics most relevant to you.
		
		Since most of algorithms discuss have great practical utility, address implementation concerns \& other engineering issues. Often provide practical alternatives to few algorithms that are primarily of theoretical interest.
		
		If wish to implement any of algorithms, should find translation of our pseudocode into your favorite programming language to be a fairly straightforward task. Have designed pseudocode to present each algorithm clearly \& succinctly. Consequently, do not address error handling \& other software-engineering issues that require specific assumptions about your programming environment. Attempt to present each algorithm simply \& directly without allowing idiosyncrasies of a particular programming language to obscure its essence. If used to 0-origin arrays, might find our frequent practice of indexing arrays from 1 a minor stumbling block. Can always either subtract 1 from our indices or just overallocate array \& leave position 0 unused.
		
		Understand: if using this book outside of a course, then might be unable to check your solutions to problems \& exercises against solutions provided by an instructor. Website \url{http://mitpress.mit.edu/algorithms/}, links to solutions for some of problems \& exercises so that can check work.
		\item {\sf To colleagues.} Have supplied an extensive bibliography \& pointers to current literature. Each chap ends with a set of chap notes that give historical details \& references. Chap notes do not provide a complete reference to whole field of algorithms, however. Though it may be hard to believe for a book of this size, space constraints prevented us from including many interesting algorithms.
		
		Despite myriad requests from students for solutions to problems \& exercises, have adopted policy of not citing references for them, removing temptation for students to look up a solution rather than to discover it themselves.
		\item {\sf Changes for 4e.} As said about changes for 2e \& 3e, depending on how you look at it, book changed either not much or quite a bit. A quick look at table of contents shows: most of 3e chaps \& sects appear in 4e. Removed 3 chaps \& several sects, but have added 3 new chaps \& several new sects apart from these new chaps.
		
		Kept hybrid organization (tổ chức hỗn hợp) from 1st 3 editions. Rather than organizing chaps only by problem domains or only according to techniques, this book incorporates elements of both. It contains technique-based chaps on divide-\&-conquer, dynamic programming, greedy algorithms, amortized analysis, augmenting data structures, NP-completeness, \& approximation algorithms. But it also has entire parts on sorting, on data structures for dynamic sets, \& on algorithms for graph problems. Find: although need to know how to apply techniques for designing \& analyzing algorithms, problems seldom announce to you which techniques are most amenable to solving them.
		
		Some of changes in 4e apply generally across book, \& some are specific to particular chaps or sects. Here is a summary of most significant general changes:
		\begin{itemize}
			\item Added 140 new exercises \& 22 new problems. Also improved many of old exercises \& problems, often as result of reader feedback. (Thanks to all readers who made suggestions.)
			\item Have color! With designers from MIT Press, selected a limited palette, devised to convey information \& to be pleasing to eye. (Delighted to display red-black trees in -- get this -- red \& black!) To enhance readability, defined terms, pseudocode comments, \& page numbers in index are in color.
			\item Pseudocode procedures appear on a tan background to make them easier to spot, \& they do not necessarily appear on page of their 1st ref. When they don't, text directs you to relevant page. In same vein, nonlocal refs to numbers equations, theorems, lemmas, \& corollaries include page number.
			\item Removed topics that were rarely taught. Dropped in their entirety chaps on Fibonacci heaps, van Emde Boas trees, \& computational geometry. In addition, following material was excised (vật liệu đã được cắt bỏ): maximum-subarray problem, implementing pointers \& objects, perfect hashing, randomly built binary search trees, matroids, push-relabel algorithms for maximum flow, iterative fast Fourier transform method, details of simplex algorithm for linear programming, \& integer factorization. Can find all removed material on website \url{http://mitpress.mit.edu/algorithms/}.
			\item Reviewed entire book \& rewrote sentences, paragraphs, \& sects to make writing cleaner, more personal, \& gender neural. E.g., ``traveling-salesman problem'' in prev editions is now called ``traveling-salesperson problem.'' Believe: critically important for engineering \& science, including our own field of CS, to be welcoming to everyone. (The 1 place that stumped us is in Chap. 13, which requires a term for a parent's sibling. Because English language has no such gender-neural term, regretfully stuck with ``uncle''.)
			\item Chap notes, bibliography, \& index were updated, reflecting dramatic growth of field of algorithsm since 3e.
			\item Corrected errors, posting most corrections on our website of 3e errata. Those what were reported while were in full swing preparing this edition were not posted, but were corrected in this edition. (Thanks again to all readers who helped us identify issues.)
		\end{itemize}
		Specific changes for 4e include following:
		\begin{itemize}
			\item Renamed Chap. 3 \& added a sect giving an overview of asymptotic notation before delving into formal defs.
			\item Chap. 4 underwent substantial changes to improve its mathematical foundation \& make it more robust \& intuitive. Notion of an algorithmic recurrence was introduced, \& topic of ignoring floors \& ceilings in recurrences was addressed more rigorously. 2nd case of master theorem incorporates polylogarithmic factors, \& a rigorous proof of a ``continuous'' version of master theorem is now provided. Also present powerful \& general Akra-Bazzi methodd (without proof).
			\item Deterministic order-statistic algorithm in Chap. 9 is slightly different, \& analyses of both randomized \& deterministic order-statistic algorithms have been revamped.
			\item In addition to stacks \& queues, Sect. 10.1 discusses ways to store arrays \& matrices.
			\item Chap. 11 on hash tables includes a modern treatment of hash functions. Also emphasize linear probing as an efficient method for resolving collisions when underlying hardware implements caching to favor local searches.
			\item To replace sects on matroids in Chap. 15, converted a problem in 3e about offline caching into a full sect.
			\item Sect. 16.4 now contains a more intuitive explanation of potential functions to analyze table doubling \& halving.
			\item Chap. 17 on augmenting data structures was relocated from Part III to Part V, reflecting our view: this techniques goes beyond basic material.
			\item Chap. 25 is a new chap about matchings in bipartite graphs. It presents algorithms to find a matching of maximum cardinality, to solve stable-marriage problem, \& to find a maximum-weight matching (known as ``assignment problem'').
			\item Chap. 26, on task-parallel computing, has been updated with modern terminology, including name of chap.
			\item Chap. 27, which covers online algorithms, is another new chap. In an online algorithm, input arrives over time, rather than being available in its entirety at start of algorithm. Chap describes several examples of online algorithms, including determining how long to wait for an elevator before taking stairs, maintaining a linked list via move-to-front heuristic, \& evaluating replacement policies for caches.
			\item In Chap. 29, removed detailed representation of simplex algorithm, as it was math heavy without really conveying many algorithmic ideas. Chap now focuses on key aspect of how to model problems as linear programs, along with essential duality property of linear programming.
			\item Sect. 32.5 adds to chap on string matching simple, yet powerful, structure of suffix arrays.
			\item Chap. 33, on ML, is 3rd new chap. Introduce several basic methods used in ML: clustering to group similar items together, weighted-majority algorithms, \& gradient descent to find minimizer of a function.
			\item Sect. 34.5.6 summarizes strategies for polynomial-time reductions to show: problems are NP-hard.
			\item Proof of approximation algorithm for set-covering problem in Sect. 35.3 has been revised.
		\end{itemize}
		\item {\sf Website.} Can use website \url{http://mitpress.mit.edu/algorithms/}, to obtain supplementary information \& to communicate with us. Website links to a list of known errors, material from 3e that is not included in 4e, solutions to selected exercises \& problems, Python implementations of many of algorithms in this book, a list explaining corny professor jokes (of course), as well as other content, which may add to. Website also tells how to report errors or make suggestions.
	\end{itemize}
	\item {\sf I. FOUNDATIONS.}
	\begin{itemize}
		\item {\sf Introduction.} When design \& analyze algorithms, need to be able to describe how they operate \& how to design them. Also need some mathematical tools to show: your algorithms do right thing \& do it efficiently. This part will get you started. Later parts of this book will build upon this base.
		\begin{enumerate}
			\item Chap. 1 provides an overview of algorithms \& their place in modern computing systems. This chap defines what an algorithm is \& lists some examples. It also makes a case for considering algorithms as a technology, alongside technologies e.g. fast hardware, graphical user interfaces, object-oriented systems, \& networks.
			\item Chap. 2, see 1st algorithms, which solve problem of sorting a sequence of $n$ numbers. They are written in a pseudocode which, although not directly translatable to any conventional programming language, conveys structure of algorithm clearly enough that you should be able to implement it in language of your choice. Sorting algorithms examined are insertion sort, which uses an incremental approach, \& merge sort, which uses a recursive technique known as ``divide-\&-conquer.'' Although time each requires increases with value of $n$, rate of increase differs between 2 algorithms. Determine these running times in Chap. 2 \& develop a useful ``asymptotic'' notation to express them.
			\item Chap. 3 precisely defines asymptotic notation. Use asymptotic notation to bound growth of functions -- most often, functions that describe running time of algorithms -- from above \& below. Chap starts by informally defining most commonly used asymptotic notations \& giving an example of how to apply them. It then formally defines 5 asymptotic notations \& presents conventions for how to put them together. Rest of Chap. 3 is primarily a presentation of mathematical notation, more to ensure your use of notation matches that in this book than to teach new mathematical concepts.
			\item Chap. 4 delves further into divide-\&-conquer method introduced in Chap. 2. It provides 2 additional examples of divide-\&-conquer algorithms for multiplying square matrices, including Strassen's surprising method. Chap. 4 contains methods for solving recurrences, which are useful for describing running times of recursive algorithms. In substitution method, guess an answer \& prove it correct. Recursion trees provide 1 way to generate a guess. Chap. 4 also presents powerful technique of ``master method'', which can often use to solve recurrences that arise from divide-\&-conquer algorithms. Although chap provides a proof of a foundational theorem on which master theorem depends, should feel free to employ master method without delving into proof. Chap. 4 concludes with some advanced topics.
			\item Chap. 5 introduces probabilistic analysis \& randomized algorithms. Typically use probabilistic analysis to determine running time of an algorithm in cases in which, due to presence of an inherent probability distribution, running time may differ on different inputs of same size. In some cases, might assume: inputs conform to a known probability distribution, so that you are averaging running time over all possible inputs. In other cases, probability distribution comes not from inputs but from random choices made during course of algorithm. An algorithm whose behavior is determined not only by its input but by values produced by a random-number generator is a randomized algorithm. Can use randomized algorithms to enforce a probability distribution on inputs -- thereby ensuring: no particular input always causes poor performance -- or even to bound error rate of algorithms that are allowed to produce incorrect results on a limited basis.
			\item Appendices A--D contain other mathematical material that you will find helpful as read this book. Might have seen much of material in appendix chaps before having read this book (although specific defs \& notational conventions use may differ in some cases from what you have seen in past), \& so you should think of appendices as reference material. On other hand, probably have not already seen most of material in Part I. All chaps in Part I \& appendices are written with a tutorial flavor.
		\end{enumerate}		
		\item {\sf1. Role of Algorithms in Computing.} What are algorithms? Why is study of algorithms worthwhile? What is role of algorithms relative to other technologies used in computers? This chap will answer these questions.
		\begin{itemize}
			\item {\sf1.1. Algorithms.} Informally, an {\it algorithm} is any well-defined computational procedure that takes some value, or set of values, as input \& produces some value, or set of values, as output in a finite amount of time. An algorithm is thus a sequence of computational steps that transform input into output.
			
			p. 28
		\end{itemize}
		\item {\sf2. Getting Started.}
		\item {\sf3. Characterizing Running Times.}
		\item {\sf4. Divide-\&-Conquer.}
		\item {\sf5. Probabilistic Analysis \& Randomized Algorithms.}
	\end{itemize}
	\item {\sf II. SORTING \& ORDER STATISTICS.}
	\begin{itemize}
		\item {\sf Introduction.}
		\item {\sf6. Heapsort.}
		\item {\sf7. Quicksort.}
		\item {\sf8. Sorting in Linear Time.}
		\item {\sf9. Medians \& Other Statistics.}
	\end{itemize}
	\item {\sf III. DATA STRUCTURES.}
	\begin{itemize}
		\item {\sf Introduction.}
		\item {\sf10. Elementary Data Structures.}
		\item {\sf11. Hash Tables.}
		\item {\sf12. Binary Search Trees.}
		\item {\sf13. Red-Black Trees.}
	\end{itemize}
	\item {\sf IV. ADVANCED DESIGN \& ANALYSIS TECHNIQUES.}
	\begin{itemize}
		\item {\sf Introduction.} This part covers 3 important techniques used in designing \& analyzing efficient algorithms: dynamic programming (Chap. 14), greedy algorithms (Chap. 15), \& amortized analysis (Chap. 16). Earlier parts have presented other widely applicable techniques, e.g. divide-\&-conquer, randomization, \& how to solve recurrences. Techniques in this part are somewhat more sophisticated, but will be able to use them solve many computational problems. Themes introduced in this part will recur later in this book.
		
		Dynamic programming typically applies to optimization problems in which make a set of choices in order to arrive at an optimal solution, each choice generates subproblems of same form as original problem, \& same subproblems arise repeatedly. Key strategy: store solution to each such subproblem rather than recompute it. Chap. 14 shows how this simple idea can sometimes transform exponential-time algorithms into polynomial-time algorithms.
		
		Like dynamic-programming algorithms, greedy algorithms typically apply to optimization problems in which you make a set of choices in order to arrive at an optimal solution. Idea of a greedy algorithm: make each choice in a locally optimal manner, resulting in a faster algorithm than you get with dynamic programming. Chap. 15 will help you determine when greedy approach works.
		
		Technique of amortized analysis (phân tích khấu hao) applies to certain algorithms that perform a sequence of similar operations. Instead of bounding cost of sequence of operations by bounding actual cost of each operation separately, an amortized analysis provides a worst-case bound on actual cost of entire sequence. 1 advantage of this approach: although some operations might be expensive, many others might be cheap. Can use amortized analysis when designing algorithms, since design of an algorithm \& analysis of running time are often closely intertwined. Chap. 16 introduces 3 ways to perform an amortized analysis of an algorithm.
		\item {\sf14. Dynamic Programming.} Dynamic programming, like divide-\&-conquer method, solves problems by combining solutions to subproblems. (``Programming'' in this context refers to a tabular method, not to writing computer code.) As saw in Chaps. 2 \& 4, divide-\&-conquer algorithms partition problem into disjoint subproblems, solve subproblems recursively, \& then combine their solutions to solve original problem. In contrast, dynamic programming applies when subproblems overlap -- i.e., when subproblems share subsubproblems. In this context, a divide-\&-conquer algorithm does more work than necessary, repeatedly solving common subsubproblems. A dynamic-programming algorithm solves each subsubproblem just once \& then saves its answer in a table, thereby avoiding work of recomputing answer every time it solves each subsubproblem.
		
		Dynamic programming typically applies to {\it optimization problems}. Such problems can have many possible solutions. Each solution has a value, \& want to find a solution with optimal (minimum or maximum) value. Call such a solution {\it an} optimal solution to problem, as opposed to {\it the} optimal solution, since there may be several solutions that achieve optimal value.
		
		To develop a dynamic-programming algorithm, follow a sequence of 4 steps:
		\begin{enumerate}
			\item Characterize structure of an optimal solution.
			\item Recursively define value of an optimal solution.
			\item Compute value of an optimal solution, typically in a bottom-up fashion.
			\item Construct an optimal solution from computed information.
		\end{enumerate}
		Steps 1--3 form basis of a dynamic-programming solution to a problem. If need only value of an optimal solution, \& not solution itself, then can omit step 4. When do perform step 4, it often pays to maintain additional information during step 3 so that can easily construct an optimal solution.
		
		Sects that follow use dynamic-programming method to solve some optimization problems. Sects. 14.1 examines problem of cutting a rod into rods of smaller length in a way that maximizes their total value. Sect. 14.2 shows how to multiply a chain of matrices while performing fewest total scalar multiplications. Given these examples of dynamic programming, Sect. 14.3 discusses 2 key characteristics that a problem must have for dynamic programming to be a viable solution technique. Sect. 14.4 then shows how to find longest common subsequence of 2 sequences via dynamic programming. Finally, Sect. 14.5 uses dynamic programming to construct binary search trees that are optimal, given a known distribution of keys to be looked up.
		\begin{itemize}
			\item {\sf14.1. Rod cutting.} 1st example uses dynamic programming to solve a simple problem in deciding where to cut steel rods. Serling Enterprises buys long steel rods \& cuts them into shorter rods, which it then sells. Each cut is free. Management of Serling Enterprises wants to know best way to cut up rods.
			
			Serling Enterprises has a table giving, for $i = 1,2,\ldots$, price $p_i$ in dollars that they charge for a rod of length $i$ inches. Length of each rod in inches is always an integer. {\sf Fig. 14.1: A sample price table for rods. Each rod of length $i$ inches earns company $p_i$ dollars of revenue.} gives a sample price table.
			
			{\it Rod-cutting problem} is following. Given a rod of length $n$ inches \& a table of prices $p_i$ for $i = 1,\ldots,n$, determine maximum revenue $r_n$ obtainable by cutting up rod \& selling pieces. If price $p_n$ for a rod of length $n$ is large enough, an optimal solution might require no cutting at all.
			
			Consider case when $n = 4$. {\sf Fig. 14.2: 8 possible ways of cutting a rod of length 4. Above each piece is value of that piece, according to sample price chart of Fig. 14.1. Optimal strategy is part (c) -- cutting rod into 2 pieces of length 2 -- which has total value 10.} shows all ways to cut up a rod of 4 inches in length, including way with no cuts at all. Cutting a 4-inch rod into 2 2-inch pieces produces revenue $p_2 + p_2 = 5 + 5 = 10$, which is optimal.
			
			Serling Enterprises can cut up a rod of length $n$ in $2^{n-1}$ different ways, since they have an independent option of cutting, or not cutting, at distance $i$ inches from left end, for $i = 1,\ldots,n-1$ [If pieces are required to be cut in order of monotonically increasing size, there are fewer ways to consider. For $n = 4$, only 5 such ways are possible: Number of ways is called {\it partition function}, which is approximately equal to $\dfrac{e^{\pi\sqrt{\frac{2n}{3}}}}{4n\sqrt{3}}$. This quantity is $< 2^{n-1}$, but still much greater than any polynomial in $n$. Won't pursue this line of inquiry further, however.] Denote a decomposition into pieces using ordinary additive notation, so that $7 = 2 + 2 + 3$ indicates: a rod of length $7$ is cut into 3 pieces -- 2 of length 2 \& 1 of length 3. If an optimal solution cuts rod into $k$ pieces, for some $1\le k\le n$, then an optimal decomposition $n = \sum_{j=1}^k i_j$ of rod into pieces of lengths $i_1,\ldots,i_k$ provides maximum corresponding revenue $r_n = \sum_{j=1}^k p_{i_j}$.
			
			For sample problem in {\sf Fig. 14.1}, can determine optimal revenue figures $r_i$, for $i = 1,\ldots,10$, by inspection, with corresponding optimal decompositions [value of $r_1,\ldots,r_{10}$].
			
			More generally, can express values $r_n$ for $n\ge1$ in terms of optimal revenues from shorter rods: (14.1)
			\begin{equation*}
				r_n = \max\{p_n,r_1 + r_{n-1},r_2 + r_{n-2},\ldots,r_{n-1} + r_1\}.
			\end{equation*}
			1st argument $p_n$ corresponds to making no cuts at all \& selling rod of length $n$ as is. Other $n - 1$ arguments to max correspond to maximum revenue obtained by making an initial cut of rod into 2 pieces of size $i,n-i$, for each $i = 1,\ldots,n - 1$, \& then optimally cutting up those pieces further, obtaining revenues $r_i,r_{n-i}$ from those 2 pieces. Since don't know ahead of time which value of $i$ optimizes revenue, have to consider all possible values for $i$ \& pick the one that maximizes revenue. Also have option of picking no $i$ at all if greatest revenue comes from selling rod uncut.
			
			To solve original problem of size $n$, solve smaller problems of same type. Once make 1st cut, 2 resulting pieces form independent instances of rod-cutting problem. Overall optimal solution incorporates optimal solutions to 2 resulting subproblems, maximizing revenue from each of those 2 pieces. Say: rod-cutting problem exhibits {\it optimal substructure}: optimal solutions to a problem incorporate optimal solutions to related subproblems, which you may solve independently.
			
			In a related, but slightly simpler, way to arrange a recursive structure for rod-cutting problem, view a decomposition as consisting of a 1st piece of length $i$ cut off left-hand end, \& then a right-hand remainder of length $n - i$. Only remainder, \& not 1st piece, may be further divided. Think of every decomposition of a length-$n$ rod in this way: as a 1st piece followed by some decomposition of remainder. Then can express solution with no cuts at all by saying: 1st piece has size $i = n$ \& revenue $p_n$ \& remainder has size 0 with corresponding revenue $r_0 = 0$. Thus obtain following simpler version of equation (14.1): (14.2)
			\begin{equation*}
				r_n = \max\{p_i + r_{n_i}:1\le i\le n\}.
			\end{equation*}
			In this formulation, an optimal solution embodies solution to only {\it1} related subproblem -- remainder -- rather than 2.
			\begin{itemize}
				\item {\bf Recursive top-down implementation.} CUT-ROD procedure implements computation implicit in (14.2) in a straightforward, top-down, recursive manner. It takes as input an array $p[1:n]$ of prices \& an integer $n$, \& it returns maximum revenue possible for a rod of length $n$. For length $n = 0$, no revenue is possible, \& so CUT-ROD returns 0 in line 2. Line 3 initializes maximum revenue $q$ to $-\infty$, so that {\tt for} loop in lines 4--5 correctly computes $q = \max\{p_i + CUT-ROD(p,n - i):1\le i\le n\}$. Line 6 then returns this value. A simple induction on $n$ proves: this answer $=$ desired answer $r_n$ using (14.2). {\tt[CUT-ROD$(p,n)$ algorithm]}.
				
				If code up CUT-ROD in favorite programming language \& run it on your computer, find: once input size becomes moderately large, your program takes a long time to run. For $n = 40$, your program may take several minutes \& possibly $> 1$ hour. For large values of $n$, also discover: each time increase $n$ by 1, your program's running time approximately doubles.
				
				Why is CUT-ROD so inefficient? Problem: CUT-ROD calls itself recursively over \& over again with same parameter values, i.e., it solves same subproblems repeatedly. {\sf Fig. 14.3: Recursion tree showing recursive calls resulting from a call CUT-ROD$(p,n)$ for $n = 4$. Each node label gives size $n$ of corresponding subproblem, so that an edge from a parent with label $s$ to a child with label $t$ corresponds to cutting off an initial piece of size $s - t$ \& leaving a remaining subproblem of size $t$. A path from root to a leaf corresponds to 1 of $2^{n-1}$ ways of cutting up a rod of length $n$. In general, this recursion tree has $2^n$ nodes \& $2^{n-1}$ leaves.} shows a recursion tree demonstrating what happens for $n = 4$: CUT-ROD$(p,n)$ calls CUT-ROD$(p,n - i)$ for $i = 1,\ldots,n$. Equivalently, CUT-ROD$(p,n)$ calls CUT-ROD$(p,j)$ for each $j = 0,1,\ldots,n - 1$. When this process unfolds recursively, amount of work done, as a function of $n$, grows explosively.
				
				To analyze running time of CUT-ROD, let $T(n)$ denote total number of calls made to CUT-ROD$(p,n)$ for a particular value of $n$. This expression equals number of nodes in a subtree whose root is labeled $n$ in recursion tree. Count includes initial call at its root. Thus, $T(0) = 1$ \& (14.3)
				\begin{equation*}
					T(n) = 1 + \sum_{j=0}^{n-1} T(j).
				\end{equation*}
				Initial 1 is for call at root, \& term $T(j)$ counts number of calls (including recursive calls) due to call CUT-ROD$(p,n - i)$, where $j = n - i$. Exercise 14.1-1: $T(n) = 2^n$ \& so running time of CUT-ROD is exponential in $n$.
				
				In retrospect, this exponential running time is not so surprising. CUT-ROD explicitly considers all possible ways of cutting up a rod of length $n$. How many ways are there? A rod of length $n$ has $n - 1$ potential locations to cut. Each possible way to cut up rod makes a cut at some subset of these $n - 1$ locations, including empty set, which makes for no cuts. Viewing each cut location as a distinct member of a set of $n - 1$ elements, can see: there are $2^{n-1}$ subsets. Each leaf in recursion tree of {\sf Fig. 14.3} corresponds to 1 possible way to cut up rod. Hence, recursion tree has $2^{n-1}$ leaves. Labels on simple path from root to a leaf give sizes of each remaining right-hand piece before making each cut. I.e., labels give corresponding cut points, measured from right-hand end of rod.
				\item {\bf Using dynamic programming for optimal rod cutting.}
			\end{itemize}
		\end{itemize}
		\item {\sf15. Greedy Algorithms.}
		\item {\sf16. Amortized Analysis.}
	\end{itemize}
	\item {\sf V. ADVANCED DATA STRUCTURES.}
	\begin{itemize}
		\item {\sf Introduction.}
		\item {\sf17. Augmenting Data Structures.}
		\item {\sf18. B-Trees.}
		\item {\sf19. Data Structures for Disjoint Sets.}
	\end{itemize}
	\item {\sf VI. GRAPH ALGORITHMS.}
	\begin{itemize}
		\item {\sf Introduction.}
		\item {\sf20. Elementary Graph Algorithms.}
		\item {\sf21. Minimum Spanning Trees.}
		\item {\sf22. Single-Source Shortest Paths.}
		\item {\sf23. All-Pairs Shortest Paths.}
		\item {\sf24. Maximum Flow.}
		\item {\sf25. Matching in Bipartite Graphs.}
	\end{itemize}
	\item {\sf VII. SELECTED TOPICS.}
	\begin{itemize}
		\item {\sf Introduction.}
		\item {\sf26. Parallel Algorithms.}
		\item {\sf27. Online Algorithms.}
		\item {\sf28. Matrix Operations.}
		\item {\sf29. Linear Programming.}
		\item {\sf30. Polynomials \& FFT.}
		\item {\sf31. Number-Theoretic Algorithms.}
		\item {\sf32. String Matching.}
		\item {\sf33. Machine-Learning Algorithms.}
		\item {\sf34. NP-Completeness.}
		\item {\sf35. Approximation Algorithms.}
	\end{itemize}
	\item {\sf VIII. APPENDIX: MATHEMATICAL BACKGROUND.}
	\begin{itemize}
		\item {\sf Introduction.}
		\item {\sf A. Summations.}
		\item {\sf B. Sets, etc.}
		\item {\sf C. Counting \& Probability.}
		\item {\sf D. Matrices.}
	\end{itemize}
\end{itemize}

%------------------------------------------------------------------------------%

\section{{\sc Donald Knuth}. The Art of Computer Programming. Volume 1: Fundamental Algorithms}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Knuth1997}. {\sc Donald Knuth}. {\it The Art of Computer Programming. Volume 1: Fundamental Algorithms}.
	
	Với bản dịch tiếng Việt chứa nhiều lỗi chính tả đến mức đáng bị cảnh sát ghé thăm:
	\item \cite{Khoa_art_programming}. {\sc Nguyễn Văn Khoa}. {\it Nghệ Thuật Lập Trình Máy Tính}.
\end{enumerate}
This series of books is affectionately dedicated to the Type 650 computer once installed at Case Institute of Technology, in remembrance of many pleasant evenings.

The author \& publisher have taken care in the preparation of this book, but make no expressed or implied warranty of any kind \& assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.

\subsection{Preface}
{\it``Here is your book, the one your thousands of letters have asked us to publish. It has taken us years to do, checking \& rechecking countless recipes to bring you only the best, only the interesting, only the perfect. Now we can say, without a shadow of a doubt, that every single 1 of them, if you follow the directions to the letter, will work for you exactly as well as it did for us, even if you have never cooked before.''} -- {\sc McCall}'s Cookbook (1963)

``The process of preparing programs for a digital computer is especially attractive, not only because it can be economically \& scientifically rewarding, but also because it can be an aesthetic experience much like composing poetry or music. This book is the 1st volume of a multi-volume set of books that has been designed to train the reader in various skills that go into a programmer's craft.

The following chapters are {\it not} meant to serve as an introduction to computer programming; the reader is supposed to have had some previous experience. The prerequisites are actually very simple, but a beginner requires time \& practice in order to understand the concept of a digital computer. The reader should
possess:
\begin{enumerate}
	\item Some idea of how a stored-program digital computer works; not necessarily the electronics, rather the manner in which instructions can be kept in the machine's memory \& successively executed.
	\item An ability to put the solutions to problems into such explicit terms that a computer can ``understand'' them. (These machines have no common sense; they do exactly as they are told, no more \& no less. This fact is the hardest concept to grasp when one 1st tries to use a computer.)
	\item Some knowledge of the most elementary computer techniques, e.g. looping (performing a set of instructions repeatedly), the use of subroutines, \& the use of indexed variables.
	\item A little knowledge of common computer jargon -- ``memory,'' ``registers,'' ``bits,'' ``floating point,'' ``overflow,'' ``software.'' Most words not defined in the text are given brief definitions in the index at the close of each volume.
\end{enumerate}
These 4 prerequisites can perhaps be summed up into the single requirement that the reader should have written \& tested at least, say, 4 programs for at least 1 computer.

I have tried to write this set of books in such a way that it will fill several needs. In the 1st place, these books are reference works that summarize the knowledge that has been acquired in several important fields. In the 2nd place, they can be used as textbooks for self-study or for college courses in the computer \& information sciences. To meet both of these objectives, I have incorporated a large number of exercises into the text \& have furnished answers for most of them. I have also made an effort to fill the pages with facts rather than with vague, general commentary.

This set of books is intended for people who will be more than just casually interested in computers, yet it is by no means only for the computer specialist. Indeed, 1 of my main goals has been to make these programming techniques more accessible to the many people working in other fields who can make fruitful use of computers, yet who cannot afford the time to locate all of the necessary information that is buried in technical journals.

We might call the subject of these books \fbox{``nonumerical analysis.''} Computers have traditionally been associated with the solution of numerical problems e.g. calculation of roots of an equation, numerical interpolation \& integration, etc., but such topics are not treated here except in passing. Numerical computer programming is an extremely interesting \& rapidly expanding field, \& many books have been written about it. Since the early 1960s, however, computers have been used even more often for problems in which numbers occur only by coincidence; the computer's decision-making capabilities are being used, rather than its ability to do arithmetic. We have some use for addition \& subtraction in nonnumerical problems, but we rarely feel any need for multiplication \& division. Of course, even a person who is primarily concerned with numerical computer programming will benefit from a study of the nonnumerical techniques, for they are present in the background of numerical programs as well.

The results of research in nonnumerical analysis are scattered throughout numerous technical journals. My approach has been to try to distill this vast literature by studying the techniques that are most basic, in the sense that they can be applied to many types of programming situations. I have attempted to coordinate the ideas into more or less of a ``theory,'' as well as to show how the theory applies to a wide variety of practical problems.

Of course, ``nonnumerical analysis'' is a terribly negative name for this field of study; it is much better to have a positive, descriptive term that characterizes the subject. ``Information processing'' is too broad a designation for the material I am considering, \& ``programming techniques'' is too narrow. Therefore I wish to propose \fbox{\it analysis of algorithms} as an appropriate name for the subject matter covered in these books. This name is meant to imply ``the theory of the properties of particular computer algorithms.''

The complete set of books, entitled {\it The Art of Computer Programming}, has the following general outline:
\begin{enumerate}
	\item {\it Vol. 1: Fundamental Algorithms}. Chap. 1: Basic Concepts. Chap. 2: Information Structures.
	\item {\it Vol. 2: Seminumerical Algorithms}. Chap. 3: Random Numbers. Chap. 4: Arithmetic.
	\item {\it Vol. 3: Sorting \& Searching}. Chap. 5: Sorting. Chap. 6: Searching.
	\item {\it Vol. 4: Combinatorial Algorithms}. Chap. 7: Combinatorial Searching. Chap. 8: Recursion.
	\item {\it Vol. 5: Syntactical Algorithms}. Chap. 9: Lexical Scanning. Chap. 10: Parsing.
\end{enumerate}
Vol. 4 deals with such a large topic, it actually represents several separate books (Vols. 4A, 4B, etc.). 2 additional volumes on more specialized topics are also planned: Vol. 6: {\it The theory of Languages} (Chap. 11)' Vol. 7: {\it Compilers} (Chap. 12).

I started out in 1962 to write a single book with this sequence of chapters, but I soon found that it was more important to treat the subjects in depth rather than to skim over them lightly. The resulting length of the text has meant that each chapter by itself contains more than enough material for a 1-semester college course; so it has become sensible to publish the series in separate volumes. I know that it is strange to have only 1 or 2 chapters in an entire book, but I have decided to retain the original chapter numbering in order to facilitate cross references. A shorter version of Vols. 1--5 is planned, intended specifically to serve as a more general reference \&{\tt/}or text for undergraduate computer courses; its contents will be a subset of the material in these books, with the more specialized information omitted. The same chapter numbering will be used in the abridged edition as in the complete work.

The present volume may be considered as the ``intersection'' of the entire set, in the sense that it contains basic material that is used in all the other books. Vols. 2--5, on the other hand, may be read independently of each other. Vol. 1 is not only a reference book to be used in connection with the remaining volumes; it may also be used in college courses or for self-study as a text on the subject of {\it data structures} (emphasizing the material of Chap. 2), or as a text on the subject of {\it discrete mathematics}, or as a text on the subject of {\it machine-language programming}.

The point of view I have adopted while writing these chapters differs from that taken in most contemporary books about computer programming in that I am not trying to teach the reader how to use somebody else's software. I am concerned rather with teaching people how to write better software themselves.

My original goal was to bring readers to the frontiers of knowledge in every subject that was treated. But it is extremely difficult to keep up with a field that is economically profitable, \& the rapid rise of computer science has made such a dream impossible. The subject has become a vast tapestry\footnote{tấm thảm.} with $a\cdot10^4$ of subtle results contributed by $a\cdot10^4$ of talented people all over the world. Therefore my new goal has been to concentrate on ``classic'' techniques that are likely to remain important for many more decades, \& to describe them as well as I can. In particular, I have tried to trace the history of each subject, \& to provide a solid foundation for future progress. I have attempted to choose terminology that is concise \& consistent with current usage. I have tried to include all of the known ideas about sequential computer programming that are both beautiful \& easy to state.

A few words are in order about the mathematical content of this set of books. The material has been organized so that persons with no more than a knowledge of high-school algebra may read it, skimming briefly over the more mathematical portions; yet a reader who is mathematically inclined will learn about many interesting mathematical techniques related to discrete mathematics. This dual level of presentation has been achieved in part by assigning ratings to each of the exercises so that the primarily mathematical ones are marked specifically as such, \& also by arranging most sections so that the main mathematical results are stated {\it before} their proofs. The proofs are either left as exercises (with answers to be found in a separate section) or they are given at the end of a section.

A reader who is interested primarily in programming rather than in the associated mathematics may stop reading most sections as soon as the mathematics becomes recognizably difficult. On the other hand, a mathematically oriented reader will find a wealth of interesting material collected here. Much of the published mathematics about computer programming has been faulty, \& 1 of the purposes of this book is to instruct readers in proper mathematical approaches to this subject. Since I profess to be a mathematician, it is my duty to \fbox{maintain mathematical integrity} as well as I can.

A knowledge of elementary calculus will suffice for most of the mathematics in these books, since most of the other theory that is needed is developed herein. However, I do need to use deeper theorems of complex variable theory, probability theory, number theory, etc., at times, \& in such cases I refer to appropriate textbooks where those subjects are developed.

The hardest decision that I had to make while preparing these books concerned the manner in which to present the various techniques. The advantages of flow charts \& of an informal step-by-step description of an algorithm are well known; for a discussion of this, see the article ``Computer-Drawn Flowcharts'' in the ACM {\it Communications}, Vol. 6 (Sep. 1963), pp. 555--563. Yet a formal, precise language is also necessary to specify any computer algorithm, \& I needed to decide whether to use an algebraic language, e.g. ALGOL or FORTRAN, or to use a machine-oriented language for this purpose. Perhaps many of today's computer experts will disagree with my decision to use a machine-oriented language, but I have become convinced that it was definitely the correct choice, for the following reasons:
\begin{enumerate}
	\item A programmer is greatly influenced by the language in which programs are written; there is an overwhelming tendency to prefer constructions that are simplest in that language, rather than those that are best for the machine. By understanding a machine-oriented language, the programmer will tend to use a much more efficient method; it is much closer to reality.
	\item The programs we require are, with a few exceptions, all rather short, so with a suitable computer there will be no trouble understanding the programs.
	\item High-level languages are inadequate for discussing important low-level details e.g. coroutine linkage, random number generation, multi-precision arithmetic, \& many problems involving the efficient usage of memory.
	\item A person who is more than casually interested in computers should be well schooled in machine language, since it is a fundamental part of a computer.
	\item Some machine language would be necessary anyway as output of the software programs described in many of the examples.
	\item New algebraic languages go in \& out of fashion every 5 years or so, while I am trying to emphasize concepts that are timeless.
\end{enumerate}
From the other point of view, I admit that it is somewhat easier to write programs in higher-level programming languages, \& it is considerably easier to debug the programs. Indeed, I have rarely used low-level machine language for my own programs since 1970, now that computers are so large \& so fast. Many of the problems of interest to us in this book, however, are those for which the programmer's art is most important. E.g., some combinatorial calculations need to be repeated a trillion times, \& we save about 11.6 days of computation for every microsecond we can squeeze out of their inner loop. Similarly, it is worthwhile to put an additional effort into the writing of software that will be used many times each day in many computer installations, since the software needs to be written only once.

Given the decision to use a machine-oriented language, which language should be used? I could have chosen the language of a particular machine $X$, but then those people who do not possess machine $X$ would think this book is only for $X$-people. Furthermore, machine $X$ probably has a lot of idiosyncrasies\footnote{đặc điểm riêng.} that are completely irrelevant to the material in this book yet which must be explained; \& in 2 years the manufacturer of machine $X$ will put out machine $X + 1$ or machine $10X$, \& machine $X$ will no longer be of interest to anyone.

To avoid this dilemma, I have attempted to design an ``ideal'' computer with very simple rules of operation (requiring, say, only an hour to learn), which also resembles actual machines very closely. There is no reason why a student should be afraid of learning the characteristics of $> 1$ computer; once 1 machine language has been mastered, others are easily assimilated. Indeed, serious programmers may expect to meet different machine languages in the course of their careers. So the only remaining disadvantage of a mythical machine is the difficulty of executing any programs written for it. Fortunately, that is not really a problem, because many volunteers have come toward to write simulators for the hypothetical machine. Such simulators are ideal for instructional purposes, since they are even easier to use than a real computer would be. I have attempted to cite the best early papers in each subject, together with a sampling of more recent work. When referring to the literature, I use standard abbreviations for the names of periodicals, except that the most commonly cited journals are abbreviated as follows:
\begin{enumerate}
	\item CACM $=$ Communications of the Association for Computing Machinery
	\item CACMJACM $=$ Journal of the Association for Computing Machinery
	\item CACMComp. J. $=$ The Computer Journal (British Computer Society)
	\item CACMMath. Comp. $=$ Mathematics of Computation
	\item CACMAMM $=$ American Mathematical Monthly
	\item CACMSICOMP $=$ SIAM Journal on Computing
	\item CACMFOCS $=$ IEEE Symposium on Foundations of Computer Science
	\item CACMSODA $=$ ACM–SIAM Symposium on Discrete Algorithms
	\item CACMSTOC $=$ ACM Symposium on Theory of Computing
	\item CACMCrelle $=$ Journal für die reine und angewandte Mathematik
\end{enumerate}
I also use ``CMath'' to stand for the book {\it Concrete Mathematics}.

{\bf Preface to the 3rd Edition.} After having spent 10 years developing the \TeX\ \& METAFONT systems for computer typesetting, I am now able to fulfill the dream that I had when I began that work, by applying those systems to {\it The Art of Computer Programming}. At last the entire text of this book has been captured inside my personal computer, in an electronic form that will make it readily adaptable to future changes in printing \& display technology. The new setup has allowed me to make literally thousands of improvements that I've been wanting to incorporate for a long time.

In this new edition I have gone over every word of the text, trying to retain the youthful exuberance\footnote{sự hồ hởi.} of my original sentences while perhaps adding some more mature judgment. Dozens of new exercises have been added; dozens of old exercises have been given new \& improved answers.

{\it The Art of Computer Programming} is, however, still a work in progress. Therefore some parts of this book are headed by an ``under construction'' icon, to apologize for the fact that the material is not up-to-date. My files are bursting with important material that I plan to include in the final, glorious, 4th edition of Vol. 1, perhaps 15 years from now; but I must finish Vols. 4 --5 1st, \& I do not want to delay their publication any more than absolute necessary.

My efforts to extend \& enhance these volumes have been enormously enhanced since 1980 by the wise guidance of Addison--Wesley's editor {\sc Peter Gordon}. He has become not only my ``publishing partner'' but also a close friend, while continually nudging me to move in fruitful directions. Indeed, my interactions with dozens of Addison--Wesley people during $> 3$ decades have been much better than any author deserves. The tireless support of managing editor {\sc John Fuller}, whose meticulous attention to detail has maintained the highest standards of production quality in spite of frequent updates, has been particularly praiseworthy.
\begin{quote}
	{\it``Things have changed in the past 2 decades.''} -- {\sc Bill Gates} (1995)
	
	{\it``Woe be to him that reads but one book.''} -- {\sc George Herbert}, {\it Jacula Prudentum}, 1144 (1640)
	
	{\it``Le défaut unique de tous les ouvrages c'est d'être trop longs.''} -- {\sc Vauvenargues}, {\it R\'eflexions}, 628 (1746)
	
	{\it``Books are a triviality\footnote{sự tầm thường.}. Life alone is great.''} -- {\sc Thomas Carlyle}, {\it Journal} (1839)
\end{quote}
{\bf Notes on the Exercises.} The exercises in this set of books have been designed for self-study as well as for classroom study. It is difficult, if not impossible, for anyone to learn a subject purely by reading about it, without applying the information to specific problems \& thereby being encouraged to think about what has been read. Furthermore, we all learn best the things that we have discovered for ourselves. Therefore the exercises form a major part of this work; a definite attempt has been made to keep them as informative as possible \& to select problems that are enjoyable as well as instructive.

In many books, easy exercises are found mixed randomly among extremely difficult ones. A motley\footnote{sặc sỡ.} mixture is, however, often unfortunate because readers like to know in advance how long a problem ought to take -- otherwise they may just skip over all the problems. A classic example of such a situation is the book {\it Dynamic Programming} by {\sc Richard Bellman}; this is an important, pioneering work in which a group of problems is collected together at the end of some chapters under the heading ``Exercises \& Research Problems,'' with extremely trivial questions appearing in the midst of deep, unsolved problems. It is rumored that someone once asked Dr. {\sc Bellman} how to tell the exercises apart from the research problems, \& he replied, ``If you can solve it, it is an
exercise; otherwise it's a research problem.''

Good arguments can be made for including both research problems \& very easy exercises in a book of this kind; therefore, to save the reader from the possible dilemma of determining which are which, {\it rating numbers} have been provided to indicate the level of difficulty. These numbers have the following general significance: {\sf Rating: Interpretation}
\begin{itemize}
	\item 00: An extremely easy exercise that can be answered immediately if the material of the text has been understood; such an exercise can almost always be worked ``in your head.''
	\item 10: A simple problem that makes you think over the material just read, but is by no means difficult. You should be able to do this in one minute at most; pencil \& paper may be useful in obtaining the solution.
	\item 20: An average problem that tests basic understanding of the text material, but you may need about 15 or 20 minutes to answer it completely.
	\item 30: A problem of moderate difficulty \&{\tt/}or complexity; this one may involve $> 2$ hours' work to solve satisfactorily, or even more if the TV is on.
	\item 40: Quite a difficult or lengthy problem that would be suitable for a term project in classroom situations. A student should be able to solve the problem in a reasonable amount of time, but the solution is not trivial.
	\item 50: A research problem that has not yet been solved satisfactorily, as far as the author knew at the time of writing, although many people have tried. If you have found an answer to such a problem, you ought to write it up for publication; furthermore, the author of this book would appreciate hearing about the solution as soon as possible (provided that it is correct).
\end{itemize}
By interpolation in this ``logarithmic'' scale, the significance of other rating numbers becomes clear. E.g., a rating of 17 would indicate an exercise that is a bit simpler than average. Problems with a rating of 50 that are subsequently solved by some reader may appear with a 40 rating in later editions of the book, \& in the errata posted on the Internet.

The remainder of the rating number divided by 5 indicates the amount of detailed work required. Thus, an exercise rated 24 may take longer to solve than an exercise that is rated 25, but the latter will require more creativity. All exercises with ratings of 46 or more are open problems for future research, rated according to the number of different attacks that they've resisted so far.

The author has tried earnestly to assign accurate rating numbers, but it is difficult for the person who makes up a problem to know just how formidable it will be for someone else to find a solution; \& everyone has more aptitude for certain types of problems than for others. It is hoped that the rating numbers represent a good guess at the level of difficulty, but the should be taken as general guidelines, not as absolute indicators.

This book has been written for readers with varying degrees of mathematical training \& sophistication; as a result, some of the exercises are intended only for the use of more mathematically inclined readers. The rating is preceded by an $M$ if the exercise involves mathematical concepts or motivation to a greater extent than necessary for someone who is primarily interested only in programming the algorithms themselves. An exercise is marked with the letters ``$HM$'' if its solution necessarily involves a knowledge of calculus or other higher mathematics not developed in this book. An ``$HM$'' designation does {\it not} necessarily imply difficulty.

Some exercises are preceded by an arrowhead, $\triangleright$; this designates problems that are especially instructive \& especially recommended. Of course, no reader{\tt/}student is expected to work {\it all} of the exercises, so those that seem to be the most valuable have been singled out. (This distinction is not meant to detract from the other exercises!) Each reader should at least make an attempt to solve all of the problems whose rating is 10 or less; \& the arrows may help to indicate which of the problems with a higher rating should be given priority.

Solutions to most of the exercises appear in the answer section. Please use them wisely; do not turn to the answer until you have made a genuine effort to solve the problem by yourself, or unless you absolutely do not have time to work this particular problem. {\it After} getting your own solution or giving the problem a decent try, you may find the answer instructive \& helpful. The solution given will often be quite short, \& it will sketch the details under the assumption that you have earnestly tried to solve it by your own means 1st. Sometimes the solution gives less information than was asked; often it gives more. It is quite possible that you may have a better answer than the one published here, or you may have found an error in the published solution; in such a case, the author will be pleased to know the details. Later printings of this book will give the improved solutions together with the solver's name where appropriate.

When working an exercise you may generally use the answers to previous exercises, unless specifically forbidden from doing so. The rating numbers have been assigned with this in mind; thus it is possible for exercise $n + 1$ to have a lower rating than exercise $n$, even though it includes the result of exercise $n$ as a special case.

{\sf Summary of codes.} $\triangleright$: Recommended. $M$: Mathematical oriented. $HM$: Requiring ``higher math''. 00: Intermediate. 10: Simple (1 min). 20: Medium (15 mins). 30: Moderately hard. 40: Term project. 50: Research problem.

{\bf2.} [10] Of what value can the exercises in a textbook be to the reader? {\bf3.} Generalize your answer. [This is an example of a horrible kind of problem that the author has tried to avoid.]
\begin{quotation}
	{\it``We can face our problem. We can arrange such facts as we have with order \& method.''} -- {\sc Hercule Poirot}, in {\it Murder on the Orient Express} (1934)
\end{quotation}

\subsection{Chap. 1: Basic Concepts}

\begin{quotation}
	{\it``Many persons who are not conversant with mathematical studies imagine that because the business of [Babbage's Analytical Engine] is to give its results in numerical notation, the nature of its processes must consequently be arithmetical \& numerical, rather than algebraical \& analytical. This is an error. The engine can arrange \& combine its numerical quantities exactly as if they were letters or any other general symbols; \& in fact it might bring out its results in algebraical notation, were provisions made accordingly.''} -- {\sc Augusta Ada}, {\it Countess of Lovelace} (1843)
	
	{\it``Practice yourself, for heaven's sake, in little things; \& thence proceed to greater.''} -- {\sc Epictetus}, {\it Discourses} IV.i
\end{quotation}

\subsubsection{Algorithms}
The notion of an {\it algorithm} is basic to all of computer programming, so we should begin with a careful analysis of this concept.

The word ``algorithm'' itself is quite interesting; at 1st glance it may look as though someone intended to write ``logarithm'' but jumbled up the 1st 4 letters. The word did not appear in {\it Webster's New World Dictionary} as late as 1957; we find only the older form ``algorism'' with its ancient meaning, the process of doing arithmetic using Arabic numerals. During the Middle Ages, abacists computed on the abacus \& algorists computed by algorism. By the time of the Renaissance, the origin of this word was in doubt, \& early linguists attempted to guess at its derivation by making combinations like {\it algiros} [painful] $+$ {\it arithmos} [number]; others said no, the word comes from ``King Algor of Castile.'' Finally, historians of mathematics found the true origin of the word algorism: It comes from the name of a famous Persian textbook author, Abu `Abd Allah Muh ammad ibn Musa al-Khwarizmi (c. 825) -- literally, ``Father of Abdullah, Mohammed,
son of Moses, native of Khwarizm.'' The Aral Sea in Central Asia was once known as Lake Khwarizm, \& the Khwarizm region is located in the Amu River basin just south of that sea. Al-Khwarizmi wrote the celebrated Arabic text {\it Kitab al-jabr wa'l-muqabala} (``Rules of restoring \& equating''); another word, ``algebra,'' stems from the title of that book, which was a systematic study of the solution of linear \& quadratic equations.

Gradually the form \& meaning of {\it algorism} became corrupted; as explained by the {\it Oxford English Dictionary}, the word ``passed through many pseudo-etymological perversions, including a recent {\it algorithm}, in which it is learnedly confused'' with the Greek root of the word {\it arithmetic}. This change from ``algorism'' to ``algorithm'' is not hard to understand in view of the fact that people had forgotten the original derivation of the word. An early German mathematical dictionary, {\it Vollständiges mathematisches Lexicon} (Leipzig: 1747), gave the following definition for the word {\it Algorithmus}: ``Under this designation are combined the notions of the 4 types of arithmetic calculations, namely addition, multiplication, subtraction, \& division.'' The Latin phrase {\it algorithmus infinitesimalis} was at that time used to denote ``ways of calculation with infinitely small quantities, as invented by {\sc Leibniz}.''

By 1950, the word algorithm was most frequently associated with {\sc Euclid}'s algorithm, a process for finding the greatest common divisor of 2 numbers appearing in {\sc Euclid}'s {\it Elements} (Book 7, Props. 1--2), see \cite[Algorithm E: {\sc Euclid}'s algorithm, p. 2]{Knuth1997}.

Each algorithm we consider has been given an identifying letter (E in the preceding example), \& the steps of the algorithm are identified by this letter followed by a number (E1, E2, E3).

Each step of an algorithm, e.g. step E1 above, begins with a phrase in brackets that sums up as briefly as possible the principal content of that step. This phrase also usually appears in an accompanying {\it flow chart} so that the reader will be able to picture the algorithm more readily.

After the summarizing phrase comes a description in words \& symbols of some {\it action} to be performed or some decision to be made. Parenthesized {\it comments}, like the 2nd sentence in step E1, may also appear. Comments are included as explanatory information about that step, often indicating certain invariant characteristics of the variables or the current goals. They do not specify actions belonging to the algorithm, but are meant only for the reader's benefit as possible aids to comprehension.

\subsection{Chap. 2: Information Structures}

%------------------------------------------------------------------------------%

\section{Competitive Programming (CP)}

\subsection{\cite{Durr_Vie2021}. {\sc Christoph D\"urr, Jill-J\^enn Vie}. Competitive Programming in Python: 128 Algorithms to Develop Your Coding Skills. 2021}
Want to kill it at your job interview in tech industry? Want to win that coding competition? Learn all algorithmic techniques \& programming skills you need from 2 experienced coaches, problem-setters, \& judges for coding competitions. Authors highlight versatility of each algorithms by considering a variety of problems \& show how to implement algorithms in simple \& efficient code. What to expect:
\begin{itemize}
	\item Master 128 algorithms in Python.
	\item Discover right way to tackle a problem \& quickly implement a solution of low complexity
	\item Understand classic problems like Dijkstra's shortest path algorithm \& Knuth--Morris--Pratt's string matching algorithm, plus lesser-known data structures like Fenwick trees \& Knuth's dancing links.
	\item Develop a framework to tackle algorithmic problem solving, including: Def, Complexity, Applications, Algorithm, Key Information, Implementation, Variants, In Practice, \& Problems.
	\item Python code included in book \& on companion website.
\end{itemize}
{\sc Christoph D\"urr} is a senior researcher at French National Center for Scientific Research (CNRS), affiliated with Sorbonne University in Paris. After a PhD in 1996 at Paris-Sud University, worked for 1 year as a postdoctoral researcher at International CS Institute in Berkeley \& 1 year in School of CS \& Engineering in Hebrew University of Jerusalem in Israel. Has worked in fields of quantum computation, discrete tomography (chụp cắt lớp rời rạc), \& algorithmic game theory, \& his current research activity focuses on algorithms \& optimization. From 2007--2014: taught a preparation course for programming contests at engineering school \'Ecole Polytechnique, \& acts regularly as a problem setter, trainer, or competitor for various coding competitions. Love carrot cake.

{\sc Jill-J\^enn Vie} is a research scientist at Inria in ML. An alumnus from \'Ecole normale sup\'erieure Paris-Saclay, where founded algorithmic club of Paris-Saclay (CAPS) \& coached several teams for International Collegiate Programming Contest (ICPC). Published a book in theoretical CS to help students prepare for prestigious French competitive exams e.g. {\it Grandes \'Ecoles} pr {\it agr\'egation}, \& directed a television show ``Blame the Algorithm'' about algorithms that govern our lives. He is part of advisory board of French CS Society (SIF), itself a member of International Federation for Information Processing (IFIP).
\begin{itemize}
	\item {\sf Preface.} Algorithms play an important role in our society, solving numerous mathematical problems which appear in a broad spectrum of situations. To give a few examples, think of planning taxi routes given a set of reservations (Sect. 9.1.2); assigning students to schools in a large urban school district, e.g. New York (Sect. 9.4); or identifying a bottleneck in a transportation network (Sect. 9.8). This is why job interviews in IT industry test candidates for their problem-solving skills. Many programming contests are organized by companies e.g. Google, Facebook, \& Microsoft to spot gifted candidates \& then send them job offers. This book will help students to develop a culture of algorithms \& data structures, so that they know how to apply them properly when faced with new mathematical problems.
	
	Designing right algorithm to solve a given problem is only half of work; to complete job, algorithm needs to be implemented efficiently. This is why this book also emphasizes implementation issues, \& provides full source code for most of algorithms presented. Have chosen Python for these implementations. What makes this language so enticing: Python allows a particularly clear \& refined expression, illustrating essential steps of algorithm, without obscuring things behind burdensome notations describing data structures. Surprisingly, Python is actually possible to re-read code written several months ago \& even understand it!
	
	Have collected 128 algorithmic problems, indexed by theme rather than by technique. Many are classic, whereas certain are atypical (khác biệt). This work should prove itself useful when preparing to solve wide variety of problems posed in programming contests e.g. ICPC, Google Code Jam, Facebook Hacker Cup, Prologin, France-ioi, etc. Hope: could serve as a basis for an advanced course in programming \& algorithms, where even certain candidates for `agr\'egation de math\'ematiques option informatique' (French competitive exam for highest teacher's certification) will find a ew original developments. Website \url{https://tryalgo.org/}, maintained by authors, contains links to code of this book $+$ selected problems at various online contests. This allows readers to verity their freshly acquired skills.
	
	Hope: reader will pass many long hours tackling algorithmic problems that at 1st glance appear insurmountable (không thể vượt qua), \& in end feel profound joy when a solution, especially an elegant solution, suddenly becomes apparent. Attention, it's all systems go!
	\item {\sf1. Introduction.}
	\begin{quote}
		You, my young friend, are going to learn to program algorithms of this book, \& then go on to win programming contests, sparkle during job interviews, \& finally roll up your sleeves, get to work, \& greatly improve gross national product!
	\end{quote}
	Mistakenly, computer scientists are still often considered magicians of modern times. Computers have slowly crept into our businesses, our homes, \& our machines, \& have become important enablers in functioning of our world. However, there are many that use these devices without really mastering them, \& hence, they do not fully enjoy their benefits. Knowing how to program provides ability to fully exploit their potential to solve problems in an efficient manner. Algorithms \& programming techniques have become a necessary background for many professions. Their mastery allows development of creative \& efficient computer-based solutions to problems encountered every day.
	
	This text presents a variety of algorithmic techniques to solve a number of classic problems. It describes practical situations where these problems arise, \& presents simple implementations written in programming language Python. Correctly implementing an algorithm is not always easy: there are numerous traps to avoid \& techniques to apply to guarantee announced running times. Examples in text are embellished with explanations of important implementation details which must be respected.
	
	For last several decades, programming competitions have sprung up at every level all over world, in order to promote a broad culture of algorithms. Problems proposed in these contests are often variants of classic algorithmic problems, presented as frustrating enigmas that will never let you give up until you solve them!
	\begin{itemize}
		\item {\sf1.1. Programming Competitions.} In a programming competition, candidates must solve several problems in a fixed time. Problems are often variants of classic problems, e.g. those addressed in this book, dressed up with a short story. Inputs to problems are called {\it instances}. An instance can be, e.g., adjacency matrix of a graph for a shortest path problem. In general, a small example of an instance is provided, along with its solution. Source code of a solution can be uploaded to a server via a web interface, where it is compiled \& tested against instances hidden from public. For some problems code is called for each instance, whereas for others input begins with an integer indicating number of instances occurring in input. In latter case, program must then loop over each instance, solve it, \& display results. A submission is accepted if it gives correct results in a limited time, on order of a few secs. {\sf Fi.1.1: Logo of ICPC nicely shows steps in resolution of a problem. A helium balloon is presented to team for each problem solved.} To give a list of all programming competitions \& training sites is quite impossible, \& such a list would quickly become obsolete. Nevertheless, review some of most important ones.
		\begin{itemize}
			\item {\bf ICPC.} Oldest of these competitions was founded by {\it Association for Computing Machinery} i 1977 \& supported by them up until 2017. This contest, known as ICPC, for {\it International Collegiate Programming Contest}, is organized in form of a tournament. Starting point is 1 of regional competitions, e.g. {\it South-West European Regional Contest} (SWERC), where 2 best teams qualify for worldwide final. Particularity of this contest: each 3-person team has only a single computer at their disposal (xử lý). Have only 5 hours to solve a maximum number of problems among 10 proposed. 1st ranking criterion: number of submitted solutions accepted (i.e. tested successfully against a set of unknown instances). Next criterion: sum over submitted problems of time between start of contest \& moment of accepted submission. For each erroneous submission, a penalty of 20 minutes is added.
			
			There are several competing theories on what ideal composition of a team is. In general, a good programmer \& someone familiar with algorithms is required, along with a specialist in different domains e.g. graph theory, dynamic programming, etc. \&, of course, team members need to get along together, even in stressful situations!
			
			For contest, each team can bring 25 pages of reference code printed in an 8-point font. They can also access online documentation of Java API \& C++ standard library.
		\end{itemize}
	\end{itemize}
	\item {\sf2. Character Strings.}
	\item {\sf3. Sequences.}
	\item {\sf4. Arrays.}
	\item {\sf5. Intervals.}
	\item {\sf6. Graphs.}
	\item {\sf7. Cycles in Graphs.}
	\item {\sf8. Shortest Paths.}
	\item {\sf9. Matchings \& Flows.}
	\item {\sf10. Trees.}
	\item {\sf11. Sets.}
	\item {\sf12. Points \& Polygons.}
	\item {\sf13. Rectangles.}
	\item {\sf14. Numbers \& Matrices.} Present a few efficient implementations of classic manipulations of numbers: arithmetical operations, evaluation of expressions, resolution of linear systems, \& sequences of multiplication of matrices.
	\begin{itemize}
		\item {\sf14.1. GCD.} Given $a,b\in\mathbb{Z}$, seek largest integer $p$ s.t. $a,b$ can be expressed as integer multiples of $p$; this is their {\it greatest common divisor} (GCD).
		
		Calculation of GCD can be implemented recursively to be very efficient. A mnemonic trick (mẹo ghi nhớ): from 2nd iteration on, arrange to always have 2nd argument smaller than 1st: $a\mod b < b$.
		\begin{verbatim}
			def pgcd(a, b):
			    return a if b == 0 else pgcd(b, a % b)
		\end{verbatim}
		Complexity of this division version of Euclid's algorithm is $O(\log a + \log b)$. Indeed, 1st parameter diminishes by at least a factor of 2 every 2nd iteration.
		\item {\sf14.2. B\'ezout Coefficients.} Def: For $a,b\in\mathbb{Z}$, would like to find $u,v\in\mathbb{Z}$ s.t. $au + bv = d$ where $d = \gcd(a,b)$.
		
		This calculation is based on an observation similar to above. If $a = bq + r$, then $au + bv = d$ corresponds to $(bq + r)u + bv = d$, or $bu' + rv' = d$ for $u' = qu + v,v' = u\Leftrightarrow u = v',v = u' - qv'$. This calculation also terminates in $O(\log a + \log b)$ steps.
		
		{\it Variant.} Certain problems involve calculation of extremely large numbers, \& consequently require a response modulo a large prime number $p$ in order to test if solution is correct. Since $p$ is prime, can easily divide by an integer $a$ non-multiple of $p$: $(a,p) = 1$, hence their B\'ezout coefficients satisfy $au + pv = 1$, hence $au = 1(\mod p)$, \& $u$ is inverse of $a$. Hence, to divide by $a$, can instead multiply by $u(\mod p)$.
		\item {\sf14.3. Binomial Coefficients.} In calculation of $\binom{n}{k}$, equal to $\frac{n!}{k!(n - k)!}$, risky to calculate $n(n - 1)\cdots(n - k + 1)$ \& $k!$ separately, given possibility of an overflow. Can exploit fact: product of $i$ consecutive integers always contains a term divisible by $i$.
		\begin{verbatim}
			def binom(n, k):
			    prod = 1
			    for i in range(k):
			        prod = (prod * (n - i)) // (i + 1)
			    return prod
		\end{verbatim}
		For most of these problems, calculation of binomial coefficients needs to be taken modulo a prime number $p$. Code then becomes as follows, with complexity $O(k(\log k + \log p))$, relying on calculation of B\'ezout coefficients.
		\begin{verbatim}
			def binom_modulo(n, k, p):
			    prod = 1
			    for i in range(k):
			        prod = (prod * (n - i) * inv(i + 1, p)) % p
			    return prod
		\end{verbatim}
		An alternative: calculate Pascal's triangle by dynamic programming, which could be interesting if $\binom{n}{k}$ needs to be calculated for numerous pairs $n,k$.
		\item {\sf14.4. Fast Exponentiation.} Def: Given $a,b$ wish to calculate $a^b$. Again, as result risks being enormous, often asked to perform calculation module a given integer $p$, but this does not change nature of problem.
		
		{\it Algorithm in $O(\log b)$.} Naive approach performs $b - 1$ multiplications by $a$. However, can rapidly calculate powers of $a$ of form $a^1,a^2,a^4,a^8,\ldots$ using relation $a^{2^k}\cdot a^{2^k} = a^{2^{k+1}}$. A trick consists of combining these values according to binary decomposition of $b$. E.g.: $a^{13} = a^{8 + 4 + 1} = a^8\cdot a^4\cdot a^1$. For this calculation, suffice to generate $O(\log_2 b)$ powers of $a$. Implementation below is reproduced with gracious permission of {\sc Louis Abraham}. At $i$th iteration, variable {\tt a} contains $a_0^{2^i}\mod p$ \& variable {\tt b} contains $\lfloor\frac{b_0}{2^i}\rfloor$, where $a_0,b_0$: inputs to function. Thus, it suffices to test parity bit of {\tt b} in body of loop to determine binary decomposition of $b$. Operation {\tt b >>= 1} $\Leftrightarrow$ performing an integer division of $b$ by 2.
		\begin{verbatim}
			def fast_exponentiation(a, b, q):
			    assert a >= 0 \& b >= 0 \& q >= 1
			    result = 1
			    while b:
			        if b % 2 == 1:
			            result = (result * a) % q
			        a = (a * a) % q
		        	b >>= 1
			    return result
		\end{verbatim}
		{\it Variant.} This technique can also be applied to matrix multiplications. Let $A$: a matrix, $b\in\mathbb{N}^\star$. Rapid exponentiation allows calculation of $A^b$ with only $O(\log b)$ matrix multiplications.
		
		\begin{problem}[Last digit \href{https://www.spoj.com/problems/LASTDIG/}{spoj:LASTDIG}]
			
		\end{problem}
		
		\begin{problem}[Tiling a grid with dominoes \href{http://www.spoj.com/problems/GNY07H/}{spoj:GNY07H]}]
			
		\end{problem}
		\item {\sf14.5. Prime numbers.} {\it Sieve of Eratosthenes.} Given $n$, seek all prime numbers $< n$. Sieve of Eratosthenes is a simple method to execute this task. Begin with a list of all integers $< n$, with initially 0 \& 1 marked. Then, for each $p = 2,3,4,\ldots,n - 1$, if $p$ is not marked, then $p$ is prime, \& in this case mark all multiples of $p$. Complexity of this procedure is delicate to analyze: $O(n\log\log n)$.
		
		{\it Implementation Details.} Proposed implementation skips marking 0, 1 as well as multiples of 2. This is why iteration over $p$ is done with a step of 2, in order to test only odd numbers.
		\begin{verbatim}
			def eratosthene(n):
			    P = [True] * n
			    answ = [2]
			    for i in range(3, n, 2):
			        if P[i]:
			            answ.append(i)
			            for j in range(2 * i, n, i):
			                P[j] = False
			    return answ
		\end{verbatim}
		{\sf Gries--Misra Sieve.} A deficiency of preceding algorithm: it marks same composite number several times. An improvement was proposed by {\sc David Gries \& Jayadev Misra} in 1978 [Ref] that gets around this deficiency \& has a theoretical complexity of $O(n)$. Thus gain a factor of $\log\log n$. Their algorithm is not much longer but multiplicative constant in complexity is a bit larger. Our experiments have shown an improvement in execution time with, in general, a factor $\frac{1}{2}$ for interpretor {\tt pypy}, but a deterioration by a factor 3 for interpretor {\tt python3}.
		
		{\sc Dexter Kozen} showed: algorithm could at same time produce an array {\tt factor} associating with every integer $2\le x < n$ smallest nontrivial integer factor of $x$. This array is very useful in generation of decomposition in prime factors of a given integer.
		
		Algorithm is based on unique prime decomposition of a composite integer (fundamental theorem of arithmetic). Indeed, an integer $y$ can be written in form $y = {\tt factor}[y]\cdot x$ with ${\tt factor}[y]\le{\tt factor}[x]$.
		
		Algorithm enumerates all of composite integers by looping 1st on $x = 2,\ldots,n - 1$, \& then over all prime numbers $p$, with $p\le{\tt factor}[x]$, where $p$ plays role of ${\tt factor}[y]$ in expression $y = p\cdot x$. Algorithm is correct, since at time of processing $x$, all prime numbers $\le x$ have been found, as well as smallest factor of $x$. As every number $y$ between 2 \& $n - 1$ is examined exactly once, complexity of algorithm is $O(n)$.
		\begin{verbatim}
			def gries_misra(n):
			    primes = []
			    factor = [0] * n
			    for x in range(2, n):
			        if not factor[x]: # no factor found
			            factor[x] = x # meaning x is prime
			            primes.append(x)
			        for p in primes:  # loop over primes found so far
			            if p > factor[x] or p * x >= n:
			                break
			            factor[p * x] = p # p is smallest factor of p * x
			    return primes, factor
		\end{verbatim}
		
		\begin{problem}[Spiral of primes \href{https://icpcarchive.ecs.baylor.edu/index.php?option=com_onlinejudge&Itemid=8&category=79&page=show_problem&problem=121}{[icpcarchive:2120]}]
			
		\end{problem}
		
		\begin{problem}[Prime or not \href{https://www.spoj.com/problems/PON/}{[spoj:PON]}]
			
		\end{problem}
		
		\begin{problem}[Bazinga! \href{https://www.spoj.com/problems/DCEPC505/}{[spoj:DCEPC505]}]
			
		\end{problem}
		
		\item {\sf14.6. Evaluate an Arithmetic Expression.} Def: Given an expression obeying a certain fixed syntax, construct syntax (parse) tree or evaluate value of expression, see {\sf Fig. 14.1: Syntax tree associated with expression $2 + (3\times 4)/2$.}
		
		{\it Approaches.} p. 218
		\item {\sf14.7. System of Linear Equations.}
		\item {\sf14.8: Multiplication of a Matrix Sequence.}
	\end{itemize}	
	\item {\sf15. Exhaustive Search.}
	\item {\sf16. Conclusion.}
	\begin{itemize}
		\item {\sf16.1. Combine Algorithms to Solve a Problem.} At times, problem may require to find an optimal value. Can this value be found by dichotomy (sự phân đôi)?  If it lies between 0 \& $N$ \& if condition verifies a certain property, this adds only a factor $\log N$ to complexity. This is why it is always profitable to know how to efficiently code a binary search. Try your skills on this problem, 1 of most difficult: it can be arranged \href{https://open.kattis.com/problems/itcanbearranged}{[kattis:itcanbearranged]}.
		
		Do you have to count number of subsequences, or some other combinatorial structure, module some large prime number? Then, a recurrence relation by dynamic programming can be combined with replacing every division by a multiplication with inverse modulo $p$ (Sect. 14).
		
		Is a greedy algorithm sufficient, or are we faced with a problem of dynamic programming? What is recurrence? Is recursive structure of problem at hand a special case of some known problem? It is only by solving lots \& lots of problems that you can build \& hone these reflexes.
		
		Finally, size of instances can sometimes provide a clue as to expected complexity, see table in Sect. 1.4.
		\item {\sf16.2. For Further Reading.} A selection of works completing subjects treated in this book.
		\begin{itemize}
			\item An essential ref for fundamental algorithms: substantial {\it Introduction to Algorithms} by {\sc T.H. Cormen, C. E. Leiserson, R. L. Rivest, \& C. Stein}, MIT Press.
			\item For a variety of more specialized algorithms, see {\it Encyclopedia of Algorithms}, a collective work edited by {\sc Ming-Yang Kao}, Springer Verlag, 2e, 2016.
			\item Flow algorithms are studied from top to bottom in {\it Network Flows: Theory, Algorithms, \& Applications} by {\sc R.K. Ahuja, T. L. Magnanti, \& J. B. Orlin}, Pearson, 2013.
			\item A good introduction to algorithms for problems in geometry is {\it Computational Geometry: Algorithms \& Applications} by {\sc M. de Berg, O. Cheung, M. van Kreveld, M. Overmars}, Springer Verlag 2008.
			\item If would like to learn more about tricky manipulations with binary representation of integers, a delightful ref: {\it Hacker's Delight} by {\sc Henry S. Warren, Jr}, Addison-Wesley, 2013.
			\item A very good introduction to programming in Python: {\it Think Python: How to Think Like a Computer Scientist} by {\sc Allen Downey}, O'Reilly Media, 2015.
			\item Other highly appreciated books include {\it Python Essential Reference} by {\sc David M. Beazley}, Pearson Education, 2009 \& {\it Python Cookbook} by {\sc Brian K. Jones}, O'Reilly Media, 2013.
			\item 2 texts more adapted to preparation for programming contests: {\it Competitive Programming} by {\sc Steven \& Felix Halim}, Lulu, 2013 \& {\it The Algorithm Design Manual} by {\sc Steven S. Skiena}, Springer Verlag, 2009.
		\end{itemize}
		\item {\sf16.3. Rendez-vous on \url{tryalgo.org}.} This book is accompanied by a website \url{https://tryalgo.org/}, where code of all Python programs described here can be found $+$ test data, training exercises \& solutions that, of course, must not be read before having attempted problems. Package {\tt tryalgo} is available on GitHub \& PyPI under MIT license, \& can be installed under Python 2 or 3 via {\tt pip install tryalgo}.
		\begin{verbatim}
			>>> import tryalgo
			>>> help(tryalgo)		 # for the list of modules
			>>> help(tryalgo.arithm) # for a particular module
		\end{verbatim}
	\end{itemize}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{\cite{Laaksonen2020,Laaksonen2024}. {\sc Antti Laaksonen}. Guide to Competitive Programming: Learning \& Improving Algorithms Through Contests}
\begin{itemize}
	\item {\sf Amazon review.} This textbook features new material on advanced topics, e.g. calculating Fourier transforms, finding minimum cost flows in graphs, \& using automata in string problems. Critically, text accessibly describes \& shows how CP is a proven method of implementing \& testing algorithms, as well as developing computational thinking \& improving both programming \& debugging skills.
	
	{\bf Topics \& features.}
	\begin{enumerate}
		\item Introduces dynamic programming \& other fundamental algorithm design techniques, \& investigates a wide selection of graph algorithms
		\item Compatible with IOI Syllabus, yet also covering more advanced topics, e.g. maximum flows, Nim theory, \& suffix structures
		\item Provides advice for students aiming for IOI contest
		\item Surveys specialized algorithms for trees, \& discusses mathematical topics that are relevant in CP
		\item Examines use of Python language in CP
		\item Discusses sorting algorithms \& binary search, \& examines a selection of data structures of C++ standard library
		\item Explores how GenAI will impact on future of field
		\item Covers such advanced algorithm design topics as bit-parallelism \& amortized analysis, \& presents a focus on efficiently processing array range queries
		\item Describes a selection of more advanced topics, including square-root algorithms \& DP optimization
	\end{enumerate}
	Fully updated, expanded \& easy to follow, this core textbook{\tt/}guide is an ideal reference for all students needing to learn algorithms \& to practice for programming contests. Knowledge of programming basics is assumed, but prev background in algorithm design or programming contests is not necessary. With its breadth of topics, examples, \& references, book is eminently suitable for both beginners \& more experienced readers alike.
	\item {\sf1. Introduction.} This chap shows what CP is about, outlines contents of book, \& discusses additional learning resources.
	\begin{itemize}
		\item Sect. 1.1 goes through elements of CP, introduces a selection of popular programming contests, \& gives advice on how to practice CP.
		\item Sect. 1.2 discusses goals \& topics of this book, \& briefly describes contents of each chap.
		\item Sect. 1.3 presents CSES Problem set, which contains a collection of practice problems. Solving problems while reading book is a good way to learn CP.
		\item Sect. 1.4 discusses other books related to CP \& design of algorithms.
	\end{itemize}
	
	\begin{itemize}
		\item {\sf1.1. What is CP?} CP combines 2 topics: design of algorithms \& implementation of algorithms.
		
		{\bf Design of Algorithms.} Core of CP is about inventing efficient algorithms that solve well-defined computational problems. Design of algorithms requires problem solving \& mathematical skills. Often a solution to a problem is a combination of well-known methods \& new insights.
		
		Mathematics play an important role in CP. Actually, there are no clear boundaries between algorithm design \& mathematics. This book has been written so that not much background in mathematics is needed. Appendix of book reviews some mathematical concepts that are used throughout book, e.g. sets, logic \& functions, \& appendix can be used as a reference when reading book.
		
		{\bf Implementation of Algorithms.} In CP, solutions to problems are evaluated by testing an implemented algorithm using a set of test cases. Thus, after coming up with an algorithm that solves problem, next step: correctly implement it, which requires good programming skills. CP greatly differs from traditional software engineering: programs are short (usually at most some hundreds of lines), they should be written quickly, \& not need to maintain them after contest.
		
		At tie of writing this book, C++ is clearly most popular language in CP. Java \& Python also have some popularity, \& other languages are little used. E.g., in 2023, C++ was used in 91\% of CSES Problem Set submissions, Java in 3\% \& Python in 5\%.
		
		Many people regard C++ as best choice for a competitive programmer. In particular, almost all top competitive programmers use C++. Benefits of using C++ are that it is a very efficient language \& its standard library contains a large collection of data structures \& algorithms.
		
		All examples programs in this book are written in C++, except for Chap. 16 that discusses Python. Data structures \& algorithms available in C++ standard library are often used in book. Programs follow C++11 standard, which can be used in most contests nowadays. If cannot program in C++ yet, now is a good time to start learning.
		\begin{itemize}
			\item {\sf1.1.1. Programming Contests.}
			\item {\sf1.1.2. Tips for Practicing.}
		\end{itemize}
		\item {\sf1.2. About This Book.}
		\item {\sf1.3. CSES Problem Set.}
		\item {\sf1.4. Other Resources.}
	\end{itemize}
	\item {\sf2. Programming Techniques.} This chap presents some of features of C++ programming language that are useful in CP, \& gives examples of how to use recursion \& bit operations in programming.
	\begin{itemize}
		\item Sect. 2.1 discusses a selection of topics related to C++, including input \& output methods, working with numbers, \& how to shorten code.
		\item Sect. 2.2 focuses on recursive algorithms. 1st learn an elegant way to generate all subsets \& permutations of a set using recursion. After this, use backtracking to count number of ways to place $n$ non-attacking queens on $n\times n$ chessboard.
		\item Sect. 2.3 discusses basics of bit operations, \& shows how to use t hem to represent subsets of sets.
	\end{itemize}
	
	\begin{itemize}
		\item {\sf2.1. Language Features.} A typical C++ code template for CP looks like this:
		\begin{verbatim}
			#include <bits/stdc++.h>
			using namespace std;
			int main() {
			    // solution comes here
			}
		\end{verbatim}
		\verb|#include| line at beginning of code is a feature of {\tt g++} compiler that allows us to include entire standard library. Thus, not needed separately include libraries e.g. {\it iostream, vector, algorithm}, but rather they are available automatically.
		
		{\tt using} line declares: classes \& functions of standard library can be used directly in code. Without {\tt using} line would have to write, e.g., {\tt std::cout}, but now it suffices to write {\tt cout}.
		
		Code can be compiled using command:
		\begin{verbatim}
			g++ -std=c++11 -O2 -Wall test.cpp -o test
		\end{verbatim}
		This command produces a binary file {\tt test} from source code {\tt test.cpp}. Compiler follows C++11 standard {\tt-std=c++11}, optimizes code {\tt-O2} \& shows warnings about possible errors {\tt-Wall}.
		\begin{itemize}
			\item {\sf2.1.1. Input \& Output.} In most contests, standard streams are used for reading input \& writing output. In C++, standard streams are {\tt cin} for input \& {\tt cout} for output. Also C functions, e.g. {\tt scanf, printf} can be used.
			
			Input for program usually consists of numbers \& strings separated with spaces \& newlines. they can be read from {\tt cin} stream as follows:
			\begin{verbatim}
				int a, b;
				string x;
				cin >> a >> b >> x;
			\end{verbatim}
			This kind of code always works, assuming: there is at least 1 space or newline between each element in input. E.g., above code can read both following inputs:
			\begin{verbatim}
				123 456 monkey
				123    456
				monkey
			\end{verbatim}
			{\tt cout} stream is used for output as follows:
			\begin{verbatim}
				int a = 123, b = 456;
				string x = "monkey";
				cout << a << " " << b << " " << x << "\n";
			\end{verbatim}
			Input \& output is sometimes a bottleneck in program. Following lines at beginning of code make input \& output more efficient:
			\begin{verbatim}
				ios::sync_with_stdio(0);
				cin.tie(0);
			\end{verbatim}
			Note: newline \verb|"\n"| works faster than {\tt endl}, because {\tt endl} always causes a flush operation, see, e.g., \href{https://www.geeksforgeeks.org/buffer-flush-means-c/}{Geeks4Geeks{\tt/}What does buffer flush means in C++?}
			
			C functions {\tt scanf, printf} are an alternative to C++ standard streams. They are usually slightly faster, but also more difficult to use. Code reads 2 integers from input:
			\begin{verbatim}
				int a, b;
				scanf("%d %d", &a, &b);
			\end{verbatim}
			Code prints 2 integers:
			\begin{verbatim}
				int a = 123, b = 456;
				printf("%d %d\n", a, b);
			\end{verbatim}
			Sometimes program should read a whole input line, possibly containing spaces. This can be accomplished by using {\tt getline} function:
			\begin{verbatim}
				string s;
				getline(cin, s);
			\end{verbatim}
			If amount of data is unknown, following loop is useful:
			\begin{verbatim}
				while (cin >> x) {
				    // code
				}
			\end{verbatim}
			This loop reads elements from input one after another, until there is no more data available in input.
			
			In some contest systems, files are used for input \& output. An easy solution for this: write code as usual using standard streams, but add following lines to beginning of code:
			\begin{verbatim}
				freopen("input.txt", "r", stdin);
				freopen("output.txt", "w", stdout);
			\end{verbatim}
			After this, program reads input from file {\tt input.txt} \& writes output to file {\tt output.txt}.
			\item {\sf2.1.2. Working with Numbers.}
			\item {\sf2.1.3. Shortening Code.}
		\end{itemize}
	\end{itemize}
	\item {\sf3. Efficiency.}
	\item {\sf4. Sorting \& Searching.}
	\item {\sf5. Data Structures.}
	\item {\sf6. Dynamic Programming.}
	\item {\sf7. Graph Algorithms.}
	\item {\sf8. Algorithm Design Topics.}
	\item {\sf9. Range Queries.}
	\item {\sf10. Tree Algorithms.}
	\item {\sf11. Mathematics.}
	\item {\sf12. Advanced Graph Algorithms.}
	\item {\sf13. Geometry.}
	\item {\sf14. String Algorithms.}
	\item {\sf15. Additional Topics.}
	\item {\sf16. Python in Competitive Programming.} While C++ is predominant language in CP, Python has also gained some popularity in recent years. Even if one usually uses C++, Python has some useful features that can be worth learning. In this chap, take a look at Python language from a CP perspective.
	\begin{itemize}
		\item Sect. 16.1 shows how to solve an example CP problem using Python. After that, go through some Python features: handling input \& output, working with numbers \& generating combinations of objects.
		\item Sect. 16.2 deals with Python data structures that are useful in CP: list structures, hash structures \& priority queues. Also discuss differences between Python \& C++ when using data structures.
		\item Sect. 16.3 presents 2 scenarios where a natural C++ solution: use binary search tree data structures. Python standard library does not have such data structures, \& have to find alternative ways to solve problems.
		\item Sect. 16.4 discusses use of recursive functions in Python. See how to increase default recursion depth limit \& how to implement dynamic programming solutions in Python.
		\item Sect. 16.5 studies efficiency of Python through experiments. Both compare efficiency of 2 Python implementations (CPython \& PyPy) \& efficiency between Python \& C++.
		\item Sect. 16.6 shows how Python can be used as a tool for generating tests, stress testing solutions \& implementing an algorithm for finding polynomials.
	\end{itemize}
	
	\begin{itemize}
		\item {\sf16.1. Introduction.} At beginning of this book, created a C++ solution to {\it Weird Algorithm} problem from CSES Problem Set. Now solve problem in Python.
		
		When solved problem in C++, had to carefully select type of variable $n$ so that it is large enough to hold all intermediate values during calculation. In Python, do not have to think about this because built-in Python integers can contain arbitrary large values. Other than that, there are no big differences when implementing solution in C++ \& Python.
		\begin{itemize}
			\item {\sf16.1.1. Input \& Output.} Python function {\tt input} reads a line from standard input \& returns line as a string. E.g., following code reads 2 lines from standard input. 1st line is converted to an integer, \& 2nd line is stored as a string.
			\begin{verbatim}
				n = int(input())
				s = input()
			\end{verbatim}
			If a line consists of several values separated by spaces, can use {\tt split} function to convert them to a list:
			\begin{verbatim}
				t = input().split()
			\end{verbatim}
			Using above code, each value in list is a string. To convert each value to an integer, can use following code which uses list comprehension syntax to construct a list of integers:
			\begin{verbatim}
				t = [int(x) for x in input().split()]
			\end{verbatim}
			Another approach: use {\tt map} function for integer conversion \& {\tt list} function to create a list from a map object.
			\begin{verbatim}
				t = list(map(int, input().split()))
			\end{verbatim}
			{\tt print} function writes a line to standard output. E.g., code writes 3 lines:
			\begin{verbatim}
				print(a)
				print(b)
				print(c)
			\end{verbatim}
			Code writes each value on same line, separated by spaces:
			\begin{verbatim}
				print(a, b, c)
			\end{verbatim}
			{\tt end, sep} parameters can be used to change newline \& separator strings when {\tt print} function. By default, {\tt end} is \verb|"\n"| \& {\tt sep} is {\tt" "}. Code writes values on same line, separated by spaces:
			\begin{verbatim}
				print(a, end=" ")
				print(b, end=" ")
				print(c)
			\end{verbatim}
			Code writes each value on a separate line:
			\begin{verbatim}
				print(a, b, c, sep="\n")
			\end{verbatim}
			\item {\sf16.1.2. Working with Numbers.} In Python, built-in integers can contain arbitrarily large values. E.g., following code prints integer $1337^{13}$:
			\begin{verbatim}
				print(1337**13)
			\end{verbatim}
			Output of code:
			\begin{verbatim}
				43622273306113847375878664912656177214297
			\end{verbatim}
			Thus, convenient to use Python when necessary to handle integers that do not fit into 64 bit or 128 bit integer types in C++. [However, in some recent Python versions, conversions between large integers \& their string representations are restricted. E.g., not possible by default to print an integer that has $> 4300$ digits. Purpose of this change: prevent denial of service attacks in Python applications, because such conversions are slow. \verb|sys.set_int_max_str_digits| function can be used to increase limit.]
			
			Operator {\tt/} always produces a floating point number, even if both numbers are integers. Operator {\tt//} can be used for integer division.
			\begin{verbatim}
				print(3 / 2) # 1.5
				print(3 // 2) # 1
			\end{verbatim}
			{\tt pow} function can be used to efficiently calculate value of an expression $a^b\mod c$. E.g., code prints value of $999^{10^>6}\mod123$.
			\begin{verbatim}
				print(pow(999, 10**6, 123)) # 42
			\end{verbatim}
			Module {\tt math} contains some useful functions for integer calculations. [Some of these functions are not available in older Python versions.] Functions {\tt gcd, lcm} calculate greatest common divisor \& lowest common multiple for a list of numbers. Function {\tt factorial} returns factorial of a number, \& function {\tt comb} can be used to calculate binomial coefficients.
			\begin{verbatim}
				import math
				print(math.gcd(8, 12)) # 4
				print(math.gcd(8, 12, 6)) # 2
				print(math.lcm(8, 12)) # 24
				print(math.factorial(5)) # 120
				print(math.comb(5, 3)) # 10
			\end{verbatim}
			Module {\tt fractions} provides a way to perform exact calculations with fractions. E.g., code creates fractions $\frac{1}{2}$ \& $\frac{5}{7}$:
			\begin{verbatim}
				from fractions import Fraction
				a = Fraction(1, 2)
				b = Fraction(5, 7)
				print(a) # 1/2
				print(b) # 5/7
				print(float(a)) # 0.5
				print(float(b)) # 0.7142857142857143
			\end{verbatim}
			Fractions are automatically shown in reduced form:
			\begin{verbatim}
				print(Fraction(1, 2)) # 1/2
				print(Fraction(2, 4)) # 1/2
				print(Fraction(3, 6)) # 1/2
			\end{verbatim}
			Mathematical operators can be used for calculating with fractions:
			\begin{verbatim}
				a = Fraction(1, 2)
				b = Fraction(5, 7)
				print(a + b) # 17/14
				print(a * b) # 5/14
				print(a < b) # True
			\end{verbatim}
			\item {\sf16.1.3. Generating Combinations.} Module {\tt itertools} can be used to generate combinations of objects. Module includes following functions:
			\begin{itemize}
				\item Function {\tt permutations} generate all permutations of input sequence. E.g., permutations of $[1,2,3]$ are $(1,2,3),(1,3,2),(2,1,3),(2,3,1),(3,1,2),(3,2,1)$.
				\item Function {\tt combinations} generates all subsequences of input sequence that have $k$ elements. E.g., when input sequence is $[1,2,3]$ \& $k = 2$, combinations are $(1,2),(1,3),(2,3)$. Each subsequence corresponds to a subset of size $k$.
				\item Function {\tt product} generates all sequences of length $k$ where each element comes from input sequence. E.g., when input sequence if $[1,2,3]$ \& $k = 2$, sequences are $(1,1),(1,2),(1,3),(2,1),(2,2),(2,3),(3,1),(3,2),(3,3)$.
				\item Function \verb|combinations_with_replacements| generates all sequences of length $k$ where each element comes from input sequence \& order of elements is same as input sequence. E.g., when input sequence is $[1,2,3]$ \& $k = 2$, combinations are $(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)$.
			\end{itemize}
			Code demonstrates how to use functions:
			\begin{verbatim}
				import itertools
				s = [1, 2, 3]
				k = 2
				print(list(itertools.permutations(s)))
				print(list(itertools.combinations(s, k)))
				print(list(itertools.product(s, repeat=k)))
				print(list(itertools.combinations_with_replacement(s, k)))
			\end{verbatim}
			Output of code:
			\begin{verbatim}
				[(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2),
				(3, 2, 1)]
				[(1, 2), (1, 3), (2, 3)]
				[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1),
				(3, 2), (3, 3)]
				[(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]
			\end{verbatim}
		\end{itemize}
		\item {\sf16.2. Data Structures.} Python standard library has several data structures that are useful in CP. In this sect, discuss some of those data structures \& also highlight some differences between Python \& C++ data structures.
		
		1 difference between Python \& C++: in Python, syntax {\tt a = b} only copies reference to data structure \& does not copy contents of data structure like in C++. Code demonstrates this:
		\begin{verbatim}
			a = [1, 2, 3]
			b = a
			a.append(4)
			print(a) # [1, 2, 3, 4]
			print(b) # [1, 2, 3, 4]
		\end{verbatim}
		Here variables {\tt a, b} point to same list \& when an element is added through {\tt a}, it will also be visible through {\tt b}.
		
		Same applies to function calls: if modify a list given to a function as a parameter, changes will be visible outside function. In following code, function adds a new element to a list that is given as a parameter.
		\begin{verbatim}
			def test(x):
			    x.append(4)
			a = [1, 2, 3]
			test(a)
			print(a) # [1, 2, 3, 4]
		\end{verbatim}
		Another difference: Python has 2 types of data structures: mutable \& immutable data structures. Mutable data structures can be modified using methods \& operators but immutable data structures cannot be modified.
		
		E.g., a list is a mutable data structure because can use {\tt[]} syntax to modify list:
		\begin{verbatim}
			x = [1, 2, 3]
			x[1] = 5
			print(x) # [1, 5, 3]
		\end{verbatim}
		However, strings \& tuples are immutable \& there are no methods or operators that could be used to modify them. E.g., following code does not work because it is not allowed to modify a string:
		\begin{verbatim}
			x = "abc"
			x[1] = "e" # TypeError
			print(x)
		\end{verbatim}
		\begin{itemize}
			\item {\sf16.2.1. List Structures.} In Python, a list is a dynamic array where elements can be efficiently added \& removed at end of list. Python list structure corresponds to C++ vector structure.
			
			Lists can be created using {\tt[]} syntax. Following code creates a list with 3 elements:
			\begin{verbatim}
				t = [1, 2, 3]
			\end{verbatim}
			Another way to create a list: use method {\tt append} that adds a new element at end of list:
			\begin{verbatim}
				t = []
				t.append(1)
				t.append(2)
				t.append(3)
				print(t) # [1, 2, 3]
			\end{verbatim}
			Method {\tt pop} removes \& returns last element of list:
			\begin{verbatim}
				t = [1, 2, 3]
				print(t.pop()) # 3
				print(t) # [1, 2]
			\end{verbatim}
			Elements of list can be accessed using {\tt[]} syntax:
			\begin{verbatim}
				t = [1, 2, 3]
				print(t[1]) # 2
				t[1] = 5
				print(t[1]) # 5
			\end{verbatim}
			{\bf Sorting lists.} There are 2 ways to sort a list. 1st way: use {\tt sort} method:
			\begin{verbatim}
				t = [3, 2, 1]
				t.sort()
				print(t) # [1, 2, 3]
			\end{verbatim}
			Another way: use {\tt sorted} function which creates a new sorted list without modifying original list:
			\begin{verbatim}
				t = [3, 2, 1]
				print(sorted(t)) # [1, 2, 3]
				print(t) # [3, 2, 1]
			\end{verbatim}
			{\bf Deques.} Python also has a deque data structure that allows efficient insertion \& deletion of elements both at beginning at end of list. It has 2 special methods {\tt appendleft, popleft} that modify beginning of list.
			
			Code shows how a deque can be used:
			\begin{verbatim}
				from collections import deque
				d = deque()
				d.append(1)
				d.append(2)
				d.appendleft(3)
				print(d) # [3, 1, 2]
				d.pop()
				print(d) # [3, 1]
				d.popleft()
				print(d) # [1]
			\end{verbatim}
			In Python, deques are implemented as linked lists \& not possible to efficiently access their elements using {\tt[]} syntax. This differs from C++ where deques are implemented as dynamic arrays.
			\item {\sf16.2.2. Hash Structures.} Python has 2 useful data structures that are based on hash tables: a set \& a dictionary. They correspond to C++ \verb|unordered_set, unordered_map| data structures.
			
			{\bf Sets.} A set maintains a collection of elements. It provides efficient methods {\tt add, remove} for element insertion \& removal. In addition, operator {\tt in} can be used to efficiently check if a set contains an element.
			
			Code shows how to use set data structure:
			\begin{verbatim}
				s = set()
				s.add(1)
				s.add(2)
				s.add(3)
				print(s) # {1, 2, 3}
				print(2 in s) # True
				s.remove(2)
				print(2 in s) # False
			\end{verbatim}
			Each element can appear at most once in a set:
			\begin{verbatim}
				s = set()
				s.add(5)
				s.add(5)
				s.add(5)
				print(s) # {5}
			\end{verbatim}
			{\bf Dictionaries.} A dictionary consists of key-value pairs which can be efficiently accessed through keys. Dictionaries can be created using \verb|{}| syntax, \& values can be accessed using {\tt[]} syntax.
			
			Code shows how to use dictionary data structure:
			\begin{verbatim}
				d = {}
				d["monkey"] = 1
				d["banana"] = 2
				d["harpsichord"] = 3
				print("banana" in d) # True
				print(d["banana"]) # 2
			\end{verbatim}
			Unlike in C++, there are no default values. E.g., following code does not work because dictionary does not have key ``monkey''.
			\begin{verbatim}
				d = {}
				print(d["monkey"]) # KeyError: 'monkey'
			\end{verbatim}
			However, there is another data structure {\tt defaultdict} that has default values for missing keys. E.g., can define a dictionary with type {\tt int} that works as follows:
			\begin{verbatim}
				from collections import defaultdict
				d = defaultdict(int)
				print(d["monkey"]) # 0
				d["monkey"] += 1
				print(d["monkey"]) # 1
			\end{verbatim}
			Only immutable values, e.g. members, strings \& tuples, can be used as keys in Python sets \& dictionaries. E.g., code does not work because a list is not immutable:
			\begin{verbatim}
				s = set()
				s.add([1, 2, 3]) # TypeError
			\end{verbatim}			
			\item {\sf16.2.3. Priority Queues.} Module {\tt heapq} has functions that perform binary heap operations on a list. 1st element of list is minimum element. Function {\tt heappush} adds an element to heap, \& function {\tt heappop} removes \& returns minimum element. Using those functions, can use lists as priority queues.
			
			Code shows how functions can be used:
			\begin{verbatim}
				from heapq import heappush, heappop
				q = []
				heappush(q, 2)
				heappush(q, 1)
				heappush(q, 4)
				heappush(q, 3)
				print(q[0]) # 1
				heappop(q)
				print(q[0]) # 2
			\end{verbatim}
			Both functions {\tt heappush, heappop} work in $O(\log n)$ time. In addition, function {\tt heapify} can be used to convert a list to a heap in $O(n)$ time. Function can be used as follows:
			\begin{verbatim}
				from heapq import heapify
				q = [2, 1, 4, 3]
				heapify(q)
				print(q) # [1, 2, 4, 3]
			\end{verbatim}
		\end{itemize}
		\item {\sf16.3. Coping Without Binary Search Trees.} Python standard library does not have binary search tree data structures. Thus, there are no equivalents for C++ data structures {\tt set, map} in Python.
		
		Using binary search tree data structures, can maintain a set where possible to efficiently find minimum \& maximum elements \& also process queries like ``what is smallest element larger than $x$'' or ``what is largest element smaller than $x$''. In Python, such features are not available in standard library.
		
		Fortunately, even if it would seem at 1st glance: a problem requires binary search trees, can often solve problem using an alternative way that only requires tools included in Python standard library, e.g. sorting, hash structures \& priority queues.
		\begin{itemize}
			\item {\sf16.3.1. Minimum Queries.} 1st consider situation where would like to use a data structure that has following operations:
			\begin{itemize}
				\item add an element to set
				\item remove an element from set
				\item find minimum element in set
			\end{itemize}
			Turn out: can create such a data structure using 2 Python data structures: a set \& a priority queue. When an element is added, add it to both data structures. When an element is removed, remove it only from set because not possible to remove arbitrary elements from a priority queue.
			
			Most interesting operation in data structure is finding minimum element. Priority queue can be used to find minimum element, but it can contain elements that have already been removed. For this reason, as long as minimum element in priority queue is not in set anymore, remove it also from priority queue. Then, when find an element that is also in set, return it.
			
			Can implement operations as follows:
			\begin{verbatim}
				def add(x):
				    s.add(x)
				    heappush(q, x)
				def remove(x):
				    s.remove(x)
				def find_min():
				    while q[0] not in s:
				        heappop(q)
				    return q[0]
			\end{verbatim} 
			Using this implementation, \verb|find_min| function may need to remove a large number of elements from priority queue before returning actual minimum element. However, every element that is added to set is removed at most once. For this reason, each function works efficiently on average.
			
			Note: previously used as similar trick for implementing Dijkstra's algorithm using a C++ priority queue (Sect. 7.3.2).
			\item {\sf16.3.2. Example Problem.} While can support minimum \& maximum queries using a combination of a set \& a priority queue, there is no easy way to process queries like ``what is smallest element $> x$''. However, if would need such queries in a problem, there may still be a way to avoid them using an alternative approach.
			
			Consider problem from CSES Problem Set:
			\begin{problem}
				There are $n$ concert tickets available, each with a certain price. Then, $m$ customers arrive, one after another.
				
				Each customer announces the maximum price they are willing to pay for a ticket, \& after this, they will get a ticket with nearest possible price such that it does not exceed the maximum price.
				\item {\sf Input.} 1st input line contains $n,m\in\mathbb{N}$: number of tickets \& number of customers. The next line contains $n$ integers $h_1,h_2,\ldots,h_n$: the price of each ticket. The last line contains $m$ integers $t_1,t_2,\ldots,t_m$: the maximum price for each customer in the order they arrive.
				\item {\sf Output.} Print, for each customer, the price that they will pay for their ticket. After this, ticket cannot be purchased again. If a customer cannot get any ticket, print $-1$.
				\item {\sf Constraints.} $1\le m,n\le 2\cdot10^5$, $1\le h_i,t_i\le10^9$.
			\end{problem}
			In C++, could use a {\tt multiset} for solving problem. 1st, could add all ticket prices to set \& then efficiently find ticket price for each customer. To find ticket price, could use \verb|upper_bound| function to find smallest ticket price that is too large \& then choose prev element in set which is desired ticket price.
			
			To solve problem in Python, have to design another solution that does not require maintaining a set of ticket prices with efficient queries for finding ticket price for a customer. Turn out: this problem is easier to solve if change order customers are processed \& create an offline solution.
			
			Idea: create a list of events. There are 2 types of events: (1) a customer wants to buy a ticket whose price is $\le x$ \& (2) there is a new ticket available with price $x$. Sort list in descending order by ticket price, \& then process events 1 by 1. In addition, maintain a priority queue that contains customers who have already requested a ticket. Customers are sorted by arrival time in priority queue.
			
			When process an event of type 1, add customer to priority queue. When process an event of type 2, remove customer with minimum arrival time from priority queue \& give ticket to that customer. If there are no customers in priority queue, nobody will get ticket. After have processed all events, can report ticket price for each customer.
			
			There is a linear number of events \& can efficiently process each event using priority queue, which results in an efficient algorithm.
		\end{itemize}
		\item {\sf16.4. Recursive Functions.} Consider recursive Python function that computes factorial of $n$:
		\begin{verbatim}
			def factorial(n):
			    if n == 0:
			        return 1
			    return factorial(n - 1) * n
		\end{verbatim}
		For small numbers, function works fine:
		\begin{verbatim}
			print(factorial(0)) # 1
			print(factorial(2)) # 2
			print(factorial(5)) # 120
			print(factorial(9)) # 362880
		\end{verbatim}
		However, cannot compute factorial of 1000:
		\begin{verbatim}
			print(factorial(1000)) # RecursionError
		\end{verbatim}
		Reason for this: maximum recursion depth in Python is quite small by default. Can increase limit by using {\tt sys.setrecursionlimit} functions as follows:
		\begin{verbatim}
			import sys
			sys.setrecursionlimit(5000)
			print(factorial(1000)) # 402387260077093773543702433923...
		\end{verbatim}
		
		\begin{itemize}
			\item {\sf16.4.1. Dynamic Programming.} Can often use dynamic programming to make a recursive function efficient. A recursive function that calculates Catalan numbers (Sect. 11.2.2):
			\begin{verbatim}
				def catalan(n):
				    if n == 0:
				        return 1
				    s = 0
				    for i in range(n):
				        s += catalan(i) * catalan(n - i - 1)
				    return s
			\end{verbatim}
			For small numbers, function works fine:
			\begin{verbatim}
				print(catalan(2)) # 2
				print(catalan(3)) # 5
				print(catalan(5)) # 42
			\end{verbatim}
			However, for larger numbers function is slow because number of recursive calls is too large.
			\begin{verbatim}
				print(catalan(100)) # too slow
			\end{verbatim}
			A way to make function efficient using DP:
			\begin{verbatim}
				def catalan(n, d={}):
				    if n == 0:
				        return 1
				    if n not in d:
				        s = 0
				        for i in range(n):
				            s += catalan(i) * catalan(n - i - 1)
				        d[n] = s
				    return d[n]
			\end{verbatim}
			Function uses a dictionary to store its return values \& it makes recursive calls only once for each parameter. After this modification, function is efficient:
			\begin{verbatim}
				print(catalan(100)) # 896519947090131496687170070074...
			\end{verbatim}
			Note how each function call uses same dictionary to store results, which is given as a parameter. In Python, if a function parameter has a default value which creates a data structure, each function call that uses default value uses same data structure.
			
			In above situation this feature is useful but it can sometimes cause confusion. E.g., consider following code:
			\begin{verbatim}
				def test(t=[]):
				    t.append(1)
				    print(t)
				test() # [1]
				test() # [1, 1]
				test() # [1, 1, 1]
			\end{verbatim}
			One could think: each function call adds an element to an empty list. However, in reality each function call adds an element to same list.
			\item {\sf16.4.2. Cache Decorator.} In Python there is also a built-in way to store function results \& create efficient dynamic programming solutions. Module {\tt functools} has a decorator {\tt cache} that can be used as follows [{\tt cache} decorator was recently added to Python. Older Python versions have a similar decorator \verb|lru_cache(maxsize=None)|.]
			\begin{verbatim}
				import functools
				@functools.cache
				def catalan(n):
				    if n == 0:
				        return 1
				    s = 0
				    for i in range(n):
				        s += catalan(i) * catalan(n - i - 1)
				    return s
			\end{verbatim}
			Using decorator, function return values for different parameters are stored automatically \& previously calculated value is returned if function is called again with same parameter.
		\end{itemize}
		\item {\sf16.5. Efficiency.} In this sect, compare efficiency of 2 Python implementations (CPython \& PyPy) \& C++. CPython is standard Python implementation which is most common way to execute Python code. PyPy is an alternative Python implementation which includes a just-in-time compiler \& is often faster.
		\begin{itemize}
			\item {\sf16.5.1. Finding Primes.} In 1st experiment, count number of primes between 2 \& $n$ using sieve of Eratosthenes. Python code used in experiment:
			\begin{verbatim}
				sieve = [0]*(n+1)
				count = 0
				for i in range(2, n+1):
				    if sieve[i]:
				        continue
				    count += 1
				    for j in range(2*i, n+1, i):
				        sieve[j] = 1
				print(count)
			\end{verbatim}
			Corresponding code in C++:
			\begin{verbatim}
				vector<int> sieve(n+1);
				int count = 0;
				for (int i = 2; i <= n; i++) {
				    if (sieve[i]) continue;
				    count++;
				    for (int j = 2*i; j <= n; j += i) {
				        sieve[j] = 1;
				    }
				}
				cout << count << "\n";
			\end{verbatim}
			{\sf Table 16.1: Results of prime counting experiment} shows results of experiment. It can be seen: PyPy \& C++ are much faster than CPython in large tests. However, difference between PyPy \& C++ is quite small.
			\item {\sf16.5.2. Counting Permutations.}
		\end{itemize}
	\end{itemize}
	\item {\sf17. Preparing for IOI.}
	\item {\sf18. Future of Competitive Programming.}
	\item {\sf Appendix: Mathematical Background.}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{\cite{Wu_Wang2016}. {\sc Yonghui Wu, Jiande Wang}. Data Structure Practice for Collegiate Programming Contests \& Education}

\begin{itemize}
	\item {\sf Amazon review.} Combining knowledge with strategies, {\it Data Structure Practice for Collegiate Programming Contests \& Education} presents 1st comprehensive book on data structure in programming contests. This book is designed for training collegiate programming contest teams in nuances of data structure \& for helping college students in computer-related majors to gain deeper understanding of data structure.
	
	Based on successful experiences in many world-level contests, book includes 204 typical problems \& detailed analyzes selected from ACM International Collegiate Programming Contest \& other major programming contests since 1990. It is divided into 4 sects that focus on:
	\begin{itemize}
		\item Fundamental programming skills
		\item Experiments for linear lists
		\item Experiments for trees
		\item Experiments for graphs
	\end{itemize}
	Each chap contains a set of problems \& includes hints. Book also provides test data for most problems as well as sources \& IDs for online judgments that help with improving programming skills.
	
	Introducing a multi-options model \& considerations of context, {\it Data Structure Practice for Collegiate Programming Contests \& Education} encourages students to think creatively in solving programming problems. By taking readers through practical contest problems from analysis to implementation, it provides a complete source for enhancing understanding \& polishing skills in programming.
	
	{\sf Author Author.} {\sc Yonghui Wu} was coach of Fudan University programming contest teams 2001--2011. Under his guidance, Fudan University qualified for Association for Computing Machinery International Collegiate Programming Contest (ACM-ICPC) World Finals every year, winning 3 medals during that span: bronze medal in 2002, silver medal in 2005, \& bronze medal in 2010. Since 2012, he has published a series of books for programming contests \& education. He is now chair of ICPC Asia Programming Contest 1st Training Committee.
	
	{\sc Jian-De Wang} is a famous coach for Olympiad in Informatics in China. Under his guidance, his students have won 7 gold medals, 3 silver medals, \& 2 bronze medals for China in International Olympiad in Informatics. He has published 24 books for programming contests.
	\item {\sf Preface.} Since 1990s, ACM International Collegiate Programming Contest (ACM-ICPC) has become a worldwide programming contest. Every year, $> 10000$ students \& $> 1000$ universities participate in local contests, preliminary contests, \& regional contests all over world. In meantime, programming contests' problems from all over world can be gotten, analyzed, \& solved by us. These contest problems can be used not only for programming contest training, but also for education.
	
	In our opinion, not only a programming contestant's ability, but also a computer student's ability is based on his or her programming knowledge system \& programming strategies for solving problems. Programming knowledge system can be summarized as a famous formula: algorithms $+$ data structures $=$ programs. It is also foundation for knowledge system of CS \& engineering. Strategies solving problems are strategies for data modeling \& algorithm design. When data models \& algorithms for problems are not standard, what strategies should take to solve these problems?
	
	Based on ACM-ICPC, published a series of books, not only for systematic programming contest training, but also for better polishing computer students' programming skill, using programming contests' problems: ``Data Structure Experiment: For Collegiate Programming Contest \& Education'', ``Algorithm Design Experiment: For Collegiate Programming Contest \& Education'', \& ``Programming Strategies Solving Problems'' in Mainland China. \& traditional Chinese versions for ``Data Structure Experiment: For Collegiate Programming Contest \& Education'' \& ``Programming Strategies Solving Problems'' were also published in Taiwan.
	
	``Data Structure Practice: For Collegiate Programming Contests \& Education'' is English version for ``Data Structure Experiment: For Collegiate Programming Contest \& Education''. There are 4 sects, 14 chaps, \& 200 programming contest problems in this book. Sect. I, ``Fundamental Programming Skills'', focused on experiments \& practices for simple computing, simple simulation, \& simple recursion, for students just learning programming languages. Sect. II, ``Experiments for Linear Lists'', Sect. III, ``Experiments for Trees'', \& Sect. IV ``Experiments for Graphs'', focus on experiments \& practices for data structure.
	
	Characteristics of book:
	\begin{enumerate}
		\item Book's outlines are based on outlines of data structures. Programming contest problems \& their analyzes \& solutions are used as experiments. For each chap, there is a ``Problems'' sect to let students solve programming contests' problems, \& hints for these problems are also shown.
		\item Problems in book are all selected from ACM-ICPC regional \& world finals programming contests, universities' local contests, \& online contests, \& from 1990--now.
		\item Not only analyzes \& solutions or hints to problems are shown, but also test data for most of problems are provided. Sources \& IDs for online judges for these problems are also given. They can help readers better \& more easily polish their programming skills.
	\end{enumerate}
	Therefore, book can be used not only as an experiment book, but also for systematic programming contests' training.
	
	 Online judge systems for problems in this book:
	 \begin{itemize}
	 	\item Peking University Online Judge System [POJ] \url{http://poj.org/}
	 	\item Zhejiang University Online Judge System [ZOJ] \url{http://acm.zju.edu.cn/onlinejudge/}
	 	\item UVA Online Judge System [UVA] \url{http://uva.onlinejudge.org/}
	 	\item \url{http://livearchive.onlinejudge.org/}
	 	\item Ural Online Judge System [Ural] \url{http://acm.timus.ru/}
	 	\item SGU Online Judge System [SGU] \url{http://acm.sgu.ru/}
	 \end{itemize}
	\item {\sf SECT. I: FUNDAMENTAL PROGRAMMING SKILLS.} Programming language is an introductory course of data structures \& algorithms. This course enables students to program by programming languages. Programming languages, data structures, \& algorithm designs are skills that computer students must polish. Therefore, polishing fundamental programming skills is 1st sect for this book. There are 3 chaps in Sect. I covering: 1. Computing. 2. Simulation. 3. Recursion. These 3 chaps are not only a review of programming languages, but also an introductory course on data structure.
	\begin{itemize}
		\item {\sf1. Practice for Simple Computing.} Pattern of a programming contest problem is input--process--output. A problem for simple computing is a problem whose process is simple. For such a problem, should only consider optimizing process \& dealing with input \& output correctly. Goals of Chap. 1:
		\begin{enumerate}
			\item Students master C{\tt/}C++ or Java programming language.
			\item Students become familiar with online judge systems \& programming environments.
			\item Students begin to learn how to transfer a practical problem into a computing process, implement computing process by a program, \& debug program to pass all test cases.
		\end{enumerate}
		``God is in details.'' In Chap. 1, problems are relatively simple. Should notice formats of input \& output, precision, \& time complexity. Therefore, following topics are discussed in this chap:
		\begin{enumerate}
			\item Programming style
			\item Multiple test cases
			\item Precision of real numbers
			\item Improving time complexity by dichotomy (sự phân đôi, not đĩ chó Tố My)
		\end{enumerate}
		Normally, a complex problem consists of several subproblems for simple computing. ``Even longest journey begins with a single step.'' Polishing programming skills should begin with solving simple computing problems.
		\begin{itemize}
			\item {\sf1.1. Improving Programming Style.} A program's writing style is not only for its visual sense, but also for examining program \& debugging its errors. A program's style also shows whether its programming idea is clear. Hard to say which kind of programming style is good, but there are some rules for programming style. They are discussed in following experiments.
			\begin{problem}[Financial Management]
				{\sc Larry} graduated this year \& finally has a job. He's making a lot of money, but somehow never seems to have enough. {\sc Larry} has decided: need to get a hold of his financial portfolio \& solve his financial problems. 1st step: figure out what's been going on with his money. {\sc Larry} has his bank account statements \& wants to see how much money he has. Help {\sc Larry} by writing a program to take his closing balance from each of past 12 months \& calculate his average account balance.
				\begin{itemize}
					\item {\bf Input.} Input will be 12 lines. Each line will contain closing balance of his bank account for a particular month. Each number will be positive \& displayed to penny. No dollar sign will be included.
					\item {\bf Output.} Output will be a single number, average (mean) of closing balances for 12 months. It will be rounded to nearest penny, preceded immediately by a dollar sign, \& followed by end of line. There will be no other spaces or characters in output.
					\item Source: ACM Mid-Atlantic United States 2001.
					\item IDs for online judges: POJ 1004, ZOJ 1048, UVA 2362.
				\end{itemize}
			\end{problem}
			{\it Analysis.} Problem's pattern, input--process--output, is very simple: 1st, income of 12 months {\tt a[0..11]} is input by a for statement {\tt for(i=0; i < 12; i++)}, \& total income $sum = \sum_{i=0}^{11} a[i]$ is calculated. Then average monthly income $avg = \frac{sum}{12}$ is calculated. Finally, $avg$ is output in accordance with problem's output format.
			
			From above program, can get: 1st, input \& output of program must meet formats for input \& output. In this problem, each input number will be positive \& displayed to penny, \& output will be rounded to nearest penny, preceded immediately by a dollar sign \& followed by an end of line. If program doesn't meet formats for input \& output, it will be judged as wrong answer.
			
			2nd, a program should be readable. Style of a program should be serration based on a logical level.
			
			Finally, program annotations should be given
			\item {\sf1.2. Multiple Test Cases.} Financial management problem (Sect. 1.1.1) has only 1 test case. In order to guarantee correctness of a program, for most problems there are multiple test cases. In some circumstances, number of test cases is given; in other circumstances, number of test cases isn't given, but mark of input end is given.
			\begin{problem}[Doubles]
				As part of an arithmetic competency program, your students will be given randomly generated lists of 2--15 unique positive integers \& asked to determine how many items in each list are twice some other item in same list. Will need a program to help you with grading. This program should be able to scan lists \& output correct answer for each one. E.g., given list {\tt 1 4 3 2 9 7 18 22}, your program should answer 3, as 2 is twice 1, 4 is twice 2, \& 18 is twice 9.
				\item {\bf Input.} Input file will consist of 1 or more lists of numbers. There will be 1 list of numbers per line. Each list will contain from 2--15 unique positive integers. No integer will be $> 99$. Each line will be terminated with integer 0, which is not considered part of list. A line with single number $-1$ will mark end of file. Example input below shows 3 separate lists. Some lists may not contain any doubles.
				\item {\bf Output.} Output will consist of 1 line per input list, containing a count of items that are double some other item.
				\item Source: ACM Mid-Central United States 2003.
				
				IDs for online judges: POJ 1552, ZOJ 1760, UVA 2787.
			\end{problem}
			{\it Analysis.} There are multiple test cases for problem. Therefore, a loop statement is used to deal with multiple test cases. Loop enumerates every test case. $-1$ marks end of input. Therefore, $-1$ is end condition of loop. In loop statement, there are 2 steps:
			\begin{enumerate}
				\item A loop inputs a test case into array {\tt a} \& accumulates number of elements $n$ in test case. 0 marks end of test case.
				\item A double loop enumerates all pairs of $a[i]$ \& $a[j]$ ($0\le i < n - 1,i + 1 \le j < n$) in test case \& determines whether {\tt(a[i]*2 == a[j] || a[j]*2 == a[i])} holds.
			\end{enumerate}
			In this problem, number of test cases \& size of a test case are unknown. Normally, a double-loop statement is used for program structure: outer loop is used to enumerate every test case, \& inner loop is used to deal with a test case.
			
			In some problems, if size of test data is larger, all test cases are dealt with by same method, \& result area is known, its time complexity can be improved by an offline method. 1st, all solutions within specified range are calculated \& stored in a constant array. Then program deals with constant array directly for each test case. It can avoid duplication of computing.
			\begin{problem}[Sum of consecutive prime numbers]
				Some positive integers can be represented by a sum of 1 or more consecutive prime numbers. How many such representations does a given positive integer have? E.g., integer $53$ has 2 representations $5 + 7 + 11 + 13 + 17$ \& $53$. Integer $41$ has 3 representations: $2 + 3 + 5 + 7 + 11 + 13$, $11 + 13 + 17$, \& $41$. Integer $3$ has only 1 representation, which is $3$. Integer $20$ has no such representations. Note: summands must be consecutive prime numbers, so neither $7 + 13$ nor $3 + 5 + 5 + 7$ is a valid representation for integer $20$. Your mission: write a program that reports number of representations for given positive integer.
				\item {\bf Input.} Input is a sequence of positive integers, each in a separate line. Integers are between $2$ \& $10000$, inclusive. End of input is indicated by a $0$.
				\item {\bf Output.} Output should be composed of lines each corresponding to an input line, except last $0$. An output line includes number of representations for input integer as sum of 1 or more consecutive prime numbers. No other character should be inserted in output.
				\item Source: ACM Japan 2005.
				
				IDs for online judges: POJ 2739, UVA 3399.
			\end{problem}
			{\it Analysis.} Because program needs to deal with consecutive prime numbers for each test case, \& upper limit of prime numbers is $10000$, offline method can be used to solve problem. 1st, all prime numbers $< 10001$ are obtained \& stored in array {\tt prime[1 .. total]} in ascending order. Then deal with test cases 1 by 1: Suppose input number is $n$; sum of consecutive prime numbers is {\tt cnt}; number of representation for {\tt cnt == n} is {\tt ans}. A double loop is used to get number of representations for $n$:
			\begin{itemize}
				\item Outer loop $i$: {\tt for(int i = 0; n >= prime[i]; i++)} enumerates all possible minimum {\tt prime[i]}.
				\item Inner loop $j$: \verb|for(int j = i; j < total && cnt < n; j++), cnt += prime[j]|, is to calculate sum of consecutive prime numbers. If ${\tt cnt}\ge n$, then loop ends, \& if {\tt cnt == n}, then number of representations is {\tt ans++}.
			\end{itemize}
			When outer loop ends, {\tt ans} is solution to test case.
		\end{itemize}
		\item {\sf2. Simple Simulation.} In real world, there are many problems that we can solve by simulating their processes. Such problems are called simulation problems. For these problems, solution procedures \& rules are showed in problem descriptions. Programs must simulate procedures or implement rules based on descriptions.
		
		Normally there are 2 kinds of simulations: stochastic simulation \& process simulation.
		
		Problems for stochastic simulation show or imply probabilities. Programmers make use of random functions \& round functions to set random value for a range, making random value meet probability as a parameter. Then programmers design algorithm by simulating mathematical model. Because of uncertainty, there are fewer problems for stochastic simulation in programming contests.
		
		Problems for process simulation require programmers to design parameters for mathematical models, \& to observe changes of states caused by parameters. Programmers design algorithms based on process simulation. Programs depend entirely on authenticity \& correctness of process simulation without any uncertainties.
		
		This chap focuses on process simulation. There are 3 kinds of process simulation:
		\begin{enumerate}
			\item Simulation of direct statement
			\item Simulation by sieve method
			\item Simulation by construction
		\end{enumerate}
		
		\begin{itemize}
			\item {\sf2.1. Simulation of Direct Statement.} For problems for simulation of direct statement, programmers are required to solve them by strictly following rules showed in problem's descriptions. Programmers must read such problems carefully \& simulate processes based on descriptions. A problem for simulation of direct statement gets harder as number of rules increases. It causes amount of code to grow \& become more illegible.
		\end{itemize}
		\item {\sf3. Simple Recursion.}
		\item {\sf Summary of Sect. I.}
	\end{itemize}
	\item {\sf SECT. II: EXPERIMENTS FOR LINEAR LISTS.}
	\begin{itemize}
		\item {\sf4. Linear Lists Accessed Directly.}
		\item {\sf5. Applications of Linear Lists for Sequential Access.}
		\item {\sf6. Generalized List Using Indexes.}
		\item {\sf7. Sort of Linear Lists.}
		\item {\sf Summary of Sect. II.}
	\end{itemize}
	\item {\sf SECT. III: EXPERIMENTS FOR TREES.}
	\begin{itemize}
		\item {\sf8. Programming by Tree Structure.}
		\item {\sf9. Applications of Binary Trees.}
		\item {\sf10. Applications of Classical Trees.}
	\end{itemize}
	\item {\sf SECT. IV: EXPERIMENTS FOR GRAPHS.}
	\begin{itemize}
		\item {\sf11. Applications of Graph Traversal.}
		\item {\sf12. Algorithms of Minimum Spanning Trees.}
		\item {\sf13. Algorithms of Best Paths.}
		\item {\sf14. Algorithms of Bipartite Graphs \& Flow Networks.}
		\item {\sf Summary of Sect. IV.}
	\end{itemize}
\end{itemize}

%------------------------------------------------------------------------------%

\subsection{\cite{Wu_Wang2018}. {\sc Yonghui Wu, Jiande Wang}. Algorithm Design Practice for Collegiate Programming Contests \& Education}

\begin{itemize}
	\item {\sf Amazon review.} This book can be used as an experiment \& reference book for algorithm design courses, as well as a training manual for programming contests. It contains 247 problems selected from ACM-ICPC programming contests \& other programming contests. There's detailed analysis for each problem. All problems, \& test datum for most of problems will be provided online. Content will follow usual algorithms syllabus, \& problem-solving strategies will be introduced in analyses \& solutions to problem cases. For students in computer-related majors, contestants \& programmers, this book can polish their programming \& problem-solving skills with familarity of algorithms \& mathematics.
	
	{\sf Author Author.} Dr. {\sc Yonghui Wu} serves as Associate Professor at the school of CS in Fudan University, China. He acted coach of Fudan University Programming Contest teams from 2001 to 2011. Under his guidance Fudan University was qualified for ACM ICPC World Finals every year \& won 3 medals (bronze medal in 2002, silver medal in 2005, \& bronze medal in 2010) in ACM ICPC World Finals. Since 2012, he has published a series of books for programming contest \& education in China covering datastructures, algorithms \& strategies, which are warmly welcomed not only in Mainland China, but also in Taiwan, Hongkong, Singapore, \& other Chinese speaking areas. He just published his 1st book's English version: {\it Data Structure Practice: for Collegiate Programming Contests \& Education} with CRC Press. Since 2013, he has been giving lectures in Oman, Taiwan \& the United States for programming contest training. He is currently chair of ICPC Asia Programming Contest 1st Training Committee.
	\item {\sf Preface.} Programming contests are contests solving problems by programming. Starting in 1990s, ACM International Collegiate Programming Contest (ACM-ICPC) has become a worldwide programming contest. Every year, 6 continents, over 110 countries, 50000 students, 5000 coaches, \& 3000 universities participate in ACM-ICPC local contests, preliminary contests, \& regional contests all over world. Alongside, some international programming contests, e.g. Google Code Jam, TopCoder Open Algorithm, Facebook Hacker Cup, Internet Problem Solving Contest (IPSC), \& so on, are held every year. Programmers from all over world, in addition to students, can participate in these contests through Internet.
	
	Based on these programming contests, programming contests' problems from all over world can be obtained, analyzed, \& solved by students. These contest problems can be used not only for programming contest training, but also for education.
	
	In our opinion, not only programming contestants' ability to solve problems, but also computer students' programming skills are based on their programming knowledge system \& programming strategies for solving problems. Programming knowledge system can be summarized as ``Algorithms $+$ Data Structures $=$ Programs.'' Also foundation for knowledge system of CS \& engineering. Strategies for solving problems are strategies for data modeling \& algorithm design. When data models \& algorithms for problems are not standard, need to take some strategies to solve these problems.
	
	Based on these facts, published a series of books, not only for systematic programming contest training, but also for polishing computer students' programming skill better, using programming contests problems: {\it Data Structure Experiment for Collegiate Programming Contest \& Education, Algorithm Design Experiment for Collegiate Programming Contest \& Education, \& Programming Strategies Solving Problems} in Mainland China. \& traditional Chinese version for {\it Data Structure Experiment for Collegiate Programming Contest \& Education, \& Programming Strategies Solving Problems} were also published in Taiwan. In 2016, 1st book's English version {\it Data Structure Practice: for Collegiate Programming Contest \& Education} was published by CRC Press.
	
	{\it Algorithm Design Practice for Collegiate Programming Contest \& Education} is English version for {\it Algorithm Design Experiment for Collegiate Programming Contest \& Education}. There are 9 chaps \& 247 programming contest problems in this book.
	\begin{itemize}
		\item Chap. 1: ``Practice for Ad Hoc Problems'', focuses on solving problems that there are no classical algorithms to solve. There are 2 methods to solve such problems: mechanism analysis method \& statistical analysis method.
		\item Chap. 2: ``Practice for Simulation Problems'', experiments \& practices for simulation problems are shown. In problem descriptions, solution procedures or rules are shown. Simulation problems are solved by implementing rules or simulating solution procedures.
		\item Chap. 3: ``Practice for Number Theory'', Chap. 4: ``Practice for Combinatorics'', \& Chap. 8: ``Practice for Computational Geometry'', introduce mathematical background for number theory, combinatorics, \& computational geometry, resp., \& then show problems solved by mathematical methods. Greedy algorithms \& DP are used to solve optimization problems.
		\item Chap. 5: ``Practice for Greedy Algorithms'', \& Chap. 6, ``Practice for DP'', introduce greedy algorithms \& DP resp., \& show problems solved by greedy algorithms \& DP.
		\item Chap. 7: ``Practice for Advanced Data Structures'', describes using suffix arrays, segment trees, \& some graph algorithms to solve problems. Search technologies are fundamental to CS \& technology.
		\item Chap. 9: ``Practice for State Space Search'', describes implementation of state space search through solving contest problems.
	\end{itemize}
	Feature of book:
	\begin{enumerate}
		\item Book's outlines are based on outlines of algorithms. Programming contest problems \& their analyses \& solutions are used as experiments. For each chap, there is a ``Problems'' sect to let students solve programming contests' problems, \& hints for these problems are also included.
		\item Problems in book are all selected from ACM-ICPC regional \& world finals programming contests, universities' local contests, \& online contests, from 1990 to now.
		\item Not only analyses \& solutions, or hints to problems are shown, but also test data for most of problems are provided. Sources \& IDs for Online Judge for these problems are also provided. This can help readers polish their programming skills better \& more easily.
	\end{enumerate}
	Book can be used not only as an experiment book, but also for training for systematic programming contests.
	\item {\sf1. Practice for Ad Hoc Problems.} Ad hoc means ``for special purpose or end presently under consideration.'' (cho mục đích đặc biệt hoặc mục đích hiện đang được xem xét) there are no classical algorithms that can solve these ad hoc problems. Programmers need to design specific algorithms to solve ad hoc problems. There are 2 strategies to design algorithms for solving ad hoc problems: mechanism analysis \& statistical analysis.
	
	To solve an ad hoc problem, need to see past its appearance \& understand its essence. In this chap, 2 kinds of analyses solving ad hoc problems are shown: Mechanism Analysis \& Statistical Analysis.
	\begin{itemize}
		\item {\sf1.1. Solving Problems by Mechanism Analysis.} Mechanism analysis examines characteristics \& internal mechanisms of an object to find a mathematical representation of problem. Therefore, key to mechanism analysis is mathematical modeling. Solving problems by mechanism analysis is a top-down method.
		\item {\sf1.2. Solving Problems by Statistical Analysis.} Unlike mechanism analysis, statistical analysis begins with a partial solution to problem, \& overall global solution is found based on analyzing partial solution. Solving problems by statistical analysis is a bottom-up method.
	\end{itemize}
	\item {\sf2. Practice for Simulation Problems.}
	\item {\sf3. Practice for Number Theory.}
	\item {\sf4. Practice for Combinatorics.}
	\item {\sf5. Practice for Greedy Algorithms.}
	\item {\sf6. Practice for Dynamic Programming.}
	\item {\sf7. Practice for Advanced Data Structures.}
	\item {\sf8. Practice for Computational Geometry.}
	\item {\sf9. Practice for State Space Search.}
	\item {\sf Bibliography.}
\end{itemize}

%------------------------------------------------------------------------------%

\section{Conda}

\subsection{Should I use Anaconda Distribution or Miniconda?}
\url{https://docs.anaconda.com/distro-or-miniconda/}. Both Anaconda Distribution \& Miniconda installers include conda package \& environment manager, but how you plan to use software will determine which installer you want to choose. {\sf Table of Cfs.}

\noindent{\bf What's your experience level?}
\begin{itemize}
	\item {\it I'm just starting out \& don't know what packages I should use.} Install Anaconda Distribution! It includes over \href{https://docs.anaconda.com/anaconda/release-notes/}{300 standard DS \& ML packages}, which will give you a kickstart in your development journey.
	\item {\it I don't have much experience with the command line.} Install Anaconda Distribution! The install includes Anaconda Navigator, a desktop application that is built on top of conda. You can use Navigator's graphical user interface (GUI) to create environments, install packages, \& launch development applications like Jupyter Notebooks \& Spyder. For more information on Navigator, see \href{https://docs.anaconda.com/navigator/getting-started/}{Getting started with Navigator}.
	\item {\it I know exactly what packages I want to use \& I don't want a large download.} Install Miniconda! Miniconda is a minimal installer that only includes a very small installation of Anaconda's distribution--conda, Python, \& a few other packages. For more information, see \href{https://docs.anaconda.com/miniconda/}{Miniconda documentation}.
	\item {\it I only use the command line.} Install Miniconda or Anaconda Distribution! Both installations include conda, the command line package \& environment manager. For more information on conda, see \href{https://conda.io/projects/conda/en/latest/user-guide/getting-started.html}{conda Getting Started page} or download \href{https://docs.conda.io/projects/conda/en/latest/user-guide/cheatsheet.html}{conda cheatsheet}.
\end{itemize}

\subsection{Anaconda Distribution}
{\it The Most Trusted Distribution for Data Science}. Anaconda Distribution is a Python{\tt/}R data science distribution that contains:
\begin{itemize}
	\item \href{https://docs.conda.io/en/latest}{conda} - a package \& environment manager for your command line interface
	\item \href{https://docs.anaconda.com/navigator/}{Anaconda Navigator} - a desktop application built on conda, with options to launch other development applications from your managed environments.
	\item \href{https://docs.anaconda.com/anaconda/release-notes/}{$> 300$ automatically-installed packages} that work well together out of box
	\item Access to \href{https://repo.anaconda.com/pkgs/}{Anaconda Public Repository}, with 8000 open-source DS \& ML packages
\end{itemize}

\subsubsection{System requirements}

\begin{itemize}
	\item License: Free for individuals \& small organizations ($< 200$ employees). A paid license is required for larger organizations \& anyone embedding or mirroring Anaconda. See \href{https://legal.anaconda.com/policies/en/}{TOS} for details.
	\item OS: Windows 10 or later, 64-bit macOS 10.15+ (for Intel) or 64-bit macOS 11.1+ (for Apple Silicon), or Linux, including Ubuntu, RedHat, CentOS 7+, \& others.
	\item If OS is older than what is currently supported, can find older versions of Anaconda installers in \href{https://repo.anaconda.com/archive/}{archive} that might work for you. See \href{https://docs.anaconda.com/anaconda/advanced-install/old-os/#older-versions-distro}{Using Anaconda on older OSs} for version recommendations.
	\item System architecture: Windows - 64-bit x86; MacOS - 64-bit x86 or Apple Silicon (ARM64); Linux - 64-bit x86, 64-bit aarch64 (AWS Graviton2), or s390x (Linux on IBM Z \& LinuxONE).
	\item {\tt linux-aarch64} Miniconda installer requires {\tt glibc >=2.26} \& thus will not work with CentOS 7, Ubuntu 16.04, or Debian 9 (``stretch'').
	\item {\tt linux-aarch64} package builds might not be compatible with certain Raspberry Pi setups, as Anaconda uses compiler options that target server-class Neoverse N1{\tt/}N2 microarchitecture.
	\item Minimum 5 GB disk space to download \& install.
\end{itemize}

\begin{remark}
	Best practice to install Anaconda Distribution for local user, which does not require administrator permissions \& is most robust type of installation. However, if have administrator permissions, can install Anaconda Distribution system-wide.
\end{remark}

\subsubsection{Installing Anaconda Distribution}
Provides instructions for installing Anaconda Distribution on Windows, macOS, \& Linux.

\begin{remark}
	If prefer an installation without extensive collection of packages included in Anaconda Distribution, install Miniconda instead.
	
	Miniconda is a free, miniature installation of Anaconda Distribution that includes only conda, Python, packages they both depend on, \& a small number of other useful packages.
\end{remark}

\begin{itemize}
	\item {\sf Basic install instructions.}
	
	\begin{remark}
		If you've installed multiple versions of Anaconda Distribution, system defaults to using most current version, as long as you haven't altered default install path.
	\end{remark}
	{\sf Linux installer.} Anaconder Navigator is included with Anaconda Distribution by default. However, following extended dependencies might be required for certain versions of Anaconda Distribution in order to use Anaconda Navigator (\& other GUI packages) with Linux:
	\begin{itemize}
		\item {\bf Debian.}
		\begin{verbatim}
			nqbh@nqbh-dell:~$ sudo apt-get install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6
			sudo: unable to resolve host nqbh-dell: Name or service not known
			[sudo] password for nqbh: 
			Reading package lists... Done
			Building dependency tree... Done
			Reading state information... Done
			Package libasound2 is a virtual package provided by:
			liboss4-salsa-asound2 4.2-build2020-1ubuntu3
			libasound2t64 1.2.11-1build2 (= 1.2.11-1build2)
			You should explicitly select one to install.
			
			Package libgl1-mesa-glx is not available, but is referred to by another package.
			This may mean that the package is missing, has been obsoleted, or
			is only available from another source
			
			E: Package 'libgl1-mesa-glx' has no installation candidate
			E: Unable to locate package libegl1-mesa
			E: Package 'libasound2' has no installation candidate
			
			nqbh@nqbh-dell:~$ curl -O https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh
		\end{verbatim}
		Ensure that you are downloading an installer that is compatible with your operating system!
		
		(Recommended) Verify the integrity of your installer to ensure that it was not corrupted or tampered with during download. To ensure that your downloaded installer has not been tampered with or corrupted, generate its SHA-256 hash value \& compare it to the official hash provided in \href{https://repo.anaconda.com/archive/}{archive}. E.g.,
		\begin{verbatim}
			nqbh@nqbh-dell:~$ shasum -a 256 ~/Anaconda3-2024.10-1-Linux-x86_64.sh
			3ba0a298155c32fbfd80cbc238298560bf69a2df511783054adfc151b76d80d8  /home/nqbh/Anaconda3-2024.10-1-Linux-x86_64.sh
		\end{verbatim}
		Note: generated SHA-256 hash value from the output. Visit \url{repo.anaconda.com/archive} to find the official SHA-256 hash for your installer. Compare the hash values. If they match, the installer is safe to use.
		
		Install Anaconda Distribution by running 1 of following commands (depending on your Linux architecture):
		\begin{verbatim}
			bash ~/Anaconda3-2024.10-1-Linux-x86_64.sh
		\end{verbatim}
		Press return to review license agreement \& hold return to scroll. Enter yes to agree to the license agreement.
		\begin{verbatim}
			Downloading \& Extracting Packages:
			
			Preparing transaction: done
			Executing transaction: done
			installation finished.
			Do you wish to update your shell profile to automatically initialize conda?
			This will activate conda on startup \& change the command prompt when activated.
			If you'd prefer that conda's base environment not be activated on startup,
			run the following command when conda is activated:
			
			conda config --set auto_activate_base false
			
			You can undo this by running `conda init --reverse $SHELL`? [yes|no]
			[no] >>>
			
			You have chosen to not have conda modify your shell scripts at all.
			To activate conda's base environment in your current shell session:
			
			eval "$(/home/nqbh/anaconda3/bin/conda shell.YOUR_SHELL_NAME hook)" 
			
			To install conda's shell functions for easier access, first activate, then:
			
			conda init
			
			Thank you for installing Anaconda3!
		\end{verbatim}
		Press return to accept default install location (\verb|PREFIX=/Users/<USER>/anaconda3|), or enter another file path to specify an alternate installation directory. Installation might take a few minutes to complete. Choose an initialization options:
		\begin{itemize}
			\item Yes - conda modifies your shell configuration to initialize conda whenever you open a new shell \& to recognize conda commands automatically.
			\item No - conda will not modify your shell scripts. After installation, if you want to initialize, you must do so manually. For more information, see \href{https://docs.anaconda.com/anaconda/install/#manual-shell-init-linux}{Manual Shell Initialization}.
		\end{itemize}
		Installer finishes \& displays, ``Thank you for installing Anaconda3!'' Close \& re-open your terminal window for the installation to fully take effect, or use the following command to refresh the terminal, depending on your shell: \verb|source ~/.bashrc|.
		
		{\bf Manual Shell Initialization.} Once installation has successfully completed, initialize your shell by running following command:
		\begin{verbatim}
			# Replace <PATH_TO_CONDA> with the path to your conda install
			source <PATH_TO_CONDA>/bin/activate
			conda init
			
			qbh@nqbh-dell:~$ source ~/anaconda3/bin/activate 
			(base) nqbh@nqbh-dell:~$ conda init
			no change     /home/nqbh/anaconda3/condabin/conda
			no change     /home/nqbh/anaconda3/bin/conda
			no change     /home/nqbh/anaconda3/bin/conda-env
			no change     /home/nqbh/anaconda3/bin/activate
			no change     /home/nqbh/anaconda3/bin/deactivate
			no change     /home/nqbh/anaconda3/etc/profile.d/conda.sh
			no change     /home/nqbh/anaconda3/etc/fish/conf.d/conda.fish
			no change     /home/nqbh/anaconda3/shell/condabin/Conda.psm1
			no change     /home/nqbh/anaconda3/shell/condabin/conda-hook.ps1
			no change     /home/nqbh/anaconda3/lib/python3.12/site-packages/xontrib/conda.xsh
			no change     /home/nqbh/anaconda3/etc/profile.d/conda.csh
			modified      /home/nqbh/.bashrc
			
			==> For changes to take effect, close \& re-open your current shell. <==
			
			(base) nqbh@nqbh-dell:~$
		\end{verbatim}
		
		\begin{remark}
			You can also control whether or not your shell has the base environment activated each time it opens. Following commands only work if conda has been initialized 1st:
			\begin{itemize}
				\item Activated by default: \verb|conda config --set auto_activate_base True|
				\item Not activated by default: \verb|conda config --set auto_activate_base False|
			\end{itemize}
		\end{remark}
		{\bf Verify install.} Anaconda Navigator, Graphical User Interface (GUI) for conda, should automatically open after successful installation of Anaconda Distribution. If it does not, verify your installation by opening the application manually, or by using the CLI:
		\begin{itemize}
			\item Opening Navigator manually: Open Navigator by running the following command: \verb|anaconda-navigator|
			\item Using conda to verify manually: Access the CLI for your operating system. You should see (base) in the command line prompt. This tells you that you're in your base conda environment. To learn more about environments, see \href{https://docs.anaconda.com/working-with-conda/environments/}{Environments}. Run any conda command, e.g.:
			\begin{itemize}
				\item {\tt conda list} - Displays a list of packages installed in your active environment \& their versions.
				\item {\tt anaconda-navigator} - Opens Anaconda Navigator.
			\end{itemize}
		\end{itemize}
	\end{itemize}
	\item {\sf Advanced install options.} For more advanced installation instructions, such as installing with silent mode, installing on older operating systems, or multi-user installs, see \href{https://docs.anaconda.com/anaconda/advanced-install/}{Advanced installation}.
	\item {\sf Other ways to get Anaconda or Miniconda.} For instructions on using Anaconda Docker images or the Anaconda Cloudera Distributed Hadoop cluster, see  \href{https://docs.anaconda.com/working-with-conda/applications/}{Applications{\tt/}Integrations}.
\end{itemize}

\subsubsection{Advanced installation}

\subsubsection{Getting started}
This document is here to help you get started with Anaconda Distribution, which includes conda \url{https://conda.io/en/latest/}, \href{https://docs.anaconda.com/navigator/}{Anaconda Navigator}, \& over 300 scientific \& machine learning packages.
\begin{itemize}
	\item {\sf Should I use Anaconda Navigator or conda?} Anaconda Navigator is a desktop application that is included with every installation of Anaconda Distribution. It is built on top of conda, open-source \& environment manager, \& allows you to manage your packages \& environments from a graphical user interface (GUI). This is especially helpful when you're not comfortable with command line.
	
	A command line interface (or CLI) is a program on your computer that processes text commands to do various tasks. Conda is a CLI program, which means it can only be used via command line. On Windows computers, Anaconda recommends: use Anaconda Prompt CLI to work with conda. MacOS \& Linux users can use their built-in command line applications.
	\begin{remark}
		If installed Miniconda instead of Anaconda Distribution, Anaconda Navigator is not included. Use command {\tt conda install anaconda-navigator} to manually install Navigator onto your computer.
	\end{remark}
	\item {\sf Free Anaconda Learning course - Get Started with Anaconda.} Learn to use Anaconda Navigator to launch an application. Then, create \& run a simple Python program with Spyder \& Jupyter Notebook. Watch short training videos on Anaconda Learning to get up \& running with Jupyter Notebook \& JupyterLab, along with several other popular integrated development environments (IDEs): \href{https://learning.anaconda.cloud/get-started-with-anaconda?utm_campaign=learning&utm_medium=documentation&utm_source=anacondadocs&utm_content=getstartedbutton}{Anaconda Learning}.
\end{itemize}

\subsubsection{Anaconda Distribution release notes}

\subsubsection{Uninstalling Anaconda Distribution}

\subsection{Miniconda}
\url{https://docs.anaconda.com/miniconda/}. Miniconda is a free, miniature installation of Anaconda Distribution that includes only conda, Python, packages they both depend on, \& a small number of other useful packages.

If need more packages, use {\tt conda install} command to install from thousands of packages available by default in Anaconda's public repo, or from other channels, like conda-forge or bioconda.

\subsubsection{Latest Miniconda installer links}
For latest Miniconda installers for Python 3.12, go to \url{https://www.anaconda.com/download/}. Miniconda installers are on same page as Anaconda Distribution installers, past registration.

For a list of Miniconda hashes \& an archive of Miniconda versions, including installers or older versions of Python, see \url{https://repo.anaconda.com/miniconda}.

\subsubsection{Quick command line install}

%------------------------------------------------------------------------------%

\section{\LaTeX}

\subsection{Overleaf{\tt/}glossaries}
``


'' -- \href{https://www.overleaf.com/learn/latex/Glossaries}{Overleaf{\tt/}glossaries}

%------------------------------------------------------------------------------%

\section{Linux}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Shotts2019}. {\sc William Shotts}. {\it The Linux Command Line: A Complete Introduction}.
\end{enumerate}
I used SUSE \& OpenSUSE in WIAS Berlin but I do not like them \& the like, so I go back to Ubuntu.

%------------------------------------------------------------------------------%

\section{Programming}

\subsection{C{\tt/}C++}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Ngoc_C}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình C}.
	\item \cite{Ngoc_C++}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình C++}.
	\item \cite{Stroustrup2013}. {\sc Bjarne Stroustrup}. {\it The C++ Programming Language}.
	\item \cite{Stroustrup2018}. {\sc Bjarne Stroustrup}. {\it A Tour of C++}.
\end{enumerate}

\subsection{Pascal}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Ngoc_Pascal}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình Pascal}.
	\item \cite{Ngoc_BT_Pascal}. {\sc Quách Tuấn Ngọc}. {\it Bài Tập Ngôn Ngữ Lập Trình Pascal}.
	\item \cite{Doanh_Tuan_Pascal}. {\sc Lê Văn Doanh, Trần Khắc Tuấn}. {\it101 Thuật Toán \& Chương Trình Bài Toán Khoa Học Kỹ Thuật \& Kinh Tế Bằng Ngôn Ngữ Turbo-Pascal}.
\end{enumerate}

\subsection{Python}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Duc_200_BT_Python}. {\sc Nguyễn Tiến Đức}. {\it Tuyển Tập 200 Bài Tập Lập Trình Bằng Ngôn Ngữ Python}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_1}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 1}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_2}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 2}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_3}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 3}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_4}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 4}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_5}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 5}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_6}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 6}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_7}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 7}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Software}

\subsection{FeNiCS}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Dokken_Mitusch_Funke2020}. {\sc J\o rgen S. Dokken}. {\it Automatic shape derivatives for transient PDEs in FEniCS \& Firedrake}.
	\item \cite{Langtangen_Logg2016}. {\sc Hans Petter Langtangen, Anders Logg}. {\it Solving PDEs in Python}.
\end{enumerate}

\subsection{Firedrake}

\subsection{Fireshape}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Paganini_Wechsung_Fireshape2020}. {\sc Alberto Paganini, Florian Wechsung}. {\it Fireshape Documentation, Release 0.0.1}.
	\item \cite{Paganini_Wechsung2020}. {\sc Alberto Paganini, Florian Wechsung}. {\it Fireshape: a shape optimization toolbox for Firedrake}.
\end{enumerate}

\subsection{Git}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Chacon_Straub2014}. {\sc Scott Chacon, Ben Straub}. {\it Pro Git}.
\end{enumerate}

\subsection{Gmsh}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Geuzaine_Remacle2009}. {\sc Christophe Geuzaine, Jean-Fran\c{c}ois Remacle}. {\it Gmsh: A 3D finite element mesh generator with built-in pre- \& post-processing facilities}.
\end{enumerate}

\subsection{OpenFOAM}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item There are 3 variants of OpenFOAM:
	\begin{enumerate}
		\item OpenFOAM.com: Commercial.
		\item OpenFOAM.org: Open-source with a large community.
		\item Extended OpenFOAM.
	\end{enumerate}
	\item \cite{Greenshields_Weller2022}. {\sc Christopher Greenshields, Henry Weller}. {\it Notes on Computational Fluid Dynamics: General Principles}.
	\item \cite{Towara_Naumann2013}. {\sc M. Towara, U. Naumann}. {\it A Discrete Adjoint Model for OpenFOAM}.
\end{enumerate}

\subsection{ParMooN}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{ParMooN2017}. {\sc Ulrich Wilbrandt, Clemens Bartsch, Naveed Ahmed, Volker John}. {\it ParMooN -- a modernized program package based on mapped finite elements}.
\end{enumerate}

\subsection{SU2}

\subsection{Sublime Text}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Bos2014}. {\sc Wes Bos}. {\it Sublime Text Power User: A Complete Guide}.
	\item \cite{Peleg2014}. {\sc Dan Peleg}. {\it Mastering Sublime Text}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{SymPy}

\subsection{Matrices}
A module that handles matrices. Includes functions for fast creating matrices like zero, one/eye, random matrix, etc.
\begin{itemize}
	\item {\sf Matrices (linear algebra).}
	\begin{itemize}
		\item {\sf Creating Matrices.} Linear algebra module is designed to be as simple as possible. 1st, import \& declare 1st {\tt Matrix} object:
		\begin{verbatim}
			>>> from sympy.interactive.printing import init_printing
			>>> init_printing(use_unicode=False)
			>>> from sympy.matrices import Matrix, eye, zeros, ones, diag, GramSchmidt
			>>> M = Matrix([[1,0,0], [0,0,0]]); M
			[1  0  0]
			[       ]
			[0  0  0]
			>>> Matrix([M, (0, 0, -1)])
			[1  0  0 ]
			[        ]
			[0  0  0 ]
			[        ]
			[0  0  -1]
			>>> Matrix([[1, 2, 3]])
			[1 2 3]
			>>> Matrix([1, 2, 3])
			[1]
			[ ]
			[2]
			[ ]
			[3]
		\end{verbatim}
		In addition to creating a matrix from a list of appropriately-sized lists \&{\tt/}or matrices, SymPy also supports more advanced methods of matrix creation including a single list of values \& dimension inputs:
		\begin{verbatim}
			>>> Matrix(2, 3, [1, 2, 3, 4, 5, 6])
			[1  2  3]
			[       ]
			[4  5  6]
		\end{verbatim}
		More interesting (\& useful), is ability to use a 2-variable function (or {\tt lambda}) to create a matrix. Create an indicator function which is 1 on diagonal \& then use it to make identity matrix:
		\begin{verbatim}
			>>> def f(i,j):
			...     if i == j:
			...         return 1
			...     else:
			...         return 0
			>>> Matrix(4, 4, f)
			[1  0  0  0]
			[          ]
			[0  1  0  0]
			[          ]
			[0  0  1  0]
			[          ]
			[0  0  0  1]
		\end{verbatim}
		Use {\tt lambda} to create a 1-line matrix with 1's in even permutation entries:
		\begin{verbatim}
			>>> Matrix(3, 4, lambda i,j: 1 - (i+j) % 2)
			[1  0  1  0]
			[          ]
			[0  1  0  1]
			[          ]
			[1  0  1  0]
		\end{verbatim}
		There are also a couple of special constructors for quick matrix construction: {\tt eye}: identity matrix, {\tt zeros, ones} for matrices of all 0s \& 1s, resp., \& {\tt diag} to put matrices or elements along diagonal:
		\begin{verbatim}
			>>> eye(4)
			[1  0  0  0]
			[          ]
			[0  1  0  0]
			[          ]
			[0  0  1  0]
			[          ]
			[0  0  0  1]
			>>> zeros(2)
			[0  0]
			[    ]
			[0  0]
			>>> zeros(2, 5)
			[0  0  0  0  0]
			[             ]
			[0  0  0  0  0]
			>>> ones(3)
			[1  1  1]
			[       ]
			[1  1  1]
			[       ]
			[1  1  1]
			>>> ones(1, 3)
			[1  1  1]
			>>> diag(1, Matrix([[1, 2], [3, 4]]))
			[1  0  0]
			[       ]
			[0  1  2]
			[       ]
			[0  3  4]
		\end{verbatim}
		\item {\sc Basic Manipulation.} While learning to work with matrices, choose one where entries are readily identifiable. 1 useful thing to know: while matrices are 2D, storage is not \& so it is allowable -- though one should be careful -- to access entries as if they were a 1D list.
		\begin{verbatim}
			>>> M = Matrix(2, 3, [1, 2, 3, 4, 5, 6])
			>>> M[4]
			5
		\end{verbatim}
		More standard entry access is a pair of indices which will always return value at corresponding row \& column of matrix"
		\begin{verbatim}
			>>> M[1, 2]
			6
			>>> M[0, 0]
			1
			>>> M[1, 1]
			5
		\end{verbatim}
		Since this is Python, also able to slice submatrices; slices always give a matrix in return, even if dimension is $1\times1$:
		\begin{verbatim}
			>>> M[0:2, 0:2]
			[1  2]
			[    ]
			[4  5]
			>>> M[2:2, 2]
			[]
			>>> M[:, 2]
			[3]
			[ ]
			[6]
			>>> M[:1, 2]
			[3]
		\end{verbatim}
		In 2nd example above notice: slice 2:2 gives an empty range. Note also (in keeping with 0-based indexing of Python) 1st row{\tt/}column is 0.
		
		Cannot access rows or columns that are not present unless they are in a slice:
		\begin{verbatim}
			>>> M[:, 10] # the 10-th column (not there)
			Traceback (most recent call last):
			...
			IndexError: Index out of range: a[[0, 10]]
			>>> M[:, 10:11] # the 10-th column (if there)
			[]
			>>> M[:, :10] # all columns up to the 10-th
			[1  2  3]
			[       ]
			[4  5  6]
		\end{verbatim}
		Slicing an empty matrix works as long as use a slice for coordinate that has no size:
		\begin{verbatim}
			>>> Matrix(0, 3, [])[:, 1]
			[]
		\end{verbatim}
		Slicing gives a copy of what is sliced, so modifications of 1 object do not affect the other:
		\begin{verbatim}
			>>> M2 = M[:, :]
			>>> M2[0, 0] = 100
			>>> M[0, 0] == 100
			False			
		\end{verbatim}
		Notice: changing {\tt M2} didn't change {\tt M}. Since can slice, can also assign entries:
		\begin{verbatim}
			>>> M = Matrix(([1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]))
			>>> M
			[1   2   3   4 ]
			[              ]
			[5   6   7   8 ]
			[              ]
			[9   10  11  12]
			[              ]
			[13  14  15  16]
			>>> M[2,2] = M[0,3] = 0
			>>> M
			[1   2   3   0 ]
			[              ]
			[5   6   7   8 ]
			[              ]
			[9   10  0   12]
			[              ]
			[13  14  15  16]
		\end{verbatim}
		as well as assign slices:
		\begin{verbatim}
			>>> M = Matrix(([1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]))
			>>> M[2:,2:] = Matrix(2,2,lambda i,j: 0)
			>>> M
			[1   2   3  4]
			[            ]
			[5   6   7  8]
			[            ]
			[9   10  0  0]
			[            ]
			[13  14  0  0]
		\end{verbatim}
		All standard arithmetic operations are supported:
		\begin{verbatim}
			>>> M = Matrix(([1,2,3],[4,5,6],[7,8,9]))
			>>> M - M
			[0  0  0]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
			>>> M + M
			[2   4   6 ]
			[          ]
			[8   10  12]
			[          ]
			[14  16  18]
			>>> M * M
			[30   36   42 ]
			[             ]
			[66   81   96 ]
			[             ]
			[102  126  150]
			>>> M2 = Matrix(3,1,[1,5,0])
			>>> M*M2
			[11]
			[  ]
			[29]
			[  ]
			[47]
			>>> M**2
			[30   36   42 ]
			[             ]
			[66   81   96 ]
			[             ]
			[102  126  150]
		\end{verbatim}
		As well as some useful vector operations:
		\begin{verbatim}
			>>> M.row_del(0)
			>>> M
			[4  5  6]
			[       ]
			[7  8  9]
			>>> M.col_del(1)
			>>> M
			[4  6]
			[    ]
			[7  9]
			>>> v1 = Matrix([1,2,3])
			>>> v2 = Matrix([4,5,6])
			>>> v3 = v1.cross(v2)
			>>> v1.dot(v2)
			32
			>>> v2.dot(v3)
			0
			>>> v1.dot(v3)
			0			
		\end{verbatim}
		Recall: \verb|row_del(), col_del()| operations don't return a value -- they simply change matrix object. Can also ``glue'' together matrices of appropriate size:
		\begin{verbatim}
			>>> M1 = eye(3)
			>>> M2 = zeros(3, 4)
			>>> M1.row_join(M2)
			[1  0  0  0  0  0  0]
			[                   ]
			[0  1  0  0  0  0  0]
			[                   ]
			[0  0  1  0  0  0  0]
			>>> M3 = zeros(4, 3)
			>>> M1.col_join(M3)
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
			[       ]
			[0  0  0]
		\end{verbatim}
		\item {\sf Operations on entries.} Not restricted to have multiplication between 2 matrices:
		\begin{verbatim}
			>>> M = eye(3)
			>>> 2*M
			[2  0  0]
			[       ]
			[0  2  0]
			[       ]
			[0  0  2]
			>>> 3*M
			[3  0  0]
			[       ]
			[0  3  0]
			[       ]
			[0  0  3]
		\end{verbatim}
		but can also apply functions to our matrix entries using {\tt applyfunc()}. Declare a function that double any input number. Then apply it to $3\times3$ identity matrix:
		\begin{verbatim}
			>>> f = lambda x: 2*x
			>>> eye(3).applyfunc(f)
			[2  0  0]
			[       ]
			[0  2  0]
			[       ]
			[0  0  2]
		\end{verbatim}
		If want to extract a common factor from a matrix, can do so by applying {\tt gcd} to data of matrix:
		\begin{verbatim}
			>>> from sympy.abc import x, y
			>>> from sympy import gcd
			>>> m = Matrix([[x, y], [1, x*y]]).inv('ADJ'); m
			[  x*y       -y    ]
			[--------  --------]
			[ 2         2      ]
			[x *y - y  x *y - y]
			[                  ]
			[  -1         x    ]
			[--------  --------]
			[ 2         2      ]
			[x *y - y  x *y - y]
			>>> gcd(tuple(_))
			   1
			--------
			 2
			x *y - y
			>>> m/_
			[x*y  -y]
			[       ]
			[-1   x ]			
		\end{verbatim}
		1 more useful matrix-wide entry application function: substitution function. Declare a matrix with symbolic entries then substitute a value. Remember: can substitute anything -- even another symbol!
		\begin{verbatim}
			>>> from sympy import Symbol
			>>> x = Symbol('x')
			>>> M = eye(3) * x
			>>> M
			[x  0  0]
			[       ]
			[0  x  0]
			[       ]
			[0  0  x]
			>>> M.subs(x, 4)
			[4  0  0]
			[       ]
			[0  4  0]
			[       ]
			[0  0  4]
			>>> y = Symbol('y')
			>>> M.subs(x, y)
			[y  0  0]
			[       ]
			[0  y  0]
			[       ]
			[0  0  y]
		\end{verbatim}
		\item {\sf Linear algebra.} Now have basics out of way, see what can do with actual matrices. Determinant:
		\begin{verbatim}
			>>> M = Matrix(( [1, 2, 3], [3, 6, 2], [2, 0, 1] ))
			>>> M.det()
			-28
			>>> M2 = eye(3)
			>>> M2.det()
			1
			>>> M3 = Matrix(( [1, 0, 0], [1, 0, 0], [1, 0, 0] ))
			>>> M3.det()
			0
		\end{verbatim}
		Another common operation is inverse: In SymPy, this is computed by Gaussian elimination by default (for dense matrices) but can specify it be done by $LU$ decomposition as well:
		\begin{verbatim}
			>>> M2.inv()
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
			>>> M2.inv(method="LU")
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
			>>> M.inv(method="LU")
			[-3/14  1/14  1/2 ]
			[                 ]
			[-1/28  5/28  -1/4]
			[                 ]
			[ 3/7   -1/7   0  ]
			>>> M * M.inv(method="LU")
			[1  0  0]
			[       ]
			[0  1  0]
			[       ]
			[0  0  1]
		\end{verbatim}
		Can perform a $QR$ factorization which is handy for solving systems:
		\begin{verbatim}
			>>> A = Matrix([[1,1,1],[1,1,3],[2,3,4]])
			>>> Q, R = A.QRdecomposition()
			>>> Q
			[  ___     ___      ___ ]
			[\/ 6   -\/ 3    -\/ 2  ]
			[-----  -------  -------]
			[  6       3        2   ]
			[                       ]
			[  ___     ___      ___ ]
			[\/ 6   -\/ 3     \/ 2  ]
			[-----  -------   ----- ]
			[  6       3        2   ]
			[                       ]
			[  ___     ___          ]
			[\/ 6    \/ 3           ]
			[-----   -----      0   ]
			[  3       3            ]
			>>> R
			[           ___         ]
			[  ___  4*\/ 6       ___]
			[\/ 6   -------  2*\/ 6 ]
			[          3            ]
			[                       ]
			[          ___          ]
			[        \/ 3           ]
			[  0     -----      0   ]
			[          3            ]
			[                       ]
			[                   ___ ]
			[  0       0      \/ 2  ]
			>>> Q*R
			[1  1  1]
			[       ]
			[1  1  3]
			[       ]
			[2  3  4]
		\end{verbatim}
		In addition to solvers in {\tt solver.py} file, can solve system $A{\bf x} = {\bf b}$ by passing vector ${\bf b}$ to matrix $A$'s {\tt LUsolve} function. Here cheat a little choose $A$ \& ${\bf x}$ then multiply to get ${\bf b}$. Then can solve for ${\bf x}$ \& check it's correct:
		\begin{verbatim}
			>>> A = Matrix([ [2, 3, 5], [3, 6, 2], [8, 3, 6] ])
			>>> x = Matrix(3,1,[3,7,5])
			>>> b = A*x
			>>> soln = A.LUsolve(b)
			>>> soln
			[3]
			[ ]
			[7]
			[ ]
			[5]
		\end{verbatim}
		***STOP HERE***
	\end{itemize}
	\item {\sf Matrix Kind.}
	\item {\sf Dense Matrices.}
	\item {\sf Sparse Matrices.}
	\item {\sf Sparse Tools.}
	\item {\sf Immutable Matrices.}
	\item {\sf Matrix Expressions.}
	\item {\sf Matrix Normal Forms.}
\end{itemize}

%------------------------------------------------------------------------------%

\section{Miscellaneous}

%------------------------------------------------------------------------------%

%------------------------------------------------------------------------------%

\section{Wikipedia}

\subsection{Wikipedia{\tt/}abstraction (computer science)}
``In \href{https://en.wikipedia.org/wiki/Software_engineering}{software engineering} \& \href{https://en.wikipedia.org/wiki/Computer_science}{computer science}, {\it abstraction} is the process of \href{https://en.wikipedia.org/wiki/Generalization}{generalizing} \href{https://en.wikipedia.org/wiki/Abstract_and_concrete}{concrete} details, e.g. \href{https://en.wikipedia.org/wiki/Attribute_(computing)}{attributes}, away from the study of \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{objects} \& \href{https://en.wikipedia.org/wiki/System}{systems} to focus attention on details of greater importance. \href{https://en.wikipedia.org/wiki/Abstraction}{Abstraction} is a fundamental concept in computer science \& \href{https://en.wikipedia.org/wiki/Software_engineering}{software engineering}, especially within the \href{https://en.wikipedia.org/wiki/Object-oriented_programming}{object-oriented programming} paradigm. E.g.:
\begin{itemize}
	\item the usage of \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data types} to separate usage from working representations of \href{https://en.wikipedia.org/wiki/Data_(computer_science)}{data} within \href{https://en.wikipedia.org/wiki/Computer_program}{programs}.
	\item the concept of \href{https://en.wikipedia.org/wiki/Procedure_(computer_science)}{functions} or subroutines which represent a specific way of implementing \href{https://en.wikipedia.org/wiki/Control_flow}{control flow};
	\item the process of reorganizing common behavior from groups of non-abstract \href{https://en.wikipedia.org/wiki/Class_(computer_programming)}{classes} into abstract classes using \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance} \& \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)#Subclasses_and_superclasses}{subclasses}, as seen in object-oriented programming languages.
\end{itemize}

\subsubsection{Rationale}

\begin{quote}
	``The essence of abstraction is preserving information that is relevant in a given context, \& forgetting information that is irrelevant in that context.'' -- \href{https://en.wikipedia.org/wiki/John_Guttag}{\sc John V. Guttag}
\end{quote}
Computing mostly operates independently of the concrete world. The hardware implements a \href{https://en.wikipedia.org/wiki/Model_of_computation}{model of computation} that is interchangeable with others. The software is structured in \href{https://en.wikipedia.org/wiki/Software_architecture}{architectures} to enable humans to create the enormous systems by concentrating on a few issues at a time. These architectures are made of specific choices of abstractions. \href{https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule}{Greenspun's 10th rule} is an \href{https://en.wikipedia.org/wiki/Aphorism}{aphorism} on how such an architecture is both inevitable \& complex.

Language abstraction is a central form of abstraction in computing: new artificial languages are developed to express specific aspects of a system. \href{https://en.wikipedia.org/wiki/Modeling_languages}{\it Modeling languages} help in planning. \href{https://en.wikipedia.org/wiki/Computer_language}{\it Computer language} from the \href{https://en.wikipedia.org/wiki/First-generation_programming_language}{machine language} to the \href{https://en.wikipedia.org/wiki/Second-generation_programming_language}{assembly language} \& the \href{https://en.wikipedia.org/wiki/Third-generation_programming_language}{high-level language}. Each stage can be used as a stepping stone for the next stage. The language abstraction continues e.g. in \href{https://en.wikipedia.org/wiki/Scripting_language}{scritping languages} \& \href{https://en.wikipedia.org/wiki/Domain-specific_programming_language}{domain-specific programming languages}.

Within a programming language, some features let the programmer create new abstractions. These include \href{https://en.wikipedia.org/wiki/Subroutine}{subroutines}, \href{https://en.wikipedia.org/wiki/Module_(programming)}{modules}, \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism}, \& \href{https://en.wikipedia.org/wiki/Software_component}{software components}. Some other abstractions such as \href{https://en.wikipedia.org/wiki/Software_design_pattern}{software design pattens} \& \href{https://en.wikipedia.org/wiki/Software_architecture#Architectural_styles_and_patterns}{architectural styles} remain invisible to a \href{https://en.wikipedia.org/wiki/Translator_(computing)}{translator} \& operate only in the design of a system.

Some abstractions try to limit the range of concepts a programmer needs to be aware of, by completely hiding the abstractions they are built on. The software engineer \& writer \href{https://en.wikipedia.org/wiki/Joel_Spolsky}{\sc Joel Spolsky} has criticized these efforts by claiming that all abstractions are \href{https://en.wikipedia.org/wiki/Leaky_abstraction}{\it leaky} -- that they can never completely hide the details below; however, this does not negate the usefulness of abstraction.

Some abstractions are designed to inter-operate with other abstractions -- e.g., a programming language may contain a \href{https://en.wikipedia.org/wiki/Foreign_function_interface}{foreign function interface} for making calls to the lower-level language.

\subsubsection{Abstraction features}

\paragraph{Programming languages.} Main article: \href{https://en.wikipedia.org/wiki/Programming_language}{Wikipedia{\tt/}programming language}. Different programming languages provide different types of abstraction, depending on the intended applications for the language. E.g.:
\begin{itemize}
	\item In \href{https://en.wikipedia.org/wiki/Object-oriented_programming_language}{OOP languages} e.g. \href{https://en.wikipedia.org/wiki/C%2B%2B}{C++}, \href{https://en.wikipedia.org/wiki/Object_Pascal}{Object Pascal}, or \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}, the concept of {\it abstraction} has itself become a declarative statement -- using the \href{https://en.wikipedia.org/wiki/Syntax_(programming_languages)}{syntax} \verb|function(parameters) = 0;| (in C++) or the \href{https://en.wikipedia.org/wiki/Keyword_(computer_programming)}{keywords} {\tt abstract} \& {\tt interface} (in \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}). After such a declaration, it is the responsibility of the programmer to implement a \href{https://en.wikipedia.org/wiki/Class_(computer_science)}{class} to instantiate the \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{object} of the declaration.
	\item \href{https://en.wikipedia.org/wiki/Functional_programming_language}{Functional programming languages} commonly exhibit abstractions related to functions, e.g. \href{https://en.wikipedia.org/wiki/Lambda_abstraction}{lambda abstractions} (making a term into a function of some variable) \& \href{https://en.wikipedia.org/wiki/Higher-order_function}{higher-order functions} (parameters are functions).
	\item Modern members of the Lisp programming language family e.g. \href{https://en.wikipedia.org/wiki/Clojure}{Clojure}, \href{https://en.wikipedia.org/wiki/Scheme_(programming_language)}{Scheme}, \& \href{https://en.wikipedia.org/wiki/Common_Lisp}{Common Lisp} support \href{https://en.wikipedia.org/wiki/Macro_(computer_science)#Syntactic_macros}{macro systems} to allow syntactic abstraction. Other programming languages such as \href{https://en.wikipedia.org/wiki/Scala_(programming_language)}{Scala} also have macros, or very similar \href{https://en.wikipedia.org/wiki/Metaprogramming}{metaprogramming} features (e.g., \href{https://en.wikipedia.org/wiki/Haskell_(programming_language)}{Haskell} has \href{https://en.wikipedia.org/wiki/Template_Haskell}{Template Haskell}, \& \href{https://en.wikipedia.org/wiki/OCaml}{OCaml} has \href{https://en.wikipedia.org/wiki/MetaOCaml}{MetaOCaml}). These can allow a programmer to eliminate \href{https://en.wikipedia.org/wiki/Boilerplate_code}{boilerplate code}, abstract away tedious function call sequences, implement new \href{https://en.wikipedia.org/wiki/Control_flow}{control flow structures}, \& implement \href{https://en.wikipedia.org/wiki/Domain-specific_language}{Domain Specific Languages (DSLs)}, which allow domain-specific concepts to be expressed in concise \& elegant ways. All of these, when used correctly, improve both the programmer's efficiency \& the clarity of the code by making the intended purpose more explicit. A consequence of syntactic abstraction is also that any Lisp dialect \& in fact almost any programming language can, in principle, be implemented in any modern Lisp with significantly reduced (but still nontrivial in most cases) effort when compared to ``more traditional'' programming languages such as Python, C, or Java.
\end{itemize}

\paragraph{Specification methods.} Main article: \href{https://en.wikipedia.org/wiki/Formal_specification}{Wikipedia{\tt/}formal specification}. Analysts have developed various methods to formally specify software systems. Some known methods include:
\begin{itemize}
	\item Abstract-model based method (VDM, Z);
	\item Algebraic techniques (Larch, CLEAR, OBJ, ACT ONE, CASL);
	\item Process-based techniques (LOTOS, SDL, Estelle);
	\item Trace-based techniques (SPECIAL, TAM);
	\item Knowledge-based techniques (Refine, Gist).
\end{itemize}

\paragraph{Specification languages}
Main article: \href{https://en.wikipedia.org/wiki/Specification_language}{Wikipedia{\tt/}specification language}. Specification languages generally rely on abstractions of 1 kind or another, since specifications are typically defined earlier in a project, (\& at a more abstract level) than an eventual implementation. The \href{https://en.wikipedia.org/wiki/Unified_Modeling_Language}{UML} specification language, e.g., allows the definition of {\it abstract} classes, which in a waterfall project, remain abstract during the architecture \& specification phrase of the project.

\subsubsection{Control abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Control_flow}{Wikipedia{\tt/}control flow}. Programming languages offer control abstraction as 1 of the main purposes of their use. Computer machines understand operations at the very low level such as moving some bits from 1 location of the memory to another location \& producing the sum of 2 sequences of bits. Programming languages allow this to be done in the higher level. E.g., consider this statement written in a Pascal-like fashion: \verb|a := (1 + 2) * 5|. To a human, this seems a fairly simple \& obvious calculation. However, the lower-level steps necessary to carry out this evaluation, \& return the value 15, \& then assign that value to the variable {\tt a}, are actually quite subtle \& complex. The values need to be converted to binary representation (often a much more complicated task than one would think) \& the calculations decomposed (by the compiler or interpreter) into assembly instructions (again, which are much less intuitive to the programmer: operations such as shifting a binary register left, or adding the binary complement of the contents of 1 register to another, are simply not how humans think about the abstract arithmetical operations of addition or multiplication). Finally, assigning the resulting value of 15 to the variable labeled {\tt a}, so that {\tt a} can be used later, involves additional `behind-the-scenes' steps of looking up a variable's label \& the resultant location in physical or virtual memory, storing the binary representation of 15 to that memory location, etc.

Without control abstraction, a programmer would need to specify {\it all} the register{\tt/}binary-level steps each time they simply wanted to add or multiply a couple of numbers \& assign the result to a variable. Such duplication of effort has 2 serious negative consequences:
\begin{enumerate}
	\item it forces the programmer to constantly repeat fairly common tasks every time a similar operation is needed.
	\item it forces the programmer to program for the particular hardware \& instruction set.
\end{enumerate}

\paragraph{Structured programming.} Main article: \href{https://en.wikipedia.org/wiki/Structured_programming}{Wikipedia{\tt/}structured programming}. Structured programming involves the splitting of complex program tasks into smaller pieces with clear flow-control \& interfaces between components, with a reduction of the complexity potential for side-effects.

In a simple program, this may aim to ensure that loops have single or obvious exit points \& (where possible) to have single exit points from functions \& procedures.

In a larger system, it may involve breaking down complex tasks into many different modules. Consider a system which handles payroll on ships \& at shore offices:
\begin{itemize}
	\item The uppermost level may feature a menu of typical end-user operations.
	\item Within that could be standalone executables or libraries for tasks such as signing on \& off employees or printing checks.
	\item Within each of those standalone components there could be many different source files, each containing the program code to handle a part of the problem, with only selected interfaces available to other parts of the program. A sign on program could have source files for each data entry screen \& the database interface (which may itself be a standalone 3rd party library or a statically linked set of library routines).
	\item Either the database or the payroll application also has to initiate the process of exchanging data with between ship \& shore, \& that data transfer task will often contain many other components.
\end{itemize}
These layers produce the effect of isolating the implementation details of 1 component \& its assorted internal methods from the others. Object-oriented programming embraces \& extends this concept.

\subsubsection{Data abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Abstract_data_type}{Wikipedia{\tt/}abstract data type}. Data abstraction enforces a clear separation between the {\it abstract} properties of a \href{https://en.wikipedia.org/wiki/Data_type}{data type} \& the {\it concrete} details of its implementation. The abstract properties are those that are visible to client code that makes use of the data type -- the {\it interface} to the data type -- while the concrete implementation is kept entirely private, \& indeed can change, e.g. to incorporate efficiency improvements over time. The idea is that such chances are not supposed to have any impact on client code, since they involve no difference in the abstract behavior.

E.g., one could define an \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data type} called {\it lookup table} which uniquely associates {\it keys} with values, \& in which values may be retrieved by specifying their corresponding keys. Such a lookup table may be implemented in various ways: as a \href{https://en.wikipedia.org/wiki/Hash_table}{hash table}, a \href{https://en.wikipedia.org/wiki/Binary_search_tree}{binary search tree}, or even a simple linear \href{https://en.wikipedia.org/wiki/List_(computing)}{list} of {\tt(key:value)} pairs. As far as client code is concerned, the abstract properties of the type are the same in each case.

Of course, this all relies on getting the details of the interface right in the 1st place, since any changes there can have major impacts on client code. As 1 way to look at this: the interface forms a {\it contract} on agreed behavior between the data type \& client code; anything not spelled out in the contract is subject to change without notice.

\subsubsection{Manual data abstraction}
While much of data abstraction occurs through computer science \& automation, there are times when this process is done manually \& without programming intervention. 1 way this can be understood is through data abstraction within the process of conducting a \href{https://en.wikipedia.org/wiki/Systematic_review}{systematic review} of the literature. In this methodology, data is abstracted by 1 or several abstractors when conducting a \href{https://en.wikipedia.org/wiki/Meta-analysis}{meta-analysis}, with errors reduced through dual data abstraction followed by independent checking, known as \href{https://en.wikipedia.org/wiki/Adjudication}{adjudication}.

\subsubsection{Abstraction in OOP}
Main article: \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{Wikipedia{\tt/}object (computer science)}. In \href{https://en.wikipedia.org/wiki/Object-oriented_programming}{OOP} theory, {\it abstraction} involves the facility to define objects that represent abstract ``actors'' that can perform work, report on \& change their state, \& ``communicate'' with other objects in the system. The term \href{https://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming)}{encapsulation} refers to the hiding of \href{https://en.wikipedia.org/wiki/State_(computer_science)}{state} details, but extending the concept of {\it data type} from earlier programming languages to associate {\it behavior} most strongly with the data, \& standardizing the way that different data types interact, is the beginning of {\it abstraction}. When abstraction proceeds into the operations defined, enabling objects of different types to be substituted, it is called \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism}. When it proceeds in the opposite direction, inside the types or classes, structuring them to simplify a complex set of relationships, it is called \href{https://en.wikipedia.org/wiki/Delegation_(object-oriented_programming)}{delegation} or \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance}.

Various OOP languages offer similar facilities for abstraction, all to support a general strategy of \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism} in object-oriented programming, which includes the substitution of 1 type for another in the same or similar role. Although not as generally supported, a configuration or image or package may predetermine a great many of these \href{https://en.wikipedia.org/wiki/Name_binding}{bindings} at \href{https://en.wikipedia.org/wiki/Compile-time}{compile-time}, \href{https://en.wikipedia.org/wiki/Link-time}{link-time}, or \href{https://en.wikipedia.org/wiki/Loadtime}{loadtime}. This would leave only a minimum of such bindings to change at \href{https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)}{run-time}.

\href{https://en.wikipedia.org/wiki/Common_Lisp_Object_System}{Commmon Lisp Object System} or \href{https://en.wikipedia.org/wiki/Self_(programming_language)}{Self}, e.g., feature less of a class-instance distinction \& more use of delegation for \href{https://en.wikipedia.org/wiki/Polymorphism_in_object-oriented_programming}{polymorphism}. Individual objects \& functions are abstracted more flexibly to better fit with a shared functional heritage from \href{https://en.wikipedia.org/wiki/Lisp_programming_language}{Lisp}.

C++ exemplifies another extreme: it relies heavily on \href{https://en.wikipedia.org/wiki/Generic_programming}{templates} \& \href{https://en.wikipedia.org/wiki/Method_overloading}{overloading} \& other static bindings at compile-time, which in turn has certain flexibility problems.

Although these examples offer alternate strategies for achieving the same abstraction, they do not fundamentally alter th need to support abstract nouns in code -- all programming relies on an ability to abstract verbs as functions, nouns as data structures, \& either as processes.

Consider e.g. a sample Java fragment to represent some common farm ``animals'' to a level of abstraction suitable to model simple aspects of their hunger \& feeding. It defines an {\tt Animal} class to represent both the state of the animal \& its functions:
\begin{verbatim}
	public class Animal extends LivingThing
	{
		private Location loc;
		private double energyReserves;
		
		public boolean isHungry() {
			return energyReserves < 2.5;
		}
		
		public void eat(Food food) {
			// Consume food
			energyReserves += food.getCalories();
		}
		
		public void moveTo(Location location) {
			// Move to new location
			this.loc = location;
		}
	}
\end{verbatim}
With the above definition, one could create objects of type {\tt Animal} \& call their methods like this:
\begin{verbatim}
	thePig = new Animal();
	theCow = new Animal();
	if (thePig.isHungry()) {
		thePig.eat(tableScraps);
	}
	if (theCow.isHungry()) {
		theCow.eat(grass);
	}
	theCow.moveTo(theBarn);
\end{verbatim}
In the above example, the class {\tt Animal} is an abstraction used in place of an actual animal, {\tt LivingThing} is a further abstraction (in this case a generalization) of {\tt Animal}.

If one requires a more differentiated hierarchy of animals -- to differentiate, say, those who provide milk from those ho provide nothing except meat at the end of their lives -- that is an intermediary level of abstraction, probably {\tt DairyAnimal(cows,goats)} who would eat foods suitable to giving good milk, \& {\tt MeatAnimal(pigs,steers)} who would eat foods to give the best meat-quality.

Such an abstraction could remove the need for the application coder to specify the type of food, so they could concentrate instead on the feeding schedule. The 2 classes could be related using \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance} or stand alone, \& the programmer could define varying degrees of \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism} between the 2 types. These facilities tend to vary drastically between languages, but in general each can achieve anything that is possible with any of the others. A great many operation overloads, data type by data type, can have the same effect at compile-time as any degree of inheritance or other means to achieve polymorphism. The class notation is simply a coder's convenience.

\paragraph{Object-oriented design.} Main article: \href{https://en.wikipedia.org/wiki/Object-oriented_design}{Wikipedia{\tt/}object-oriented design}. Decisions regarding what to abstract \& what to keep under the control of the coder become the major concern of object-oriented design \& \href{https://en.wikipedia.org/wiki/Domain_analysis}{domain analysis} -- actually determining the relevant relationships in the real world is the concern of \href{https://en.wikipedia.org/wiki/Object-oriented_analysis_and_design}{object-oriented analysis} or legacy analysis.

In general, to determine appropriate abstraction, one must make many small decisions about scope (domain analysis), determine what other systems one must cooperate with (legacy analysis), then perform a detailed object-oriented analysis which is expressed within project time \& budget constraints as an object-oriented design. In our simple example, the domain is the barnyard, the live pigs \& cows \& their eating habits are the legacy constraints, the detailed analysis is that coders must have the flexibility to feed the animals what is available \& thus there is no reason to code the type of food into the class itself, \& the design is a single simple {\tt Animal} class of which pigs \& cows are instances with the same functions. A decision to differentiate {\tt DairyAnimal} would change the detailed analysis but the domain \& legacy analysis would be unchanged -- thus it is entirely under the control of the programmer, \& it is called an abstraction in object-oriented programming as distinct from abstraction in domain or legacy analysis.

\subsubsection{Considerations}
When discussing \href{https://en.wikipedia.org/wiki/Formal_semantics_of_programming_languages}{formal semantics of programming languages}, \href{https://en.wikipedia.org/wiki/Formal_methods}{formal methods} or \href{https://en.wikipedia.org/wiki/Abstract_interpretation}{abstract interpretation}, {\it abstraction} refers to the act of considering a less detailed, but safe, definition of the observed program behaviors. E.g., one may observe only the final result of program executions instead of considering all the intermediate steps of executions. Abstraction is defined to a {\it concrete} (more precise) model of execution.

Abstraction may be {\it exact} or {\it faithful} w.r.t. a property if one can answer a question about the property equally well on the concrete or abstract model. E.g., if one wishes to know what the result of the evaluation of a mathematical expression involving only integers $+,-,\cdot$, is worth \href{https://en.wikipedia.org/wiki/Modular_arithmetic}{module} $n$, then one needs only perform all operations module $n$ (a familiar form of this abstraction is \href{https://en.wikipedia.org/wiki/Casting_out_nines}{casting out nines}).

Abstractions, however, though not necessarily {\it exact}, should be {\it sound}. I.e., it should be possible to get sound answers from them -- even though the abstraction may simply yield a result of \href{https://en.wikipedia.org/wiki/Undecidable_problem}{undecidability}. E.g., students in a class may be abstracted by their minimal \& maximal ages; if one asks whenever a certain person belongs to that class, one may simply compare that person's age with the minimal \& maximal ages; if his age lies outside the range, one may safely answer that the person does not belong to the class; if it does not, one may only answer ``I don't know''.

The level of abstraction included in a programming language can influence its overall \href{https://en.wikipedia.org/wiki/Usability}{usability}. The \href{https://en.wikipedia.org/wiki/Cognitive_dimensions}{Cognitive dimensions} framework includes the concept of {\it abstraction gradient} in a formalism. This framework allows the designer of a programming language to study the trade-offs between abstraction \& other characteristics of the design, \& how changes in abstraction influence the language usability.

Abstractions can prove useful when dealing with computer programs, because nontrivial properties of computer programs are essentially \href{https://en.wikipedia.org/wiki/Undecidable_problem}{undecidable} (\href{https://en.wikipedia.org/wiki/Rice%27s_theorem}{Rice's theorem}). As a consequence, automatic methods for deriving information on the behavior of computer programs either have to drop termination (on some occasions, they may fail, crash or never yield out a result), soundness (they may provide false information), or precision (they may answer ``I don't know'' to some questions).

Abstraction is the core concept of \href{https://en.wikipedia.org/wiki/Abstract_interpretation}{abstract interpretation}. \href{https://en.wikipedia.org/wiki/Model_checking}{Model checking} generally takes place on abstract versions of the studied systems.

\subsubsection{Levels of abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Abstraction_layer}{Wikipedia{\tt/}abstraction layer}. Computer science commonly presents {\it levels} (or, less commonly, {\it layers}) of abstraction, wherein each level represents a different model of the same information \& processes, but with varying amounts of detail. Each level uses a system of expression involving a unique set of objects \& compositions that apply only to a particular domain. Each relatively abstract, ``higher'' level builds on a relatively concrete, ``lower'' level, which tends to provide an increasingly ``granular'' representation. E.g., gates build on electronic circuits, binary on gates, machine language on binary, programming language on machine language, applications \& operating systems on programming languages. Each level is embodied, but not determined, by the level beneath it, making it a language of description that is somewhat self-contained.

\paragraph{Database systems.} Main article: \href{https://en.wikipedia.org/wiki/Database_management_system}{Wikipedia{\tt/}database management system}. {\sf Data abstraction levels of a database system}. Since many users of database systems lack in-depth familiarity with computer data-structures, database developers often hide complexity through the following levels"
\begin{itemize}
	\item {\bf Physical level.} The lowest level of abstraction describes {\it how} a system actually stores data. The physical level describes complex low-level data structures in detail.
	\item {\bf Logical level.} The next higher level of abstraction describes {\it what} data the database stores, \& what relationships exist among those data. The logical level thus describes an entire database in terms of a small number of relatively simple structures. Although implementation of the simple structures at the logical level may involve complex physical level structures, the user of the logical level does not need to be aware of this complexity. This is referred to as \href{https://en.wikipedia.org/wiki/Physical_data_independence}{physical data independence}. \href{https://en.wikipedia.org/wiki/Database_administrator}{Database administrators}, who must decide what information to keep in a database, use the logical level of abstraction.
	\item {\bf View level.} The highest level of abstraction describes only part of the entire database. Even though the logical level uses simpler structures, complexity remains because of the variety of information stored in a large database. Many users of a database system do not need all this information; instead, they need to access only a part of the database. The view level of abstraction exists to simplify their interaction with the system. The system may provide may \href{https://en.wikipedia.org/wiki/View_(database)}{views} for the same database.
\end{itemize}

\paragraph{Layered architecture.} Main article: \href{https://en.wikipedia.org/wiki/Abstraction_layer}{Abstraction layer}. The ability to provide a \href{https://en.wikipedia.org/wiki/Design}{design} of different levels of abstraction can
\begin{itemize}
	\item simplify the design considerably
	\item enable different role players to effectively work at various levels of abstraction
	\item support the portability of \href{https://en.wikipedia.org/wiki/Software_artifact}{software artifacts} (model-based ideally)
\end{itemize}
\href{https://en.wikipedia.org/wiki/Systems_design}{System designs} \& \href{https://en.wikipedia.org/wiki/Business_process_modeling}{business process design} can both use this. Some \href{https://en.wikipedia.org/wiki/Software_modeling}{design processes} specifically generate designs that contain various levels of abstraction.

Layered architecture partitions the concerns of the application into stacked groups (layers). It is a technique used in designing computer software, hardware, \& communications in which system or network components are isolated in layers so that changes can be made in 1 layer without affecting the others.'' -- \href{https://en.wikipedia.org/wiki/Abstraction_(computer_science)}{Wikipedia{\tt/}abstraction (computer science)}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Anaconda}
``{\it Anaconda} is an \href{https://en.wikipedia.org/wiki/Open_source}{open source} \href{https://en.wikipedia.org/wiki/Data_science}{data science} \& AI \href{https://en.wikipedia.org/wiki/Software_distribution}{distribution} platform for Python \& R programming languages. Developed by Anaconda, Inc., an American company founded in 2012, platform is used to develop \& manage data science \& AI projects. In 2024, Anaconda Inc. has about 300 employees \& 45 million users.

\subsubsection{History}
Co-founded in \href{https://en.wikipedia.org/wiki/Austin,_Texas}{Austin, Texas} in 2012 as Continuum Analytics by {\it Peter Wang} \& \href{https://en.wikipedia.org/wiki/Travis_Oliphant}{\sc Travis Oliphant}, Anaconda Inc. operates from US \& Europe.

Anaconda Inc. developed \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda}, a \href{https://en.wikipedia.org/wiki/Cross-platform}{cross-platform}, language-agnostic binary \href{https://en.wikipedia.org/wiki/Package_manager}{package manager}. It also launched PyData community workshops \& Jupyter Cloud Notebook service (Wakari.io). In 2013, it received funding from \href{https://en.wikipedia.org/wiki/DARPA}{DARPA}. In 2015, company had 2 million users including 200 of \href{https://en.wikipedia.org/wiki/Fortune_500}{Fortune 500} companies \& raised \$24 million in a \href{https://en.wikipedia.org/wiki/Series_A}{Series A} funding round led by \href{https://en.wikipedia.org/wiki/General_Catalyst}{General Catalyst} \& BuildGroup. Anaconda secured an additional \$30 million in funding in 2021.

Continuum Analytics rebranded as Anaconda in 2017. That year, it announced release of Anaconda Enterprise 5, an integration with \href{https://en.wikipedia.org/wiki/Microsoft_Azure}{Microsoft Azure}, \& had over 13 million users by year's end.

In 2022, it released Anaconda Business; new integrations with Snowflake \& others; \& open-source PyScript. It also required PythonAnywhere, while Anaconda's user base exceeded 30 million in 2022. In 2023, Anaconda released Python in Excel, a new integration with \href{https://en.wikipedia.org/wiki/Microsoft_Excel}{Microsoft Excel}, \& launched \url{PyScript.com}.

Company made a series of investments in AI during 2024. Feb, Anaconda partnered with \href{https://en.wikipedia.org/wiki/IBM}{IBM} to import its repository of Python packages into \href{https://en.wikipedia.org/wiki/Watsonx}{Watsonx}, IBM's \href{https://en.wikipedia.org/wiki/Generative_AI}{generative AI} platform. Same year, Anaconda joined IBM's AI Alliance \& releasedan integration with \href{https://en.wikipedia.org/wiki/Teradata}{Teradata} \& \href{https://en.wikipedia.org/wiki/Lenovo}{Lenovo}.

In 2024, Anaconda's user base reached 45 million users \& {\sc Barry Libert} was named company CEO, after serving on Anaconda's board of directors.

\subsubsection{Overview}
{\it Anaconda distribution} comes with $> 300$ packages automatically installed, \& $> 7500$ additional open-source packages can be installed from Anaconda repository as well as Conda package \& \href{https://en.wikipedia.org/wiki/Virtual_environment_software}{virtual environment} manager. It also includes a \href{https://en.wikipedia.org/wiki/Graphical_user_interface}{GUI}, {\it Anaconda Navigator}, as a graphical alternative to \href{https://en.wikipedia.org/wiki/Command-line_interface}{command-line interface} (CLI).

\href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda} was developed to address dependency conflicts native to \href{https://en.wikipedia.org/wiki/Pip_(package_manager)}{pip package manager}, which would automatically install any dependent Python packages without checking for conflicts with previously installed packages (until its version 20.3, which later implemented consistent dependency resolution). Conda package manager's historical differentiation analyzed \& resolved these installation conflicts.

Anaconda is a distribution of Python \& R programming languages for \href{https://en.wikipedia.org/wiki/Scientific_computing}{scientific computing} (DS, ML applications, large-scale \href{https://en.wikipedia.org/wiki/Data_processing}{data processing}, \href{https://en.wikipedia.org/wiki/Predictive_analytics}{predictive analysis}, etc.), that aims to simplify \href{https://en.wikipedia.org/wiki/Package_management}{package management} \& \href{https://en.wikipedia.org/wiki/Deployment_environment}{deployment}. Anaconda distribution includes data-science packages suitable for Windows, Linux, \& macOS. Other company products include Anaconda Free, \& subscription-based Starter, Business, \& Enterprise. Anaconda's business tier offers Package Security Manager.

Package versions in Anaconda are managed by package management system \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda}, which was spun out as a separate open-source package as useful both independently \& for applications other than Python. There is also a small, \href{https://en.wikipedia.org/wiki/Bootstrapping}{bootstrap} version of Anaconda called {\it Miniconda}, which includes only Conda, Python, packages they depend on, \& a small number of other packages.

Open source packages can be individually installed from Anaconda repository, Anaconda Cloud (\url{anaconda.org}), or user's own private repository or mirror, using {\tt conda install} command. Anaconda, Inc. compiles \& builds packages available in Anaconda repository itself, \& provides \href{https://en.wikipedia.org/wiki/Binary_file}{binaries} for Windows 32{\tt/}64 bit, Linux 64 bit \& MacOS 64-bit (Intel, Apple Silicon). Anything available on PyPI may be installed into a Conda environment using {\tt pip}, \& Conda will keep track of what it has installed \& what pip has installed. Custom packages can be made using {\tt conda build} command, \& can be shared with others by uploading them to Anaconda Cloud, PyPI or other repositories.

Default installation of Anaconda2 includes Python 2.7 \& Anaconda3 includes Python 3.7. However, possible to create new environments that include any version of Python packaged with Conda.
\begin{itemize}
	\item {\sf Anaconda Navigator.} Anaconda Navigator is a desktop graphical user interface (GUI) included in Anaconda distribution that allows users to launch applications \& manage Conda packages, environments \& channels without using \href{https://en.wikipedia.org/wiki/Command-line_interface}{command-line commands}. Navigator can search for packages on Anaconda Cloud or in a local Anaconda Repository, install them in an environment, run the packages \& update them. Available for Windows, macOS \& Linux.
	
	Applications are available by default in Navigator:
	\begin{itemize}
		\item \href{https://en.wikipedia.org/wiki/Project_Jupyter#JupyterLab}{JupyterLab}
		\item \href{https://en.wikipedia.org/wiki/Project_Jupyter#Jupyter_Notebook}{Jupyter Notebook}
		\item QtConsole
		\item \href{https://en.wikipedia.org/wiki/Spyder_(software)}{Spyder}
		\item \href{https://en.wikipedia.org/wiki/Glue_(software)}{Glue}
		\item \href{https://en.wikipedia.org/wiki/Orange_(software)}{Orange}
		\item \href{https://en.wikipedia.org/wiki/RStudio}{RStudio}
		\item \href{https://en.wikipedia.org/wiki/Visual_Studio_Code}{Visual Studio Code}
	\end{itemize}
	\item {\sf Conda.} \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Conda} is an open source, \href{https://en.wikipedia.org/wiki/Cross-platform}{cross-platform}, language-agnostic \href{https://en.wikipedia.org/wiki/Package_manager}{package manager} \& environment management system that installs, runs, \& updates packages \& their dependencies. It was created for Python programs, but it can package \& distribute software for any language (e.g., R), including multi-language projects. Conda package \& environment manager is included in all versions of Anaconda, Miniconda, \& Anaconda Repository.
\end{itemize}

\subsubsection{Anaconda.org}
Anaconda Cloud is a package management service by Anaconda where users can find, access, store \& share public \& private notebooks, environments, \& Conda \& PyPI packages. Cloud hosts useful Python packages, notebooks \& environments for a wide variety of applications. Users do not need to log in or to have a Cloud account, to search for public packages, download \& install them. Users can build new Conda packages using Conda-build \& then use Anaconda Client CLI upload packages to \url{Anaconda.org}. Notebooks users can be aided with writing \& debugging code with Anaconda's AI Assistant.'' -- \href{https://en.wikipedia.org/wiki/Anaconda_(Python_distribution)}{Wikipedia{\tt/}Anaconda}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}computational learning theory}
``In CS, {\it computational learning theory} (or just {\it learning theory}) is a subfield of AI devoted to studying design \& analysis of ML algorithms.

\subsubsection{Overview}
Theoretical results in ML mainly deal with a type of inductive learning called \href{https://en.wikipedia.org/wiki/Supervised_learning}{supervised learning}. In supervised learning, an algorithm is given samples that are \href{https://en.wikipedia.org/wiki/Labeled_data}{labeled} in some useful way. E.g., samples might be descriptions of mushrooms, \& labels could be whether or not mushrooms are edible. Algorithm takes these previously labeled samples \& uses them to induce a classifier. This classifier is a function that assigns labels to samples, including samples that have not been seen previously by algorithm. Goal of supervised learning algorithm: optimize some measure of performance e.g. minimizing number of mistakes made on new samples.

In addition to performance bounds, computational learning theory studies time complexity \& feasibility of learning. In computational learning theory, a computation is considered {\it feasible} (khả thi) if it can be done in \href{https://en.wikipedia.org/wiki/Polynomial_time}{polynomial time}. There are 2 kinds of time complexity results:
\begin{itemize}
	\item Positive results -- showing: a certain class of functions is learnable in polynomial time.
	\item Negative results -- showing: certain classes cannot be learned in polynomial time.
\end{itemize}
Negative results often rely on commonly believed, but yet unproven assumptions, e.g.:
\begin{itemize}
	\item Computational complexity - \href{https://en.wikipedia.org/wiki/P_versus_NP_problem}{P$\ne$NP (P vs. NP problem)}
	\item \href{https://en.wikipedia.org/wiki/Cryptography}{Cryptographic} -- \href{https://en.wikipedia.org/wiki/One-way_function}{1-way functions} exist.
\end{itemize}
There are several different approaches to computational learning theory based on making different assumptions about \href{https://en.wikipedia.org/wiki/Inference}{inference} principles used to generalize from limited data. This includes different definitions of probability (see \href{https://en.wikipedia.org/wiki/Frequency_probability}{frequency probability}, \href{https://en.wikipedia.org/wiki/Bayesian_probability}{Bayesian probability}) \& different assumptions on generation of samples. Different approaches include:
\begin{itemize}
	\item Exact learning, proposed by \href{https://en.wikipedia.org/wiki/Dana_Angluin}{\sc Dana Angluin}
	\item \href{https://en.wikipedia.org/wiki/Probably_approximately_correct_learning}{Probably approximately correct learning} (PAC learning), proposed by \href{https://en.wikipedia.org/wiki/Leslie_Valiant}{\sc Leslie Valiant}
	\item \href{https://en.wikipedia.org/wiki/VC_theory}{VC theory}, proposed by \href{https://en.wikipedia.org/wiki/Vladimir_Vapnik}{\sc Vladimir Vapnik} \& \href{https://en.wikipedia.org/wiki/Alexey_Chervonenkisv}{\sc Alexey Chervonenkis}
	\item \href{https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference}{Inductive inference} as developed by \href{https://en.wikipedia.org/wiki/Ray_Solomonoff}{\sc Ray Solomonoff}
	\item \href{https://en.wikipedia.org/wiki/Algorithmic_learning_theory}{Algorithmic learning theory}, from work of \href{https://en.wikipedia.org/wiki/E._Mark_Gold}{\sc E. Mark Gold}.
	\item \href{https://en.wikipedia.org/wiki/Online_machine_learning}{Online ML}, from work of {\sc Nick Littlestone}.
\end{itemize}
While its primary goal is to understand learning abstractly, computational learning theory has led to development of practical algorithms. E.g., PAC theory inspired \href{https://en.wikipedia.org/wiki/Boosting_(meta-algorithm)}{boosting}, VC theory led to \href{https://en.wikipedia.org/wiki/Support_vector_machine}{support vector machines}, \& Bayesian inference led to \href{https://en.wikipedia.org/wiki/Belief_networks}{belief networks}.'' -- \href{https://en.wikipedia.org/wiki/Computational_learning_theory}{Wikipedia{\tt/}computational learning theory}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}Conda (package manager)}
``{\it Conda} is an open-source, \href{https://en.wikipedia.org/wiki/Cross-platform}{cross-platform}, \href{https://en.wikipedia.org/wiki/Language-agnostic}{language-agnostic} \href{https://en.wikipedia.org/wiki/Package_manager}{package manager} \& environment management system. It was originally developed to solve package management challenges faced by Python data scientists, \& today is a popular package manager for Python \& R. At 1st, \href{https://en.wikipedia.org/wiki/Anaconda_(Python_distribution)}{Anaconda Python distribution} was developed by Anaconda Inc.; later, it was spun out as a separate package, released under \href{https://en.wikipedia.org/wiki/BSD_licenses}{BSD license}. Conda package \& environment manager is included in all versions of \href{https://en.wikipedia.org/wiki/Anaconda_(Python_distribution)}{Anaconda}, \href{https://en.wikipedia.org/wiki/Miniconda}{Miniconda}, \& Anaconda Repository. Conda is a NumFOCUS affiliated project.

\subsubsection{Features}
As a package manger, Conda allows users to install different versions of \href{https://en.wikipedia.org/wiki/Binary_file}{binary} software packages \& their required software \href{https://en.wikipedia.org/wiki/Coupling_(computer_programming)}{dependencies} appropriate for their \href{https://en.wikipedia.org/wiki/Computing_platform}{computing platform} from a \href{https://en.wikipedia.org/wiki/Software_repository}{software repository}. Conda checks everything that has been installed, any version limitations that user specifies (e.g., user wants a specific package to be at least version 2.1.3), \& determines a set of versions for all requested packages \& their dependencies that makes total set compatible with 1 another. If there is no set of compatible dependencies, it will tell user: requested combination of software packages at requested versions is not possible.

Secondly, Conda allows users to create such a set of software packages in isolation from rest of computing platform, in what Conda calls an {\it environment}. This allows user to create various sets of software packages for different projects. When users switches between those projects, they switch to relevant environment, thereby avoiding re-installation or removal of conflicting packages. To further facilitate setup of such environments, Conda can also install Python, interpreter for software packages itself.

Conda is written in Python programming language, but can manage projects containing code written in any language, including multi-language projects.

A popular Conda channel for \href{https://en.wikipedia.org/wiki/List_of_bioinformatics_software}{bioinformatics software} is {\it Bioconda}, which provides multiple software distributions for computational biology.'' -- \href{https://en.wikipedia.org/wiki/Conda_(package_manager)}{Wikipedia{\tt/}Conda (package manager)}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}data structure}
{\sf A data structure known as a \href{https://en.wikipedia.org/wiki/Hash_table}{hash table}.} ``In computer science, a {\it data structure} is a \href{https://en.wikipedia.org/wiki/Data}{data} organization \& storage format that is usually chosen for \href{https://en.wikipedia.org/wiki/Efficiency}{efficient} \href{https://en.wikipedia.org/wiki/Data_access}{access} to data. More precisely, a data structure is a collection of data values, the relationships among them, \& the \href{https://en.wikipedia.org/wiki/Function_(computer_programming)}{functions} or \href{https://en.wikipedia.org/wiki/Operator_(computer_programming)}{operations} that can be applied to the data, i.e., it is an \href{https://en.wikipedia.org/wiki/Algebraic_structure}{algebraic structure} about \href{https://en.wikipedia.org/wiki/Data}{data}.

\subsubsection{Usage}
Data structures serve as the basis for \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data types} (ADT). The ADT defines the logical form of the data type. The data structure implements the physical form of the \href{https://en.wikipedia.org/wiki/Data_type}{data type}.

Different types of data structures are suited to different kinds of applications, \& some are highly specialized to specific tasks. E.g., \href{https://en.wikipedia.org/wiki/Relational_database}{relational databases} commonly use \href{https://en.wikipedia.org/wiki/B-tree}{B-tree} indexes for data retrieval, while \href{https://en.wikipedia.org/wiki/Compiler}{compiler} \href{https://en.wikipedia.org/wiki/Implementation}{implementations} usually use \href{https://en.wikipedia.org/wiki/Hash_table}{hash tables} to look up \href{https://en.wikipedia.org/wiki/Identifier_(computer_languages)}{identifiers}.

Data structures provide a means to manage large amounts of data efficiently for uses such as large \href{https://en.wikipedia.org/wiki/Database}{databases} \& internet indexing services. Usually, efficient data structures are key to designing efficient \href{https://en.wikipedia.org/wiki/Algorithm}{algorithms}. Some formal design methods \& \href{https://en.wikipedia.org/wiki/Programming_language}{programming language} emphasize data structures, rather than algorithms, as the key organizing factor in software design. Data structures can be used to organize the storage \& retrieval (thu hồi) of information stored in both \href{https://en.wikipedia.org/wiki/Main_memory}{main memory} \& \href{https://en.wikipedia.org/wiki/Computer_data_storage}{secondary memory}.

\subsubsection{Implementation}
Data structures can be implemented using a variety of programming languages \& techniques, but they all share the common goal of efficiently organizing \& storing data. Data structures are generally based on the ability of a \href{https://en.wikipedia.org/wiki/Computer}{computer} to fetch \& store data at any place in its memory, specified by a \href{https://en.wikipedia.org/wiki/Pointer_(computer_programming)}{pointer} -- a \href{https://en.wikipedia.org/wiki/Bit}{bit} \href{https://en.wikipedia.org/wiki/String_(computer_science)}{string}, representing a \href{https://en.wikipedia.org/wiki/Memory_address}{memory address}, that can be itself stored in memory \& manipulated by the program. Thus, the \href{https://en.wikipedia.org/wiki/Array_data_structure}{array} \& \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{record} data structures are based on computing the addresses of data items with \href{https://en.wikipedia.org/wiki/Arithmetic_operations}{arithmetic operations}, while the \href{https://en.wikipedia.org/wiki/Linked_data_structure}{linked data structures} are based on storing addresses of data items within the structure itself. This approach to data structuring has profound implications for the efficiency \& scalability of algorithms. E.g., the contiguous memory allocation in arrays facilitates rapid access \& modification operations, leading to optimized performance in sequential data processing scenarios.

The implementation of a data structure usually requires writing a set of \href{https://en.wikipedia.org/wiki/Subroutine}{procedures} that create \& manipulate instances of that structure. The efficiency of a data structure cannot ne analyzed separately from those operations. This observation motivates the theoretical concept of an \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data type}, a data structure that is defined indirectly by the operations that may be performed on it, \& the mathematical properties of those operations (including their space \& time cost).

\subsubsection{Examples}
{\sf The standard \href{https://en.wikipedia.org/wiki/Data_type}{type} hierarchy of the programming language \href{https://en.wikipedia.org/wiki/Python_(programming_language)}{Python 3}.} Main article: \href{https://en.wikipedia.org/wiki/List_of_data_structures}{Wikipedia{\tt/}list of data structures}. There are numerous types of data structures, generally built upon simpler \href{https://en.wikipedia.org/wiki/Primitive_data_type}{primitive data types}. Well known examples are:
\begin{itemize}
	\item An \href{https://en.wikipedia.org/wiki/Array_(data_structure)}{array} is a number of elements in a specific order, typically all of the same type (depending on the language, individual elements may either all be forced to be the same type, or may be of almost any type). Elements are accessed using an integer index to specify which element is required. Typical implementations allocate contiguous memory words for the elements of arrays (but this is not always a necessity). Arrays may be fixed-length or resizable.
	\item A \href{https://en.wikipedia.org/wiki/Linked_list}{linked list} (also just called {\it list}) is a linear collection of data elements of any type, called {\it nodes}, where each node has itself a value, \& points to the next node in the linked list. The principal advantage of a linked list over an array is that values can always be efficiently inserted \& removed without relocating the rest of the list. Certain other operations, e.g. \href{https://en.wikipedia.org/wiki/Random_access}{random access} to a certain element, are however slower on lists than on arrays.
	\item A \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{record} (also called {\it tuple} or {\it struct}) is an \href{https://en.wikipedia.org/wiki/Aggregate_data}{aggregate data} structure. A record is a value that contains other values, typically in fixed number \& sequence \& typically indexed by names. The elements of records are usually called {\it fields} or {\it members}. In the context of OOP, records are known as \href{https://en.wikipedia.org/wiki/Plain_old_data_structure}{plain old data structures} to distinguish them from objects.
	\item \href{https://en.wikipedia.org/wiki/Hash_table}{Hash tables}, also known as hash maps, are data structures that provide fast retrieval of values based on keys. They use a hashing function to map keys to indexes in an array, allowing for constant-time access in the average case. Hash tables are commonly used in dictionaries, caches, \& database indexing. However, hash collisions can occur, which can impact their performance. Techniques like chaining \& open addressing are employed to handle collisions.
	\item \href{https://en.wikipedia.org/wiki/Graph_(abstract_data_type)}{Graphs} are collections of nodes connected by edges, representing relationships between entities. Graphs can be used to model social networks, computer networks, \& transportation networks, among other things. They consist of vertices (nodes) \& edges (connections between nodes). Graphs can be directed or undirected, \& they can have cycles or be acylic. Graph traversal algorithms include breadth-1st search \& depth-1st search.
	\item \href{https://en.wikipedia.org/wiki/Stack_(abstract_data_type)}{Stacks} \& \href{https://en.wikipedia.org/wiki/Queue_(abstract_data_type)}{queues} are abstract data types that can be implemented using arrays or linked lists. A stack has 2 primary operations: push (adds an element to the top of the stack) \& pop (removes the topmost element from the stack), that follow the Last In, First Out (LIFO) principle. Queues have 2 main operations: enqueue (adds an element to the rear of the queue) \& dequeue (removes an element from the front of the queue) that follow the First In, First Out (FIFO) principle.
	\item \href{https://en.wikipedia.org/wiki/Tree_(data_structure)}{Trees} represents a hierarchical organization of elements. A tree consists of nodes connected by edges, with 1 node being the root \& all other nodes forming subtrees. Trees are widely used in various algorithms \& data storage scenarios. \href{https://en.wikipedia.org/wiki/Binary_tree}{Binary trees} (particularly \href{https://en.wikipedia.org/wiki/Heap_(data_structure)}{heaps}), \href{https://en.wikipedia.org/wiki/AVL_tree}{AVL trees}, \& \href{https://en.wikipedia.org/wiki/B-tree}{B-trees} are some popular types of trees. They enable efficient \& optimal searching, sorting, \& hierarchical representation of data.
\end{itemize}
A \href{https://en.wikipedia.org/wiki/Trie}{trie}, or prefix tree, is a special type of tree used to efficiently retrieve strings. In a trie, each node represents a character of a string, \& the edges between nodes represent the characters that connect them. This structure is especially useful for tasks like autocomplete, spell-checking, \& creating dictionaries. Tries allow for quick searches \& operations based on string prefixes.

\subsubsection{Language support}
Most \href{https://en.wikipedia.org/wiki/Assembly_language}{assembly languages} \& some \href{https://en.wikipedia.org/wiki/Low-level_programming_language}{low-level languages}, such as \href{https://en.wikipedia.org/wiki/BCPL}{BCPL} (Basic Combined Programming Language), lack built-in support for data structures. On the other hand, many \href{https://en.wikipedia.org/wiki/High-level_programming_language}{high-level programming languages} \& some higher-level assembly languages, e.g. \href{https://en.wikipedia.org/wiki/MASM}{MASM}, have special syntax or other built-in support for certain data structures, e.g. records \& arrays. E.g., the \href{https://en.wikipedia.org/wiki/C_(programming_language)}{C} (a direct descendant of BCPL) \& \href{https://en.wikipedia.org/wiki/Pascal_(programming_language)}{Pascal} languages support \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{structs} \& records, respectively, in addition to vectors (1D \href{https://en.wikipedia.org/wiki/Array_data_type}{arrays}) \& multi-dimensional arrays.

Most programming languages feature some sort of \href{https://en.wikipedia.org/wiki/Library_(computing)}{library} mechanism that allows data structure implementations to be reused by different programs. Modern languages usually come with standard libraries that implement the most common data structures. E.g., \href{https://en.wikipedia.org/wiki/Standard_Template_Library}{C++ Standard Template Library}, \href{https://en.wikipedia.org/wiki/Java_Collections_Framework}{Java Collections Framework}, \& \href{https://en.wikipedia.org/wiki/Microsoft}{Microsoft} \href{https://en.wikipedia.org/wiki/.NET_Framework}{.NET Framework}.

Modern languages also generally support \href{https://en.wikipedia.org/wiki/Modular_programming}{modular programming}, the separation between the \href{https://en.wikipedia.org/wiki/Interface_(computing)}{interface} of a library module \& its implementation. Some provide \href{https://en.wikipedia.org/wiki/Opaque_data_type}{apaque data types} that allow clients to hide implementation details. \href{https://en.wikipedia.org/wiki/Object-oriented_programming_language}{OOP languages}, e.g. C++, Java, \& \href{https://en.wikipedia.org/wiki/Smalltalk}{Smalltalk}, typically use \href{https://en.wikipedia.org/wiki/Classes_(computer_science)}{classes} for this purpose.

Many known data structures have \href{https://en.wikipedia.org/wiki/Concurrent_data_structure}{concurrent} versions which allow multiple computing threads to access a single concrete instance of a data structure simultaneously.'' -- \href{https://en.wikipedia.org/wiki/Data_structure}{Wikipedia{\tt/}data structure}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}level set (data structures)}
``In computer science, a \href{https://en.wikipedia.org/wiki/Level_set}{level set} \href{https://en.wikipedia.org/wiki/Data_structure}{data structure} is designed to represent discretely \href{https://en.wikipedia.org/wiki/Sampling_(statistics)}{sampled} dynamic level sets functions. A common use of this form of data structure is in efficient image \href{https://en.wikipedia.org/wiki/Rendering_(computer_graphics)}{rendering}. The underlying method constructs a \href{https://en.wikipedia.org/wiki/Distance_transform}{signed distance field} that extends the boundary, \& can be used to solve the motion of the boundary in this field.

\subsubsection{Chronological developments}
The powerful \href{https://en.wikipedia.org/wiki/Level-set_method}{level-set method} is due to \href{https://en.wikipedia.org/wiki/Stanley_Osher}{\sc Osher} \& \href{https://en.wikipedia.org/wiki/James_Sethian}{\sc Sethian} 1988. However, the straightforward implementation via a dense $d$-dimensional \href{https://en.wikipedia.org/wiki/Array_data_structure}{array} of values, results in both time \& storage complexity of $O(n^d)$, where $n$ is the cross sectional resolution of the spatial extents of the domain \& $d$ is the number of spatial dimensions of the domain.
\begin{enumerate}
	\item {\bf Narrow band.} The narrow band level set method, introduced in 1995 by {\sc Adalsteinsson \& Sethian}, restricted most computations to a thin band of active \href{https://en.wikipedia.org/wiki/Voxel}{voxels} immediately surrounding the interface, thus reducing the time complexity in 3D to $O(n^2)$ for most operations. Periodic updates of the narrowband structure, to rebuild the list of active voxels, were required which entailed an $O(n^3)$ operation in which voxels over the entire volume were accessed. The storage complexity for this narrowband scheme was still $O(n^3)$. Differential constructions over the narrow band domain edge require careful interpolation \& domain alternation schemes to stabilize the solution.
	\item {\bf Sparse field.} This $O(n^3)$ time complexity was eliminated in the approximate ``sparse field'' level set method introduced by {\sc Whitaker} in 1998. The sparse field level set method employs a set of linked list to track the active voxels around the interface. This allows incremental extension of the active region as needed without incurring any significant overhead. While consistently $O(n^2)$ efficient in time, $O(n^3)$ storage space is still required by the sparse field level set method.
	\item {\bf Sparse block grid.} The sparse block grid method, introduced by {\sc Bridson} in 2003, divides the entire \href{https://en.wikipedia.org/wiki/Bounding_volume}{bounding volume} of size $n^3$ into small cubic blocks of $m^3$ voxels each. A coarse grid of size $\left(\frac{n}{m}\right)^3$ then stores pointers only to those blocks that intersect that narrow band of the level set. Block allocation \& deallocation occur as the surface propagates to accommodate to the deformations. This method has a suboptimal storage complexity of $O(\left(\frac{n}{m}\right)^3 + m^3n^2)$, but retains the constant time access inherent to dense grids.
	\item {\bf Octree.} The \href{https://en.wikipedia.org/wiki/Octree}{octree} level set method, introduced by {\sc Strain} in 1999 \& refined by {\sc Losasso, Gibu, \& Fedkiw}, \& more recently by {\sc Min \& Gibou} uses a tree of nested cubes of which the leaf nodes contain signed distance values. Octree level sets currently require uniform refinement along the interface (i.e., the narrow band) in order to obtain sufficient precision. This representation is efficient in terms of storage, $O(n^2)$, \& relatively efficient in terms of access queries, $O(\log n)$. A advantage of the level method on octree data structures is that one can solve the PDEs associated with typical free boundary problems that use the level set method. The CASL research group has developed this line of work in computational materials, CFD, electrokinetics, image guided surgery \& controls.
	\item {\bf Run-length encoded.} The \href{https://en.wikipedia.org/wiki/Run-length_encoding}{run-length encoding} (RLE) level set method, introduced in 2004, applies the RLE scheme to compress regions away from the narrow band to just their sign representation while storing with full precision the narrow band. The sequential traversal of the narrow band is optimal \& storage efficiency is further improved over the octree level set. The additional of an acceleration lookup table allows for fast $O(\log r)$ random access, where $r$ is the number of runs per cross section. Additional efficiency is gained by applying the RLE scheme in a dimensional recursive fashion, a technique introduced by {\sc Nielsen \& Museth}'s similar DT-Grid.
	\item {\bf Hash Table Local Level Set.} The Hash Table Local Level Set method, introduced in 2011 by {\sc Eyiyurekli \& Breen} \& extended in 2012 by {\sc Brun, Guittet, \& Gibou}, only computes the level set data in a band around the interface, as in the Narrow Band Level-Set Method, but also only stores the data in that same band. A hash table data structure is used, which provides an $O(1)$ access to the data. However, {\sc Brun} et al. conclude that their method, while being easier to implement, performs worse than a quadtree implementation. They find that
	\begin{quote}
		as it is, [$\ldots$] a quadtree data structure seems more adapted than the hash table data structure for level-set algorithms.
	\end{quote}
	3 main reasons for worse efficiency are listed:
	\begin{enumerate}
		\item to obtain accurate results, a rather large band is required close to the interface, which counterbalances the absence of grid nodes far from the interface;
		\item the performances are deteriorated by extrapolation procedures on the outer edges of the local grid \&
		\item the width of the band restricts the time step \& slows down the method.
		\item {\bf Point-based.} {\sc Corbett} in 2005 introduced the point-based level set method. Instead of using a uniform sampling of the level set, the continuous level set function is reconstructed from a set of unorganized point samples via \href{https://en.wikipedia.org/wiki/Moving_least_squares}{moving least squares}.'' -- \href{https://en.wikipedia.org/wiki/Level_set_(data_structures)}{Wikipedia{\tt/}level set (data structures)}
	\end{enumerate}
\end{enumerate}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}pip (package manager)}
``{\tt pip} (also known by \href{https://en.wikipedia.org/wiki/Python_3}{Python 3}'s alias {\tt pip3}) is a \href{https://en.wikipedia.org/wiki/Package_manager}{package-management system} written in Python \& is used to install \& mange \href{https://en.wikipedia.org/wiki/Package_(package_management_system)}{software packages}. \href{https://en.wikipedia.org/wiki/Python_Software_Foundation}{Python Software Foundation} recommends using pip for installing Python applications \& its dependencies during deployment. Pip connects to an \href{https://en.wikipedia.org/wiki/Software_repository}{online repository} of public packages, called \href{https://en.wikipedia.org/wiki/Python_Package_Index}{Python Package Index}. Pip can be configured to connect to other package repositories (local or remote), provided that they comply to \href{https://en.wikipedia.org/wiki/Python_Enhancement_Proposal}{Python Enhancement Proposal} 503.

Most distributions of Python come with pip preinstalled. Python 2.7.9 \& later (on python2 series), \& Python 3.4 \& later include pip by default.

\subsubsection{History}
1st introduced as {\tt pyinstall} in 2008 by {\sc Ian Bicking} (creator of {\tt virtualenv} package) as an alternative to easy install, pip was chosen as new name from 1 of several suggestions: creator received on his blog post. According to {\sc Bicking} himself, the name is a \href{https://en.wikipedia.org/wiki/Recursive_acronym}{recursive acronym} for ``Pip Installs Packages''. In 2011, Python Packaging Authority (PyPA) was created to take over maintenance of pip \& virtualenv from {\sc Bicking}, led by {\sc Carl Meyer, Brian Rosner, \& Jannis Leidel}.

With release of pip version 6.0 (2014-12-22), the version naming process was changed to have version in X.Y format \& drop preceding 1 from version label.

\subsubsection{Command-line interface}
{\sf An output of {\tt pip install virtualenv}}. Pip's \href{https://en.wikipedia.org/wiki/Command-line_interface}{command-line interface} allows install of Python software packages by issuing a command: {\tt pip install some-package-name}. Users can also remove package by issuing a command: {\tt pip uninstall some-package-name}. pip has a feature to manage full lists of packages \& corresponding version numbers, possible through a ``requirements'' file. This permits efficient re-creation of an entire group of packages in a separate environment (e.g. another computer) or \href{https://en.wikipedia.org/wiki/Virtualization}{virtual environment}. This can be achieved with a properly formatted file \& following command, where {\tt requirements.txt} is name of file: {\tt pip install -r requirements.txt}.

To install some package for a specific python version, pip provides following command, where \verb|${version}| is replaced by 2, 3, 3.4, etc.: \verb|pip${version} install some-package-name|.

\begin{itemize}
	\item {\sf Using {\tt setup.py}.} Pip provides a way to install user-defined projects locally with use of {\tt setup.py} file. This method requires python project to have following {\sf file structure}.
	
	Within this structure, user can add {\tt setup.py} to root of project (i.e. \verb|example_project| for above structure) with following content:
	\begin{verbatim}
		from setuptools import setup, find_packages
		
		setup(
		    name='example',  # Name of the package. This will be used, when the project is imported as a package.
		    version='0.1.0',
		    packages=find_packages(include=['exampleproject', 'exampleproject.*'])  # Pip will automatically install the dependencies provided here.
		)
	\end{verbatim}
	After this, pip can install this custom project by running following command, from project root directory: {\tt pip install -e}.
\end{itemize}

\subsubsection{Custom repository}
Besides default PyPI repository, Pip supports custom repositories as well. Such repositories can be located on an HTTP(s) URL or on a file system location. A custom repository can be specified using the {\tt-i} or {\tt--index-url} option, like so:
\begin{verbatim}
	pip install -i https://your-custom-repo/simple <package name>
\end{verbatim}
or with a filesystem: \verb|pip install -i /path/to/your/custom-repo/simple <package name>|.'' -- \href{https://en.wikipedia.org/wiki/Pip_(package_manager)}{Wikipedia{\tt/}pip (package manager)}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}