import networkx as nx
from Node2Vec import Node2Vec

# generate N2V embeddings
book_graph = nx.read_gml('polbooks.gml') # loads graph data from a GML file into a NetworkX graph object
node2vec = Node2Vec(book_graph, dimensions = 64, walk_length = 30, num_walks = 200, workers = 4) # initialize N2V model with specified parameters for input graph
model = node2vec.fit(window = 10, min_count = 1, batch_words = 4) # train N2V model
embeddings = {str(node) : model.wv[str(node)] for node in gml_graph.nodes()} # extract & store node embeddings generated by N2V model in a dictionary

node_embedding = model.wv['Losing Bin Laden']
print(node_embedding)

# visualize embeddings using UMAP
node_embedding = [embeddings[str(node)] for node in gml_graph.nodes()] # transform embeding into a list of vectors for UMAP
node_embedding_array = np.array(node_embedding)

umap_model = umap.UMAP(n_neighbors = 15, min_dist = 0.1, n_components = 2, random_state = 42)
umap_features = umap_model.fit_transform(node_embedding_array) # initialize & fit UMAP

plt.scatter(umap_features[:, 0], umap_features[:, 1], color = node_colors, alpha = 0.7) # plots the nodes with UMAP embeddings & color by their value

# visualizing 2D N2V embeddings without t-SNE
node2vec = Node2Vec(gml_graph, dimensions = 2, walk_length = 30, num_walks = 200, workers = 4) # initialize N2V with 2D embeddings for visualization
model = node2vec.fit(window = 10, min_count = 1, batch_words = 4) # train N2V model with specified window & walks settings
embeddings_2D = {str(node) : model.wv[str(node)] for node in gml_graph.nodes()} # map nodes to their 2D embeddings
points = np.array([embeddings_2D[node] for node in gml_graph.nodes()]) # form an array of 2D points for each node's embedding
plt.scatter(points[:, 0], points[:, 1], color = node_colors, alpha = 0.7) # plot 2D embeddings with specified node colors

# SimpleGNN class
class SimpleGNN_embeddings(torch.nn.Module):
	def __init__(self, num_features, hidden_channels): # initialize GNN class with input & hidden layer sizes
		super(SimpleGNN, self).__init__()
		self.conv1 = GCNConv(num_features, hidden_channels) # 1st GCN layer from input features to hidden channels
		self.conv2 = GCNConv(hidden_channels, hidden_channels) # 2nd GCN layer within hidden space

	def forward(self, x, edge_index): # forward pass function defines data flow
		x = self.conv1(x, edge_index) # 1st GCN layer processing
		x = torch.relu(x) # activation function for nonlinearity
		x = torch.dropout(x, p = 0.5, train = self.training) #  dropout for regularization during training
		x = self.conv2(x, edge_index) # 2nd GCN layer processing
		return x # return final node embeddings

# data preparation
data.x = torch.randn((data.num_nodes, 64), dtype = torch.float)
'nn.init.xavier_uniform_(data.x) '

node_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]
node_features = torch.tensor(node_embedding, dtype = torch.float)
data.x = node_features

model = SimpleGNN(num_features = data.x.shape[1], hidden_channels = 64)
model.eval()
with torch.no_grad():
	gnn_embeddings = model(data.x, data.edge_index)
gnn_embeddings_np = gnn_embeddings.detach().cpu().numpy()

# preprocessing for semi-supervised problem
labels = []
for node, data in gml_graph.nodes(data = True): # extract labels & handle neural values
	if data['value'] == 'c':
		labels.append('right')
	elif data['value'] == 'l':
		labels.append('left')
	else:
		labels.append('neutral')
	labels = np.array(labels)
	random.seed(52) # random seed for reproducibility
	indices = list(range(len(labels))) # indices of all nodes
	labeled_percentages = 0.2 # 20% of data to keep as labeled, 80% unlabeled
	labeled_indices = random.sample(indices, int(labeled_percentages * len(labels))) # select a subset of indices to remain labeled
	labeled_mask = np.zeros(len(labels), dtype = bool) # initialize masks for labeled & unlabeled data
	unlabeled_mask = np.ones(len(labels), dtype = bool)
	labeled_mask[labeled_indices] = True # update masks
	unlabeled_mask[labeled_indices] = False
	labeled_labels = labels[labeled_mask] # use masks to split dataset
	unlabeled_labels = labels[unlabeled_mask]
	label_mapping = {'left': 0, 'right': 1, 'neural': 2} # transformed labels to numeric form
	numeric_labels = np.array([label_mapping[label] for label in labels])

'''
nqbh@nqbh:~/advanced_STEM_beyond/graph_neural_network/Python$ python3 generate_N2V_embedding.py 
Traceback (most recent call last):
  File "/home/nqbh/advanced_STEM_beyond/graph_neural_network/Python/generate_N2V_embedding.py", line 1, in <module>
    import NetworkX as nx
ModuleNotFoundError: No module named 'NetworkX'
'''