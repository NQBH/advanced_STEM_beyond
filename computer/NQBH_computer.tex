\documentclass{article}
\usepackage[backend=biber,natbib=true,style=alphabetic,maxbibnames=50]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[utf8]{vietnam}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,enumitem,float,graphicx,mathtools,tikz}
\usetikzlibrary{angles,calc,intersections,matrix,patterns,quotes,shadings}
\allowdisplaybreaks
\newtheorem{assumption}{Assumption}
\newtheorem{baitoan}{}
\newtheorem{cauhoi}{Câu hỏi}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{dangtoan}{Dạng toán}
\newtheorem{definition}{Definition}
\newtheorem{dinhly}{Định lý}
\newtheorem{dinhnghia}{Định nghĩa}
\newtheorem{example}{Example}
\newtheorem{ghichu}{Ghi chú}
\newtheorem{hequa}{Hệ quả}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{lemma}{Lemma}
\newtheorem{luuy}{Lưu ý}
\newtheorem{nhanxet}{Nhận xét}
\newtheorem{notation}{Notation}
\newtheorem{note}{Note}
\newtheorem{principle}{Principle}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{question}{Question}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{vidu}{Ví dụ}
\usepackage[left=1cm,right=1cm,top=5mm,bottom=5mm,footskip=4mm]{geometry}
\def\labelitemii{$\circ$}
\DeclareRobustCommand{\divby}{%
	\mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\title{Computer -- Máy Tính}
\author{Nguyễn Quản Bá Hồng\footnote{A Scientist {\it\&} Creative Artist Wannabe. E-mail: {\tt nguyenquanbahong@gmail.com}. Bến Tre City, Việt Nam.}}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
	This text is a part of the series {\it Some Topics in Advanced STEM \& Beyond}:
	
	{\sc url}: \url{https://nqbh.github.io/advanced_STEM/}.
	
	Latest version:
	\begin{itemize}
		\item {\it Computer -- Máy Tính}.
		
		PDF: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/computer/NQBH_computer.pdf}.
		
		\TeX: {\sc url}: \url{https://github.com/NQBH/advanced_STEM_beyond/blob/main/computer/NQBH_computer.tex}.
	\end{itemize}
\end{abstract}
\tableofcontents

%------------------------------------------------------------------------------%

\section{Wikipedia}

\subsection{Wikipedia{\tt/}abstraction (computer science)}
``In \href{https://en.wikipedia.org/wiki/Software_engineering}{software engineering} \& \href{https://en.wikipedia.org/wiki/Computer_science}{computer science}, {\it abstraction} is the process of \href{https://en.wikipedia.org/wiki/Generalization}{generalizing} \href{https://en.wikipedia.org/wiki/Abstract_and_concrete}{concrete} details, e.g. \href{https://en.wikipedia.org/wiki/Attribute_(computing)}{attributes}, away from the study of \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{objects} \& \href{https://en.wikipedia.org/wiki/System}{systems} to focus attention on details of greater importance. \href{https://en.wikipedia.org/wiki/Abstraction}{Abstraction} is a fundamental concept in computer science \& \href{https://en.wikipedia.org/wiki/Software_engineering}{software engineering}, especially within the \href{https://en.wikipedia.org/wiki/Object-oriented_programming}{object-oriented programming} paradigm. E.g.:
\begin{itemize}
	\item the usage of \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data types} to separate usage from working representations of \href{https://en.wikipedia.org/wiki/Data_(computer_science)}{data} within \href{https://en.wikipedia.org/wiki/Computer_program}{programs}.
	\item the concept of \href{https://en.wikipedia.org/wiki/Procedure_(computer_science)}{functions} or subroutines which represent a specific way of implementing \href{https://en.wikipedia.org/wiki/Control_flow}{control flow};
	\item the process of reorganizing common behavior from groups of non-abstract \href{https://en.wikipedia.org/wiki/Class_(computer_programming)}{classes} into abstract classes using \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance} \& \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)#Subclasses_and_superclasses}{subclasses}, as seen in object-oriented programming languages.
\end{itemize}

\subsubsection{Rationale}

\begin{quote}
	``The essence of abstraction is preserving information that is relevant in a given context, \& forgetting information that is irrelevant in that context.'' -- \href{https://en.wikipedia.org/wiki/John_Guttag}{\sc John V. Guttag}
\end{quote}
Computing mostly operates independently of the concrete world. The hardware implements a \href{https://en.wikipedia.org/wiki/Model_of_computation}{model of computation} that is interchangeable with others. The software is structured in \href{https://en.wikipedia.org/wiki/Software_architecture}{architectures} to enable humans to create the enormous systems by concentrating on a few issues at a time. These architectures are made of specific choices of abstractions. \href{https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule}{Greenspun's 10th rule} is an \href{https://en.wikipedia.org/wiki/Aphorism}{aphorism} on how such an architecture is both inevitable \& complex.

Language abstraction is a central form of abstraction in computing: new artificial languages are developed to express specific aspects of a system. \href{https://en.wikipedia.org/wiki/Modeling_languages}{\it Modeling languages} help in planning. \href{https://en.wikipedia.org/wiki/Computer_language}{\it Computer language} from the \href{https://en.wikipedia.org/wiki/First-generation_programming_language}{machine language} to the \href{https://en.wikipedia.org/wiki/Second-generation_programming_language}{assembly language} \& the \href{https://en.wikipedia.org/wiki/Third-generation_programming_language}{high-level language}. Each stage can be used as a stepping stone for the next stage. The language abstraction continues e.g. in \href{https://en.wikipedia.org/wiki/Scripting_language}{scritping languages} \& \href{https://en.wikipedia.org/wiki/Domain-specific_programming_language}{domain-specific programming languages}.

Within a programming language, some features let the programmer create new abstractions. These include \href{https://en.wikipedia.org/wiki/Subroutine}{subroutines}, \href{https://en.wikipedia.org/wiki/Module_(programming)}{modules}, \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism}, \& \href{https://en.wikipedia.org/wiki/Software_component}{software components}. Some other abstractions such as \href{https://en.wikipedia.org/wiki/Software_design_pattern}{software design pattens} \& \href{https://en.wikipedia.org/wiki/Software_architecture#Architectural_styles_and_patterns}{architectural styles} remain invisible to a \href{https://en.wikipedia.org/wiki/Translator_(computing)}{translator} \& operate only in the design of a system.

Some abstractions try to limit the range of concepts a programmer needs to be aware of, by completely hiding the abstractions they are built on. The software engineer \& writer \href{https://en.wikipedia.org/wiki/Joel_Spolsky}{\sc Joel Spolsky} has criticized these efforts by claiming that all abstractions are \href{https://en.wikipedia.org/wiki/Leaky_abstraction}{\it leaky} -- that they can never completely hide the details below; however, this does not negate the usefulness of abstraction.

Some abstractions are designed to inter-operate with other abstractions -- e.g., a programming language may contain a \href{https://en.wikipedia.org/wiki/Foreign_function_interface}{foreign function interface} for making calls to the lower-level language.

\subsubsection{Abstraction features}

\paragraph{Programming languages.} Main article: \href{https://en.wikipedia.org/wiki/Programming_language}{Wikipedia{\tt/}programming language}. Different programming languages provide different types of abstraction, depending on the intended applications for the language. E.g.:
\begin{itemize}
	\item In \href{https://en.wikipedia.org/wiki/Object-oriented_programming_language}{OOP languages} e.g. \href{https://en.wikipedia.org/wiki/C%2B%2B}{C++}, \href{https://en.wikipedia.org/wiki/Object_Pascal}{Object Pascal}, or \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}, the concept of {\it abstraction} has itself become a declarative statement -- using the \href{https://en.wikipedia.org/wiki/Syntax_(programming_languages)}{syntax} \verb|function(parameters) = 0;| (in C++) or the \href{https://en.wikipedia.org/wiki/Keyword_(computer_programming)}{keywords} {\tt abstract} \& {\tt interface} (in \href{https://en.wikipedia.org/wiki/Java_(programming_language)}{Java}). After such a declaration, it is the responsibility of the programmer to implement a \href{https://en.wikipedia.org/wiki/Class_(computer_science)}{class} to instantiate the \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{object} of the declaration.
	\item \href{https://en.wikipedia.org/wiki/Functional_programming_language}{Functional programming languages} commonly exhibit abstractions related to functions, e.g. \href{https://en.wikipedia.org/wiki/Lambda_abstraction}{lambda abstractions} (making a term into a function of some variable) \& \href{https://en.wikipedia.org/wiki/Higher-order_function}{higher-order functions} (parameters are functions).
	\item Modern members of the Lisp programming language family e.g. \href{https://en.wikipedia.org/wiki/Clojure}{Clojure}, \href{https://en.wikipedia.org/wiki/Scheme_(programming_language)}{Scheme}, \& \href{https://en.wikipedia.org/wiki/Common_Lisp}{Common Lisp} support \href{https://en.wikipedia.org/wiki/Macro_(computer_science)#Syntactic_macros}{macro systems} to allow syntactic abstraction. Other programming languages such as \href{https://en.wikipedia.org/wiki/Scala_(programming_language)}{Scala} also have macros, or very similar \href{https://en.wikipedia.org/wiki/Metaprogramming}{metaprogramming} features (e.g., \href{https://en.wikipedia.org/wiki/Haskell_(programming_language)}{Haskell} has \href{https://en.wikipedia.org/wiki/Template_Haskell}{Template Haskell}, \& \href{https://en.wikipedia.org/wiki/OCaml}{OCaml} has \href{https://en.wikipedia.org/wiki/MetaOCaml}{MetaOCaml}). These can allow a programmer to eliminate \href{https://en.wikipedia.org/wiki/Boilerplate_code}{boilerplate code}, abstract away tedious function call sequences, implement new \href{https://en.wikipedia.org/wiki/Control_flow}{control flow structures}, \& implement \href{https://en.wikipedia.org/wiki/Domain-specific_language}{Domain Specific Languages (DSLs)}, which allow domain-specific concepts to be expressed in concise \& elegant ways. All of these, when used correctly, improve both the programmer's efficiency \& the clarity of the code by making the intended purpose more explicit. A consequence of syntactic abstraction is also that any Lisp dialect \& in fact almost any programming language can, in principle, be implemented in any modern Lisp with significantly reduced (but still nontrivial in most cases) effort when compared to ``more traditional'' programming languages such as Python, C, or Java.
\end{itemize}

\paragraph{Specification methods.} Main article: \href{https://en.wikipedia.org/wiki/Formal_specification}{Wikipedia{\tt/}formal specification}. Analysts have developed various methods to formally specify software systems. Some known methods include:
\begin{itemize}
	\item Abstract-model based method (VDM, Z);
	\item Algebraic techniques (Larch, CLEAR, OBJ, ACT ONE, CASL);
	\item Process-based techniques (LOTOS, SDL, Estelle);
	\item Trace-based techniques (SPECIAL, TAM);
	\item Knowledge-based techniques (Refine, Gist).
\end{itemize}

\paragraph{Specification languages}
Main article: \href{https://en.wikipedia.org/wiki/Specification_language}{Wikipedia{\tt/}specification language}. Specification languages generally rely on abstractions of 1 kind or another, since specifications are typically defined earlier in a project, (\& at a more abstract level) than an eventual implementation. The \href{https://en.wikipedia.org/wiki/Unified_Modeling_Language}{UML} specification language, e.g., allows the definition of {\it abstract} classes, which in a waterfall project, remain abstract during the architecture \& specification phrase of the project.

\subsubsection{Control abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Control_flow}{Wikipedia{\tt/}control flow}. Programming languages offer control abstraction as 1 of the main purposes of their use. Computer machines understand operations at the very low level such as moving some bits from 1 location of the memory to another location \& producing the sum of 2 sequences of bits. Programming languages allow this to be done in the higher level. E.g., consider this statement written in a Pascal-like fashion: \verb|a := (1 + 2) * 5|. To a human, this seems a fairly simple \& obvious calculation. However, the lower-level steps necessary to carry out this evaluation, \& return the value 15, \& then assign that value to the variable {\tt a}, are actually quite subtle \& complex. The values need to be converted to binary representation (often a much more complicated task than one would think) \& the calculations decomposed (by the compiler or interpreter) into assembly instructions (again, which are much less intuitive to the programmer: operations such as shifting a binary register left, or adding the binary complement of the contents of 1 register to another, are simply not how humans think about the abstract arithmetical operations of addition or multiplication). Finally, assigning the resulting value of 15 to the variable labeled {\tt a}, so that {\tt a} can be used later, involves additional `behind-the-scenes' steps of looking up a variable's label \& the resultant location in physical or virtual memory, storing the binary representation of 15 to that memory location, etc.

Without control abstraction, a programmer would need to specify {\it all} the register{\tt/}binary-level steps each time they simply wanted to add or multiply a couple of numbers \& assign the result to a variable. Such duplication of effort has 2 serious negative consequences:
\begin{enumerate}
	\item it forces the programmer to constantly repeat fairly common tasks every time a similar operation is needed.
	\item it forces the programmer to program for the particular hardware \& instruction set.
\end{enumerate}

\paragraph{Structured programming.} Main article: \href{https://en.wikipedia.org/wiki/Structured_programming}{Wikipedia{\tt/}structured programming}. Structured programming involves the splitting of complex program tasks into smaller pieces with clear flow-control \& interfaces between components, with a reduction of the complexity potential for side-effects.

In a simple program, this may aim to ensure that loops have single or obvious exit points \& (where possible) to have single exit points from functions \& procedures.

In a larger system, it may involve breaking down complex tasks into many different modules. Consider a system which handles payroll on ships \& at shore offices:
\begin{itemize}
	\item The uppermost level may feature a menu of typical end-user operations.
	\item Within that could be standalone executables or libraries for tasks such as signing on \& off employees or printing checks.
	\item Within each of those standalone components there could be many different source files, each containing the program code to handle a part of the problem, with only selected interfaces available to other parts of the program. A sign on program could have source files for each data entry screen \& the database interface (which may itself be a standalone 3rd party library or a statically linked set of library routines).
	\item Either the database or the payroll application also has to initiate the process of exchanging data with between ship \& shore, \& that data transfer task will often contain many other components.
\end{itemize}
These layers produce the effect of isolating the implementation details of 1 component \& its assorted internal methods from the others. Object-oriented programming embraces \& extends this concept.

\subsubsection{Data abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Abstract_data_type}{Wikipedia{\tt/}abstract data type}. Data abstraction enforces a clear separation between the {\it abstract} properties of a \href{https://en.wikipedia.org/wiki/Data_type}{data type} \& the {\it concrete} details of its implementation. The abstract properties are those that are visible to client code that makes use of the data type -- the {\it interface} to the data type -- while the concrete implementation is kept entirely private, \& indeed can change, e.g. to incorporate efficiency improvements over time. The idea is that such chances are not supposed to have any impact on client code, since they involve no difference in the abstract behavior.

E.g., one could define an \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data type} called {\it lookup table} which uniquely associates {\it keys} with values, \& in which values may be retrieved by specifying their corresponding keys. Such a lookup table may be implemented in various ways: as a \href{https://en.wikipedia.org/wiki/Hash_table}{hash table}, a \href{https://en.wikipedia.org/wiki/Binary_search_tree}{binary search tree}, or even a simple linear \href{https://en.wikipedia.org/wiki/List_(computing)}{list} of {\tt(key:value)} pairs. As far as client code is concerned, the abstract properties of the type are the same in each case.

Of course, this all relies on getting the details of the interface right in the 1st place, since any changes there can have major impacts on client code. As 1 way to look at this: the interface forms a {\it contract} on agreed behavior between the data type \& client code; anything not spelled out in the contract is subject to change without notice.
	
\subsubsection{Manual data abstraction}
While much of data abstraction occurs through computer science \& automation, there are times when this process is done manually \& without programming intervention. 1 way this can be understood is through data abstraction within the process of conducting a \href{https://en.wikipedia.org/wiki/Systematic_review}{systematic review} of the literature. In this methodology, data is abstracted by 1 or several abstractors when conducting a \href{https://en.wikipedia.org/wiki/Meta-analysis}{meta-analysis}, with errors reduced through dual data abstraction followed by independent checking, known as \href{https://en.wikipedia.org/wiki/Adjudication}{adjudication}.

\subsubsection{Abstraction in OOP}
Main article: \href{https://en.wikipedia.org/wiki/Object_(computer_science)}{Wikipedia{\tt/}object (computer science)}. In \href{https://en.wikipedia.org/wiki/Object-oriented_programming}{OOP} theory, {\it abstraction} involves the facility to define objects that represent abstract ``actors'' that can perform work, report on \& change their state, \& ``communicate'' with other objects in the system. The term \href{https://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming)}{encapsulation} refers to the hiding of \href{https://en.wikipedia.org/wiki/State_(computer_science)}{state} details, but extending the concept of {\it data type} from earlier programming languages to associate {\it behavior} most strongly with the data, \& standardizing the way that different data types interact, is the beginning of {\it abstraction}. When abstraction proceeds into the operations defined, enabling objects of different types to be substituted, it is called \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism}. When it proceeds in the opposite direction, inside the types or classes, structuring them to simplify a complex set of relationships, it is called \href{https://en.wikipedia.org/wiki/Delegation_(object-oriented_programming)}{delegation} or \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance}.

Various OOP languages offer similar facilities for abstraction, all to support a general strategy of \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism} in object-oriented programming, which includes the substitution of 1 type for another in the same or similar role. Although not as generally supported, a configuration or image or package may predetermine a great many of these \href{https://en.wikipedia.org/wiki/Name_binding}{bindings} at \href{https://en.wikipedia.org/wiki/Compile-time}{compile-time}, \href{https://en.wikipedia.org/wiki/Link-time}{link-time}, or \href{https://en.wikipedia.org/wiki/Loadtime}{loadtime}. This would leave only a minimum of such bindings to change at \href{https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)}{run-time}.

\href{https://en.wikipedia.org/wiki/Common_Lisp_Object_System}{Commmon Lisp Object System} or \href{https://en.wikipedia.org/wiki/Self_(programming_language)}{Self}, e.g., feature less of a class-instance distinction \& more use of delegation for \href{https://en.wikipedia.org/wiki/Polymorphism_in_object-oriented_programming}{polymorphism}. Individual objects \& functions are abstracted more flexibly to better fit with a shared functional heritage from \href{https://en.wikipedia.org/wiki/Lisp_programming_language}{Lisp}.

C++ exemplifies another extreme: it relies heavily on \href{https://en.wikipedia.org/wiki/Generic_programming}{templates} \& \href{https://en.wikipedia.org/wiki/Method_overloading}{overloading} \& other static bindings at compile-time, which in turn has certain flexibility problems.

Although these examples offer alternate strategies for achieving the same abstraction, they do not fundamentally alter th need to support abstract nouns in code -- all programming relies on an ability to abstract verbs as functions, nouns as data structures, \& either as processes.

Consider e.g. a sample Java fragment to represent some common farm ``animals'' to a level of abstraction suitable to model simple aspects of their hunger \& feeding. It defines an {\tt Animal} class to represent both the state of the animal \& its functions:
\begin{verbatim}
public class Animal extends LivingThing
{
    private Location loc;
    private double energyReserves;
	
    public boolean isHungry() {
        return energyReserves < 2.5;
    }

    public void eat(Food food) {
        // Consume food
        energyReserves += food.getCalories();
    }
	
    public void moveTo(Location location) {
        // Move to new location
        this.loc = location;
    }
}
\end{verbatim}
With the above definition, one could create objects of type {\tt Animal} \& call their methods like this:
\begin{verbatim}
thePig = new Animal();
theCow = new Animal();
if (thePig.isHungry()) {
    thePig.eat(tableScraps);
}
if (theCow.isHungry()) {
    theCow.eat(grass);
}
theCow.moveTo(theBarn);
\end{verbatim}
In the above example, the class {\tt Animal} is an abstraction used in place of an actual animal, {\tt LivingThing} is a further abstraction (in this case a generalization) of {\tt Animal}.

If one requires a more differentiated hierarchy of animals -- to differentiate, say, those who provide milk from those ho provide nothing except meat at the end of their lives -- that is an intermediary level of abstraction, probably {\tt DairyAnimal(cows,goats)} who would eat foods suitable to giving good milk, \& {\tt MeatAnimal(pigs,steers)} who would eat foods to give the best meat-quality.

Such an abstraction could remove the need for the application coder to specify the type of food, so they could concentrate instead on the feeding schedule. The 2 classes could be related using \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inheritance} or stand alone, \& the programmer could define varying degrees of \href{https://en.wikipedia.org/wiki/Polymorphism_(computer_science)}{polymorphism} between the 2 types. These facilities tend to vary drastically between languages, but in general each can achieve anything that is possible with any of the others. A great many operation overloads, data type by data type, can have the same effect at compile-time as any degree of inheritance or other means to achieve polymorphism. The class notation is simply a coder's convenience.

\paragraph{Object-oriented design.} Main article: \href{https://en.wikipedia.org/wiki/Object-oriented_design}{Wikipedia{\tt/}object-oriented design}. Decisions regarding what to abstract \& what to keep under the control of the coder become the major concern of object-oriented design \& \href{https://en.wikipedia.org/wiki/Domain_analysis}{domain analysis} -- actually determining the relevant relationships in the real world is the concern of \href{https://en.wikipedia.org/wiki/Object-oriented_analysis_and_design}{object-oriented analysis} or legacy analysis.

In general, to determine appropriate abstraction, one must make many small decisions about scope (domain analysis), determine what other systems one must cooperate with (legacy analysis), then perform a detailed object-oriented analysis which is expressed within project time \& budget constraints as an object-oriented design. In our simple example, the domain is the barnyard, the live pigs \& cows \& their eating habits are the legacy constraints, the detailed analysis is that coders must have the flexibility to feed the animals what is available \& thus there is no reason to code the type of food into the class itself, \& the design is a single simple {\tt Animal} class of which pigs \& cows are instances with the same functions. A decision to differentiate {\tt DairyAnimal} would change the detailed analysis but the domain \& legacy analysis would be unchanged -- thus it is entirely under the control of the programmer, \& it is called an abstraction in object-oriented programming as distinct from abstraction in domain or legacy analysis.

\subsubsection{Considerations}
When discussing \href{https://en.wikipedia.org/wiki/Formal_semantics_of_programming_languages}{formal semantics of programming languages}, \href{https://en.wikipedia.org/wiki/Formal_methods}{formal methods} or \href{https://en.wikipedia.org/wiki/Abstract_interpretation}{abstract interpretation}, {\it abstraction} refers to the act of considering a less detailed, but safe, definition of the observed program behaviors. E.g., one may observe only the final result of program executions instead of considering all the intermediate steps of executions. Abstraction is defined to a {\it concrete} (more precise) model of execution.

Abstraction may be {\it exact} or {\it faithful} w.r.t. a property if one can answer a question about the property equally well on the concrete or abstract model. E.g., if one wishes to know what the result of the evaluation of a mathematical expression involving only integers $+,-,\cdot$, is worth \href{https://en.wikipedia.org/wiki/Modular_arithmetic}{module} $n$, then one needs only perform all operations module $n$ (a familiar form of this abstraction is \href{https://en.wikipedia.org/wiki/Casting_out_nines}{casting out nines}).

Abstractions, however, though not necessarily {\it exact}, should be {\it sound}. I.e., it should be possible to get sound answers from them -- even though the abstraction may simply yield a result of \href{https://en.wikipedia.org/wiki/Undecidable_problem}{undecidability}. E.g., students in a class may be abstracted by their minimal \& maximal ages; if one asks whenever a certain person belongs to that class, one may simply compare that person's age with the minimal \& maximal ages; if his age lies outside the range, one may safely answer that the person does not belong to the class; if it does not, one may only answer ``I don't know''.

The level of abstraction included in a programming language can influence its overall \href{https://en.wikipedia.org/wiki/Usability}{usability}. The \href{https://en.wikipedia.org/wiki/Cognitive_dimensions}{Cognitive dimensions} framework includes the concept of {\it abstraction gradient} in a formalism. This framework allows the designer of a programming language to study the trade-offs between abstraction \& other characteristics of the design, \& how changes in abstraction influence the language usability.

Abstractions can prove useful when dealing with computer programs, because nontrivial properties of computer programs are essentially \href{https://en.wikipedia.org/wiki/Undecidable_problem}{undecidable} (\href{https://en.wikipedia.org/wiki/Rice%27s_theorem}{Rice's theorem}). As a consequence, automatic methods for deriving information on the behavior of computer programs either have to drop termination (on some occasions, they may fail, crash or never yield out a result), soundness (they may provide false information), or precision (they may answer ``I don't know'' to some questions).

Abstraction is the core concept of \href{https://en.wikipedia.org/wiki/Abstract_interpretation}{abstract interpretation}. \href{https://en.wikipedia.org/wiki/Model_checking}{Model checking} generally takes place on abstract versions of the studied systems.

\subsubsection{Levels of abstraction}
Main article: \href{https://en.wikipedia.org/wiki/Abstraction_layer}{Wikipedia{\tt/}abstraction layer}. Computer science commonly presents {\it levels} (or, less commonly, {\it layers}) of abstraction, wherein each level represents a different model of the same information \& processes, but with varying amounts of detail. Each level uses a system of expression involving a unique set of objects \& compositions that apply only to a particular domain. Each relatively abstract, ``higher'' level builds on a relatively concrete, ``lower'' level, which tends to provide an increasingly ``granular'' representation. E.g., gates build on electronic circuits, binary on gates, machine language on binary, programming language on machine language, applications \& operating systems on programming languages. Each level is embodied, but not determined, by the level beneath it, making it a language of description that is somewhat self-contained.

\paragraph{Database systems.} Main article: \href{https://en.wikipedia.org/wiki/Database_management_system}{Wikipedia{\tt/}database management system}. {\sf Data abstraction levels of a database system}. Since many users of database systems lack in-depth familiarity with computer data-structures, database developers often hide complexity through the following levels"
\begin{itemize}
	\item {\bf Physical level.} The lowest level of abstraction describes {\it how} a system actually stores data. The physical level describes complex low-level data structures in detail.
	\item {\bf Logical level.} The next higher level of abstraction describes {\it what} data the database stores, \& what relationships exist among those data. The logical level thus describes an entire database in terms of a small number of relatively simple structures. Although implementation of the simple structures at the logical level may involve complex physical level structures, the user of the logical level does not need to be aware of this complexity. This is referred to as \href{https://en.wikipedia.org/wiki/Physical_data_independence}{physical data independence}. \href{https://en.wikipedia.org/wiki/Database_administrator}{Database administrators}, who must decide what information to keep in a database, use the logical level of abstraction.
	\item {\bf View level.} The highest level of abstraction describes only part of the entire database. Even though the logical level uses simpler structures, complexity remains because of the variety of information stored in a large database. Many users of a database system do not need all this information; instead, they need to access only a part of the database. The view level of abstraction exists to simplify their interaction with the system. The system may provide may \href{https://en.wikipedia.org/wiki/View_(database)}{views} for the same database.
\end{itemize}

\paragraph{Layered architecture.} Main article: \href{https://en.wikipedia.org/wiki/Abstraction_layer}{Abstraction layer}. The ability to provide a \href{https://en.wikipedia.org/wiki/Design}{design} of different levels of abstraction can
\begin{itemize}
	\item simplify the design considerably
	\item enable different role players to effectively work at various levels of abstraction
	\item support the portability of \href{https://en.wikipedia.org/wiki/Software_artifact}{software artifacts} (model-based ideally)
\end{itemize}
\href{https://en.wikipedia.org/wiki/Systems_design}{System designs} \& \href{https://en.wikipedia.org/wiki/Business_process_modeling}{business process design} can both use this. Some \href{https://en.wikipedia.org/wiki/Software_modeling}{design processes} specifically generate designs that contain various levels of abstraction.

Layered architecture partitions the concerns of the application into stacked groups (layers). It is a technique used in designing computer software, hardware, \& communications in which system or network components are isolated in layers so that changes can be made in 1 layer without affecting the others.'' -- \href{https://en.wikipedia.org/wiki/Abstraction_(computer_science)}{Wikipedia{\tt/}abstraction (computer science)}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}data structure}
{\sf A data structure known as a \href{https://en.wikipedia.org/wiki/Hash_table}{hash table}.} ``In computer science, a {\it data structure} is a \href{https://en.wikipedia.org/wiki/Data}{data} organization \& storage format that is usually chosen for \href{https://en.wikipedia.org/wiki/Efficiency}{efficient} \href{https://en.wikipedia.org/wiki/Data_access}{access} to data. More precisely, a data structure is a collection of data values, the relationships among them, \& the \href{https://en.wikipedia.org/wiki/Function_(computer_programming)}{functions} or \href{https://en.wikipedia.org/wiki/Operator_(computer_programming)}{operations} that can be applied to the data, i.e., it is an \href{https://en.wikipedia.org/wiki/Algebraic_structure}{algebraic structure} about \href{https://en.wikipedia.org/wiki/Data}{data}.

\subsubsection{Usage}
Data structures serve as the basis for \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data types} (ADT). The ADT defines the logical form of the data type. The data structure implements the physical form of the \href{https://en.wikipedia.org/wiki/Data_type}{data type}.

Different types of data structures are suited to different kinds of applications, \& some are highly specialized to specific tasks. E.g., \href{https://en.wikipedia.org/wiki/Relational_database}{relational databases} commonly use \href{https://en.wikipedia.org/wiki/B-tree}{B-tree} indexes for data retrieval, while \href{https://en.wikipedia.org/wiki/Compiler}{compiler} \href{https://en.wikipedia.org/wiki/Implementation}{implementations} usually use \href{https://en.wikipedia.org/wiki/Hash_table}{hash tables} to look up \href{https://en.wikipedia.org/wiki/Identifier_(computer_languages)}{identifiers}.

Data structures provide a means to manage large amounts of data efficiently for uses such as large \href{https://en.wikipedia.org/wiki/Database}{databases} \& internet indexing services. Usually, efficient data structures are key to designing efficient \href{https://en.wikipedia.org/wiki/Algorithm}{algorithms}. Some formal design methods \& \href{https://en.wikipedia.org/wiki/Programming_language}{programming language} emphasize data structures, rather than algorithms, as the key organizing factor in software design. Data structures can be used to organize the storage \& retrieval (thu hồi) of information stored in both \href{https://en.wikipedia.org/wiki/Main_memory}{main memory} \& \href{https://en.wikipedia.org/wiki/Computer_data_storage}{secondary memory}.

\subsubsection{Implementation}
Data structures can be implemented using a variety of programming languages \& techniques, but they all share the common goal of efficiently organizing \& storing data. Data structures are generally based on the ability of a \href{https://en.wikipedia.org/wiki/Computer}{computer} to fetch \& store data at any place in its memory, specified by a \href{https://en.wikipedia.org/wiki/Pointer_(computer_programming)}{pointer} -- a \href{https://en.wikipedia.org/wiki/Bit}{bit} \href{https://en.wikipedia.org/wiki/String_(computer_science)}{string}, representing a \href{https://en.wikipedia.org/wiki/Memory_address}{memory address}, that can be itself stored in memory \& manipulated by the program. Thus, the \href{https://en.wikipedia.org/wiki/Array_data_structure}{array} \& \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{record} data structures are based on computing the addresses of data items with \href{https://en.wikipedia.org/wiki/Arithmetic_operations}{arithmetic operations}, while the \href{https://en.wikipedia.org/wiki/Linked_data_structure}{linked data structures} are based on storing addresses of data items within the structure itself. This approach to data structuring has profound implications for the efficiency \& scalability of algorithms. E.g., the contiguous memory allocation in arrays facilitates rapid access \& modification operations, leading to optimized performance in sequential data processing scenarios.

The implementation of a data structure usually requires writing a set of \href{https://en.wikipedia.org/wiki/Subroutine}{procedures} that create \& manipulate instances of that structure. The efficiency of a data structure cannot ne analyzed separately from those operations. This observation motivates the theoretical concept of an \href{https://en.wikipedia.org/wiki/Abstract_data_type}{abstract data type}, a data structure that is defined indirectly by the operations that may be performed on it, \& the mathematical properties of those operations (including their space \& time cost).

\subsubsection{Examples}
{\sf The standard \href{https://en.wikipedia.org/wiki/Data_type}{type} hierarchy of the programming language \href{https://en.wikipedia.org/wiki/Python_(programming_language)}{Python 3}.} Main article: \href{https://en.wikipedia.org/wiki/List_of_data_structures}{Wikipedia{\tt/}list of data structures}. There are numerous types of data structures, generally built upon simpler \href{https://en.wikipedia.org/wiki/Primitive_data_type}{primitive data types}. Well known examples are:
\begin{itemize}
	\item An \href{https://en.wikipedia.org/wiki/Array_(data_structure)}{array} is a number of elements in a specific order, typically all of the same type (depending on the language, individual elements may either all be forced to be the same type, or may be of almost any type). Elements are accessed using an integer index to specify which element is required. Typical implementations allocate contiguous memory words for the elements of arrays (but this is not always a necessity). Arrays may be fixed-length or resizable.
	\item A \href{https://en.wikipedia.org/wiki/Linked_list}{linked list} (also just called {\it list}) is a linear collection of data elements of any type, called {\it nodes}, where each node has itself a value, \& points to the next node in the linked list. The principal advantage of a linked list over an array is that values can always be efficiently inserted \& removed without relocating the rest of the list. Certain other operations, e.g. \href{https://en.wikipedia.org/wiki/Random_access}{random access} to a certain element, are however slower on lists than on arrays.
	\item A \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{record} (also called {\it tuple} or {\it struct}) is an \href{https://en.wikipedia.org/wiki/Aggregate_data}{aggregate data} structure. A record is a value that contains other values, typically in fixed number \& sequence \& typically indexed by names. The elements of records are usually called {\it fields} or {\it members}. In the context of OOP, records are known as \href{https://en.wikipedia.org/wiki/Plain_old_data_structure}{plain old data structures} to distinguish them from objects.
	\item \href{https://en.wikipedia.org/wiki/Hash_table}{Hash tables}, also known as hash maps, are data structures that provide fast retrieval of values based on keys. They use a hashing function to map keys to indexes in an array, allowing for constant-time access in the average case. Hash tables are commonly used in dictionaries, caches, \& database indexing. However, hash collisions can occur, which can impact their performance. Techniques like chaining \& open addressing are employed to handle collisions.
	\item \href{https://en.wikipedia.org/wiki/Graph_(abstract_data_type)}{Graphs} are collections of nodes connected by edges, representing relationships between entities. Graphs can be used to model social networks, computer networks, \& transportation networks, among other things. They consist of vertices (nodes) \& edges (connections between nodes). Graphs can be directed or undirected, \& they can have cycles or be acylic. Graph traversal algorithms include breadth-1st search \& depth-1st search.
	\item \href{https://en.wikipedia.org/wiki/Stack_(abstract_data_type)}{Stacks} \& \href{https://en.wikipedia.org/wiki/Queue_(abstract_data_type)}{queues} are abstract data types that can be implemented using arrays or linked lists. A stack has 2 primary operations: push (adds an element to the top of the stack) \& pop (removes the topmost element from the stack), that follow the Last In, First Out (LIFO) principle. Queues have 2 main operations: enqueue (adds an element to the rear of the queue) \& dequeue (removes an element from the front of the queue) that follow the First In, First Out (FIFO) principle.
	\item \href{https://en.wikipedia.org/wiki/Tree_(data_structure)}{Trees} represents a hierarchical organization of elements. A tree consists of nodes connected by edges, with 1 node being the root \& all other nodes forming subtrees. Trees are widely used in various algorithms \& data storage scenarios. \href{https://en.wikipedia.org/wiki/Binary_tree}{Binary trees} (particularly \href{https://en.wikipedia.org/wiki/Heap_(data_structure)}{heaps}), \href{https://en.wikipedia.org/wiki/AVL_tree}{AVL trees}, \& \href{https://en.wikipedia.org/wiki/B-tree}{B-trees} are some popular types of trees. They enable efficient \& optimal searching, sorting, \& hierarchical representation of data.
\end{itemize}
A \href{https://en.wikipedia.org/wiki/Trie}{trie}, or prefix tree, is a special type of tree used to efficiently retrieve strings. In a trie, each node represents a character of a string, \& the edges between nodes represent the characters that connect them. This structure is especially useful for tasks like autocomplete, spell-checking, \& creating dictionaries. Tries allow for quick searches \& operations based on string prefixes.

\subsubsection{Language support}
Most \href{https://en.wikipedia.org/wiki/Assembly_language}{assembly languages} \& some \href{https://en.wikipedia.org/wiki/Low-level_programming_language}{low-level languages}, such as \href{https://en.wikipedia.org/wiki/BCPL}{BCPL} (Basic Combined Programming Language), lack built-in support for data structures. On the other hand, many \href{https://en.wikipedia.org/wiki/High-level_programming_language}{high-level programming languages} \& some higher-level assembly languages, e.g. \href{https://en.wikipedia.org/wiki/MASM}{MASM}, have special syntax or other built-in support for certain data structures, e.g. records \& arrays. E.g., the \href{https://en.wikipedia.org/wiki/C_(programming_language)}{C} (a direct descendant of BCPL) \& \href{https://en.wikipedia.org/wiki/Pascal_(programming_language)}{Pascal} languages support \href{https://en.wikipedia.org/wiki/Record_(computer_science)}{structs} \& records, respectively, in addition to vectors (1D \href{https://en.wikipedia.org/wiki/Array_data_type}{arrays}) \& multi-dimensional arrays.

Most programming languages feature some sort of \href{https://en.wikipedia.org/wiki/Library_(computing)}{library} mechanism that allows data structure implementations to be reused by different programs. Modern languages usually come with standard libraries that implement the most common data structures. E.g., \href{https://en.wikipedia.org/wiki/Standard_Template_Library}{C++ Standard Template Library}, \href{https://en.wikipedia.org/wiki/Java_Collections_Framework}{Java Collections Framework}, \& \href{https://en.wikipedia.org/wiki/Microsoft}{Microsoft} \href{https://en.wikipedia.org/wiki/.NET_Framework}{.NET Framework}.

Modern languages also generally support \href{https://en.wikipedia.org/wiki/Modular_programming}{modular programming}, the separation between the \href{https://en.wikipedia.org/wiki/Interface_(computing)}{interface} of a library module \& its implementation. Some provide \href{https://en.wikipedia.org/wiki/Opaque_data_type}{apaque data types} that allow clients to hide implementation details. \href{https://en.wikipedia.org/wiki/Object-oriented_programming_language}{OOP languages}, e.g. C++, Java, \& \href{https://en.wikipedia.org/wiki/Smalltalk}{Smalltalk}, typically use \href{https://en.wikipedia.org/wiki/Classes_(computer_science)}{classes} for this purpose.

Many known data structures have \href{https://en.wikipedia.org/wiki/Concurrent_data_structure}{concurrent} versions which allow multiple computing threads to access a single concrete instance of a data structure simultaneously.'' -- \href{https://en.wikipedia.org/wiki/Data_structure}{Wikipedia{\tt/}data structure}

%------------------------------------------------------------------------------%

\subsection{Wikipedia{\tt/}level set (data structures)}
``In computer science, a \href{https://en.wikipedia.org/wiki/Level_set}{level set} \href{https://en.wikipedia.org/wiki/Data_structure}{data structure} is designed to represent discretely \href{https://en.wikipedia.org/wiki/Sampling_(statistics)}{sampled} dynamic level sets functions. A common use of this form of data structure is in efficient image \href{https://en.wikipedia.org/wiki/Rendering_(computer_graphics)}{rendering}. The underlying method constructs a \href{https://en.wikipedia.org/wiki/Distance_transform}{signed distance field} that extends the boundary, \& can be used to solve the motion of the boundary in this field.

\subsubsection{Chronological developments}
The powerful \href{https://en.wikipedia.org/wiki/Level-set_method}{level-set method} is due to \href{https://en.wikipedia.org/wiki/Stanley_Osher}{\sc Osher} \& \href{https://en.wikipedia.org/wiki/James_Sethian}{\sc Sethian} 1988. However, the straightforward implementation via a dense $d$-dimensional \href{https://en.wikipedia.org/wiki/Array_data_structure}{array} of values, results in both time \& storage complexity of $O(n^d)$, where $n$ is the cross sectional resolution of the spatial extents of the domain \& $d$ is the number of spatial dimensions of the domain.
\begin{enumerate}
	\item {\bf Narrow band.} The narrow band level set method, introduced in 1995 by {\sc Adalsteinsson \& Sethian}, restricted most computations to a thin band of active \href{https://en.wikipedia.org/wiki/Voxel}{voxels} immediately surrounding the interface, thus reducing the time complexity in 3D to $O(n^2)$ for most operations. Periodic updates of the narrowband structure, to rebuild the list of active voxels, were required which entailed an $O(n^3)$ operation in which voxels over the entire volume were accessed. The storage complexity for this narrowband scheme was still $O(n^3)$. Differential constructions over the narrow band domain edge require careful interpolation \& domain alternation schemes to stabilize the solution.
	\item {\bf Sparse field.} This $O(n^3)$ time complexity was eliminated in the approximate ``sparse field'' level set method introduced by {\sc Whitaker} in 1998. The sparse field level set method employs a set of linked list to track the active voxels around the interface. This allows incremental extension of the active region as needed without incurring any significant overhead. While consistently $O(n^2)$ efficient in time, $O(n^3)$ storage space is still required by the sparse field level set method.
	\item {\bf Sparse block grid.} The sparse block grid method, introduced by {\sc Bridson} in 2003, divides the entire \href{https://en.wikipedia.org/wiki/Bounding_volume}{bounding volume} of size $n^3$ into small cubic blocks of $m^3$ voxels each. A coarse grid of size $\left(\frac{n}{m}\right)^3$ then stores pointers only to those blocks that intersect that narrow band of the level set. Block allocation \& deallocation occur as the surface propagates to accommodate to the deformations. This method has a suboptimal storage complexity of $O(\left(\frac{n}{m}\right)^3 + m^3n^2)$, but retains the constant time access inherent to dense grids.
	\item {\bf Octree.} The \href{https://en.wikipedia.org/wiki/Octree}{octree} level set method, introduced by {\sc Strain} in 1999 \& refined by {\sc Losasso, Gibu, \& Fedkiw}, \& more recently by {\sc Min \& Gibou} uses a tree of nested cubes of which the leaf nodes contain signed distance values. Octree level sets currently require uniform refinement along the interface (i.e., the narrow band) in order to obtain sufficient precision. This representation is efficient in terms of storage, $O(n^2)$, \& relatively efficient in terms of access queries, $O(\log n)$. A advantage of the level method on octree data structures is that one can solve the PDEs associated with typical free boundary problems that use the level set method. The CASL research group has developed this line of work in computational materials, CFD, electrokinetics, image guided surgery \& controls.
	\item {\bf Run-length encoded.} The \href{https://en.wikipedia.org/wiki/Run-length_encoding}{run-length encoding} (RLE) level set method, introduced in 2004, applies the RLE scheme to compress regions away from the narrow band to just their sign representation while storing with full precision the narrow band. The sequential traversal of the narrow band is optimal \& storage efficiency is further improved over the octree level set. The additional of an acceleration lookup table allows for fast $O(\log r)$ random access, where $r$ is the number of runs per cross section. Additional efficiency is gained by applying the RLE scheme in a dimensional recursive fashion, a technique introduced by {\sc Nielsen \& Museth}'s similar DT-Grid.
	\item {\bf Hash Table Local Level Set.} The Hash Table Local Level Set method, introduced in 2011 by {\sc Eyiyurekli \& Breen} \& extended in 2012 by {\sc Brun, Guittet, \& Gibou}, only computes the level set data in a band around the interface, as in the Narrow Band Level-Set Method, but also only stores the data in that same band. A hash table data structure is used, which provides an $O(1)$ access to the data. However, {\sc Brun} et al. conclude that their method, while being easier to implement, performs worse than a quadtree implementation. They find that
	\begin{quote}
		as it is, [$\ldots$] a quadtree data structure seems more adapted than the hash table data structure for level-set algorithms.
	\end{quote}
	3 main reasons for worse efficiency are listed:
	\begin{enumerate}
		\item to obtain accurate results, a rather large band is required close to the interface, which counterbalances the absence of grid nodes far from the interface;
		\item the performances are deteriorated by extrapolation procedures on the outer edges of the local grid \&
		\item the width of the band restricts the time step \& slows down the method.
		\item {\bf Point-based.} {\sc Corbett} in 2005 introduced the point-based level set method. Instead of using a uniform sampling of the level set, the continuous level set function is reconstructed from a set of unorganized point samples via \href{https://en.wikipedia.org/wiki/Moving_least_squares}{moving least squares}.'' -- \href{https://en.wikipedia.org/wiki/Level_set_(data_structures)}{Wikipedia{\tt/}level set (data structures)}
	\end{enumerate}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Linux}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Shotts2019}. {\sc William Shotts}. {\it The Linux Command Line: A Complete Introduction}.
\end{enumerate}
I used SUSE \& OpenSUSE in WIAS Berlin but I do not like them \& the like, so I go back to Ubuntu.

%------------------------------------------------------------------------------%

\section{Programming}

\subsection{C{\tt/}C++}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Ngoc_C}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình C}.
	\item \cite{Ngoc_C++}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình C++}.
	\item \cite{Stroustrup2013}. {\sc Bjarne Stroustrup}. {\it The C++ Programming Language}.
	\item \cite{Stroustrup2018}. {\sc Bjarne Stroustrup}. {\it A Tour of C++}.
\end{enumerate}

\subsection{Pascal}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Ngoc_Pascal}. {\sc Quách Tuấn Ngọc}. {\it Ngôn Ngữ Lập Trình Pascal}.
	\item \cite{Ngoc_BT_Pascal}. {\sc Quách Tuấn Ngọc}. {\it Bài Tập Ngôn Ngữ Lập Trình Pascal}.
	\item \cite{Doanh_Tuan_Pascal}. {\sc Lê Văn Doanh, Trần Khắc Tuấn}. {\it101 Thuật Toán \& Chương Trình Bài Toán Khoa Học Kỹ Thuật \& Kinh Tế Bằng Ngôn Ngữ Turbo-Pascal}.
\end{enumerate}

\subsection{Python}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Duc_200_BT_Python}. {\sc Nguyễn Tiến Đức}. {\it Tuyển Tập 200 Bài Tập Lập Trình Bằng Ngôn Ngữ Python}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_1}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 1}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_2}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 2}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_3}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 3}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_4}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 4}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_5}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 5}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_6}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 6}.
	\item \cite{Huy_sang_tao_thuat_toan_lap_trinh_tap_7}. {\sc Nguyễn Xuân Huy}. {\it Sáng Tạo Trong Thuật Toán \& Lập Trình. Tập 7}.
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Software}

\subsection{FeNiCS}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Dokken_Mitusch_Funke2020}. {\sc J\o rgen S. Dokken}. {\it Automatic shape derivatives for transient PDEs in FEniCS \& Firedrake}.
	\item \cite{Langtangen_Logg2016}. {\sc Hans Petter Langtangen, Anders Logg}. {\it Solving PDEs in Python}.
\end{enumerate}

\subsection{Firedrake}

\subsection{Fireshape}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Paganini_Wechsung_Fireshape2020}. {\sc Alberto Paganini, Florian Wechsung}. {\it Fireshape Documentation, Release 0.0.1}.
	\item \cite{Paganini_Wechsung2020}. {\sc Alberto Paganini, Florian Wechsung}. {\it Fireshape: a shape optimization toolbox for Firedrake}.
\end{enumerate}

\subsection{Git}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Chacon_Straub2014}. {\sc Scott Chacon, Ben Straub}. {\it Pro Git}.
\end{enumerate}

\subsection{Gmsh}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Geuzaine_Remacle2009}. {\sc Christophe Geuzaine, Jean-Fran\c{c}ois Remacle}. {\it Gmsh: A 3D finite element mesh generator with built-in pre- \& post-processing facilities}.
\end{enumerate}

\subsection{OpenFOAM}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item There are 3 variants of OpenFOAM:
	\begin{enumerate}
		\item OpenFOAM.com: Commercial.
		\item OpenFOAM.org: Open-source with a large community.
		\item Extended OpenFOAM.
	\end{enumerate}
	\item \cite{Greenshields_Weller2022}. {\sc Christopher Greenshields, Henry Weller}. {\it Notes on Computational Fluid Dynamics: General Principles}.
	\item \cite{Towara_Naumann2013}. {\sc M. Towara, U. Naumann}. {\it A Discrete Adjoint Model for OpenFOAM}.
\end{enumerate}

\subsection{ParMooN}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{ParMooN2017}. {\sc Ulrich Wilbrandt, Clemens Bartsch, Naveed Ahmed, Volker John}. {\it ParMooN -- a modernized program package based on mapped finite elements}.
\end{enumerate}

\subsection{SU2}

\subsection{Sublime Text}
\textbf{\textsf{Resources -- Tài nguyên.}}
\begin{enumerate}
	\item \cite{Bos2014}. {\sc Wes Bos}. {\it Sublime Text Power User: A Complete Guide}.
	\item \cite{Peleg2014}. {\sc Dan Peleg}. {\it Mastering Sublime Text}
\end{enumerate}

%------------------------------------------------------------------------------%

\section{Miscellaneous}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}